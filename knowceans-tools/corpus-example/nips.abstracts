How does the connectivity of a neural network (number of synapses per  neuron) relate to the complexity of the problems it can handle (measured by  the entropy)? Switching theory would suggest no relation at all, since all Boolean  functions can be implemented using a circuit with very low connectivity (e.g.,  using two-input NAND gates). However, for a network that learns a problem  from examples using a local learning rule, we prove that the entropy of the  problem becomes a lower bound for the connectivity of the network.
We describe a family of learning algorithms that operate on a recurrent, symmetrically  connected, neuromorphic network that, like the Boltzmann machine, settles in the  presence of noise. These networks learn by modifying synaptic connection strengths on  the basis of correlations seen locally by each synapse. We describe a version of the  supervised learning algorilhm for a network with analog activation functions. We also  demonstrate unsupervised competitive learning with this approach, where weight  saturation and decay play an important role, and describe preliminary experiments in  reinforcement !earning, where noise is used in the search procedure. We identify the  above described phenomena as elements that can unify learning techniques at a physical  microscopic level.  These algorilhms were chosen for ease of implementation in vlsi. We have designed a  CMOS test chip in 2 micron rules that can speed up the learning about a millionfold  over an equivalent simulation on a VAX 11/780. The speedup is due to parallel analog  computation for summing and multiplying weights and activations, and the use of  physical processes for generating random noise. The components of the test chip are a  noise amplifier, a neuron amplifier, and a 300 transistor adaptive synapse, each of which  is separately testable. These components are also integrated into a 6 neuron and 15  synapse network. Finally, we point out techniques for reducing the area of the  electronic correlational synapse both in technology and design and show how the  algorithm. we study can be implemented naturally in electronic systems.
This paper generalizes the backpropagation method to a general network containing feedback connections. The network model considered consists of interconnected groups of neurons,  where each group could be fully interconnected (it could have feedback connections, with possibly asymmetric weights), but no loops between the groups are allowed. A stochastic descent  algorithm is applied, under a certain inequality constraint on each intra-group weight matrix  which ensures for the network to possess a unique equilibrium state for every input.
An artificial neural network is developed to recognize spatioqemporal  bipolar patterns associatively. The function of a formal neuron is generalized by  replacing multiplication with convolution, weights with transfer functions, and  thresholding with nonlinear transform following adaptation. The Hebbian learning rule and the delta learning rule are generalized accordingly, resulting in the  learning of weights and delays. The neural network which was first developed  for spatial patterns was thus generalized for spario-temporal patterns. It was  tested using a set of bipolar input patterns derived from speech signals, showing  robust classification of 30 model phonemes.
The complexity and computational capacity of multi-layered, feedforward  neural networks is examined. Neural networks for special purpose (structured)  functions are examined from the perspective of circuit complexity. Known results in complexity theory are applied to the special instance of neural network  circuits, and in particular, classes of functions that can be implemented in  shallow circuits characterised. Some conclusions are also drawn about learning  complexity, and some open problems raised. The dual problem of determining  the computational capacity of a class of multi-layered networks with dynamics  regulated by an algebraic Hamiltoninn is considered. Formal results are presented on the storage capacities of programmed higher-order structures, and  a tradeoff between ease of programming and capacity is shown. A precise determination is made of the static fixed point structure of random higher-order  constructs, and phase-transitions (0-1 laws) are shown.
We propose that the back propagation algorithm for supervised learning can be generalized, put on a satisfactory conceptual  footing, and very likely made more efficient by defining the values of the output and input neurons as probabilities and varying  the synaptic weights in the gradient direction of the log likelihood,  rather than the 'error'. 
In the visual cortex of the monkey the horizontal organization of the preferred  orientations of orientation-selective cells follows two opposing rules: 1) neighbors tend  to have similar orientation preferences, and 2) many different orientations are observed  in a local region. Several orientation models which satisfy these constraints are found  to differ in the spacing and the topological index of their singularities. Using the rate  of orientation change as a measure, the models are compared to published experimental  results.
We investigate the behavior of different learning algorithms  for networks of neuron-like units. As test cases we use simple pattern association problems, such as the XOR-problem and symmetry detection problems. The algorithms considered are either versions of  the Boltzmann machine learning rule or based on the backpropagation  of errors. We also propose and analyze a generalized delta rule for  linear threshold units. We find that the performance of a given  learning algorithm depends strongly on the type of units used. In  particular, we observe that networks with ñ1 units quite generally  exhibit a significantly better learning behavior than the corresponding 0,1 versions. We also demonstrate that an adaption of the  weight-structure to the symmetries of the problem can lead to a  drastic increase in learning speed.
A computer model of the hippocampal pyramidal cell (HPC) is described  which integrates data from a variety of sources in order to develop a consistent description for this cell type. The model presently includes descriptions of eleven non-linear somatic currents of the HPC, and the electrotonic  structure of the neuron is modelled with a soma/short-cable approximation.  Model simulations qualitatively or quantitatively reproduce a wide range of  somatic electrical behavior ii HPCs, and demonstrate possible roles for the  various currents in information processing.
Being able to record the electrical activities of a number of neurons simultaneously is likely  to be important in the study of the functional organization of networks of real neurons. Using  one extracellular microelectrode to record from several neurons is one approach to studying  the response properties of sets of adjacent and therefore likely related neurons. However, to  do this, it is necessary to correctly classify the signals generated by these different neurons.  This paper considers this problem of classifying the signals in such an extracellular recording,  based upon their shapes, and specifically considers the classification of signals in the case when  spikes overlap temporally.
Much experimental study of real neural networks relies on the proper classification of  extracellulary sampled neural signals (i.e. action potentials) recorded from the brains of experimental animals. In most neurophysiology laboratories this classification task is simplified  by limiting investigations to single, electrically well-isolated neurons recorded one at a time.  However, for those interested in sampling the activities of many single neurons simultaneously,  waveform classification becomes a serious concern. In this paper we describe and constrast  three approaches to this problem each designed not only to recognize isolated neural events,  but also to separately classify temporally overlapping events in real time. First we present two  formulations of waveform classification using a neural network template matching approach.  These two formulations are then compared to a simple template matching implementation.  Analysis with real neural signals reveals that simple template matching is a better solution to  this problem than either neural network approach.
Based on anatomical and physiological data, we have developed a computer simulation of piriform (olfactory) cortex which is capable of reproducing spatial and temporal patterns of actual  cortical activity under a variety of conditions. Using a simple Hebb-type learning rule in conjunction with the cortical dynamics which emerge from the anatomical and physiological organization of the model, the simulations are capable of establishing cortical representations for different input patterns. The basis of these representations lies in the interaction of sparsely distributed, highly divergent/convergent interconnections between modeled neurons. We have shown that  different representations can be stored with minimal interference, and that following learning  these representations are resistant to input degradation, allowing reconstruction of a representation following only a partial presentation of an original training stimulus. Further, we have  demonstrated that the degree of overlap of cortical representations for different stimuli can  also be modulated. For instance similar input patterns can be induced to generate distinct cortical  representations (discrimination), while dissimilar inputs can be induced to generate overlapping  representations (accommodation). Both features are presumably important in classifying olfactory stimuli.
The SIMD parallelism of the Connection Machine (CM) allows the construction of  neural network simulations by the use of simple data and control structures. Two  approaches are described which allow parallel computation of a model's nonlinear  functions, parallel modification of a model's weights, and parallel propagation of a  model's activation and error. Each approach also allows a model's interconnect  structure to be physically dynamic. A Hopfield model is implemented with each  approach at six sizes over the same number of CM processors to provide a performance  comparison.
This paper deals with a neural network model in which each neuron  performs a threshold logic function. An important property of the model  is that it always converges to a stable state when operating in a serial  mode [2,5]. This property is the basis of the potential applications of the  model such as associative memory devices and combinatorial optimization  [3,6].  One of the motivations for use of the model for solving hard combinatorial  problems is the fact that it can be implemented by optical devices and  thus operate at a higher speed than conventional electronics.  The main theme in this work is to investigate the power of the model for  solving NP-hard problems [4,8], and to understand the relation between  speed of operation and the size of a neural network. In particular, it will  be shown that for any NP-hard problem the existence of a polynomial  size network that solves it implies that NP=co-NP. Also, for Traveling  Salesman Problem (TSP), even a polynomial size network that gets an  e-approximate solution does not exist unless P=NP.  The above results are of great practical interest, because right now it is  possible to build neural networks which will operate fast but are limited  in the number of neurons.
Artificial neural networks (ANNs) are capable of accurate recognition of  simple speech vocabularies such as isolated digits [1]. This paper looks at two  more difficult vocabularies, the alphabetic E-set and a set of polysyllabic  words. The E-set is difficult because it contains weak discriminants and  polysyllables are difficult because of timing variation. Polysyllabic word  recognition is aided by a time pre-alignment technique based on dynamic programming and E-set recognition is improved by focusing attention. Recognition accuracies are better than 98% for both vocabularies when implemented  with a single layer perceptron.
The potential for presynaptic information processing within the arbor  of a single axon will be discussed in this paper. Current knowledge about  the activity dependence of the firing threshold, the conditions required for  conduction failure, and the similarity of nodes along a single axon will be  reviewed. An electronic circuit model for a site of low conduction safety in  an axon will be presented. In response to single frequency stimulation the  electronic circuit acts as a lowpass filter.
In this paper, we wish to analyze the convergence behavior of a number  of neuronal plasticity models. Recent neurophysiological research suggests that  the neuronal behavior is adaptive. In particular, memory stored within a neuron  is associated with the synaptic weights which are varied or adjusted to achieve  learning. A number of adaptive neuronal models have been proposed in the  literature. Three specific models will be analyzed in this paper, specifically the  Hebb model, the Sutton-Barto model, and the mot recent trace model. In this  paper we will examine the conditions for convergence, the position of convergence and the rate at convergence, of these models as they applied to classical  conditioning. Simulation results are also presented to verify the analysis.
The new neural network classifier we propose transforms the  classification problem into the coding theory problem of decoding a noisy  codeword. An input vector in the feature space is transformed into an internal  representation which is a codeword in the code space, and then error correction  decoded in this space to classify the input feature vector to its class. Two classes  of codes which give high performance are the Hadamard matrix code and the  maximal length sequence code. We show that the number of classes stored in an  N-neuron system is linear in N and significantly more than that obtainable by  using the Hopfield type memory as a classifier.
The capacity of an associative memory is defined as the maximum  ntuzber of words that can be stored and retrieved reliably by an address  within a given sphere of attraction. It is shown by sphere packing  ar%uents that as the address length increases, the capacity of any  associative memory is limited to an exponential growth rate of 1 where h2() is the binary entropy function in bits, and  is the radius  of the sphere of attraction. This exponential growth in capacity can  actually be achieved by the Kanerva associative memory, if its  parameters are optimally set. Formulas for these optimal values are  provided. The exponential growth in capacity for the Kanerva  associative memory contrasts sharply with the sub-linear growth in  capacity for the Hopfield associative memory.  ASSOCIATIVE MEMORY AND ITS CAPACITY  Our model of an associative memory is the following. Let (X,Y) be  an (address, datum) pair, where X is a vector of n ls and Y is a  vector of rn ls, and let (XO),YO)),...,(x(M),y(M)), be M (address,  datum) pairs stored in an associative memory. If the associative memory  is presented at the input with an address X that is close to some  stored address X (j), then it should produce at the output a word Y that  is close to the corresponding contents Y(J). To be specific, let us say  that an associative memory can corctfraction  errors if an X within  Hamming distance n6 of X (3) retrieves Y equal to yO). The Hmming  sphere around each X (3) will be called the sphere of attraction, and   will be called the radius of attraction.  One notion of the capacity of this associative memory is the  maximum number of words that it can store while correcting fraction   errors. Unfortunately, this notion of capacity is ill-defined, because  it depends on exactly which (address, datum) pairs have been stored.  Clearly, no associative memory can correct fraction  errors for ½ucry  sequence of stored (address, datum) pairs. Consider, for example, a  sequence in which several different words are written to the sme  address. No memory can reliably retrieve the contents of the  overwritten words. At the other extreme, any associative memory'can  store an unlimited number of words and retrieve them all reliably, if  their contents are identical.  A useful definition of capacity must lie somewhere between these  two extremes. In this paper, we are interested in the largest M such  that for most sequences of addresses X(1),...,X (M) and most sequences of  data y(X)...y(M), the memory can correct fraction  errors. We define  This work was supported by the National Science Foundation under NSF  grant IST-8S0980 and by an IBM Doctoral Fellowship.  ¸ American Institute of Physics 1988  185  'most sequences' in a probabilistic sense, as some set of sequences with  total probability greater than say, .99. When all sequences are  equiprobable, this reduces to the deterministic version: 99 of all  sequences.  In practice it is too difficult to compute the capacity of a given  associative memory with inputs of length n and outputs of length n.  Fortunately, though, it is easier to compute the asymptotic rate at  which M increases, as n and rn increase, for a given family of  associative memories. This is the approach taken by McEliece et al.  towards the capacity of the Hopfield associative memory. We take the  same approach towards the capacity of the Kanerva associative memory,  and towards the capacities of associative memories in general. In the  next section we provide an upper bound on the rate of growth of the  capacity of any associative memory fitting our general model. It is  shown by sphere packing arguments that capacity is limited to an  exponential rate of growth of 1h2(), where h2(5) is the binary entropy  function in bits, and  is the radius of attraction. In a later section  it will turn out that this exponential growth in capacity can actually  be achieved by the Kanerva associative memory, if its parameters are  optimally set. This exponential growth in capacity for the Kanerva  associative memory contrasts sharply with the sub-linear growth in  capacity for the Hopfield associative memory  A UNIVERSAL UPPER BOUND ON CAPACITY  Recall that our definition of the capacity of an associative memory  is the largest M such that for most sequences of addresses  .¾(1),...,x(M) and most sequences of data Y(x),...,Y(M), The memory can  correct fraction  errors. Clearly, an upper bound to this capacity is  the largest M for which there exists some sequence of addresses  X (1),... ,X © such that for most sequences of data Y(1),... ,Y(M), the  memory can correct fraction  errors. We now derive an expression for  this upper bound.  Let  be the radius of attraction and let DH(X(J),d) be the sphere  of attraction, i.½., the set of all Xs at most Hamming distance d = [nJ  from .¾(J). Since by assumption the memory corrects fraction  errors,  every address =¾ 6 DH(X(3),d) retrieves the word y(3). The size of  DH(X(),d) is easily shown to be independent of X(j) and equal to  out of a total of 2  n-bit addresses, at least ,d addresses retrieve  Y(), at least ,d addresses retrieve Y(2), at least w,d addresses  retrieve y(3), and so forth. It follows that the total number of  distinct Y(3)s can be at most 2"/,d. Now, from Stirling's formula it  can be shown that if d _ n/2, then w. = 2 h2(d/)+O(1ø$) , where  h2(5) =-51og25-(1-)1og2(1-6) is the binary entropy function in bits,  and 69(logn) is some function whose magnitude grows more slowly than a  constant times log n. Thus the total number of distinct Y()s can be at  most 2 n(-:(5))+O(1øg) . Since any set containing 'most sequences' of M  m-bit words will contain a large number of distinct words (if rn is  186  1 2 --n  Figure 1: Neural net representation of the Kanerva associative memory. Signals propagate from the bottom (input) to the top (output). Each arc multiphes the signal by its  weight; each node adds the incoming signals and then thresholds.  sufficiently large --see [2] for details), it follows that  M _< 2 n(1-h(6))+O(løgn). (1)  In general a function f(n) is said to be O(g(n)) if f(n)/g(n) is  bounded, i.e., if there exists a constant a such tha; If(n)[ < aig(n)[ for  all n. Thus (1) says that there exists a constant a such that  M < 2 n(1-h2(5))+aløg'. It should be emphasized that since ct is unknown,  this bound has no meaning for fixed n. However, it indicates that  asymptotically in n, the maximum exponential rate of growth of M is  Intuitively, only a sequence of addresses XO),...,X © that  optimally pack the address space {-1,+1} ' can hope to achieve this  upper bound. Remarkably, most such sequences are optimal in this sense,  when n is large. The Kanerva associative memory can take advantage of  this fact.  THE KANERVA ASSOCIATIVE MEMORY  The Kanerva associative memory [3,4] can be regarded as a two-layer  neural network, as shown in Figure 1, where the first layer is a  preprocessor and the second layer is the usual Hopfield style array.  The preprocessor essentially encodes each n-bit input address into a  very large k-bit internal representation, k>>n, whose size will be  permitted to grow exponentially in n. It does not seem surprising,  then, that the capacity of the Kanerva associative memory can grow  exponentially in n, for it is known that the capacity of the Hopfield  array grows almost linearly in k, assuming the coordinates of the  k-vector are drawn at random by independent flips of a fair coin  187  1 k  w  ß o  z  Figure 2: Matrix representation of the Kanerva associative memory. Signals propagate  from the right (input) to the left (output). Dimensions are shown in the box corners.  Circles stand for functional composition; dots stand for matrix multiplication.  In this situation, however, such an assumption is ridiculous: Since the  k-bit internal representation is a function of the m-bit input address,  it can contain at most m bits of information, whereas independent flips  of a fair coin contain k bits of information. Kanerva's primary  contribution is therefore the specification of the preprocessor, that  is, the specification of how to map each m-bit input address into a very  large k-bit internal representation.  The operation of the preprocessor is easily described. Consider  the matrix representation shown in Figure 2. The matrix Z is randomly  populated with ls. This randomness assumption is required to ease the  analysis. The function fr is 1 in the ith coordinate if the ith row of  Z is within Hamming distance r of X, and is 0 otherwise. This is  accomplished by thresholding the ith input against m 2r. The  parameters r and k are two essential parameters in the Kanerva  associative memoryß If r and k are set correctly, then the number of is  in the representation (ZX) will be very small in comparison to the  number of Os. Hence (ZX) can be considered to be a sparse internal  representation of X.  The second stage of the memory operates in the usual way, except on  the internal representation of X. That is, Y = g(Wfr(ZX)), where  M  W = Y(J)[fr(ZX(J))] t, (2)  j=l  and g ñs the threshold function whose ith coordinate is +1 if the  input is greater than 0 and -1 is the ith input is less than 0. The ith  column of W can be regarded as a memory location whose address is the  ith row of Z. Every X within Hamming distance r of the ith row of Z  accesses this locationß Hence r is known as the access radius, and k is  the number of memory cations.  The approach taken in this paper is to fix the linear rate p at  which r grows with n, and to fix the exponential rate  at which k grows  with m. It turns out that the capacity then grows at a fixed  exponential rate Cp,(6), depending on p, , and 6. These exponential  rates are sufficient to overcome the standard loose but simple  polynomial bounds on the errors due to combinatorial approximations.  188  THE CAPACITY OF THE KANERVA ASSOCIATIVE MEMORY  Fix OS 1, OpS 1/2, and 0S5 J mJn{2p, 1/2}. Let n be the  input address length, and let m be the output word length. It is  assumed that m is at most polynomial in n, i.e., m = exp{O(logn)}. Let  r = [pn] be the access radius, let k = 2 [n] be the number of memory  locations, and let d = [Sn] be the radius of attraction. Let Mn be the  number of stored words. The components of the n-vectors J(1),...,x(M"),  ... y(%4,), and the k x n matrix Z are assumed to be  the m-vectors y(1), ,  IID equiprobable 1 random variables. Finally, given an n-vector X,  let Y = 9(Wf.(ZX)) where W M .  Define the quantity  c.,(5) = { 25 + 2(15)n(.;_- ) + 2n(p) if  <_ o(p)  c,o()(5) if  > o(p) '  ()  where  and  o(p) = 2n(p) 2 2(1 )n([_-) + 1 n()  (4)  -r = ]2p(1 p).  Theorem: If  M <_ 2 c",()+ø0ø)  then for all e > O, all sufficiently large n, all j 6 {1,...,Mn}, and all  X ß DH(X(J),d),  P{Y  Y('/)} < e.  Proof: See [2].  Interpretation: If the exponential growth rate of the number of  stored words M is asymptotically less than Cp,(5), then for every  sufficiently large address length n, there is some realization of the  n X 2 " preprocessor matrix Z such that the associative memory can  correct fraction 5 errors for most sequences of Mn (address, datum)  pairs. Thus C,,(5) is a lower bound on the exponential growth rate of  the capacity of the Kanerva associative memory with access radius n and  number of memory locations 2 ".  Figure 3 shows C,(5) as a function of the radius of attraction 5,  for  = 0() and  = 0.1, 0.2, 0.3, 0.4 and 0.45. For. any fixed access  radius p, C,,0()(5 ) decreases as 5 increases. This reflects the fact  that fewer (address, datum) pairs can be stored if a greater fraction of  errors must be corrected. As p increases, C,,o(,)(5 ) begins at a lower  point but falls off less steeply. In a moment we shall see that  can  be adjusted to provide the optimal performance for a given 5.  Not shown in Figure 3 is the behavior of C,,(5) as a function of .  However, the behavior is simple. For  > 0(), C,,(5) remains  unchanged. while for  < 0(P). C,.(5) is simply shifted down by the  difference 0(P)This establishes the conditions under which the  Kanerva associative memory is robust against random component failures.  Although increasing the number of memory locations beyond 2 "0(") does  not increase the capacity, it does increase robustness. Random  189  t.1  =0.2  0.3  Figure 3: Graphs of Cp,o(p)(5 ) as defined by (3). The upper envelope is 1 ha(5).  component failures will not affect the capacity until so many components  have failed that the number of surviving memory locations is less than  Perhaps the most important curve exhibited in Figure 3 is the  sphere packing upper bound !h(6), which is achieved for a particular  3 2p(1p). Equivalently, the upper bound is achieved  pby=for a particular 6 by p equal to  (5)  Thus (4) and ($) specify the optimal values of the parameters  and p,  respectively. These functions are shown in Figure 4. With these  optimal values, (3) simplifies to  = the sphere packing bound.  It can also be seen that for  = 0 in (3), the exponential Towth  rate of the capacity is asymptotically equal to , which is the  exponential growth rate of the number of memory locations, k. That is,  AJ = 2 n+O(g) = k.2 0(). Kanerva [3] and Keeler [5] have argued  that the capacity at  = 0 is proportional to the number of memory  locations, i.e., /=k. , for some constant . Thus our results are  consistent with those of Kanerva and Keeler, provided the polynomial'  O(n) can be proved to be a constant. However, the usual statement of  their result, /= k. , that the capacity is simply proportional to the  number of memory locations, is false, since in light of the universal  190  o  0 0.1 0.2 0.3 0.9 0.5  p  Figure 4: Graphs of no(p) and So(p), the inverse of po(5), as defined by (4) and (5).  upper bound, ir is impossible for the capacity to grow without bound,  with no dependence on'the dimension n. In our formulation, this  difficulty does nor arise because we have explicitly related the number  of memory locations ro the input dimension: kn = 2 n. In fact, our  formulation provides explicit, coherent relationships between all of the  following variables: the capacity M, the number of memory locations k,  the input and output dimensions n and m, the radius of attraction 6,  and the access radius p. We are therefore able ro generalize the  results of [3,S] ro the case  > 0, and provide explicit expressions for  the asymptotically optimal values of p and n as well.  CONCLUSION  We described a fairly general model of associative memory and  selected a useful definition of its capacity. A universal upper bound  on the growth of the capacity of such an associative memory was shown by  a sphere packing ar&xmenr ro be exponential with rate 1 h2(), where  h2(5) is the binary entropy function and  is the radius of attraction.  We reviewed the operation of the Kanerva associative memory, and stared  a lower bound on the exponential growth rare of its capacity. This  lower bound meets the universal upper bound for optimal values of the  memory parameters p and n. We provided explicit formulas for these  optimal values. Previous results for  = 0 staring rhar the capacity of  the Kanerva associative memory is proportional to the number of memory  locations cannot be strictly true. Our formulation corrects the problem  and generalizes those results ro the case  > 0.  191  References
Various simulations o cortical subnetworks have evidenced  something like phase transitions with respect to key parameters.  We demonstrate that. such transitions must. indeed exist_ in analogous  ininite array models. For related inite array models classical  phase transit.ions (which describe steady-state behavior) may not.  exist., but. there can be distinct. qualitative changes in  ("metastable") transient. behavior as key system parameters pass  through critical values.
Transient phenomena associated with forward biased silicon p+ n n + structures at 4.2K show remarkable similarities with biological neurons. The devices play  a role similar to the two-terminal switching elements in Hodgkin-Huxley equivalent  circuit diagrams. The devices provide simpler and more realistic neuron emulation  than transistors or op-amps. They have such low power and current requirements  that they could be used in massive neural networks. Some observed properties of  simple circuits containing the devices include action potentials, refractory periods,  threshold behavior, excitation, inhibition, summation over synaptic inputs, synaptic  weights, temporal integration, memory, network connectivity modification based on  experience, pacemaker activity, firing thresholds, coupling to sensors with graded signal outputs and the dependence of firing rate on input current. Transfer functions  for simple artificial neurons with spiketrain inputs and spiketrain outputs have been  measured and correlated with input coupling.
A class of high density associative memories is constrcted,  starting from a description of des ired properties those should  exhibit. These properties include high capacity, oontrollable basins  of attraction and fast speed of convergence. lortunately enough, the  resulting memory is implementable by an artificial Neural Net.
We show how to estimate (1) the number of functions that can be implemented by a  particular network architecture, (2) how much ana]og precision is needed in the connections in the network, and (3) the number of training examples the network must see  before it can be expected to form reliable genera]izations.  Generality versus Training Data Required  Consider the following objectives: First, the network should be very powerful and versatile, i.e., it should implement any function (truth table) you like, and secondly, it  should learn easily, forming meaningful generalizations from a small number of training  examples. Well, it is information-theoretica]ly impossible to create such a network. We  will present here a simplified argument; a more complete and sophisticated version can  be found in Denker eta]. (1987).  It is customary to regard learning as a dynamica] process: adjusting the weights (etc.)  in a single network. In order to derive the results of this paper, however, we take  a different viewpoint, which we call the ensemble viewpoint. Imagine making a very  large number of replicas of the network. Each replica has the same architecture as the  original, but the weights are set differently in each case. No further adjustment takes  place; the "learning process" consists of winnowing the ensemble of replicas, searching  for the one(s) that satisfy our requirements.  Training proceeds as follows: We present each item in the training set to every network  in the ensemble. That is, we use the abscissa of the training pattern as input to the  network, and compare the ordinate of the training pattern to see if it agrees with the  actual output of the network. For each network, we keep a score reflecting how many  times (and how badly) it disagreed with a training item. Networks with the lowest score  are the ones that agree best with the training data. If we had complete confidence in   Currently at NYNEX Science and Technology, 500 Westchester Ave., White Plains, NY 10604  American Institute of Physics 1988  220  the reliability of the training set, we could at each step simply throw away all networks  that disagree.  For definiteness, let us consider a typical network architecture, with No input wires and  N! units in each processing layer l, for I E {1..-L}. For simplicity we assume NL = 1.  We recognize the importance of networks with continuous-valued inputs and outputs,  but we will concentrate for now on training (and testing) patterns that are discrete,  with N = No bits of abscissa and NL = I bit of ordinate. This allows us to classify the  networks into bins according to what Boolean input-output relation they implement,  and simply consider the ensemble of bins.  There are 22 possble bns. If the network architecture is completely general and  powerful, all 22 functions will exist in the ensemble of bins. On average, one expects  that each training item will throw away at most half of the bins. Assuming maximal  efficiency, if m training items are used, then when m > 2 N there will be only one bin  remaining, and that must be the unique function that consistently describes all the  data. But there are only 2 N possible abscissas using N bits. Therefore a truly general  network cannot possibly exhibit meaningful generalization -100% of the possible data  is needed for training.  Now suppose that the network is not completely general, so that even with all possible  settings of the weights we can only create functions in 2 30 bins, where So << 2 N. We call  So the initial entropy of the network. A more formal and general definition is given in  Denker et al. (1987). Once again, we can use the training data to winnow the ensemble,  and when m > So, there will be only one remaining bin. That function will presumably  generalize correctly to the remaining 2 N m possible patterns. Certainly that function  is the best we can do with the network architecture and the training data we were given.  The usual problem with automatic learning is this: If the network is too general, So  will be large, and an inordinate amount of training data will be required. The required  amount of data may be simply unavailable, or it may be so large that training would be  prohibitively time-consuming. The shows the critical importance of building a network  that is not more general than necessary.  Estimating the Entropy  In real engineering situations, it is important to be able to estimate the initial entropy  of various proposed designs, since that determines the amount of training data that will  be required. Calculating So directly from the definition is prohibitively difficult, but we  can use the definition to derive useful approximate expressions. (You wouldn't want to  calculate the thermodynamic entropy of a bucket of water directly from the definition,  either.)  221  Suppose that the weights in the network at each connection i were not continuously  adjustable real numbers, but rather were specified by a discrete code with bi bits. Then  the totaJ number of bits required to specify the configuration of the network is  B =  bi (1)  Now the total number of functions that could possibly be implemented by such a network  architecture would be at most 2 $. The actual number will always be smaller than this,  since there are various ways in which different settings of the weights can lead to identical  functions (bins). For one thing, for each hidden layer l E {1... L-l), the numbering of  the hidden units can be permuted, and the polarity of the hidden units can be flipped,  which means that 2 sø is less than 2 $ by a factor (among others) of I-It Nt! 2 N' ß In  addition, if there is an inordinately large number of bits bl at each connection, there  will be many settings where small changes in the connection will be immaterial. This  will make 2 sø smaller by an additional factor. We expect OSo/Obi  1 when bl is small,  and OSo/Obi  0 when bi is large; we must now figure out where the crossover occurs.  The number of "useful and significant" bits of precision, which we designate b*, typically  scaJes like the logarithm of number of connections to the unit in question. This can be  understood as follows: suppose there are N connections into a given unit, and an input  signal to that unit of some size A is observed to be significant (the exact value of A  drops out of the present caJculation). Then there is no point in having a weight with  magnitude much larger than A, nor much smaller than A/N. That is, the dynamic  range should be comparable to the number of connections. (This argument is not exact,  and it is easy to devise exceptions, but the conclusion remains useful.) If only a fraction  1/S of the units in the previous layer are active (nonzero) at a time, the needed dynamic  range is reduced. This implies b*  log(N/S).  Note: our calculation does not involve the dynamics of the learning process. Some  numerical methods (including versions of back propagation) commonly require a number  of temporary "guard bits" on each weight, as pointed out by Richard Durbin (private  communication). Another log N bits ought to suffice. These bits are not needed after  learning is complete, and do not contribute to So.  If xve combine these ideas and apply them to a network with N units in each layer, fully  connected, we arrive at the following expression for the number of different Boolean  functions that can be implemented by such a network:  2 B  (2)  N! 2 N  where  B  LN 2 log N (3)  These results depend on the fact that we are considering only a very restricted type of  processing unit: the output is a monotone function of a weighted sum of inputs. Cover  222  (1965) discussed in considerable depth the capabilities of such units. Valiant (1986) has  explored the learning capabilities of various models of computation.  Abu-Mustafa has emphasized the principles of information and entropy and applied  them to measuring the properties of the training set. At this conference, formulas  similar to equation 3 arose in the work of Baum, Psaltis, and Venkatesh, in the context  of calculating the number of different training patterns a network should be able to  memorize. We originally proposed equation 2 as an estimate of the number of patterns  the network would have to memorize before it could form a reliable generalization. The  basic idea, which has numerous consequences, is to estimate the number of (bins of)  networks that can be realized.  References
There are three existing connection:,t models in which network states are assigned a computational energy. These models Hopfield nets, Hopfield and Tank nets, and Boltzmann Machines--search for states with minimal energy. Every link in the net- work can be thought of as imposing a constraint on acceptable states, and each vio- lation adds to the total energy. This is convenient for the designer because constraint satisfaction problems can be mapped easily onto a network. Multiple constraints can be superposed, and those states satisfying the most constraints will have the lowest energy. 
We propose learning rules for recurrent neural networks with high-order interactions between some or all neurons. The designed networks exhibit the desired associative memory function: perfect storage and retrieval of pieces of information and/or sequences of information of any complexity.
We report a study bn the relationship between EEG amplitude values and unit  spike output in the prepyriform cortex of awake and motivated rats. This relationship  takes the form of a sigmoid curve, that describes normalized pulse-output for  normalized wave input. The curve is fitted using nonlinear regression and is  described by its slope and maximum value.  Measurements were made for both excitatory and inhibitory neurons in the cortex.  These neurons are known to form a monosynaptic negative feedback loop. Both  classes of cells can be described by the same parameters.  The sigmoid curve is asymmetric in that the region of maximal slope is displaced  toward the excitatory side. The data are compatible with Freeman's model of  prepyriform burst generation. Other analogies with existing neural nets are being  discussed, and the implications for signal processing are reviewed. In particular the  relationship of sigmoid slope to efficiency of neural computation is examined.
Advances in brain theory need two complementary approaches:  Analytical investigations by in situ measurements and as well synthetic modelling supported by computer simulations to generate  suggestive hypothesis on purposeful structures in the neural  tissue. In this paper research of the second line is described:  Starting from a neurophysiologically inspired model of stimulusresponse (S-R) and/or associative memorization and a psychologically motivated ministructure for basic control tasks, pre-conditions  and conditions are studied for cooperation of such units in a  hierarchical organisation, as can be assumed to be the general  layout of macrostructures in the brain.
The interaction of a set of tropisms is sufficient in many  cases to explain the seemingly complex behavioral responses  exhibited by varied classes of biological systems to combinations of  stimuli. It can be shown that a straightforward generalization of  the tropism phenomenon allows the efficient implementation of  effective algorithms which appear to respond "intelligently" to  changing environmental conditions. Examples of the utilization of  troplstic processing techniques will be presented in this paper in  applications entailing simulated behavior synthesis, path-planning,  pattern analysis (clustering), and engineering design optimization.
Intracellular recordings in spinal cord motoneurons and cerebral  cortex neurons have provided new evidence on the correlational strength of  monosynaptic connections, and the relation between the shapes of  postsynaptic potentials and the associated increased firing probability. In  these cells, excitatory postsynaptic potentials (EPSPs) produce crosscorrelogram peaks which resemble in large part the derivative of the EPSP.  Additional synaptic noise broadens the peak, but the peak area -i.e., the  number of above-chance firings triggered per EPSP -remains proportional to  the EPSP amplitude. A typical EPSP of 100 gv triggers about .01 firings per  EPSP. The consequences of these data for information processing by  polysynaptic connections is discussed. The effects of sequential polysynaptic  links can be calculated by convolving the effects of the underlying  monosynaptic connections. The net effect of parallel pathways is the sum of  the individual contributions.
The Hopfield neural network model for associative memory is generaEzed. The generalization  replaces two state neurons by neurons taking a richer set of values. Two classes of neuron input output  relations we developed guaranteeing convergence to stable states. The fu-st is a class of "continuous" relations and the second is a class of allowed quantization rules for the neurons. The information capacity for  networks from the second class is found to be of order S 3 bits for a network with S neurons.  A generalization of the sum of outer products learning rule is developed and investigated as well.  American Institute of Physics 1988  279
A computer program has been designed and implemented to allow a researcher  to analyze the oscillatory behavior of simulated neural networks with cyclic connectivity. The computer program, implemented on the Texas Instruments Explorer/Odyssey system, and the results of numerous experiments are discussed.  The program, CYCLES, allows a user to construct, operate, and inspect neural  networks containing cyclic connection paths with the aid of a powerful graphicsbased interface. Numerous cycles have been studied, including cycles with one or  more activation points, non-interruptible cycles, cycles with variable path lengths,  and interacting cycles. The final class, interacting cycles, is important due to its  ability to implement time-dependent goal processing in neural networks.
Patterns of activity over real neural structures are known to exhibit timedependent behavior. It would seem that the brain may be capable of utilizing  temporal behavior of activity in neural networks as a way of performing functions  which cannot otherwise be easily implemented. These might include the origination  of sequential behavior and the recognition of time-dependent stimuli. A model is  presented here which uses neuronal populations with recurrent feedback connections in an attempt to observe and describe the resulting time-dependent behavior.  Shortcomings and problems inherent to this model are discussed. Current models  by other researchers are reviewed and their similarities and differences discussed. 
We describe a method of constructing higher-order neural  networks that respond invariantly under geometric transformations on  the input space. By requiring each unit to satisfy a set of  constraints on the interconnection weights, a particular structure is  imposed on the network. A network built using such an architecture  maintains its invariant performance independent of the values the  weights assume, of the learning rules used, and of the form of the  nonlinearities in the network. The invariance exhibited by a firstorder network is usually of a trivial sort, e.g., responding only to  the average input in the case of translation invariance, whereas  higher-order networks can perform useful functions and still exhibit  the invariance. We derive the weight constraints for translation,  rotation, scale, and several combinations of these transformations,  and report results of simulation studies.
Information retrieval in a neural network is viewed as a procedure in  which the network computes a "most probable" or MAP estimate of the unknown information. This viewpoint allows the class of probability distributions,  P, the neural network can acquire to be explicitly specified. Learning algorithms  for the neural network which search for the "most probable" member of P can  then be designed. Statistical tests which decide if the "true" or environmental  probability distribution is in P can also be developed. Example applications of  the theory to the highly nonlinear back-propagation learning algorithm, and the  networks of Hop field and Anderson are discussed.
To process sensory data, sensory brain areas must preserve information about both  the similarities and differences among learned cues: without the latter, acuity would  be lost, whereas without the former, degraded versions of a cue would be erroneously  thought to be distinct cues, and would not be recognized. We have constructed a  model of piriform cortex incorporating a large number of biophysical, anatomical and  physiological parameters, such as two-step excitatory firing thresholds, necessary and  suicient conditions for long-term potentiation (LTP) of synapses, three distinct types  of inhibitory currents (short IPSPs, long hyperpolarizing currents (LHP) and long cellspecific afterhyperpolarization (AHP)), sparse connectivity between bulb and layer-II  cortex, caudally-fiowing excitatory collateral fibers, nonlinear dendritic summation, etc.  We have tested the model for its ability to learn similarityand difference-preserving  encodings of incoming sensory cues; the biological characteristics of the model enable it  to produce multiple encodings of each input cue in such a way that different readouts of  the cell firing activity of the model preserve both similarity and difference-iuiormation.  In particular, probabilistic quant al transmitter-release properties of pitiform synapses  give rise to probabilistic postsynaptic voltage levels which, in combination with the activity of local patches of inhibitory interneurons in layer H, differentially select bursting  rs. single-pulsing layer-II cells. Time-locked firing to the theta rhythm (Larson and  Lynch, 1986) enables distinct spatial patterns to be read out against a relatively quiescent background firing rate. raining trials using the physiological rules for induction of  LTP yield stable layer-II-cell spatial firing patterns for learned cues. Multiple simulated  olfactory input patterns (i.e., those that share many chemical features) will give rise  to strongly-overlapping bulb firing patterns, activating many shared lateral olfactory  tract (LOT) axons innervating layer Ia of pitiform cortex, which in turn yields highly  overlapping layer-H-cell excitatory potentials, enabling this spatial layer-II-cell encoding to preserve the overlap (similarity) among similar inputs. At the same time, those  synapses that are enhanced by the learning process cause stronger cell firing, yielding  strong, cell-specific afterhyperpolarizing (AHP) currents. Local inhibitory interneurons  effectively select alternate cells to fire once strongly-firing cells have undergone AHP.  These alternate cells then activate their caudally-fiowing recurrent collaterals, activating distinct populations of synapses in caudal layer Ib. Potentiation of these synapses  in combination with those of still-active LOT axons selectively enhance the response of  caudal cells that tend to accentuate the differences among even very-similar cues.  Empirical tests of the computer simulation have shown that, after training, the  initial spatial layer II cell firing responses to similar cues enhance the similarity of  the cues, such that the overlap in response is equal to or greater than the overlap in  Thls research was supported in part by the Otce of Naval lesearch under grants N00014-84-K-0391  and N00014-87-K-0838 and by the National Science Foundation under grant IST-85-12419.  © American Institute of Physics 1988  318  input cell firing (in the bulb): e.g., two cues that overlap by 65% give rise to response  patterns that overlap by 80% or more. Reciprocally, later cell firing patterns (after  AHP), increasingly enhance the differences among even very-similar patterns, so that  cues with 90% input overlap give rise to output responses that overlap by less than 10%.  This difference-enhancing response can be measured with respect to its acuity; since 90%  input overlaps are reduced to near zero response overlaps, it enables the structure to  distinguish between even very-similar cues. On the other hand, the similarity-enhancing  response is properly viewed as a partitioning mechanism, mapping quite-distinct input  cues onto nearly-identical response patterns (or category indicators). We therefore use  a statistical metric for the information value of categorizations to measure the value of  partitionings produced by the pitiform simulation network.
The efficient realization, using current silicon technology, of Very Large Connection  Networks (VLCN) with more than a billion connections requires that these networks exhibit  a high degree of communication locMity. Real neural networks exhibi't significant locality,  yet most connectionist/neurM network models have little. In this paper, the connectivity  requirements of a simple associative network are analyzed using communication theory.  Several techniques based on communication theory are presented that improve the robustness of the network in the face of sparse, local interconnect structures. Also discussed are  some potential problems when information is distributed too widely.
Many connectionist learning models are implemented using a gradient descent  in a least squares error function of the output and teacher signal. The present model  generalizes, in particular, back-propagation [1] by using Minkowski-r power metrics.  For small r's a "city-block" error metric is approximated and for large r's the  "maximum" or "suprcmum" metric is approached, while for r=2 the standard backpropagation model results. An implementation of Minkowski-r back-propagation is  described, and several experiments are done which show that different values of r  may be desirable for various purposes. Different r values may be appropriate for the  reduction of the effects of outliers (noise), modeling the input space with more  compact clusters, or modeling the statistics of a particular domain more naturally or  in a way that may be more perccptually or psychologically meaningful (e.g. speech or  vision).
We describe a new learning procedure for networks that contain groups of nonlinear units arranged in a closed loop. The aim of the learning is to discover codes  that allow the activity vectors in a "visible" group to be represented by activity  vectors in a "hidden" group. One way to test whether a code is an accurate  representation is to try to reconstruct the visible vector from the hidden vector. The  difference between the original and the reconstructed visible vectors is called the  reconstruction error, and the learning procedure aims to minimize this error. The  learning procedure has two passes. On the first pass, the original visible vector is  passed around the loop, and on the second pass an average of the original vector and  the reconstructed vector is passed around the loop. The learning procedure changes  each weight by an amount proportional to the product of the "presynaptic" activity  and the difference in the post-synaptic activity on the two passes. This procedure is  much simpler to implement than methods like back-propagation. Simulations in  simple networks show that it usually converges rapidly on a good set of codes, and  analysis shows that in certain restricted cases it performs gradient descent in the  squared reconstruction error.
This paper outlines a schema for movement control  based on two stages of signal processing. The higher stage  is a neural network model that treats the cerebellum as an  array of adjustable motor pattern generators. This network  uses sensory input to preset and to trigger elemental  pattern generators and to evaluate their performance. The  actual patterned outputs, however, are produced by intrinsic circuitry that includes recurrent loops and is thus  capable of self-sustained activity. These patterned  outputs are sent as motor commands to local feedback  systems called motor servos. The latter control the forces  and lengths of individual muscles. Overall control is thus  achieved in two stages: (1) an adaptive cerebellar network  generates an array of feedforward motor commands and (2) a  set of local feedback systems translates these commands  into actual movements.
We describe two expriments in optical neural computing. In the first  a closed optical feedback loop is used to implement auto-associative image  recall. In the second a perceptron-like learning algorithm is implemented with  photorefractive holography.
Previous work on nets with continuous-valued inputs led to generative  procedures to construct convex decision regions with two-layer percepttons (one hidden  layer) and arbitrary decision regions with three-layer percepttons (two hidden layers).  Here we demonstrate that two-layer perceptton classifiers trained with back propagation  can form both convex and disjoint decision regions. Such classifiers are robust, train  rapidly, and provide good performance with simple decision regions. When complex  decision regions are required, however, convergence time can be excessively long and  performance is often no better than that of k-nearest neighbor classifiers. Three neural  net classifiers are presented that provide more rapid training under such situations.  Two use fixed weights in the first one or two layers and are similar to classifiers that  estimate probability density functions using histograms. A third "feature map classifier"  uses both unsupervised and supervised training. It provides good performance with  little supervised training in situations such as speech recognition where much unlabeled  training data is available. The architecture of this classifier can be used to implement  a neural net k-nearest neighbor classifier.
Inverse matrix calculation can be considered as an optimization. We have  demonstrated that this problem can be rapidly solved by highly interconnected  simple neuron-like analog processors. A network for matrix inversion based on  the concept of Hopfield's neural network was designed, and implemented with  electronic hardware. With slight modifications, the network is readily applicable to  solving a linear simultaneous equation efficiently. Notable features of this circuit  are potential speed due to parallel processing, and robustness against variations of  device parameters.
Ictalurid catfish use a highly developed gustatory system to  localize, track and acquire food from their aquatic environment.  The neural organization of the gustatory system illustrates well  the importance of the four fundamental ingredients  (representation, architecture, search and knowledge) of an  "intelligent" system. In addition, the "pipelined" design of  architecture illustrates how a goal-directed system effectively  utilizes interactive feedback from its environment. Anatomical  analysis of neural networks involved in target-tracking  indicated that reticular neurons within the medullary region of  the brainstem, mediate connections between the gustatory  (sensory) inputs and the motor outputs of the spinal cord.  Ele ctrophysiological analysis suggested that these neurons  integrate selective spatic-temporal patterns of sensory input  transduced through a rapidly adapting-type peripheral filter  (responding tonically only to a continuously increasing stimulus  concentration ). The connectivity and response patterns of  reticular cells and the nature of the peripheral taste response  suggest a unique "gustation-seeking" function of reticulospinal  cells, which may enable a catfish to continuously track a  stimulus source once its directionality has been computed.
The information capacity of Kanerva's Sparse, Distributed Memory (SDM) and Hopfield-type  neural networks is investigated. Under the approximations used here, it is shown that the total information stored in these systems is proportional to the number connections in the network. The proportionality constant is the same for the SDM and Hopfield-type models independent of the particular model, or the order of the model. The approximations are  checked numerically. This same analysis can be used to show that the SDM can store sequences of spatiotemporal patterns, and the addition of time-delayed connections allows the  retrieval of context dependent temporal patterns. A minor modification of the SDM can be  used to store correlated patterns.
To us, and to other biological organisms, vision seems effortless. We open our eyes and we "see" the world in all its color, brightness, and movement. Yet, we have great difficulties when trying to endow our machines with similar abilities. In this paper we shall describe recent developments in the theory of early vision which lead from the formulation of the motion problem as an ill- posed one to its solution by minimizing certain "cost" functions. These cost or energy functions can be mapped onto simple analog and digital resistive networks.
Recently, many modifications to the McCulloch/Pitts model have been proposed  where both learning and forgetting occur. Given that the network never saturates (ceases  to function effectively due to an overload of information), the learning updates can continue indefinitely. For these networks, we need to introduce performance measures in addition to the information capacity to evaluate the different networks. We mathematically  define quantities such as the plasticity of a network, the efficacy of an information vector,  and the probability of network saturation. From these quantities we analytically compare  different networks.
There is presently great interest in the abilities of neural networks to mimic  "qualitative reasoning"by manipulating neural incodings of symbols. Less work  has been performed on using neural networks to process floating point nurnbers  and it is sometimes stated that neural networks are somehow inherently inaccurate and therefore best suited for "fuzzy"qualitative reasoning. Nevertheless,  the potential speed of massively parallel operations make neural net "number  crunching"an interesting topic to explore. In this paper we discuss some of our  work in which we demonstrate that for certain applications neural networks can  achieve significantly higher numerical accuracy than more conventional techniques. In particular, prediction of future values of a chaotic time series can  be performed with exceptionally high accuracy. We analyze how a neural net  is able to do this , and in the process show that a large class of functions from  R  -- R 'n may be accurately approximated by a backpropagation neural net  with just two "hidden"layers. The network uses this functional approximation  to perform either interpolation (signal processing applications) or extrapolation  (symbol processing applications I. Neural nets therefore use quite familiar methods to perform their tasks. The geometrical viewpoint advocated here seems to  be a useful approach to analyzing neural network operation and relates neural  networks to well studied topics in functional approximation.
A new distributed neural information-processing  model is proposed to explain the response characteristics  of the vestibulo-ocular system and to reflect more  accurately the latest anatomical and neurophysiological  data on the vestibular afferent fibers and vestibular nuclei.  In this model, head motion is sensed topographically by hair  cells in the semicircular canals. Hair cell signals are then  processed by multiple synapses in the primary afferent  neurons which exhibit a continuum of varying dynamics. The  model is an application of the concept of "multilayered"  neural networks to the description of findings in the  bullfrog vestibular nerve, and allows us to formulate  mathematically the behavior of an assembly of neurons  whose physiological characteristics vary according to their  anatomical properties.
The brain works in a state-dependent manner: processin 9  stratesies and access to stored information depends on the momentary  functional state which is continuously re-adjusted. The state is  manifest as spatial confisuration of the brain electric field.  Spontaneous and information-trissered brain electric activity is a  series of momentary field maps. Adaptive sesnentation of spontaneous  series into spatially stable epochs (states) exhibited 210 mse½ mean  sesments, discontinuous chanses. Different maps imply different  active neural populations, hence expectedly different effects on  information processins: Reaction time differred between map classes  at stimulus arrival. Se9ments misht be units of brain information  processins (content/mode/step), possibly operationalizin9  consciousness time. Related units (e. 9. trissered by stimuli durin S  fisure perception and voluntary attention) misht specify brain submechanisms of information treatment.  BRAIN FUNCTIL STATES D THEIR CHANGES  The momentary functional state of the brain is reflected by the  confisuration of the brain's electro-rnasnetic field. The state  manifests the stratesy , mode, step and content of brain information  processins, and the state constrains the choice of stratesies and  modes and the access to memory material available for processin 9 of  incomin 9 information (1). The constraints include the avaiIabIe  ranse of chanses of state in PAVLOV's classical "orientin9 reaction"  as response to new or important informations. Different states misht  be viewed as different functional connectivities between the neural  elements.  The orientin9 reaction (see 1,2) is the result of the first  ("pre-attentive") stase of information processin 9. This stase  operates automatically (no involvement of consciousness) and in a  parallel mode, and quickly determines whether (a) the information is  important or unknown and hence requires increased attention and  alertness, i.e. an orientin S reaction which means a re-adjustment of  functional state in order to deal adequately with the information  invokin 9 consciousness for further processins, or whether (b) the  information is known or unimportant and hence requires no readjustment of state, i.e. that it can be treated further with well* Present addresses: D.B. at Psychiat. Dept., V.A. Med. Center, San  Francisco CA 94121; H.O. at Lab. Physiol. for the Developmentally  Handicapped, Ibaraki Univ., Mito, Japan 310; I.P. at BioLosic  Systems Corp., Mundelein IL 60060.  American Institute of Physics 1988  468  established ("automatic") strategies. Conscious strategies are slow  but flexible (offer wide choice), automatic strategies are fast but  rigid.  Examples for functional states on a gross scale are wakefulness,  drowsiness and sleep in adults, or developmental stages as infancy,  childhood and adolescence, or drug states induced by alcohol or  other psychoactive agents. The different states are associated with  distinctly different ways of information processing. For example, in  normal adults, reality-close, abstracting strategies based on causal  relationships predominate during wakefulness, whereas in drowsiness  and sleep (dreams), reality-remote, visualizing, associative  concatenations of contents are used. Other well-known examples are  drug states.  BRAIN ELECTRIC FIELD DATA D STATES  While alive, the brain produces an ever-changing electromagnetic  field, which very sensitively reflects global and local states as  effected by spontaneous activity, incoming information, metabolism,  drugs, and diseases. The electric component of the brain's electromagnetic field as non-invasively measured from the intact human  scalp shows voltages between O.l and 250 microVolts, temporal  frequencies between O.1 and 30, 100 or 3000 Hz depending on the  examined function, and spatial frequencies up to 0.2 cycles/cm.  Brain electric field data are traditionally viewed as time series  of potentia! differences between two scalp locations (the  electroencephalogram or EEG). Time series analysis has offered an  effective way to class different gross brain functional states,  typically using EEG power spectral values. Differences between power  spectra during different gross states typically are greater than  between different locations. States of lesser functional complexity  such as childhood vs adult states, sieep vs wakefulness, and many  drug-states vs non-drug states tend to increased power in slower  frequencies (e.g. ,4).  Time series analyses of epochs of intermediate durations between  30 and 0 seconds have demonstrated (e.g. ,5,6) that there are  significant and reliable relations between spectra! power or  coherency values of EEG and characteristics of human menration  (reality-close thoughts vs free associations, visual vs non-visual  thoughts, positive vs negative emotions).  Viewing brain electric field data as series of momentary field  maps (7,8) opens the possibility to investigate the temporal  microstructure of brain functional states in the sub-second range.  The rationale is that the momentary configuration of activated  neural elements represents a given brain functional state, and that  the spatial pattern of activation is reflected by the momentary  brain electric field which is recordable on the scalp as a momentary  field map. Different configurations of activation (different field  maps) are expected to be associated with different modes,  strategies, steps and contents of information processing.  469  SE{!E]TATION OF BRuIN ELECTRIC P:P SERIES INT0 STABLE SEGME]qTS  When viewin 9 brain electric activity as series of maps of  momentary potential distributions, chan9es of functional state are  reco9nizable as chan9es of the "electric landscapes" of these maps.  Typically, several successive maps show similar landscapes, then  quickly chan9e to a new confi9uration which a9ain tends to persist  for a number of successive maps, su99estive of stable states  concatenated by non-linear transitions (9,10). Stable map landscapes  mi9ht be hypothesized to indicate the basic buildin 9 blocks of  information processin9 in the brain, the "atoms of thou9hts". Thus,  the task at hand is the reco9nition of the landscape confi9urations;  this leads to the adaptive se9rnentation of time series of momentary  maps into se9ments of stable landscapes durin9 varyin9 durations.  We have proposed and used a method which describes the  confi9uration of a momentary map by the locations of its maximal and  minimal potential values, thus invokin9 a dipole model. The  here is the phenomenolo9ical reco9nition of different momentary  functional states usin9 a very limited number of major map features  as classifiers, and we su99est conservative interpretion of the data  as to real brain locations of the 9eneratin9 processes which always  involve millions of neural elements.  We have studied (11) map series recorded from 16 scalp locations  over posterior skull areas from normal subjects durin9 relaxation  with closed eyes. For adaptive se9mentation, the maps at the times  of maximal map relief were selected for optimal si9nal/noise  conditions. The locations of the maximal and minimal (extrema)  potentials were extracted in each map as descriptors of the  landscape; takin 9 into account the basically periodic nature of  spontaneous brain electric activity (Fi9. 1), extrema locations were  treated disre9ardin9 polarity information. If over time an extreme  left its pre-set spatial window (say, one electrode distance), the  se9ment was terminated. The map series showed stable map  confi9urations for varyin9 durations (Fi9. 2), and discontinuous,  step-wise chan9es. Over 6 subjects, restin 9 alpha-type EEG showed  210 msec mean se9rnent duration; se9ments 1on9er than 323 msec  covered 50% of total time; the most prominent se9ment class (1.5% of  all classes) covered 20% of total time (prominence varied stron91y  over classes; not all possible classes occurred). Spectral power and  phase of avera9es of adaptive and pre-detemined se9ments  demonstrated the adequacy of the strate9y and the homo9eneity of  adaptive se9ment classes by their reduced within-class variance.  Se9mentation usin9 91obal map dissimilarity (sum of Euklidian  difference vs avera9e reference at all measured points) emulates the  results of the extracted-characteristics-strate9y.  FUNCTIL SIGNIFIC:qCE OF MOME]TARY MICRO STATES  Since different maps of momentary EEG fields imply activity of  different neural populations, different se9ment classes must  manifest different brain functional states with expectedly different  470  189 %o 189 117 %o 117 125 to 125 132 to 132  148 to 148  171 to 171 179 .o 179  RECORD=I FILE=:UP3EC2  148 156 to 156 164 o 164  187 o 187 195 to 195 s  qORML SUBJECT, EYES CLOSED  Fi9. 1. Series of momentary potential distribution maps of the brain  field recorded from the scalp of a normal human durin 9 relaxation  with closed eyes. Recordin 9 with 21 electrodes (one 5-electrode row  added to the 16-electrode array in Fi9. 2) usin9 128 samples/sac/  channel. Head seen from above left ear left; white positive dark  ne9ative  8 levels from +32 to -32 microVolts. Note the periodic  reversal of field polarity within the about 100 msec (one cycle of  the 8-12Hz so-called "EEG alpha" activity) while the field confi9uration remains lar9ely constant. This recordin9 and display was  done with a BIAIN ATLAS system (BioLo9ic Systems Hundelein, IL).  effects on on9oin 9 information processin9. This was supported by  measurements of selective reaction time to acoustic stimuli which  were randomly presented to ei9ht subjects durin9 different classes  of EEG se9ments (323 responses for each subject). We found  si9nificant reaction time differences over se9ment classes (ANOUA p  smaller than .02) but similar characteristics over subjects. This  indicates that the momentary sub-second state as manifest in the  potential distribution map si9nificantly influences the behavioral  consequence of information reachin 9 the brain.  Presentation of information is followed by a sequence of  potential distribution maps ("event-related potentials" or EEP's,  avera9ed over say 100 presentations of the same stimulus see  The different spatial confi9urations of these maps (12) are thou9ht  to reflect the sequential sta9es of information processin9  associated with "components" of event-related brain activity (see  e.9. i3) which are traditionally defined as times of maximal  volta9es after information input (maximal response stren9th).  471  o  Fig. 2. Sequence of spatially stable segments durin 9 a spontaneous  series of momentary EEG maps of 3.1 sec duration in a normal  volunteer. Each map shows the occurrence of the extreme potential  values during one adaptively determined segment: the momentary maps  were searched for the locations of the two extreme potentials; these  locations were accumulated, and linearly interpolated between  electrodes to construct the present maps. (The number of isofrequency-of-occurrence lines therefore is related to the number of  searched maps). Head seen from above, left ear left, electrode  locations indicated by crosses, most forward electrode at vertex.  Data FIR filtered to 8-12Hz (alpha EEG). The figure to the left  below each map is a running segment number. The figure to the right  above each map multiplied by 50 indicates the senent duration in  msec.  Application of the adaptive segnentation procedure described above  for identification of functional components of event-related brain  electric map sequences requires the inclusion of polarity  information (14); such adaptive segmentation permits to separate  different brain functional states without resorting to the strength  concept of processing stages.  An example (12) might illustrate the type of results obtained  with this analysis: Given segments of brain activity which were  triggered by visual information showed different map configurations  when subjects paid attention vs when they paid no attention to the  stimulus, and when they viewed figures vs meaningless shapes as  472  LVF RYF  FIGUR  Ss)  AATTENTION  Fi 9, 3. Four difference maps, computed as differences between maps  obtained durin9 (upper row) perception of a visual "illusionary"  triangle figure (left picture) minus a visual non-figure (ri9ht)  shown to the left and right visual hemi-fields (LVF, RVF), and  obtained durin9 (lower row) attendin9 minus durin inorin the  presented display. The analysed se9ment covered the time from 168 to  200 msec after stimulus presentations. Hean of 12 subjects. Head  seen fom above, left ear left, 16 electrodes as in Fi. 2,  isopotential contour lines at O.i microVolt steps, dotted negative  referred to mean of all values. The "illusionary" figure stimulus  was studied by Kanisza (16); see also (12). Note that the mirror  symmetric configuration of the difference maps for LVF and RVF is  found for the "figure" effect only, not for the "attention" effect,  but that the anterior-posterior difference is similar for both cases.  stimuli. Fi. 3 illustrates such differences in map configuration.  The "attention"-induced and "fi9ure"-induced chan9es in map  configuration showed certain similarities e.. in the illustrated  se9ment 168-200 msec after information arrival, supporting the  hypothesis that brain mechanisms for figure perception draw on brain  resources which in other circumstances are utilized in volontary  attention.  The spatially homogeneous temporal se9ments might be basic  buildin blocks of brain information processin9, possibly  operationalizin consciousness time (15), and offerin9 a common  concept for analysis of brain spontaneous activity and event related  brain potentials. The functional significance of the se9ments mi9ht  be types/ modes/ steps of brain information processin or  performance. Identification of related buildin9 blocks durin  different brain functions accordingly could specify brain submechanisms of information treatment.  473  Acknowledqement: Financial support by the Swiss National Science  Foundation (including Fellowships to H.O. and I.P.) and by the EMDO,  the Hartmann Muller and the SANDOZ Foundation is 9ratefully  acknowledged.  REFERENCES
General formulae for mapping optimization problems into systems of ordinary differential  equations associated with artificial neural networks are presented. A comparison is made to optimization using gradient-search methods. The performance measure is the settling time from an initial  state to a target state. A simple analytical example illustrates a situation where dynamical systems  representing artificial neural network methods would settle faster than those representing gradientsearch. Settling time was investigated for a more complicated optimization problem using computer simulations. The problem was a simplified version of a problem in medical imaging: determining loci of cerebral activity from electromagnetic measurements at the scalp. The simulations  showed that gradient based systems typically setfled 50 to 100 times faster than systems based on  current neural network optimization methods.
An information-theoretic optimization principle is proposed for the development  of each processing stage of a multilayered perceptual network. This principle of  "maximum information preservation" states that the signal transformation that is to be  realized at each stage is one that maximizes the information that the output signal values  (from that stage) convey about the input signals values (to that stage), subject to certain  constraints and in the presence of processing noise. The quantity being maximized is a  Shannon information rate. I provide motivation for this principle and -for some simple  model cases -derive some of its consequences, discuss an algorithmic implementation,  and show how the principle may lead to biologically relevant neural architectural  features such as topographic maps, map distortions, orientation selectivity, and  extraction of spatial and temporal signal correlations. A possible connection between  this information-theoretic principle and a principle of minimum entropy production in  nonequilibrium thermodynamics is suggested.
In the synchronous discrete model, the average memory capacity of  bidirectional associative memories (BAMs) is compared with that of  Hopfield memories, by means of a calculation of the percentage of good  recall for 100 random BAMs of dimension 64x64, for different numbers  of stored vectors. The memory capacity is found to be much smaller than  the Kosko upper bound, which is the lesser of the two dimensions of the  BAM. On the average, a 64x64 BAM has about 68 % of the capacity of the  corresponding Hopfield memory with the same number of neurons. Orthonormal coding of the BAM increases the effective storage capacity by  only 25 %. The memory capacity limitations are due to spurious stable  states, which arise in BAMs in much the same way as in Hopfield  memories. Occurrence of spurious stable states can be avoided by  replacing the thresholding in the backlayer of the BAM by another  nonlinear process, here called "Dominant Label Selection" (DLS). The  simplest DLS is the winner-take-all net, which gives a fault-sensitive  memory. Fault tolerance can be improved by the use of an orthogonal or  unitary transformation. An optical application of the latter is a Fourier  transform, which is implemented simply by a lens.
lecently there has been renewed interest in neural-like processing systems, evidenced for example in the two volumes Parallel Distributed Processing edited by Pumelhart and McClelland,  and discussed as parallel distributed systems, connectionist models, neural nets, value passing  systems and multiple context systems. Dissatisfaction with symbolic manipulation paradigms  for artificial intelligence seems partly responsible for this attention, encouraged by the promise  of massively parallel systems implemented in hardware. This paper relates simple neural-like  systems based on multiple context to some other well-known formalisms--namely production  systems, k-length sequence prediction, finite-state machines and Turing machines--and presents  earlier sequence prediction results in a new light.
In this paper we discuss why special purpose chips are needed for useful  implementations of connectionist neural networks in such applications as pattern  recognition and classification. Three chip designs are described: a hybrid  digital/analog programmable connection matrix, an analog connection matrix with  adjustable connection strengths, and a digital pipelined best-match chip. The common  feature of the designs is the distribution of arithmetic processing power amongst the  data storage to minimize data movement.  10 9  106  '103  ,,,/AMs  ',,, Distributed  '-computation  chip, s  I ½.jj/ '-, Conventional  ",, CPUs  10 3 10 6 10 9  Node Complexity  (No. of Transistors)  Figure 1. A schematic graph of addressable node complexity and size for conventional  computer chips. Memories can contain millions of very simple nodes each  with a very few transistors but with no processing power. CPU chips are  essentially one very complex node. Neural network chips are in the  distributed computation region where chips contain many simple fixed  instruction processors local to data storage. (After Reece and Treleaven 1 )  © American Institute of Physics 1988  516
We have studied the basins of attraction for fixed point and  oscillatory attractors in an electronic analog neural network. Basin  measurement circuitry periodically opens the network feedback loop,  loads raster-scanned initial conditions and examines the resulting  attractor. Plotting the basins for fixed points (memories), we show  that overloading an associative memory network leads to irregular  basin shapes. The network also includes analog time delay circuitry,  and we have shown that delay in symmetric networks can introduce  basins for oscillatory attractors. Conditions leading to oscillation  are related to the presence of frustration; reducing frustration by  diluting the connections can stabilize a delay network.
We donsider a class of neural networks whose performance can be  analyzed and geometrically visualized in a signal space  environment. Alternating projection neural networks (APNN's)  perform by alternately projecting between two or more constraint  sets. Criteria for desired and unique convergence are easily  established. The network can be configured in either a homogeneous  or layered form. The number of patterns that can be stored in the  network is on the order of the number of input and hidden neurons.  If the output neurons can take on only one of two states, then the  trained layered APNN can be easily configured to converge in one  iteration. More generally, convergence is at an exponential rate.  Convergence can be improved by the use of sigmoid type  nonlinearities, network relaxation and/or increasing the number of  neurons in the hidden layer. The manner in which the network  responds to data for which it was not specifically trained (i.e.  how it generalizes) can be directly evaluated analytically.
MURPHY consists of a camera looking at a robot arm, with a connectionist network  architecture situated in between. By moving its arm through a small, representative  sample of the 1 billion possible joint configurations, MURPHY learns the relationships,  backwards and forwards, between the positions of its joints and the state of its visual field.  MURPHY can use its internal model in the forward direction to "envision" sequences  of actions for planning purposes, such as in grabbing a visually presented object, or in  the reverse direction to 'qmitate", with its arm, autonomous activity in its visual field.  Furthermore, by taking explicit advantage of continuity in the mappings between visual  space and joint space, MURPHY is able to learn non-linear mappings with only a single  layer of modifiable weights.
In the present paper we survey mad utilize results from the qualitative theory of large  scale interconnected dynamical systems in order to develop a qualitative theory for the  Hop field model of neural networks. In our approach we view such networks as an interconnection of many single neurons. Our results are phrased in terms of the qualitative  properties of the individual neurons and in terms of the properties of the interconnecting  structure of the neural networks. Aspects of neural networks which we address include  asymptotic stability, exponential stability, and instability of an equilibrium; estimates  of trajectory bounds; estimates of the domain of attraction of an asymptotically stable  equilibrium; and stability of neural networks under structural perturbations.
A binary synaptic matrix chip has been developed for electronic  neural networks. The matrix chip contains a programmable 32X32  array of "long channel" NMOSFET binary connection elements implemented in a 3-um bulk CMOS process. Since the neurons are kept offchip, the synaptic chip serves as a "cascadable" building block for  a multi-chip synaptic network as large as 512X512 in size. As an  alternative to the programmable NMOSFET {long channel) connection  elements, tailored thin film resistors are deposited, in series with  FET switches, on some CMOS test chips, to obtain the weak synaptic  connections. Although deposition and patterning of the resistors  require additional processing steps, they promise substantial  savings in silcon area. The performance of a synaptic chip in a 32neuron breadboard system in an associative memory test application  is discussed.
A bit serial VLSI neural network is described from an initial architecture for a  synapse array through to silicon layout and board design. The issues surrounding bit  serial computation, and analog/digital arithmetic are discussed and the parallel  development of a hybrid analog/digital neural network is outlined. Learning and  recall capabilities are reported for the bit serial network along with a projected  specification for a 64 neuron, bit serial board operating at 20 MHz. This technique is extended to a 256 (2562 synapses) network with an update time of 3ms,  using a "paging" technique to time multiplex calculations through the synapse  array.
A novel network type is introduced which uses unit-length 2-vectors  for local variables. As an example of its applications, associative  memory nets are defined and their performance analyzed. Real systems  corresponding to such 'phasor' models can be e.g. (neuro)biological  networks of limit-cycle oscillators or optical resonators that have  a hologram in their feedback path.
We have developed a neural network which consists of cooperatively interconnected Grossberg on-center off-surround subnets and which can be used to  optimize a function related to the log likelihood function for decoding convolutional codes or more general FIR signal deconvolution problems. Connections in  the network are confined to neighboring subnets, and it is representative of the  types of networks which lend themselves to VLSI implementation. Analytical and  experimental results for convergence and stability of the network have been found.  The structure of the network can be used for distributed representation of data  items while allowing for fault tolerance and replacement of faulty units.
A general method for deriving backpropagation algorithms for networks  with recurrent and higher order networks is introduced. The propagation of activation  in these networks is determined by dissipative differential equations. The error signal  is backpropagated by integrating an associated differential equation. The method is  introduced by applying it to the recurrent generalization of the feedforward  backpropagation network. The method is extended to the case of higher order  networks and to a constrained dynamical system for training a content addressable  memory. The essential feature of the adaptive algorithms is that adaptive equation has  a simple outer product form.  Preliminary experiments suggest that learning can occur very rapidly in  networks with recurrent connections. The continuous formalism makes the new  approach more suitable for implementation in VLSI.
Many optimization models of neural networks need constraints to restrict the space of outputs to  a subspace which satisfies external criteria. Optimizations using energy methods yield "forces" which  act upon the state of the neural network. The penalty method, in which quadratic energy constraints  are added to an existing optimization energy, has become popular recently, but is not guaranteed  to satisfy the constraint conditions when there are other forces on the neural model or when there  are multiple constraints. In this paper, we present the basic differential multiplier method (BDMM),  which satisfies constraints exactly; we create forces which gradually apply the constraints over time,  using "neurons" that estimate Lagrange multipliers.  The basic differential multiplier method is a differential version of the method of multipliers  from Numerical Analysis. We prove that the differential equations locally converge to a constrained  minimum.  Examples of applications of the differential method of multipliers include enforcing permutation  codewords in the analog decoding problem and enforcing valid tours in the traveling salesman problem.
A lightness algorithm that separates surface reflectance from illumination in a  Mondrian world is synthesized automatically from a set of examples, pairs of input  (image irradiance) and desired output (surface reflectance). The algorithm, which resembles a new lightness algorithm recently proposed by Land, is approximately equivalent to filtering the image through a center-surround receptive field in individual chromatic channels. The synthesizing technique, optimal linear estimation, requires only  one assumption, that the operator that transforms input into output is linear. This  assumption is true for a certain class of early vision algorithms that may therefore be  synthesized in a similar way from examples. Other methods of synthesizing algorithms  from examples, or "learning", such as backpropagation, do not yield a significantly different or better lightness algorithm in the Mondrian world. The linear estimation and  backpropagation techniques both produce simultaneous brightness contrast effects.  The problems that a visual system must solve in decoding two-dimensional images  into three-dimensional scenes (inverse optics problems) are difficult: the information  supplied by an image is not sufficient by itself to specify a unique scene. To reduce  the number of possible interpretations of images, visual systems, whether artificial  or biological, must make use of natural constraints, assumptions about the physical  properties of surfaces and lights. Computational vision scientists have derived effective  solutions for some inverse optics problems (such as computing depth from binocular  disparity) by determining the appropriate natural constraints and embedding them in  algorithms. How might a visual system discover and exploit natural constraints on its  own? We address a simpler question: Given only a set of examples of input images and  desired output solutions, can a visual system synthesize, or "learn", the algorithm that  converts input to output? We find that an algorithm for computing color in a restricted  world can be constructed from examples using standard techniques of optimal linear  estimation.  The computation of color is a prime example of the difficult problems of inverse  optics. We do not merely discriminate between different wavelengths of light; we assign  @ American Institute of Physics 1988  623  roughly constant colors to objects even though the light signals they send to our eyes  change as the illumination varies across space and chromatic spectrum. The computatjohn.1 goal underlying color constancy seems to be to extract the invariant surface  spectral reflectance properties from the image irradiance, in which reflectance and il-'  lumination are mixed 1.  Lightness algorithms 2-s, pioneered by Land, assume that the color of an object  can be specified by its lightness, or relative surface reflectance, in each of three independent chromatic channels, and that lightness is computed in the same way in each  channel. Computing color is thereby reduced to extracting surface reflectance from the  image irradiance in a single chromatic channel.  The image irradiance, s t, is proportional to the product of the illumination intensity e t and the surface reflectance r t in that channel:  st(x,y) rt(x,y)et(x,y). (1)  This form of the image intensity equation is true for a Lambertinn reflectance model,  in which the irradiance s t has no specular components, and for appropriately chosen  color channels 9. Taking the logarithm of both sides converts it to a sum:  y) = r(x, y) + e(x,y), (2)  where s = log(s'), r = log(r') and e = log(e').  Given s(x, y) alone, the problem of solving Eq. 2 for r(x, y) is underconstrained.  Lightness algorithms constrain the problem by restricting their domain to a world of  Mondrians, two-dimensional surfaces covered with patches of random colors 2 and by  exploiting two constraints in that world: (i) r'(x,y) is uniform within patches but  has sharp discontinuities at edges between patches and (ii) e'(x,y) varies smoothly  across the Mondrian. Under these constraints, lightness algorithms can recover a good  approximation to r(x, y) and so can recover lightness triplets that label roughly constant  colors l0  We ask whether it is possible to synthesize from examples an algorithm that extracts reflectance from image irradiance, and whether the synthesized algorithm will resemble existing lightness algorithms derived from an explicit analysis of the constraints.  We make one assumption, that the operator that transforms irradiance into reflectance  is linear. Under that assumption, motivated by considerations discussed later, we use  optimal linear estimation techniques to synthesize an operator from examples. The  examples are pairs of images: an input image of a Mondrian under illumination that  varies smoothly across space and its desired output image that displays the reflectance  of the Mondrian without the illumination. The technique finds the linear estimator  that best maps input into desired output, in the least squares sense.  For computational convenience we use one-dimensional "training vectors" that  represent vertical scan lines across the Mondrian images (Fig. 1). We generate many  624  Input data  0 SO lOG 150 200 .Se 300  correct illumination  60  0 $0 100 Z$O 200 250 300  output illumination  correct reflectance  tO0 I$0 00 250 700  output reflectance  a  b  c  Fig. 1. (a) The input data, a one-dimensional vector 320 pixels long. Its random  Mondrian reflectance pattern is superimposed on a linear illumination gradient with  a random slope and offset. (b) shows the corresponding output solution, on the left  the illumination and on the right reflectance. We used 1500 such pairs of inputoutput examples (each different from the others) to train the operator shown in Fig.  2. (c) shows the result obtained by the estimated operator when it acts on the input  data (a), not part of the training set. On the left is the illumination and on the  right the reflectance, to be compared with (b). This result is fairly typical: in some  cases the prediction is even better, in others it is worse.  different input vectors s by adding together different random r and e vectors, according  to Eq. 2. Each vector r represents a pattern of step changes across space, corresponding  to one column of a reflectance image. The step changes occur at random pixels and  are of random amplitude between set minimum and maximum values. Each vector ß  represents a smooth gradient across spa:e with a random offset and slope, corresponding  to one column of an illumination image. We then arrange the training vectors s and r  as the columns of two matrices S and R, respectively. Our goal is then to compute the  optimal solution  of  LS:R  where L is a linear operator represented a a matrix.  625  It is well known that the solution of this equation that is optimal in the least  squares sense is  L = RS + (4)  where S + is the Moore-Penrose pseudoinverse . We compute the pseudoinverse by  overconstraining the problem using many more training vectors than there are number  of pixels in each vector and using the straightforward formula that applies in the  overconstrained case 2: S + = sT(ssT)-.  The operator L computed in this way recovers a good approximation to the correct  output vector r when given a new s, not part of the training set, as input (Fig. lc).  A second operator, estimated in the same way, recovers the illumination e. Acting on  a random two-dimensional Mondrian L also yields a satisfactory approximation to the  correct output image.  Our estimation scheme successfully synthesizes an aigorithm that performs the  lightness computation in a Mondrian world. What is the algorithm and what is its  relationship to other lightness algorithms? To answer these questions we examine the  structure of the matrix L. We assume that, although the operator is not a convolution  operator, it should approximate one far from the boundaries of the image. That is,  in its central part, the operator should be space-invariant, performing the same action  on each point in the image. Each row in the central part of L should therefore be  the same as the row above but displaced by one element to the right. Inspection of  the matrix confirmes this expectation. To find the form of L in its center, we thus  average the rows there, first shifting them appropriately. The result, shown in Fig. 2,  is a space-invariant filter with a narrow positive peak and a broad, shallow, negative  surround.  Interestingly, the filter our scheme synthesizes is very similar to Land's mct recent  retinex operator 5, which divides the image irradiance at each pixel by a weighted  average of the irradiance at all pixels in a large surround and takes the logarithm of  that result to yield lightness 13. The lightness triplets computed by the retinex operator  agree well with human perception in a Mondrian world. The retinex operator and our  matrix L both differ from Land's earlier retinex algorithms, which require a non-linear  thresholding step to eliminate smooth gradients of illumination.  The shape of the filter in Fig. 2, particularly of its large surround, is also suggestive of the "nonclassical" receptive fields that have been found in V4, a cortical area  implicated in mechanisms underlying color constancy 14-7  The form of the space-invariant filter is similar to that derived in our earlier formal  analysis of the lightness problem s It is qualitatively the same as that which results  from the direct application of regularization methods exploiting the spatial constraints  on reflectance and illumination described above 9.s.9 The Fourier transform of the  filter of Fig. 2 is approximately a bandpass filter that cuts out low frequencies due  626  -80 0 +80  Pixels  -80 0 +$0  Pixels  Fig. 2. The space-invariant part of the estimated operator, obtained by shifting and  averaging the rows of a 160-pixel-wide central square of the matrix L, trained on a set  of 1500 examples with linear illumination gradients (see Fig. 1). When logarithmic  illumination gradients are used, a qualitatively similar receptive field is obtained. In  a separate experiment we use a training set of one-dimensional Mondrians with either  linear illumination gradients or slowly varying sinusoidal illumination components  with random wavelength, phase and amplitude. The resulting filter is shown in  the inset. The surrounds of both filters extend beyond the range we can estimate  reliably, the range we show here.  to slow gradients of illumination and preserves intermediate frequencies due to step  changes in refiectance. In contrast, the operator that recovers the illumination, e.  takes the form of a low-pa.ss filter. We stress that the entire operator L is not a  space-invariant filter.  In this context, it is clear that the shape of the estimated operator should vary with  the type of illumination gradient in the training set. We synthesize a second operator  using a new set of examples that contain equal numbers of vectors with random, sinusoldally varying illumination components and vectors with random, linear illumination  gradients. Whereas the first operator, synthesized from examples with strictly linear  illumination gradients, has a broad negative surround that remains virtually constant  throughout its extent, the new operator's surround (Fig. 2, inset) has a smaller extc.t  627  and decays smoothly towards zero from its peak negative value in its center.  We also apply the operator in Fig. 2 to new input vectors in which the density  and amplitude of the step changes of reflectance differ greatly from those on which the  operator is trained. The operator performs well, for example, on an input vector representing one column of an image of a small patch of one reflectance against a uniform  background of a different reflectance, the entire image under a linear illumination gradient. This result is consistent with psychophysical experiments that show that color  constancy of a patch holds when its Mondrian background is replaced by an equivalent  grey background 20  The operator also produces simultaneous brightness contrast, as expected from the  shape and sign of its surround. The output reflectance it computes for a patch of fixed  input reflectance decreases linearly with increasing average irradiance of the input test  vector in which the patch appears. Similarly, to us, a dark patch appears darker when  against a light background than against a dark one.  This result takes one step towards explaining such illusions as the Koffka Ring 21  A uniform gray annulus against a bipartite background (Fig. 3a) appears to split into  two halves of different lightnesses when the midline between the light and dark halves  of the background is drawn across the annulus (Fig. 3b). The estimated operator  acting on the Koffka Ring of Fig. 3b reproduces our perception by assigning a lower  output reflectance to the left half of the annulus (which appears darker to us) than to  the right half 2 Yet the operator gives this brightness contrast effect whether or not  the midline is drawn across the annulus (Fig. 3c). Because the operator can perform  only a linear transformation between the input and output images, it is not surprising  that the addition of the midline in the input evokes so little change in the output.  These results demonstrate that the linear operator alone cannot compute lightness in  all worlds and suggest that an additional operator might be necessary to mark and  guide it within bounded regions.  Our estimation procedure is motivated by our previous observation 9,23,s that  standard regularization algorithms 9 in early vision define linear mappings between  input and output and therefore can be estimated sociatively under certain conditions. The technique of optimal linear estimation that we use is closely related to  optimal Bayesian estimation 9. If we were to ax, sume from the start that the optimal  linear operator is space-invariant, we could considerably simplify (and streamline) the  computation by using standard correlation techniques 9.4  How does our estimation technique compare with other methods of "learning" a  lightness algorithm? We can compute the regularized pseudoinverse using gratient  descent on a "neural" network s with linear unit. Since the pseudoinverse is the  unique best linear approximation in the L2 norm, a graillent descent method that  628  minimizes the square error between the actual output and desired output of a fully  connected linear network is guaranteed to converge, albeit slowly. Thus gradient descent in weight space converges to the same result as our first technique, the global  nfinimum.  input data pixel  output reflectance with edge  output reflectance without edge  Fig. 3. (a) Koffka Ring. (b) Koffka Ring with  midline drawn across annulus. (c) Horizontal  scan lines across Koffka Ring. Top: Scan  line starting at arrow in (b). Middle: Scan  line at corresponding location in the output of  linear operator acting on (b). Bottom: Scan line  at same location in the output of operator acting  on (a).  629  We also compare the linear estimation technique with a "backpropagation" network: gradient descent on a 2-layer network with sigmoid units 25 (32 inputs, 32  "hidden units", and 32 linear outputs), using training vectors 32 pixels long. The network requires an order of magnitude more time to converge to a stable configuration  than does the linear estimator for the same set of 32-pixel examples. The network's  performance is slightly, yet consistently, better, neasured as the root-mean-square error in output, averaged over sets of at least 2000 new input vectors. Interestingly, the  backpropagation network and the linear estinator err in the sane way on the same  input vectors. It is possible that the backpropagation network may show considerable  inprovement over the linear estimator in a world more complex than the Mondrian one.  We are presently examining its performance on images with real-world features such  as shading, shadows, and highlights 26.  We do not think that our results mean that color constancy may be learned during  a critical period by biological organisms. It seems more reasonable to consider them  simply as a demonstration on a toy world that in the course of evolution a visual system  may recover and exploit natural constraints hidden in the physics of the world. The  significance of our results lies in the facts that a simple statistical technique may be used  to synthesize a lightness algorithm from examples; that the technique does as well as  other techniques such as backpropagation; and that a similar technique may be used for  other problems in early vision. Furthermore, the synthesized operator resembles both  Land's psychophysically-tested retinex operator and a neuronal nonclassical receptive  field. The operator's properties suggest that simultaneous color (or brightness) contrast  might be the result of the visual system's attempt to discount illumination gradients  27  REFERENCES AND NOTES
Error propagation nets have been shown to be able to learn a variety of tasks in  which a static input pattern is mapped onto a static output pattern. This paper  presents a generalisation of these nets to deal with time varying, or dynanic  patterns, and three possible architectures are explored. As an example, dynanic  nets are applied to the problem of speech coding, in which a time sequence of  speech data are coded by one net and decoded by another. The use of dynamic  nets gives a better signal to noise ratio than that achieved using static nets.
This research investigates a new technique for unsupervised learning of nonlinear  control problems. The approach is applied both to Michie and Chambers BOXES  algorithm and to Barto, Sutton and Anderson's extension, the ASE/ACE system, and  has significantly improved the convergence rate of stochastically based learning  automata.  Recurrence learning is a new nonlinear reward-penalty algorithm. It exploits  information found during learning trials to reinforce decisions resulting in the  recurrence of nonfailing states. Recurrence learning applies positive reinforcement  during the exploration of the search space, whereas in the BOXES or ASE algorithms,  only negative weight reinforcement is applied, and then only on failure. Simulation  results show that the added information from recurrence learning increases the learning  rate.  Our empirical results show that recurrence learning is faster than both basic failure  driven learning and failure prediction methods. Although recurrence learning has only  been tested in failure driven experiments, there are goal directed learning applications  where detection of recurring oscillations may provide useful information that reduces  the learning time by applying negative, instead of positive reinforcement.  Detection of cycles provides a heuristic to improve the balance between evidence  gathering and goal directed search. 
Coarse-coded symbol memories have appeared in several neural network  symbol processing models. In order to determine how these models would scale, one  must first have some understanding of the mathematics of coarse-coded representations. We define the general structure of coarse-coded symbol memories and derive  mathematical relationships among their essential parameters: memort size, slmbol-set  size and capacitor. The computed capacity of one of the schemes agrees well with actual  measurements of the coarse-coded working memory of DCPS, Touretzky and Hinton's  distributed connectionist production system.
Recent experimental work on the stimulus velocity dependent time resolving  power of the neural units, situated in the highest order optic ganglion of the  blowfly, revealed the at first sight amazing phenomenon that at this high level of  the fly visual system, the time constants of these units which are involved in the  processing of neural activity evoked by moving objects, are -roughly spokeninverse proportional to the velocity of those objects over an extremely wide range.  In this paper we will discuss the implementation of a two dimensional heterodyne  adaptive filter construction into a computer simulation model. The features of this  simulation model include the ability to account for the experimentally observed  stimulus-tuned adaptive temporal behaviour of time constants in the fly visual  system. The simulation results obtained, clearly show that the application of such  an adaptive processing procedure delivers an improved imaging technique of  moving patterns in the high velocity range.  A FEW REMARKS ON THE FLY VISUAL SYSTEM  The visual system of the diptera, including the blowfly Calliphora  erythrocephala (Mg.) is very regularly organized and allows therefore very precise  optical stimulation techniques. Also, long term electrophysiological recordings can  be made relatively easy in this visual system. For these reasons the blowfly (which  is well-known as a very rapid and 'clever' pilot) turns out to be an extremely  suitable animal for a systematic study of basic principles that may underlie the  detection and further processing of movement information at the neural level.  In the fly visual system the input retinal mosaic structure is precisely  mapped onto the higher order optic ganglia (lamina, medulla, lobula). This means  that each neural column in each ganglion in this visual system corresponds to a  certain optical axis in the visual field of the compound eye. In the lobula complex  a set of wide-field movement sensitive neurons is found, each of which integrates  the input signals over the whole visual field of the entire eye. One of these wide  field neurons, that has been classified as H1 by Hausen I has been extensively  studied both anatomically 2, 3, 4 as well as electrophysiologically 5, 6, 7 The  obtained results generally agree very well with those found in behavioral  optomotor experiments on movement detection 8 and can be understood in terms of  Reichardts correlation model 9, 10  The H1 neuron is sensitive to horizontal movement and directionally  selective: very high rates of action potentials (spikes) up to 300 per second can be  recorded from this element in the case of visual stimuli which move horizontally  inward, i.e. from back to front in the visual field (preferred direction), whereas  movement horizontally outward, i.e. from front to back (null direction) suppresses  its activity.  American Institute of Physics 1988  663  EXPERIMENTAL RESULTS AS A MODELLING BASE  When the H1 neuron is stimulated in its preferred direction with a step wise  pattern displacement, it will respond with an increase of neural activity. By  repeating this stimulus step over and over one can obtain the averaged response:  after a 20 ms latency period the response manifests itself as a sharp increase in  average firing rate followed by a much slower decay to the spontaneous activity  level. Two examples of such averaged responses are shown in the Post Stimulus  Time Histograms (PSTH's) of figure 1. Time to peak and peak height are related  and depend on modulation depth, stimulus step size and spatial extent of the  stimulus. The tail of the responses can be described adequately by an exponential  decay toward a constant spontaneous firing rate:  R(t)=c+a ß e(-t/r)  (l)  For each setting of the stimulus parameters, the response parameters,  defined by equation (1), can be estimated by a least-squares fit to the tail of the  PSTH. The smooth lines in figure 1 are the results of two such fits.  1%0 = . ø/  50  150 W= IIø/s  s0lt'!  o 200 oo 6oo 80o  hrne Irnsl  t(ms)  300  3O  ß M=0.40  o M=010   M =o 05  o  o  o  0.3 I 3 I00 300  W {'Is )  Fig. 1  Fig.2  Averaged responses (PSTH's) obtained from the H1 neuron, being  adapted to smooth stimulus motion with velocities 0.36ø/s (top) and  11 ø/s (bottom) respectively. The smooth lines represent least-squares  fits to the PSTH's of the form R(t)=c+a.e(-t/r). Values of r for the  two PSTH's are 331 and 24 ms respectively (de Ruyter van Steveninck et  al.7).  Fitted values of r as a function of adaptation velocity for three  modulation depths M. The straight line is a least-squares fit to represent  the data for M=0.40 in the region w=0.3-100ø/s. It has the form  r=a.w-/ with a=150 ms and/=0.7 (de Ruyter van Steveninck et al.7).  664  Figure 2 shows fitted values of the response time constant r as a function of  the angular velocity of a moving stimulus (a square wave grating in most  experiments) which was presented to the animal during a period long enough to let  its visual system adapt to this moving pattern and before the step wise pattern  displacement (which reveals r) was given. The straight line, described by  (2)  (with W in ø/s and y in ms) represents a least-squares fit to the data over the  velocity range from 0.36 to 125 ø/s. For this range, r varies from 320 to roughly  10 ms, with a--150__10 ms and /=0.7_0.05. Defining the adaptation range of r as  that interval of velocities for which r decreases with increasing velocity, we may  conclude from figure 2 that within the adaptation range, y is not very sensitive to  the modulation depth.  The outcome of similar experiments with a constant modulation depth of the  pattern (M=0.40) and a constant pattern velocity but with four different values of  the contrast frequency fc (i.e. the number of spatial periods per second that  traverse an individual visual axis as determined by the spatial wavelength ns of the  pattern and the pattern velocity v according to fc=V/s) reveal also an almost  complete independency of the behaviour of y on contrast frequency. Other  experiments in which the stimulus field was subdivided into regions with different  adaptation velocities, made clear that the time constants of the input channels of  the H1 neuron were set locally by the values of the stimulus velocity in each  stimulus sub-region. Finally, it was found that the adaptation of y is driven by  the stimulus velocity, independent of its direction.  These findings can be summarized qualitatively as follows: in steady state,  the response time constants y of the neural units at the highest level in the fly  visual system are found to be tuned locally within a large velocity range  exclusively by the magnitude of the velocity of the moving pattern and not by its  direction, despite the directional selectivity of the neuron itself. We will not go  into the question of how this amazing adaptive mechanism may be hard-wired in  the fly visual system. Instead we will make advantage of the results derived thus  far and attempt to fit the experimental observations into an image processing  approach. A large number of theories and several distinct classes of algorithms to  encode velocity and direction of movement in visual systems have been suggested  by, for example, Marr and Ullman 11 and van Santen and Sperling 12  We hypothesize that the adaptive mechanism for the setting of the time  constants leads to an optimization for the overall performance of the visual system  by realizing a velocity independent representation of the moving object. In other  words: within the range of velocities for which the time constants are found to be  tuned by the velocity, the representation of that stimulus at a certain level within  the visual circuitry, should remain independent of any variation in stimulus  velocity.  OBJECT MOTION DEGRADATION: MODELLING  Given the physical description of motion and a linear space invariant model,  the motion degradation process can be represented by the following convolution  integral: oo oo  g(x,y)--f ;(h(x-u,y-v) ß f(u,v)) dudv (3)  665  where f(u,v) is the object intensity at position (u,v) in the object coordinate  frame, h(x-u,y-v) is the Point Spread Function (PSF) of the imaging system,  which is the response at (x,y) to a unit pulse at (u,v) and g(x,y) is the image  intensity at the spatial position (x,y) as blurred by the imaging system. Any  possible additive white noise degradation of the already motion blurred image is  neglected in the present considerations.  For a review of principles and techniques in the field of digital image  degradation and restoration, the reader is referred to Harris 13, Sawchuk TM,  Sondhi 15, Nahi 16, Aboutalib eta/. 17, 18, Hildebrand19, Rajala de Figueiredo 20  It has been demonstrated first by Aboutalib et al. 17 that for situations in which  the motion blur occurs in a straight line along one spatial coordinate, say along the  horizontal axis, it is correct to look at the blurred image as a collection of  degraded line scans through the entire image. The dependence on the vertical  coordinate may then be dropped and eq. (3) reduces to:  g(x) h(x-u) ø f(u)du (4)  Given the mathematical description of the relative movement, the  corresponding PSF can be derived exactly and equation (4) becomes:  g(x)= fR h<xu) ß f(u)du (5)  where R is the extent of the motion blur. Typically, a discrete version of (5),  applicable for digital image processing purposes, is described by:  L  g(k)--T. h(k-1)-f(1) ; k=l .... ,N (6)  1  where k and 1 take on integer values and L is related to the motion blur extent.  According to Aboutalib et al. 18 a scalar difference equation model (M,a,b,c)  can then be derived to model the motion degradation process:  x(k+l) = M ß x(k)+a ß f(k)  g(k) = b-x(k)+c-f(k) ; k=l,...,N  (7)  h(i) = coA(i)+clA(i -1)+ ...... +Cm.(i-m)  where x(k) is the m-dimensional state vector at position k along a scan line, f(k) is  the input intensity at position k, g(k) is the output intensity, m is the blur extent,  N is the number of elements in a line, c is a scalar, M, a and b are constant  matrices of order (mxm), (mxl) and (lxm) respectively, containing the discrete  values cj of the blurring PSF h(j) for j=0,...,m and/(.) is the Kronecker delta  function.  666  INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY  ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL  RECEPTOR ARRAY  To start with, we incorporate in our simulation model a PSF, derived from  equation (1), to model the performance of all neural columnar arranged filters in  the lobula complex, with the restriction that the time constants r remain fixed  throughout the whole range of stimulus velocities. Realization of this PSF can  easily be achieved via the just mentioned state space model.  300  250  200  150  10o  50   0  250  " 200  150  10o  5O  0 5 10 15 20  POSITION IN  ARTIFICIAL RECEPTOR ARRAY  Fig.3  upper part. Demonstration of the effect that an increase in magnitude of  the time constants of an one-dimensional array of filters will result in  increase in motion blur (while the pattern velocity remains constant).  Original pattern shown in solid lines is a square-wave grating with a  spatial wavelength equal to 8 artificial receptor distances. The three  other wave forms drawn, show that for a gradual increase increase in  magnitude of the time constants, the representation of the original  square-wave will consequently degrade. lower part. A gradual increase in  velocity of the moving square-wave (while the filter time constants are  kept fixed) results also in a clear increase of degradation.  667  First we demonstrate the effect that an increase in time constant (while the  pattern velocity remains the same) will result in an increase in blur. Therefore we  introduce an one dimensional array of filters all being equipped with the same  time constant in their impulse response. The original pattern shown in square and  solid lines in the upper part of figure 3 consists of a square wave grating with a  spatial period overlapping 8 artificial receptive filters. The 3 other patterns drawn  there show that for the same constant velocity of the moving grating, an increase  in the magnitude of the time constants of the filters results in an increased blur in  the representation of that grating. On the other hand, an increase in velocity  (while the time constants of the artificial receptive units remain the same) also  results in a clear increase in motion blur, as demonstrated in the lower part of  figure 3.  Inspection of the two wave forms drawn by means of the dashed lines in  both upper and lower half of the figure, yields the conclusion, that (apart from  rounding errors introduced by the rather small number of artificial filters  available), equal amounts of smear will be produced when the product of time  constant and pattern velocity is equal. For the upper dashed wave form the  velocity was four times smaller but the time constant four times larger than for its  equivalent in the lower part of the figure.  ADAPTIVE SCHEME  In designing a proper image processing procedure our next step is to  incorporate the experimentally observed flexibility property of the time constants  in the imaging elements of our device. In figure 4 a a scheme is shown, which  filters the information with fixed time constants, not influenced by the pattern  velocity. In figure 4 b a network is shown where the time constants also remain  fixed no matter what pattern movement is presented, but now at the next level of  information processing, a spatially differential network is incorporated in order to  enhance blurred contrasts.  In the filtering network in figure 4 c, first a measurement of the magnitude  of the velocity of the moving objects is done by thus far hypothetically introduced  movement processing algorithms, modelled here as a set of receptive elements  sampling the environment in such a manner that proper estimation of local pattern  velocities can be done. Then the time constants of the artificial receptive elements  will be tuned according to the estimated velocities and finally the same  differential network as in scheme 4 b, is used.  The actual tuning mechanism used for our simulations is outlined in figure  $: once given the range of velocities for which the model is supposed to be  operational, and given a lower limit for the time constant min (min can be the  smallest value which physically can be realized), the time constant will be tuned to  a new value according to the experimentally observed reciprocal relationship, and  will, for all velocities within the adaptive range, be larger than the fixed minimum  value. As demonstrated in the previous section the corresponding blur in the  representation of the moving stimulus will thus always be larger than for the  situation in which the filtering is done with fixed and smallest time constants  'min. More important however is the fact that due to this tuning mechanism the  blur will be constant since the product of velocity and time constant is kept  constant. So, once the information has been processed by such a system, a velocity  independent representation of the image will be the result, which can serve as the  input for the spatially differentiating network as outlined in figure 4 c.  The most elementary form for this differential filtering procedure is the one  668  in which the gradient of two filters K-I and K+I which are the nearest neighbors  of filter K, is taken and then added with a constant weighing factor to the central  output K as drawn in figure 4 b and 4 c, where the sign of the gradient depends on  the direction of the estimated movement. Essential for our model is that we claim  that this weighing factor should be constant throughout the whole set of filters  and for the whole high velocity range in which the heterodyne imaging has to be  performed. Important to notice is the existence of a so-called settling time, i.e. the  minimal time needed for our movement processing device to be able to accurately  measure the object velocity. [Note: this time can be set equal to zero in the case  that the relative stimulus velocity is known a priori, as demonstrated in figure 3].  Since, without doubt, within this settling period estimated velocity values will  come out erroneously and thus no optimal performance of our imaging device can  be expected, in all further examples, results after this initial settling procedure  will be shown. 2 3  5  Fig. 4  B-'  C.'  r  "--  Pattern movement in this figure s to the right.  A: Network consisting of a set of filters with a fixed, pattern velocity  independent, time constant in their impulse response.  Identical network as in figure 4A now followed by a spatially  differentiating circuitry which adds the weighed gradients of two  neighboring filter outputs K-I and K+I to the central filter output  K.  The time constants of the filtering network are tuned by a  hypothetical movement estimating mechanism, visualized here as a  number of receptive elements, of which the combined output tunes  the filters. A detailed description of this mechanism is shown in  figure 5. This tuned network is followed by an identical spatially  differentiating circuit as described in figure 4B.  669  Fig. 5  increasing velocity  decreasing time constant  (ø/sl  Detailed description of the mechanism used to tune the time constants.  The time constant  of a specific neural channel is set by the pattern  velocity according to the relationship shown in the insert, which is  derived from eq. (2) with cz=l and /=1.  ta, J  POSITION IN ARTIFICIAL RECEPTOR ARRAY  Fig.6  Thick lines: square-wave stimulus pattern with a spatial wavelength  overlapping 32 artificial receptive elements. Thick lines: responses for 6  different pattern velocities in a system consisting of paralleling neural  filters equipped with time constants, tuned by this velocity, and followed  by a spatially differentiating network as described.  Dashed lines: responses to the 6 different pattern velocities in a filtering  system with fixed time constants, followed by the same spatial  differentiating circuitry as before. Note the sharp overand under  shoots for this case.  670  Results obtained with an imaging procedure as drawn in figure 4 b and 4 c  are shown in figure 6. The pattern consists of a square wave, overlapping 32  picture elements. The pattern moves (to the left) with 6 different velocities v, 2v,  4v, 8v, 12v, 16v. At each velocity only one wavelength is shown. Thick lines:  square wave pattern. Dashed lines: the outputs of an imaging device as depicted in  figure 4b: constant time constants and a constant weighing factor in the spatial  processing stage. Note the large differences between the several outputs. Thin  continuous lines: the outputs of an imaging device as drawn in figure 4c: tuned  time constants according to the reciprocal relationship between pattern velocity  and time constant and a constant weighing factor in the spatial processing stage.  For further simulation details the reader is referred to Zaagman et al. 21. Now the  outputs are almost completely the same and in good agreement with the original  stimulus throughout the whole velocity range.  Figure 7 shows the effect of the gradient weighing factor on the overall  filter performance, estimated as the improvement of the deblurred images as  compared with the blurred image, measured in dB. This quantitative measure has  been determined for the case of a moving square wave pattern with motion blur  o  Fig. 7  -1 i i i  0 1 2 3 +  weighing factor =  Effect of the weighing factor on the overall filter performance. Curve  measured for the case of a moving square-wave grating. Filter  performance is estimated as the improvement in signal to noise ratio:  i=10. 101og ( 'i"J ((v(i'J)u(i'J))  1  .iZj((a(i,j)-u(i,j))'  where u(i,j) is the original intensity at position (i,j) in the image, v(i,j)  is the intensity at the same position (i,j) in the motion blurred image and  a(i,j) is the intensity at (i,j) in the image, generated with the adaptive  tuning procedure.  671  extents comparable to those used for the simulations to be discussed in section IV.  From this curve it is apparent that for this situation there is an optimum value for  this weighing factor. Keeping the weight close to this optimum value will result in  a constant output of our adaptive scheme, thus enabling an optimal deblurring of  the smeared image of the moving object.  On the other hand, starting from the point of view that the time constants  should remain fixed throughout the filtering process, we should had have to tune  the gradient weights to the velocity in order to produce a constant output as  demonstrated in figure 6 where the dashed lines show strongly differing outputs of  a fixed time constant system with spatial processing with constant weight (figure  4b). In other words, tuning of the time constants as proposed in this section results  in: 1) the realization of the blur-constancy criterion as formulated previously, and  2) -as a consequencethe possibility to deblur the obtained image optimally with  one and the same weighing factor of the gradient in the final spatial processing  layer over the whole heterodyne velocity range.  COMPUTER SIMULATION RESULTS AND  CONCLUSIONS  The image quality improvement algorithm developed in the present  contribution has been implemented on a general purpose DG Eclipse S/140 minicomputer for our two dimensional simulations. Figure 8 a shows an undisturbed  image, consisting of 256 lines of each 256 pixels, with 8 bit intensity resolution.  Figure 8 b shows what happens with the original image if the PSF is modelled  according to the exponential decay (2). In this case the time constants of all  spatial information processing channels have been kept fixed. Again, information  content in the higher spatial frequencies has been reduced largely. The  implementation of the heterodyne filtering procedure was now done as follows:  first the adaptation range was defined by setting the range of velocities. This  means that our adaptive heterodyne algorithm is supposed to operate adequately  only within the thus defined velocity range and that -in that rangethe time  constants are tuned according to relationship (2) and will always come out larger  than the minimum value rmi n. For demonstration purposes we set o=1 and B--1 in  eq. (2), thus introducing the phenomenon that for any velocity, the two  dimensional set of spatial filters with time constants tuned by that velocity, will  always produce a constant output, independent of this velocity which introduces  the motion blur. Figure 8 c shows this representation. It is important to note here  that this constant output has far more worse quality than any set of filters with  smallest and fixed time constants rmin would produce for velocities within the  operational range. The advantage of a velocity independent output at this level in  our simulation model, is that in the next stage a differential scheme can be  implemented as discussed in detail in the preceding paragraph. Constancy of the  weighing factor which is used in this differential processing scheme is guaranteed  by the velocity independency of the obtained image representation.  Figure 8 d shows the result of the differential operation with an optimized  gradient weighing factor. This weighing factor has been optimized based on an  almost identical performance curve as described previously in figure 7. A clear  and good restoration is apparent from this figure, though close inspection reveals  fine structure (especially for areas with high intensities) which is unrelated with  the original intensity distribution. These artifacts are caused by the phenomenon  that for these high intensity areas possible tuning errors will show up much more  pronounced than for low intensities.  672  c  Fig. 8a  Fig. 8b  Fig. 8c  Fig. 8d  Original 256x256x8 bit picture.  Motion degraded image with a PSF derived from R(t)=c+a-e(-t/'),  where ' is kept fixed to 12 pixels and the motion blur extent is 32  pixels.  Worst case, i.e. the result of motion degradation of the original image  with a PSF as in figure 8 b, but with tuning of the time constants based  on the velocity.  Restored version of the degraded image using the heterodyne adaptive  processing scheme.  In conclusion: a heterodyne adaptive image processing technique, inspired by  the fly visual system, has been presented as an imaging device for moving objects.  A scalar difference equation model has been used to represent the motion blur  degradation process. Based on the experimental results described and on this state  space model, we developed an adaptive filtering scheme, which produces at a  certain level within the system a constant output, permitting further differential  operations in order to produce an optimally aleblurred representation of the  moving object.  ACKNOWLEDGEMENTS  The authors wish to thank mr. Eric Bosman for his expert programming  673  assistance, mr. Franco Tommasi for many inspiring discussions and advises during  the implementation of the simulation model and dr. Rob de Ruyter van Steveninck  for experimental help. This research was partly supported by the Netherlands  Organization for the Advancement of Pure Research (Z.W.O.) through the  foundation Stichting voor Biofysica.  REFERENCES
The study of distributed memory systems has produced a  number of models which work well in limited domains.  However, until recently, the application of such systems to realworld problems has been difficult because of storage limitations,  and their inherent architectural (and for serial simulation,  computational) complexity. Recent development of memories  with unrestricted storage capacity and economical feedforward  architectures has opened the way to the application of such  systems to complex pattern recognition problems. However,  such problems are sometimes underspecified by the features  which describe the environment, and thus a significant portion  of the pattern environment is often non-separable. We will  review current work on high density memory systems and their  network implementations. We will discuss a general learning  algorithm for such high density memories and review its  application to separable point sets. Finally, we will introduce an  extension of this method for learning the probability  distributions of non-separable point sets.
A single cell theory for the development of selectivity and  ocular dominance in visual cortex has been presented previously  by Bienenstock, Cooper and Munro 1. This has been extended to a  network applicable to layer IV of visual cortex2. In this paper  we present a mean field approximation that captures in a fairly  transparent manner the qualitative, and many of the  quantitative, results of the network theory. Finally, we consider  the application of this theory to artificial neural networks and  show that a significant reduction in architectural complexity is  possible.  A SINGLE LAYER NETWORK AND THE MEAN FIELD  APPROXIMATION  We consider a single layer network of ideal neurons which  receive signals from outside of the layer and from cells within  the layer (Figure 1). The activity of the ith cell in the network is  ci =mi d+ ELij cj. (1)  J  d is a vector of afferent signals to the network. Each cell  receives input from n fibers outside of the cortical network  through the matrix of synapses mi. Intra-layer input to each cell  is then transmitted through the matrix of cortico-cortical  synapses L.  American Institute of Physics 1988  684  Afferent  Signals  d  m 1  Figure 1: The general single layer recurrent  network. Light circles are the LGN-cortica!  synapses. Dark circles are the (nonmodifiable) cortico-cortical synapses.  We now expand the response of the ith cell into individual  terms describing the number of cortical synapses traversed by  the signal d before arriving through synapses Lij at cell i.  Expanding cj in (1), the response of cell i becomes  c i = m i d + Z Lij mjd + Z Lij Ljk mk d + Z Lij [Ljk  Lkn mn d +... (2)  J j j n  Note that each term contains a factor of the form   Lqp mpd.  P  This factor describes the first order effect, on cell q, of the  cortical transformation of the signal d. The mean field  approximation consists of estimating this factor to be a constant,  independant of cell location   Lqp mpd = N fnd L o = constant.  p  (3)  685  This assumption does not imply that each cell in the network is  selective to the same pattern, (and thus that m i = mj ). Rather,  the assumption is that the vector sum is a constant  (  Lqp mp) d = (N fn L o) d.  P  This amounts to assuming that each cell in the network is  surrounded by a population of cells which represent, on average,  all possible pattern preferences. Thus the vector sum of the  afferent synaptic states describing these pattern preferences is a  constant independent of location.  Finally, if we assume that the lateral connection strengths are  a function only of i-j then Lij becomes a circular matrix so that   Lij =  Lji = L o = constant.   j  Then the response of the cell i becomes  ci=mi d +(Io+Io2+...)fnd.  (4)  -mid + (N L o/(1L o )) ,  for l Iol < 1  where we define the spatial average of cortical cell activity  = fn  d, and N is the average number of intracortical synapses.  Here, in a manner similar to that in the theory of magnetism,  we have replaced the effect of individual cortical cells by their  average effect (as though all other cortical cells can be replaced  by an 'effective' cell, figure 2). Note that we have retained all  orders of synaptic traversal of the signal d.  Thus, we now focus on the activity of the layer after  'relaxation' to equilibrium. In the mean field approximation we  can therefore write  where the mean field  with  = (miIx) d (5)  /x =arh  a = N ILol (1 + ILol)-l,  686  and we asume that  inhibitory).  L o < 0 (the network is, on average,  Afferent  Signals  d  m 1 m n  L o
We have developed a methodology for manually training autonomous control systems  based on artificial neural systems (ANS). In applications where the rule set governing an expert's  decisions is difficult to formulate, ANS can be used to extract rules by associating the information  an expert receives with the actions he. takes. Properly constructed networks imitate rules of  behavior that permits them to function autonomously when they are trained on the spanning set  of possible situations. This training can be provided manually, either under the direct supervision  of a system trainer, or indirectly using a background mode where the network assimilates training  data as the expert performs his day-to-day tasks. To demonstrate these methods we have trained  an ANS network to drive a vehicle through simulated freeway traffic.
The ability to obtain three-dimensional structure from visual motion is  important for survival of human and non-human primates. Using a parallel processing model, the current work explores how the biological visual system might solve  this problem and how the neurophysiologist might go about understanding the  solution.
Self-organization of multi-layered networks can be realized  by time-sequential organization of successive neural layers.  Lateral inhibition operating in the surround of firing cells in  each layer provides for unsupervised capture of excitation  patterns presented by the previous layer. By presenting patterns  of increasing complexity, in co-ordination with network selforganization, higher levels of the hierarchy capture concepts  implicit in the pattern set.
A synthetic neural network simulation of cerebral neocortex was  developed based on detailed anatomy and ph. ysiology. Processing elements  possess temporal nonlinearities and connecuon patterns similar to those of  cortical neurons. The network was able to replicate spatial and temporal  integration properties found experimentally in neocortex. A certain level of  randomness was found to be crucial for the robustness of at least some of  the network's computational capabilities. Emphasis was placed on how  synthetic simulations can be of use to the study of both artificial and  biological neural networks.  A variety of fields have benefited from the use of computer simulations. This is  true in spite of the fact that general theories and conceptual models are lacking in many  fields and conlzasts with the use of simulations to explore existing theoretical structures that  are extremely complex (cf. MacGregor and Lewis, 1977). When theoretical  superstructures are missing, simulations can be used to synthesize empirical findings into a  system which can then be studied analytically in and of itself. The vast compendium of  neuroanatomical and neurophysiological data that has been collected and the concomitant  absence of theories of brain function (Crick, 1979; Lewin, 1982) makes neuroscience an  ideal candidate for the application of synthetic simulations. Furthermore, in keeping with  the spirit of this meeting, neural network simulations which synthesize biological data can  make contributions to the study of artificial neural systems as general information  processing machines as well as to the study of the brain. A synthetic simulation of cerebral  neocortex is presented here and is intended to be an example of how traffic might flow on  the two-way street which this conference is trying to build between artificial neural network  modelers and neuroscientists.  The fact that cerebral neocortex is involved in some of the highest forms of  information processing and the fact that a wide variety of neurophysiological and  neuroanatomical data are amenable to simulation motivated the present development of a  synthetic simulation of neocortex. The simulation itself is comparatively simple;  nevertheless it is more realistic in terms of its structure and elemental processing units than  most artificial neural networks.  The neurons from which our simulation is constructed go beyond the simple  sigmoid or hard-saturation nonlinearities of most artificial neural systems. For example,  717  because inputs to actual neurons are mediated by ion currents whose driving force depends  on the membrane potential of the neuron, the amplitude of a cell's response to an input, i.e.  the amplitude of the post-synaptic potential (PSP), depends not only on the strength of the  synapse at which the input arrives, but also on the state of the neuron at the time of the  input's arrival. This aspect of classical neuron electrophysiology has been implemented in  our simulation (figure 1A), and leads to another important nonlinearity of neurons:  namely, current shunting. Primarily effective as shunting inhibition, excitatory current can  be shunted out an inhibitory synapse so that the sum of an inhibitory postsynaptic potential  and an excitatory postsynaptic potential of equal amplitude does not result in mutual  cancellation. Instead, interactions between the ion reversal potentials, conductance values,  relative timing of inputs, and spatial locations of synapses determine the amplitude of the  response in a nonlinear fashion (figure lB) (see Koch, Poggio, and Torre, 1983 for a  quantitative analysis). These properties of actual neurons have been ignored by most  artificial neural network designers, though detailed knowledge of them has existed for  decades and in spite of the fact that they can be used to implement complex computations  (e.g. Torre and Poggio, 1978; Houchin, 1975).  The development of action potentials and spatial interactions within the model  neurons have been simplified in our simulation. Action potentials involve preprogrmm'ned  fluctuations in the membrane potential of our neurons and result in an absolute and a  relative refractory period. Thus, during the time a cell is fh'ing a spike synaptic inputs are  ignored, and immediately following an action potential the neuron is hyperpolarized. The  modeling of spatial interactions is also limited since neurons are modeled primarily as  spheres. Though the spheres can be deformed through control of a synaptic weight which  modulates the amplitudes of ion conductances, detailed dendritic interactions are not  simulated. Nonetheless, the fact that inhibition is generally closer to a cortical neuron's  soma while excitation is more distal in a celrs dendritic tree is simulated through the use of  sUronger inhibitory synapses and relatively weaker excitatory synapses.  The relative strengths of synapses in a neural network define its connectivity.  Though initial connectivity is random in many artificial networks, brains can be thought to  contain a combination of randomness and fixed structure at distinct levels (Szentagothai,  1978). From a macroscopic perspective, all of cerebral neocortex might be structured in a  modular fashion analogous to the way the barrel field of mouse somatosensory cortex is  structured (Woolsey and Van der Loos, 1970). Though speculative, arguments for the  existence of some sort of anatomical modularity over the entire cortex are gaining ground  718  (Mountcastle, 1978; Szentagothai, 1979; Shepherd, in press). Thus, inspired by the  ban'els of mice and by growing interest in functional units of 50 to 100 microns with on the  order of 1000 neurons, our simulation is built up of five modules (60 cells each) with more  dense local interconnections and fewer intermodular contacts. Furthermore, a wide variety  of neuronal classification schemes have led us to subdivide the gross structure of each  module so as to contain four classes of neurons: cortico-cortical pyramids, output  pyramids, spiny stellate or local excitatory cells, and GABAergic or inhibirtory cells.  At this level of analysis, the impressed structure allows for control over a variety of  pathways. In our simulation each class of neurons within a module is connected to every  other class and intermodular connections are provided along pathways from cortico-cortical  pyramids to inhibitory cells, output pyramids, and cortico-cortical pyramids in immediately  adjacent modules. A general sense of how strong a pathway is can be inferred from the  product of the number of synapses a neuron receives from a particular class and the  strength of each of those synapses. The broad architecture of the simulation is further  structured to emphasize a three step path: Inputs to the network impact most su:ongly on  the spiny stellate cells of the module receiving the input; these cells in turn project to  cortico-cortical pyramidal cells more strongly than they do to other cell types; and finally,  the pathway from the cortico-cortical pyramids to the output pyramidal cells of the same  module is also particularly strong. This general architecture (figure 2) has received  empirical support in many regions of cortex (Jones, 1986).  In distinction to this synaptic architecture, a fine-grain connectivity is defined in our  simulated network as well. At a more microscopic level, connectivity in the network is  random. Thus, within the confines of the architecture described above, the determination  of which neuron of a particular class is connected to which other cell in a target class is  done at random. Two distinct levels of connectivity have, therefore, been established  (figure 3). Together they provide a middle ground between the completely arbitrary  connectivity of many artificial neural networks and the problem specific connectivities of  other artificial systems. This distinction between gross synaptic architecture and fine-grain  connectivity also has intuitive appeal for theories of brain development and, as we shall  see, has non-trivial effects on the computational capabilities of the network as a whole.  With defintions for input integration within the local processors, that is within the  neurons, and with the establishment of connectivity patterns, the network is complete and  ready to perform as a computational unit. In order to judge the simulation's capabilities in  some rough way, a qualitative analysis of its response to an input will suffice. Figure 4  719  shows the response of the network to an input composed of a small burst of action  potentials arriving at a single module. The data is displayed as a raster in which time is  mapped along the abscissa and all the cells of the network are arranged by module and cell  class along the ordinate. Each marker on the graph represents a single action potential f'n'ed  by the appropriate neuron at the indicated time. Qualitatively, what is of importance is the  fact that the network does not remain unresponsive, saturate with activity in all neurons, or  oscillate in any way. Of course, that the network behave this way was predetermined by  the combination of the properties of the neurons with a judicious selection of synaptic  weights and path strengths. The properties of the neurons were fixed from physiological  data, and once a synaptic architecture was found which produced the results in figure 4,  that too was fixed. A more detailed analysis of the temporal firing pattern and of the  distribution of activity over the different cell classes might reveal important network  properties and the relative importance of various pathways to the overall function. Such an  analysis of the sensitivity of the network to different path sU:engths and even to intmcellular  parameters will, however, have to be postponed. Suffice it to say at this point that the  network, as structured, has some nonzero, finite, non-oscillatory response which,  qualitatively, might not offend a physiologist judging cortical activity.  Though the synaptic architecture was tailored manually and fixed so as to produce  "reasonable" results, the fine-grain connectivity, i.e. the determination of exactly which  cell in a class connects to which other cell, was random. An important property of artificial  (and presumably biological) neural networks can be uncovered by exploiting the distinction  between levels of connectivity described above. Before doing so, however, a detail of  neural network design must be made explicit. Any network, either artificial or biological,  must contend with the time it takes to communicate among the processing elements. In the  brain, the time it takes for an action potential to travel from one neuron to another depends  on the conduction velocity of the axon down which the spike is traveling and on the delay  that occurs at the synapse connecting the cells. Roughly, the total transmission time from  one cortical neuron to another lies between 1 and 5 milliseconds. In our simulation two  720  paradigms were used. In one case, the transmission times between all neurons were  standardized at 1 msec.* Alternatively, the transmission times were fixed at random,  though admittedly unphysiological, values between 0.1 and 2 msec.  Now, if the time it takes for an action potential to travel from one neuron to another  were fixed for all cells at 1 msec, different fine-grain connectivity patterns are found to  produce entirely distinct network responses to the same input, in spite of the fact that the  gross synaptic architecture remained constant. This was true no matter what particular  synaptic architecture was used. If, on the other hand, one changes the transmission times  so that they vary randomly between 0.1 and 2 msec, it becomes easy to find sets of  synaptic strengths that were robust with respect to changes in the fine-grain connectivity.  Thus, a wide search of path strengths failed to produce a network which was robust to  changes in fine-grain connectivity in the case of identical transmission times, while a set of  synaptic weights that produced robust responses was easy to find when the transmission  times were randomized. Figure 5 summarizes this result. In the figure overall network  activity is measured simply as the total number of action potentials generated by pyramidal  cells during an experiment and robustness can be judged as the relative stability of this  response. The abscissa plots distinct experiments using the same synaptic architecture with  different fine-grain connectivity patterns. Thus, though the synaptic architecture remains  constant, the different trials represent changes in which particular cell is connected to which  other cell. The results show quite dramatically that the network in which the transmission  times are randomly distributed is more robust with respect to changes in fine-grain  connectivity than the network in which the transmission times are all 1 msec.  It is important to note that in either case, both when the network was robust and  when changes of fine-grain connectivity produced gross changes in network output, the  synaptic architectures produced outputs like that in figure 4 with some fine-grain  connectivities. If the response of the network to an input can be considered the result of  * Because neurons receive varying amounts of input and because integration is performed  by summating excitatory and inhibitory postsynaptic potentials in a nonlinear way, the time  each neuron needs to summate its inputs and produce an action potential varies from neuron  to neuron and from time to time. This then allows for asynchronous firing in spite of the  identical transmission times.  721  some computation, figure 5 reveals that the same computational capability is not robust  with respect to changes in fine-grain connectivity when transmission times between  neurons are all 1 msec, but is more robust when these times are randomized. Thus, a  single computational capability, viz. a response like that in figure 4 to a single input, was  found to exist in networks with different synaptic architectures and different transmission  time paradigms; this computational capability, however, varied in terms of its robustness  with respect to changes in fine-grain connectivity when present in either of the transmission  time paradigms.  A more complex computational capability emerged from the neural network  simulation we have developed and described. If we label two neighboring modules C2 and  C3, an input to C2 will suppress the response of C3 to a second input at C3 if the second  input is delayed. A convenient way of representing this spatio-temporal integration  property is given in figure 6. The ordinate plots the ratio of the normal response of one  module (say C3) to the response of the module to the same input when an input to a  neighboring module (say C2) preceeds the input to the original module (C3). Thus, a value  of one on the ordinate means the earlier spatially distinct input had no effect on the response  of the module in which this property is being measured. A value less than one represents  suppression, while values greater than one represent enhancement. On the abscissa, the  interstimulus interval is plotted. From figure 6, it can be seen that significant suppression  of the pyramidal cell output, mostly of the output pyramidal cell output, occurs when the  inputs are separated by 10 to 30 msec. This response can be characterized as a sort of  dynamic lateral inhibition since an input is suppressing the ability of a neighboring region  to respond when the input pairs have a particular time course. This property could play a  variety of role in biological and artificial neural networks. One role for this spatio-temporal  integration property, for example, might be in detecting the velocity of a moving stimulus.  The emergent spatio-temporal property of the network just described was not  explicitly built into the network. Moreover, no set of synaptic weights was able to give rise  to this computational capability when transmission times were all set to 1 msec. Thus, in  addition to providing robustness, the random transmission times also enabled a more  complex property to emerge. The important factor in the appearances of both the  robustness and the dynamic lateral inhibition was randomization; though it was  implemented as randomly varying transmission times, random spontaneous activity would  have played the same role. From the viewpoint, then, of the engineer designing artificial  neural networks, the neural network presented here has instructional value in spite of the  722  fact that it was designed to synthesize biological data. Specifically, it motivates the  consideration of randomness as a design constraint.  From the prespective of the biologists attending this meeting, a simple fact will  reveal the importance of synthetic simulations. The dynamic lateral inhibition presented in  figure 6 is known to exist in rat somatosensory cortex (Simons, 1985). By deflecting the  whiskers on a rat's face, Simons was able to stimulate individual ban'els of the posteromedial somatosensory ban'el field in combinations which revealed similar spario-temporal  interactions among the responses of the cortical neurons of the barrel field. The temporal  suppression he reported even has a time course similar to that of the simulation. What the  experiment did not reveal, however, was the class of cell in which suppression was seen;  the simulation located most of the suppression in the output pyramidal cells. Hence, for a  biologist, even a simple synthetic simulation like the one presented here can make def'mitive  predictions. What differentiates the predictions made by synthetic simulations from those  of more general artificial neural systems, of course, is that the slzong biological foundations  of synthetic simulations provide an easily grasped and highly relevant framework for both  predictions and experimental verification.  One of the advertised purposes of this meeting was to "bring together  neurobiologists, cognitive psychologists, engineers, and physicists with common interest  in natural and artificial neural networks." Towards that end, synthetic computer  simulations, i.e. simulations which follow known neurophysiological and neuroanatomical  data as if they comprised a complex recipe, can provide an experimental medium which is  useful for both biologists and engineers. The simulation of cerebral neocortex developed  here has information regarding the role of randomness in the the robustness and presence  of various computational capabilities as well as information regarding the value of distinct  levels of connectivity to contribute to the design of artificial neural networks. At the same  time, the synthetic nature of the network provides the biologist with an environment in  which he can test notions of actual neural function as well as with a system which replicates  known properties of biological systems and makes explicit predictions. Providing twoway interactions, synthetic simulations like this one will allow future generations of  artificial neural networks to benefit from the empirical findings of biologists, while the  slowly evolving theories of brain finction benefit from the more generalizable results and  methods of engineers.  723  References  Crick, F. H. C. (1979) Thinking about the brain, Scientific American, 241:219 232.  Houchin, J. (1975) Direction specificity in cortical responses to moving stimuli -a simple  model. Proceedings of the Physiological Society, 247:7 9.  Jones, E.G. (1986) Connectivity of primate sensory-motor cortex, in Cerebral Cortex,  vol. 5, E.G. Jones and A. Peters (eds), Plenum Press, New York.  Koch, C., Poggio, T., and Torre, V. (1983) Nonlinear interactions in a dendritic tree:  Localization, timing, and role in information processing. Proceedings of the  National Academy of Science, USA, 80:2799 2802.  Lewin, R. (1982) Neuroscientists look for theories, Science, 216:507.  MacGregor, R.J. and Lewis, E.R. (1977) Neural Modeling, Plenum Press, New York.  Mountcastle, V. B. (1978) An organizing principle for cerebral function: The unit module  and the distributed system, in The Mindful Brain, G. M. Edelman and V. B.  Mountcastle (eds.), MIT Press, Cambridge, MA.  Shepherd, G.M. (in press) Basic circuit of cortical organization, in Perspectives in Memory  Research, M.S. Gazzaniga (ed.), MIT Press, Cambridge, MA.  Simons, D. J. (1985) Temporal and spatial integration in the rat SI vibrissa cortex, Journal  of Neurophysiology, 54:615 635.  Szenthigothai, J. (1978) Specificity versus (quasi-) randomness in cortical connectivity, in  Architectonics of the Cerebral Cortex, M. A. B. Brazier and H. Petsche (eds.),  Raven Press, New York.  Szentfigothai, J. (1979) Local neuron circuits in the neocortex, in The Neurosciences.  Fourth Study Program, F. O. Schmitt and F. G. Worden (eds.), MIT Press,  Cambridge, MA.  Torre, V. and Poggio, T. (1978) A synaptic mechanism possibly underlying directional  selectivity to motion, Proceeding of the Royal Society (London)B, 202:409 -416.  Woolsey, T.A. and Van der Loos, H. (1970) Structural organization of layer IV in the  somatosensory region (SI) of mouse cerebral cortex, Brain Research, 17:205-242.  724  Shunting Inhibition  Figure 1A: Intracellular records of post-synaptic potentials resulting from single excitatory and  inhibitory inputs to cells at different resting potentials.
A general method, the tensor product representation, is described for the distributed representation of  value/variable bindings. The method allows the fully distributed representation of symbolic structures:  the roles in the structures, as well as the fillers for those roles, can be arbitrarily non-local. Fully and  partially localized special cases reduce to existing cases of connectionist representations of structured  data; the tensor product representation generalizes these and the few existing examples of fully  distributed representations of structures. The representation saturates gracefully as larger structures  are represented; it permits recursive construction of complex representations from simpler ones; it  respects the independence of the capacities to generate and maintain multiple bindings in parallel; it  extends naturally to continuous structures and continuous representational patterns; it permits values to  also serve as variables; it enables analysis of the interference of symbolic structures stored in  associative memories; and it leads to characterization of optimal distributed representations of roles  and a recirculation algorithm for learning them.
The aim of this paper is to explore the spatial organization of  neural networks under Markovian assumptions, in what concerns the behaviour of individual cells and the interconnection mechanism. Spaceorganizational properties of neural nets are very relevant in image  modeling and pattern analysis, where spatial computations on stochastic two-dimensional image fields are involved. As a first approach  we develop a random neural network model, based upon simple probabilistic assumptions, whose organization is studied by means of discrete-event simulation. We then investigate the possibility of approximating the random network's behaviour by using an analytical approach originating from the theory of general product-form queueing  networks. The neural network is described by an open network of nodes, in which customers moving from node to node represent stimulations and connections between nodes are expressed in terms of suitably selected routing probabilities. We obtain the solution of the  model under different disciplines affecting the time spent by a stimulation at each node visited. Results concerning the distribution  of excitation in the network as a function of network topology and  external stimulation arrival pattern are compared with measures obtained from the simulation and validate the approach followed.
Recognizing patterns with temporal context is important for  such tasks as speech recognition, motion detection and signature  verification. We propose an architecture in which time serves as its  own representation, and temporal context is encoded in the state of the  nodes. We contrast this with the approach of replicating portions of the  architecture to represent time.  As one example of these ideas, we demonstrate an architecture  with capacitive inputs serving as temporal feature detectors in an  otherwise standard back propagation model. Experiments involving  motion detection and word discrimination serve to illustrate novel  features of the system. Finally, we discuss possible extensions of the  architecture.
We propose a new scheme to construct neural networks to classify patterns. The new scheme has several novel features:  We focus attention on the important attributes of patterns in ranking  order. Extract the most important ones first and the less important  ones later.  2. In training we use the information as a measure instead of the error  function.  3. A multi-perceptron-like architecture is formed auomatically. Decision  is made according to the tree structure of learned attributes.  This new scheme is expected to self-organize and perform well in large scale  problems.  © American Institute of Physics 1988  761
An efficient method of self-organizing associative databases is proposed together with  applications to robot eyesight systemsß The proposed databases cn associate ny input  with some output. In the first half prt of discussion, n algorithm of self-organization is  proposed. From an aspect of hardware, it produces a new style of neural network. In the  latter half part, an pplicability to handwritten letter recognition and that to an autonomous  mobile robot system are demonstrated.
Networks of simple analog processors having neuron-like properties have  been employed to compute good solutions to a variety of optimization problems. This paper presents a neural-net solution to a resource allocation problem that arises in providing local access to the backbone of a wide-area communication network. The problem is described in terms of an energy function  that can be mapped onto an analog computational network. Simulation results  characterizing the performance of the neural computation are also presented.
An increasing number of pr(foundly deaf patients suffering from sensorineural deafness are using cooblear implants as prostheses. After the  implant, sound can be detected through the electrical stimulation of the  remaining peripheral auditory nervous system. Although great progress has  been achieved in this area, no useful speech recognition has been attained  with either single or multiple channel cooblear implants.  Coding evidence suggests that it is necessary for any implant which  would effectively couple with the natural speech perception system to simulate the temporal dispersion and other phenomena found in the natural  receptors, and currently not implemented in any cooblear implants. To this  end, it is presented here a computational model using artificial neural networks (ANN) to incorporate the natural phenomena in the artificial  cochlear.  The ANN model presents a series of advantages to the implementation  of such systems. First, the hardware requirements, with constraints on  power, size, and processing speeds, can be taken into account together with  the development of the underlining software, before the actual neural structures are totally defined. Second, the ANN model, since it is an abstraction  of natural neurons, carries the necessary ingredients and is a close mapping  for implementing the necessary functions. Third, some of the processing,  like sorting and majority functions, could be implemented more efficiently,  requiring only local decisions. Fourth, the ANN model allows function  modifications through parametric modification (no software recoding), which  permits a variety of fine-tuning experiments, with the opinion of the  patients, to be conceived. Some of those will permit the user some freedom  in system modification at real-time, allowing finer and more subjective  adjustments to fit differences on the condition and operation of individual's  remaining peripheral auditory system.
We describe a class of connectionist networks that have learned to play backgammon at an intermediate-to-advanced level. The networks were trained by a  supervised learning procedure on a large set of sample positions evaluated by a  human expert. In actual match play against humans and conventional computer  programs, the networks demonstrate substantial ability to generalize on the basis of  expert knowledge. Our study touches on some of the most important issues in network learning theory, including the development of efficient coding schemes and  training procedures, scaling, generalization, the use of real-valued inputs and outputs, and techniques for escaping from local minima. Practical applications in  games and other domains are also discussed.  INTRODUC'ON  A potentially quite useful testing ground for studying issues of knowledge representation and  learning in networks can be found in the domain of game playing. Board games such as chess, go,  backgammon, and Othello entail considerable sophistication and complexity at the advanced level,  and mastery of expert concepts and strategies often takes years of intense study and practice for  humans. However, the complexities in board games are embedded in relatively "clean" structured  tasks with well-defined rules of play, and well-defined criteria for success and failure. This makes  them amenable to automated play, and in fact most of these games have been extensively studied  with conventional computer science techniques. Thus, direct comparisons of the results of network  leaming can be made with more conventional approaches.  In this paper, we describe an application of network leaming to the game of backgammon.  Backgammon is a difficult board game which appears to be well-suited to neural networks, because  the way in which moves are selected is primarily on the basis of pattern-recognition or "judgemental" reasoning, as opposed to explicit "look-ahead," or tree-search computations. This is due to  the probabilistic dice rolls in backgammon, which greatly expand the branching faclor m each ply in  the search (to over 400 in typical positions).  Our leaming procedure is a supervised one  that requires a database of positions ,and moves  that have been evaluated by an expert "teacher." In contrast, in an unsupervised procedure 2-4  leaming would be based on the consequences of a given move (e.g., whether it led to a won or lost  position), and explicit teacher instructions would not be required. However, unsupervised learning  procedures thus far have been much less efficient at reaching high levels of performance than supervised leaming procedures. In part, this advantage of supervised leaming can be traced to the higher  ¸ American Institute of Physics 1988  795  quantity and quality of information available from the teacher.  Studying a problem of the scale and complexity of backgammon leads one to confront important general issues in network learning. Amongst the most important are scaling and generalization.  Most of the problems that have been examined with connectionist leaming algorithms are relatively  small scale and it is not known how well they will perform on much larger problems. Generalization  is a key issue in learning to play backgammon since it is estimated that there are 102ø possible board  positions, which is far in excess of the number of examples that can be provided during training. In  this respect our study is the most severe test of generalization in any connectionist network to date.  We have also identified in this study a novel set of special techniques for training the network  which were necessary to achieve good performance. A training set based on naturally occurring or  random examples was not sufficient to bring the network to an advanced level of performance.  Intelligent data-base design was necessary. Performance also improved when noise was added to  the training procedure under some circumstances. Perhaps the most important factor in the success  of the network was the method of encoding the input information. The best performance was  achieved when the raw input information was encoded in a conceptually significant way, and a certain number of pre-computed features were added to the raw information. These lessons may also  be useful when connectionist learning algorithms are applied to other difficult large-scale problems.  NETWORK AND DATA BASE SET-LIP  Our network is trained to select moves (i.e. to produce a real-valued score for any given  move), rather than to generate them. This avoids the difficulties of having to teach the network the  concept of move legality. Instead, we envision our network operating in tandem with a preprocessor which would take the board position and roll as input, and produce all legal moves as output. The network would be trained to score each move, and the system would choose the move with  the highest network score. Furthermore, the network is trained to produce relative scores for each  move, rather than an absolute evaluation of each final position. This approach would have greater  sensitivity in distinguishing between close alternatives, and corresponds more closely to the way  humans actually evaluate moves.  The current data base contains a total of 3202 board positions, taken from various sources 5.  For each position there is a dice roll and a set of legal moves of that roll from that position. The  moves receive commentary from a human expert in the form of a relative score in the range [100,+100], with +100 representing the best possible move and -100 representing the worst possible  move. One of us (G.T.) is a strong backgammon player, and played the role of human expert in  entering these scores. Most of the moves in the data base were  for a human expert to comment on all possible moves. (The  data in the training procedure will be discussed in the following  not scored, because it is not feasible  handling of these unscored lines of  section.)  An important result of our study is that in order to achieve the best performance, the data base  of examples must be intelligently designed, rather than haphazardly accumulated. If one simply  accumulates positions which occur in actual game play, for example, one will find that certain principles of play will appear over and over again in these positions, while other important principles  may be used only rarely. This causes problems for the network, as it tends to "overlearn" the commonly used principles, and not learn at all the rarely used principles. Hence it is necessary to have  both an intelligent selection mechanism to reduce the number of over-represented situations, and an  intelligent design mechanism to enhance the number of examples which illustrate under-represented  situations. This process is described in more detail elsewhere 5.  We use a deterministic, feed-forward network with ,an input layer, ,an output layer, and either  one or two layers of hidden units, with full connectivity between adjacent layers. (We have tried a  number of experiments with restricted receptive fields, and generally have not found them to be useful.) Since the desired output of the network is a single real value, only one output unit is required.  796  The coding of the input patterns is probably the most difficult and most important design  issue. In its current configuration the input layer contains 459 input units. A location-based  representation scheme is used, in which a certain number of input units are assigned to each of the  26 locations (24 basic plus White and Black bar) on the board. The input is inverted if necessary so  that the network always sees a problem in which White is to play.  An example of the coding scheme used until very recently is shown in Fig. 1. This is essentially a unary encoding of the number of men at each board location, with a few exceptions as indicated in the diagram. This representation scheme worked fairly well, but had one peculiar problem  in that after training, the network tended to prefer piling large numbers of men on certain points, in  particular White's 5 point (the 20 point in the 1-24 numbering scheme). Fig. 2 illustrates an example  of this peculiar behavior. In this position White is to play 5-1. Most humans would play 4-5,4-9 in  this position; however, the network chose the move 4-9,19-20. This is actually a bad move, because  it reduces White's chances of making further points in his inner board. The fault lies not with the  data base used to train the network, but rather with the representation scheme used. In Fig. l a,  notice that unit 12 is turned on whenever the final position is a point, and the number of men is different from the initial position. For the 20 point in particular, this unit will develop strong excitatory  weights due to cases in which the initial position is not a point (i.e., the move makes the point). The  20 point is such a valuable point to make that the excitation produced by turning unit 12 on might  overwhelm the inhibition produced by the poor distribution of builders.  --5 -4 -5 --2 -I  (o) 0 0 0 0 0  I 2 5 4 5  6 7 8 9 I0  4 ->5  II 12 13 14 15 16  S-5 -4 -3-<-2 -I  (b) El B 13 E! 13  I 2 3 4 5  6 7 8 9 I0  II 12 15 14 15 16 17 18  Figure 1-Two schemes used to encode the raw position information in the network's input.  Illustrated in each case is the encoding of two White men present before the move, and three  White men present after the move. (a) An essentially unary coding of the number of men at a  particular board location. Units 1-10 encode the initial position, units 11-16 encode the final  position if there has been a change from the initial position. Units are turned on in the cases  indicated on top of each unit, e.g., unit 1 is turned on if there are $ or more Black men present,  etc.. (b) A superior coding scheme with more units used to characterize the type of transition  from initial to final position. An up arrow indicates an increase in the number of men, a down  arrow indicates a decrease. Units 11-15 have conceptual interpretations: 11="clcag,"  12="slotting," 13="breaking," 14="making," 15="stripping" a point.  797  12 11 10 9 8 7 6 5 4 3 2 1  13 14 15 16 17 18 19 20 21 22 23 24  Figure 2-A sample position illustrating a defect of the coding scheme in Fig. la. White is to  play 5-1. With coding scheme (la), the network prefers 4-9, 19-20. With coding scheme (lb),  the network prefers 4-9, 4-5. The graphic display was generated on a Sun Microsystems  workstation using the Gammontool program.  In conceptual terms, humans would say that unit 12 participates in the representation of two  different concepts: the concept of making a point, and the concept of changing the number of men  occupying a made point. These two concepts are unrelated, and there is no point in representing  them with a common input unit. A superior representation scheme in which these concepts are  separated is shown in Fig. lb: In this representation unit 13 is turned on only for moves which  make the point. Other moves which change the number of men on an already-made point do not  activate unit 13, and thus do not receive any undeserved excitation. With this representation  scheme the network no longer tends to pile large numbers of men on certain points, and its overall  performance is significantly better.  In addition to this representation of the raw board position, we also utilize a number of input  units to represent certain "pre-computed" features of the raw input. The principal god of this  study has been to investigate network learning, rather than simply to obtain high performance, and  thus we have resisted the temptation of including sophisticated hand-crafted features in the input  encoding. However, we have found that a few simple features are needed in practice to obtn  minimal standards of competent play. With only "raw" board information, the order of the desired  computation (as defined by Minsky and Papert 6) is probably quite high, and the number of examples  needed to learn such a difficult computation might be intractably large. By giving the network  "hints" in the form of pre-computed features, this reduces the order of the computation, and thus  might make more of the problem leamable in a tractable number of examples.  798  TRAINING AND TESTING PROCEDURES  To train the network, we have used the standard "back-propagation" learning algorithm ?-9  for modifying the connections in a multilayer feed-forward network. (A detailed discussion of  learning parameters, etc., is provided elsewhereS.) However, our procedure differs from the standard procedure due to the necessity of dealing with the large number of uncommented moves in the  data base. One solution would be simply to avoid presenting these moves to the network. However,  this would limit the variety of input patterns presented to the network in training, and certain types  of inputs probably would be eliminated completely. The alternative procedure which we have  adopted is to skip the uncommented moves most of the time (75% for ordinary rolls and 92% for  double rolls), and the remainder of the time present the pattem to the network and generate a random teacher signal with a slight negative bias. This makes sense, because if a move has not received  comment by the human expert, it is more likely to he a bad move than a good move. The random  teacher signal is chosen uniformly from the interval [-65,+35].  We have used the following four measures to assess the network's performance after it has  been trained: (i) performance on the training data, (ii) performance on a set of test data (1000 positions) which was not used to train the network, (iii) performance in actual game play against a conventional computer program (the program Gammontool of Sun Microsystems Inc.), and (iv) performance in game play against a human expert (G.T.). In the first two measures, we define the performance as the fraction of positions in which the network picks the correct move, i.e., those positions  for which the move scored highest by the network agrees with the choice of the human expert. In  the latter two measures, the performance is defined simply as the fraction of games won, without  considering the complications of counting gammons or backgammons.  QUANTITATIVE RESULTS  A summary of our numerical results as measured by performance on the training set and  against Gammontool is presented in Table 1. The best network that we have produced so far  appears to defeat Gammontool nearly 60% of the time. Using this as a benchmark, we find that the  most serious decrease in performance occurs by removing all pre-computed features from the input  coding. This produces a network which wins at most about 41% of the time. The next most important effect is the removal of noise from the training procedure; this results in a network which wins  45% of the time. Next in importance is the presence of hidden units; a network without hidden units  wins about 50% of the games against Gammontool. In contrast, effects such as varying the exact  number of hidden units, the number of layers, or the size of the training set, results in only a few  (1-3) percentage point decrease in the number of games won.  Also included in Table 1 is the result of an interesting experiment in which we removed our  usual set of pre-computed features and substituted instead the individual terms of the Gammontool  evaluation function. We found that the resulting network, after being trained on our expert training  set, was able to defeat the Gammontool program by a small margin of 54 to 46 percent. The purpose  of this experiment was to provide evidence of the usefulness of network learning as an adjunct to  standard AI techniques for hand-crafting evaluation functions. Given a set of features to be used in  an evaluation function which have been designed, for example,' by interviewing a human expert, the  problem remains as to how to "tune" these features, i.e., the relative weightings to associate to  each feature, and at an advanced level, the context in which each feature is relevant. Little is known  in general about how to approach this problem, and often the human programmer must resort to  painstaking trial-and-error tuning by hand. We claim that network learning is a powerful, generalpurpose, automated method of approaching this problem, and has the potential to produce a tuning  which is superior to those produced by humans, given a data base of sufficiently high quality, and a  suitable scheme for encoding the features. The result of our experiment provides evidence to support this claim, although it is not firmly established since we do not have highly accurate statistics,  and we do not know how much human effort went into the tuning of the Gammontool evaluation  799  function. More conclusive evidence would be provided if the experiment were repeated with a more  sophisticated program such as Berliner's BKG ø, and similar results were obtained.  Network rini.g Perf. on Perf. rs. Comments  size cycles test set Gammontool  (a) 459-24-24-1 20 .540 .59 4.03  (b) 459.-24-1 22 .542 .57 4-.05  (c) 459.24-! 24 .518 .58 4.05  (d) 459.12-1 10 .538 .54 4.05  1600 posn. D.B.  (e) 410-24-12-1 16 .493 .54 4.03  (f) 459-1 22 .485 .50 4.OS  ($) 459-24-12-1 10 .499 .45 4.03  (h) 393-24-12-1 12 .488 .41 4.02  Gammontool features  No hidden units  No traininS noise  No features  Table 1-Summary of performance statistics for various networks. (a) The best network we  have produced, containing two layers of hidden units, with 24 vnits in each layer. (b) A  network with only one layer of 24 hidden units. (c) A network with 24 hidden units in a single  layer, trained on a training set half the normal size. (d) A network with half the number of  hidden units as in (b). (e) A network with features from the Gammontool evaluation function  substituted for the normal features. (f) A network without hidden units. (g) A network trained  with no noise in the training procedure. (h) A network with only a raw board description as  input.  QUALITATIVE RESULTS  Analysis of the weights produced by training a network is an exceedingly difficult problem,  which we have only been able to approach qualitatively. In Fig. 3 we present a diagram showing the  connection strengths in a network with 651 input units and no hidden units. The figure shows the  weights from each input unit to the output unit. (For purposes of illustration, we have shown a coding scheme with more units than normal to explicitly represent the transition from initial to final  position.) Since the weights go directly to the output, the corresponding input units can be clearly  interpreted as having either an overall excitatory or inhibitory effect on the score produced by the  network.  A great deal of columnar structure is apparent in Fig. 3. This indicates that the network has  learned that a particular number of men at a given location, or a particular type of transition at a  given location, is either good or bad independent of the exact location on the board where it occurs.  Furthermore, we can see the importance of each of the pre-computed features in the input coding.  The most significant features seem to be the number of points made in the network's inner board,  and the total blot exposure.  8OO  features {  roll {  bar  24  23  22  21  20  19  18  17  16  15  14  13  12  11  10  9  8  7  6  5  4  3  2  1  ABCDEF GH I JKLMNOP QRS TUVW  Figure 3-A Hinton diagram for a network with 651 input units and no hidden units. Small  squares indicate weights from a particular input unit to the output unit. White squares indicate  positive weights, and black squares indicate negative weights. Size of square indicates  magnitude of weight. First 24 rows from bottom up indicate raw board information. Letting  x--number of men before the move and y--number of men after the move. the interpretations of  columns are as follows: A: x<=-5; B: x=-4; C: x=-3; D: x<=-2; E: x=-l: F: x=l; G: x>=2; H:  x=3: I: x--4: $: x>=5: K: x<l & y=l; L: x<2 & y>=2: M: x<3 & y=3: N: x<4 & y--4: O: x<y &  y>=5: P: x=l & y=O; Q: x>=2 & y=O: R: x>=2 & y=l: S: x>=3 & y=2: T: x>=4 & y=3: U:  x>=$ & y--4: V: x>y & y>=$; W: prob. of a White blot at this ocation behg hit (precomputed feature). The next row encodes number of men on White and Black bars. The next  3 rows encode roll information. Remaining rows encode various pre-computed features.  Much insight into the basis for the network's judgement of various moves h,xs been gained by  actually playing games against it. In fact, one of the most revealing tests of what the network has  and has not learned came from a 20-game match played by G.T. against one of the latest generation  of networks with 48 hidden units. (A detailed description of the match is given in Ref. 11.) The  surprising result of this match was that the network actually won, 11 games to 9. However, a  801  detailed analysis of the moves played by the network during the match indicates tint the network  was extromely lucky to have won so many games, and could not reasonably be expected to continue  to do so well over a large number of games. Out of the 20 games played, thero wero 11 in which  the network did not make any serious mistakes. The network won 6 out of these 11 games, a rosult  which is quite roasonable. However, in 9 of the 20 games, the network made one or more serious  (i.e. potentially fatal) "blunders." The seriousness of these mistakes would be equivalently to dropping a piece in chess. Such a mistake is nearly always fatal in chess against a good opponent; however in backgammon thero are still chances due to the element of luck involved. In the 9 games in  which the network blunderod, it did manage to survive and win 5 of the games due to the element of  luck. (We are assuming that the mistakes made by the human, if any, wero only minor mistakes.) It  is highly unlikely that this sort of resuit would be ropeated. A much moro likely result wouid be that  the network would win only one or two of the games in which it made a serious error. This would  put the network's expected performance against expert or near-expert humans at about the 35-40%  level. (This has also been confirmed in play against other networks.)  We find that the network does act as if it has picked up many of the global concepts and strategies of advanced play. The network has also learned many important tactical elements of play at  the advanced level. As for the specific kinds of mistakes made by the network, we find that they are  not at all random, senseless mistakes, but instead fall into clear, well-defined conceptual categories,  and furthermoro, one can understand the roasons why these categories of mistakes are made. We do  not have space hero to describe these in detail, and rofer the roader instead to Ref. 5.  To summarize, qualitative analysis of the network's play indicates that it has leamed many  important strategies and tactics of advanced backgammon. This gives the network very good overall  performance in typical positions. However, the network's worst case performance leaves a groat  deal to be desired. The network is capable of making both serious, obvious, "blunders," as well  moro subtle mistakes, in many different types of positions. Worst case performance is important,  because the network must make long sequences of moves throughout the course of a game without  any serious mistakes in order to have a reasonable chance of winning against a skilled opponent.  The prospects for improving the network's worst case performance appear to be mixed. It seems  quite likely that many of the current "blunders" can be fixed with a reasonable number of handcrafted examples added to the training set. However, many of the subtle mistakes are due to a lack  of very sophisticated knowledge, such as the notion of timing. It is difficult to imagine that this kind  of knowledge could be imparted to the network in only a few examples. Probably what is required is  either an intractably large number of examples, or a major overhaul in either the pre-computed  featufos or the training paradigm.  DISCUSSION  We have seen from both quantitative and qualitative measures that the network has learned a  great deal about the general principles of backgammon play, and has not simply memorized the  individual positions in the training set. Quantitatively, the measuro of game performace provides a  clear indication of the network's ability to generalize, because apart from the first couple of moves  at the start of each game, the network must operate entirely on generalization. Qualitatively, one can  see after playing several games against the network that thero are certain characteristic kinds of  positions in which it does well, and other kinds of positions in which it systematically makes welldefined types of mistakes. Due to the network's frequent "blunders," its overall level of play is  only intermediate level, although it probably is somewhat better than the average intermediate-level  player. Against the intermediate-level program Gammontool, our best network wins almost 60% of  the games. However, against a human expert the network would only win about 35-zt0% of the time.  Thus while the network does not play at expert level, it is sufficiently good to give an expert a hard  time, and with luck in its favor can actually win a match to a small number of games.  Our simple supervised learning approach leaves out some very important sources of  802  information which are readily available to humans. The network is never told that the underlying  topological structure of its input space really corresponds to a one-dimensional spatial structure; all  it knows is that the inputs form a ,59-dimensional hypercube. It has no idea of the object of the  game, nor of the sense of temporal causality, i.e. the notion that its actions have consequences, and  how those consequences lead to the achievement of the objective. The teacher signal only says  whether a given move is good or bad, without giving any indication as to what the teacher's reasons  are for making such a judgement. Finally, the network is only capable of scoring single moves in  isolation, without any idea of what other moves are available. These sources of knowledge are  essential to the ability of humans to play backgammon well, and it seems likely that some way of  incorporating them into the network learning paradigm will be necessary in order to achieve further  substantial improvements in performance.  There are a number of ways in which these additional sources of knowledge might be incorporated, and we shall be exploring some of them in future work. For example, knowledge of alternative moves could be introduced by defining a more sophisticated error signal which takes into  account not only the network and teacher scores for the current move, but also the network and  teacher scores for other moves from the same position. However, the more immediate plans involve  a continuation of the existing strategies of hand-crafting examples and coding scheme modifications  to eliminate the most serious errors in the network's play. If these errors can be eliminated, and we  are confident that this can be achieved, then the network would become substantially better than any  commercially available program, and would be a serious challenge for human experts. We would  expect 65% performance against Gammontool, and 45% performance against human experts.  Some of the results of our study have implications beyond backgammon to more general  classes of difficult problems. One of the limitations we have found is that substantial human effort  is required both in the design of the coding scheme and in the design of the training set. It is not  sufficient to use a simple coding scheme and random training patterns, and let the automated network learning procedure take care of everything else. We expect this to be generally true when  connectionist learning is applied to difficult problem domains.  On the positive side, we foresee a potential for combining connectionist learning techniques  with conventional AI techniques for hand-crafting knowledge to make significant progress in the  development of intelligent systems. From the practical point of view, network learning can be  viewed as an "enhancer" of traditional techniques, which might produce systems with superior performance. For this particular application, the obvious way to combine the two approaches is in the  use of pre-computed features in the input encoding. Any set of hand-crafted features used in a conventional evaluation function could be encoded as discrete or continuous activity levels of input  units which represent the current board state along with the units representing the raw information.  Given a suitable encoding scheme for these features, and a training set of sufficient size and quality  (i.e., the scores in the training set should be better than those of the original evaluation function), it  seems possible that the resulting network could outperform the original evaluation function, as evidenced by our experiment with the Gammontool features.  Network learning might also hold promise as a means of achieving the long-sought goal of  automated feature discovery 2. Our network certainly appears to have learned a great deal of  knowledge from the training set which goes far beyond the amount of knowledge that w,xs explicitly  encoded in the input features. Some of this knowledge (primarily the lowest level components) is  apparent from the weight diagram when there are no hidden units (Fig. 3). However, much of the  network's knowledge remains inaccessible. What is needed now is a means of disent,'mgling the  novel features discovered by the network from either the patterns of activity in the hidden units, or  from the massive number of connection strengths which characterize the network. This is one our  top priorities for future research, although techniques for such "reverse engineering" of parallel  networks are only beginning to be developed 2.  803  ACKNOWLEDGEMENTS  This work was inspired by a conference on "Evolution, Games and Learning" held at Los  Alamos National Laboratory, May 20-24, 1985. We thank Sun Microsystems Inc. for providing the  source code for their Gammontool program, Hans Berliner for providing some of the positions used  in the data base, Subutai Allmad for writing the weight display graphics package, Bill Bogstad for  assistance in programming the back-propagation simulator, and Bartlett Mel, Peter Frey, and Scott  Kirkpalick for critical reviews of the manuscript. G.T. was supported in part by the National  Center for Supercomputing Applications. T.J.S. was supported by a NSF Presidential Young Investigator Award, and by grants from the Seavet Institute and the Lounsbury Foundation.  REFERENCES
Neural networks have attracted much interest recently, and using parallel architectures to simulate neural networks is a natural and necessary application. The SIMD model of parallel computation is chosen, because systems of this type can be built with large numbers of processing elements. However, such systems are not naturally suited to generalized communication. A method is proposed that allows an implementation of neural network connections on massively parallel SIMD architectures. The key to this system is an algorithm that allows the formation of arbitrary connections between the 'neurons '. A feature is the ability to add new connections quickly. It also has error recovery ability and is robust over a variety of network topologies. Simulations of the general connection system, and its implementation on the Connection Machine, indicate that the time and space requirements are proportional to the product of the average number of connections per neuron and the diameter of the interconnection network. 
A family of neuromorphic networks specifically designed for communications  and optical signal processing applications is presented. The information is encoded  utilizing sparse Optical Orthogonal Code sequences on the basis of unipolar, binary  (0, 1) signals. The generalized synaptic connectivity matrix is also unipolar, and  clipped to binary (0, 1) values. In addition to high-capacity associative memory,  the resulting neural networks can be used to implement general functions, such as  code filtering, code mapping, code joining, code shifting and code projecting.
The paper presents an artificial neural network concept (the  Synchronizable Oscillator Networks) where the instants of individual  firings in the form of point processes constitute the only form of  information transmitted between joining neurons. This type of  communication contrasts with that which is assumed in most other  models which typically are continuous or discrete value-passing  networks. Limiting the messages received by each processing unit to  time markers that signal the firing of other units presents significant  implementation advantages.  In our model, neurons fire spontaneously and regularly in the  absence of perturbation. When interaction is present, the scheduled  firings are advanced or delayed by the firing of neighboring neurons.  Networks of such neurons become global oscillators which exhibit  multiple synchronizing attractors. From arbitrary initial states,  energy minimization learning procedures can make the network  converge to oscillatory modes that satisfy multi-dimensional  constraints Such networks can directly represent routing and  scheduling problems that consist of ordering sequences of events.
This paper describes an approach to 2-dimensional object recognition. Complex-log conformal mapping is combined with a distributed associative memory to create a system  which recognizes objects regardless of changes in rotation or scale. Recalled information  from the memorized database is used to classify an object, reconstruct the memorized version of the object, and estimate the magnitude of changes in scale or rotation. The system  response is resistant to moderate amounts of noise and occlusion. Several experiments, using real, gray scale images, are presented to show the feasibility of our approach.
This paper presents a model of nondeterministic adaptive automata that are  constructed from simpler nondeterministic adaptive information processing  elements. The first half of the paper describes the model. The second half discusses  some of its significant adaptive properties using computer simulation examples.  Chief among these properties is that network aggregates of the model elements can  adapt appropriately when a single reinforcement channel provides the same positive  or negative reinforcement signal to all adaptive elements of the network at the same  time. This holds for multiple-input, multiple-output, multiple-layered,  combinational and sequential networks. It also holds when some network elements  are "hidden" in that their outputs are not directly seen by the external  environment.
There is a widespread misconception that the delta-rule is in some sense guaranteed to  work on networks without hidden units. As previous authors have mentioned, there is  no such guarantee for classification tasks. We will begin by presenting explicit counterexamples illustrating two different interesting ways in which the delta rule can fail. We  go on to provide conditions which do guarantee that gradient descent will successfully  train networks without hidden units to perform two-category classification tasks. We  discuss the generalization of our ideas to networks with hidden units and to multicategory classification tasks.  The Classification Task  Consider networks of the form indicated in figure 1. We discuss vaxious methods for  training such a network, that is for adjusting its weight vector, w. If we call the input  v, the output is g(w. v), where g is some function.  The classification task we wish to train the network to perform is the following. Given  two finite sets of vectors, F1 and F2, output a number greater than zero when a vector in  F1 is input, and output a number less than zero when a vector in F2 is input. Without  significant loss of generality, we assume that g is odd (i.e. g(-s) -g(s)). In that case,  the task can be reformulated as follows. Define 2  F := F U {-v such that v 6 F2}  (1)  and output a number greater than zero when a vector in F is input. The former  formulation is more natural in some sense, but the later formulation is somewhat more  convenient for analysis and is the one we use. We call vectors in F, training vectors.  A Class of Gradient Descent Algorithms  We denote the solution set by  W := {w such that g(w. v) > 0 for all v  F},  Currently at NYNEX Science and Technology, 500 Westchester Ave., White Plains, NY 10604  2We use both A := B and B =: A to denote "A is by definition B".  (2)  American Institute of Physics 1988  851  Wl W2  g(w. v))  Figure 1: a simple network  w  output  inputs  and we are interested in rules for finding some weight vector in W. We restrict our  attention to rules based upon gradient descent down error functions E(w) of the form  E(w) = y] h(w. v). (3)  vEF  The delta-rule is of this form with  h(w. v) = hs(w' v):= -(b g(w. v)) 2 (4)  for some positive number b called the target (Rumelhart, McClelland, et al.). We call  the delta rule error function Es.  Failure of Delta-rule Using Obtainable Targets  Let g be any function that is odd and differentiable with g'(s) > 0 for all s. In this  section we assume that the target b is in the range of g. We construct a set F of  training vectors such that even though W is not empty, there is a local minimum of Es  not located in W. In order to facilitate visualization, we begin by assuming that g is  linear. We will then indicate why the construction works for the nonlinear case as well.  We guess that this is the type of counter-example alluded to by Duda and Hart (p. 151)  and by Minsky and Papert (p. 15).  The input vectors are two dimensional. The arrows in figure 2 represent the training  vectors in F and the shaded region is W. There is one training vector, v , in the second  quadrant, and all the rest are in the first quadrant. The training vectors in the first  quadrant are arranged in pairs symmetric about the ray R and ending on the line L.  The line L is perpendicular to R, and intersects R at unit distance from the origin.  Figure 2 only shows three of those symmetric pairs, but to make this construction work  we might need many. The point p lies on R at a distance of g-(b) from the origin.  We first consider the contribution to Es due to any single training vector, v. The  contribution is  (1/2)(b g(w. v)) , (5)  and is represented in figure 3 in the z-direction. Since g is linear and since b is in the  82  L  -e no. '='{dYCUla 'bUtion .  {or ohß  oa . is tic ,_ 'gets  Poi ß a is t ' the co ,,,e trou_]o ectors , u a lin ß  atp  ,,esu . batrib ....  ß oo it is ol t% .. "?oa to t e first o, 'e 'plaNe, qadratic ratic tro.error ,. at, then  _  We _ bowl .,:.. Ughs .,:.. 'Ction  .uran uaSider  a bott_ta bott   qadr..øY, r ,UScon,_..,rarilv_. tp. Sn? vectors :_  a; 'tic bo...; o,e coa,_."'noOtio C*'teep b."um _ ..Y ro  .. o  _ .  due _ . .rilv  Sibe SUci_, s p, b.qadra,,   gradien. o s a o.. ,,e p So e bowl   ' have coafir,,s ev. Q'E.D. etly st t  ß ied the  o Con,. ' .  Cøcepteøes  853  y-axis  Figure 3: Error surface  We now remove the assumption that g is linear. The key observation is that  dhs/ds = hs'(s) = (b#(s))(-#'(s))  (6)  still only has a single zero at g-(b) and so h(s) still has a single minimum at g-(b).  The contribution to Es due to the training vectors in the first quadrant therefore still  has a global minimum on the xy-plane at the point p. So, as in the linear case, if there  are enough symmetric pairs of training vectors in the first quadrant, the value of Eo  at p can be made arbitrarily lower than the value along some circle in the xy-plane  centered around p, and Es = Eo + E will have a local minimum arbitrarily near p.  Q.E.D.  Failure of Delta-rule Using Unobtainable Targets  We now consider the case where the target b is greater than any number in the range  of g. The kind of counter-example presented in the previous section no longer exists,  but we will show that for some choices of g, including the traditional choices, the delta  rule can still fail. Specifically, we construct a set F of training vectors such that even  though W is not empty, for some choices of initial weights, the path traced out by going  down the gradient of Es never enters W.  854  V 1 /  R ,e  / L  ¾2  x-axis  Figure 4: Counter-example for unobtainable targets  We suppose that g has the following property. There exists a number r > 0 such that  )km 0. (7)  An example of such a g is  2  g(s)tanh(s) i + e -2s 1, (8)  for which any r greater than 1 will do.  The solid arrows in figure 4 represent the training vectors in F and the more darkly  shaded region is W. The set F has two elements,  vl: [-2] and v2: ()() [ ] (9)  The dotted ray, R lies on the diagonal {y:  Since  Es(w) -hs(w' v x) + hs(w. v2), (10)  855  the gradient descent algorithm follows the vector field  -VE(w) = -h'(w. vl)v 1 h'(w. v2)v 2. (11)  The reader can easily verify that for all w on R,  W' V 1 = --rw' v 2. (12)  So by equation (7), if we constrain w to move along R,  lim -h5(w' vl)  =0. (13)  w-.o -/zd(w.  Combining equations (11) and (13) we see that there is a point q somewhere on R such  that beyond q, -VE(w) points into the region to the right of R, as indicated by the  dotted arrows in figure 4.  Let L be the horizontal ray extending to the right from q. Since for all s,  g'(s) > 0 and b > g(s), (14)  we get that  h6'(s) = (bg(s))g'(s) > 0. (15)  So since both v 1 and v 2 have a positive y-component, -VE(w) also has a positive  y-component for all w. So once the algorithm following -VE enters the region above  L and to the right of R (indicated by light shading in figure 4), it never leaves. Q.E.D.  Properties to Guarantee Gradient Descent Learning  In this section we present three properties of an error function which guarantee that  gradient descent will not fail to enter a non-empty W.  We call an error function of the form presented in equation (3) well formed if h is  differentiable and has the following three properties.
In the analog VLSI implementation of neural systems, it is  sometimes convenient to build lateral inhibition networks by using  a locally connected on-chip resistive grid. A serious problem  of unwanted spontaneous oscillation often arises with these  circuits and renders them unusable in practice. This paper reports  a design approach that guarantees such a system will be stable,  even though the values of designed elements and parasitic elements  in the resistive grid may be unknown. The method is based on a  rigorous, somewhat novel mathematical analysis using Tellegen's  theorem and the idea of Popov multipliers from control theory. It  is thoroughly practical because the criteria are local in the sense  that no overall analysis of the interconnected system is required,  empirical in the sense that they involve only measurable frequency  response data on the individual cells, and robust in the sense that  unmodelled parasitic resistances and capacitances in the interconnection network cannot affect the analysis.
The potential of adaptive networks to learn categorization rules and to  model human performance is studied by comparing how natural and  artificial systems respond to new inputs, i.e., how they generalize. Like  humans, networks can learn a deterministic categorization task by a  variety of alternative individual solutions. An analysis of the constraints imposed by using networks with the minimal number of hidden  units shows that this "minimal configuration" conslxaint is not  sufficient to explain and predict human performance; only a few solutions were found to be shared by both humans and minimal adaptive  networks. A further analysis of human and network generalizations  indicates that initial conditions may provide important constraints on  generalization. A new technique, which we call "reversed learning",  is described for finding appropriate initial conditions.
We propose an optimality principle for training an unsupervised feedforward neural network based upon maximal  ability to reconstruct the input data from the network outputs. We describe an algorithm which can be used to train  either linear or nonlinear networks with certain types of  nonlinearity. Examples of applications to the problems of  image coding, feature detection, and analysis of randomdot stereograms are presented.
ALVIS is a reinforcement-based connectionist architecture that  learns associative maps in continuous multidimensional environments. The discovered locations of positive and negative reinforcements are recorded in "do be" and "don't be" subnetworks,  respectively. The outputs of the subnetworks relevant to the current goal are combined and compared with the current location to  produce an error vector. This vector is backpropagated through  a motor-perceptual mapping network to produce an action vector that leads the system towards do-be locations and away from  don't-be locations. ALVIS is demonstrated with a simulated robot  posed a target-seeking task.
A class of fast, supervised learning algorithms is presented. They use local representations, hashing, aild multiple scales of resolution to approximate  functions which are piece-wise continuous. Inspired by Albus's CMAC model,  the algorithms learn orders of magnitude more rapidly than typical implementations of back propagation, while often achieving comparable qualities of  generalization. Furthermore, unlike most traditional function approximation  methods, the algorithms are well suited for use in real time adaptive signal  processing. Unlike simpler adaptive systems, such as linear predictive coding, the adaptive linear combinet, and the Kalman filter, the new algorithms  are capable of efficiently capturing the structure of complicated non-linear  systems. As an illustration, the algorithm is applied to the prediction of a  chaotic timeseries.
Parallelizable optimization techniques are applied to the problem of  learning in feedforward neural networks. In addition to having superior convergence properties, optimization techniques such as the PolakRibiere method are also significantly more efficient than the Backpropagation algorithm. These results are based on experiments performed on small boolean learning problems and the noisy real-valued  learning problem of hand-written character recognition.
Classifier systems are machine learning systems incorporating a genetic algorithm as the learning mechanism. Although they respond to inputs that neural  networks can respond to, their intemal structure, representation formalisms, and  learning mechanisms differ markedly from those employed by neural network researchers in the same sorts of domains. As a result, one might conclude that these  two types of machine learning formalisms are intrinsically different. This is one  of two papers that, taken together, prove instead that classifier systems and neural  networks are equivalent. In this paper, half of the equivalence is demonstrated  through the description of a transformation procedure that will map classifier  systems into neural networks that are isomorphic in behavior. Several alterations  on the commonly-used paradigms employed by neural network researchers are  required in order to make the transformation work. These alterations are noted  and their appropriateness is discussed. The paper concludes with a discussion of  the practical import of these results, and with comments on their extensibility.
This work introduces a new method called Self Organizing  Neural Network (SONN) algorithm and demonstrates its use in a  system identification task. The algorithm constructs the network,  chooses the neuron functions, and adjusts the weights. It is compared to  the Back-Propagation algorithm in the identification of the chaotic time  series. The results shows that SONN constructs a simpler, more  accurate model, requiring less training data and epochs. The algorithm  can be applied and generalized to appilications as a classifier.
What follows extends some of our results of [1] on learning from examples in layered feed-forward networks of linear units. In particular we examine what happens when the number of layers is large or  when the connectivity between layers is local and investigate some  of the properties of an autoassociative algorithm. Notation will be  as in [1] where additional motivations and references can be found.  
We introduce a learning algorithm for multilayer neural networks composed of binary linear threshold elements. Whereas existing algorithms reduce the learning process to minimizing a cost  function over the weights, our method treats the internal representations as the fundamental entities to be determined. Once a  correct set of internal representations is arrived at, the weights are  found by the local ahd biologically plausible Perceptton Learning  Rule (PLR). We tested our learning algorithm on four problems:  adjacency, symmetry, parity and combined symmetry-parity.
We address the question of when a network can be expected to  generalize from m random training examples chosen from some arbitrary probability distribution, assuming that future test examples  are drawn from the same distribution. Among our results are the  following bounds on appropriate sample rs. network size. Assume  0 < e < 1/8. We show that if m > O( w v  _ _ .7-1og.T) random examples can be loaded on a feedforward network of linear threshold  functions with N nodes and W weights, so that at least a fraction  1  of the examples are correctly classified, then one has confidence approaching certainty that the network will correctly classify  a fraction i e of future test examples drawn from the same distribution. Conversely, for fully-connected feedforward nets with  one hidden layer, any learning algorithm using fewer than f(---)  random training examples will, for some distributions of examples  consistent with an appropriate weight choice, fail at least some  fixed fraction of the time to find a weight choice that will correctly  classify more than a 1 e fraction of the future test examples.
Nearly optimal solutions to many combinatorial problems can be  found using stochastic simulated annealing. This paper extends  the concept of simulated annealing from its original formulation  as a Markov process to a new formulation based on mean field  theory. Mean field annealing essentially replaces the discrete degrees of freedom in simulated annealing with their average values  as computed by the mean field approximation. The net result is  that equilibrium at a given temperature is achieved 1-2 orders of  magnitude faster than with simulated annealing. A general framework for the mean field annealing algorithm is derived, and its relationship to Hopfield networks is shown. The behavior of MFA is  examined both analytically and experimentally for a generic combinatorial optimization problem: graph bipartitioning. This analysis  indicates the presence of critical temperatures which could be important in improving the performance of neural networks.  STOCHASTIC VERSUS MEAN FIELD  In combinatorial optimization problems, an objective function or HamiltonJan,  H(s), is presented which depends on a vector of interacting spins, s -{sx,...,  in some complex nonlinear way. Stochastic simulated annealing (SSA) (S. Kirkpatrick, C. Gelatt, and M. Vecchi (1983)) finds a global minimum of H by combining gradient descent with a random process. This combination allows, under  certain conditions, choices of s which actually increase H, thus providing SSA with  a mechanism for escaping from local minima. The frequency and severity of these  uphill moves is reduced by slowly decreasing a parameter T (often referred to as  the temperature) such that the system settles into a global optimum.  Two conceptual operations are involved in simulated annealing: a thermostatic operation which schedules decreases in the temperature, and a relaxation operation  92 Bilbro, et al  which iteratively finds the equilibrium solution at the new temperature using the  final state of the system at the previous temperature as a starting point. In SSA, relaxation occurs by randomly altering components of s with a probability determined  by both T and the change in H caused by each such operation. This corresponds to  probabilistic transitions in a Markov chain. In mean field annealing (MFA), some  aspects of the optimization problem are replaced with their means or averages from  the underlying Markov chain (e.g. s is replaced with its average, (s)). As the temperature is decreased, the MFA algorithm updates these averages based on their  values at the previous temperature. Because computation using the means attains  equilibrium faster than using the corresponding Markov chain, MFA relaxes to a  solution at each temperature much faster than does SSA, which leads to an overall  decrease in computational effort.  In this paper, we present the MFA formulation in the context of the familiar Ising  HamiltonJan and discuss its relationship to Hopfield neural networks. Then the  application of MFA to the problem of graph bipartitioning is discussed, where we  have analytically and experimentally investigated the affect of temperature on the  behavior of MFA and observed speedups of 50:1 over SSA.  MFA AND HOPFIELD NETWORKS  Optimization theory, like physics, often concerns itself with systems possessing a  large number of interacting degrees of freedom. Physicists often simplify their problems by using the mean field approzimation: a simple analytic approximation of the  behavior of systems of particles or spins in thermal equilibrium. In a corresponding manner, arbitrary functions can be optimized by using an analytic version of  stochastic simulated annealing based on a technique analogous to the mean field  approximation. The derivation of MFA presented here uses the naive mean field  (D. J. Thouless, P.W. Anderson, and R.G. Palmer (1977)) and starts with a simple  Ising HamiltonJan of N spins coupled by a product interaction:  integer spins.  Factoring H(s) shows the interaction between a spin sl and the rest of the system:  (1)  The mean or effective field affecting si is the average of its coefficient in (1):  (2)  The last part of (2) shows that, for the Ising case, the mean field can be simply  calculated from the difference in the Hamiltonian caused by changing {si} from zero  Optimization by Mean Field Annealing 93
A new training paradigm, called the "coznparison paradigm," is introduced  for tasks in which a network must learn to choose a preferred pattern from a  set of n, alternatives, based on examples of human expert preferences. In this  paradigm, the input to the network consists of two of the n alternatives, and  the trained outtrot is the expert's judgement of which i)attcrn is better. This  paradigm is applied to the learning of backgammon, a difflcult board game in  which the expert selects a move from a set of legal moves. With comparison  training, much higher levels of performance can be achieved, wi{h networks  that are much smaller, and with coding schemes that arc much simpler and  easier to understand. Furthermore, it is possible to set up the network so  that it always produces consistent rank-orderings.
This paper proposes a means of using the knowledge in a network to  determine the functionality or relevance of individual units, both for  the purpose of understanding the network's behavior and improving its  performance. The basic idea is to iteratively train the network to a certain performance criterion, compute a measure of relevance that identifies which input or hidden units are most critical to performance, and  automatically trim the least relevant units. This skeletonization technique can be used to simplify networks by eliminating units that convey redundant information; to improve learning performance by first  learning with spare hidden units and then trimming the unnecessary  ones away, thereby constraining generalization; and to understand the  behavior of networks in terms of minimal "rules."
The concept of the stochastic Boltzmann machine (BM) is attractive for  decision making and pattern classification purposes since the probability of  attaining the network states is a function of the network energy. Hence, the  probability of attaining particular energy minima may be associated with the  probabilities of making certain decisions (or classifications). However,  because of ill stochastic nature, the complexity of the BM is fairly high and  therefore such networks are not very likely to be used in practice. In this  paper we suggest a way to alleviate this drawback by converting the stoelmstic BM into a deterministic network which we call the Boltzmann Perceplxon Network (BPN). The BPN is functionally equivalent to the BM but  has a feed-forward structure and low complexity. No annealing is required.  The conditions under which such a conversion is feasible are given. A  learning algorithm for the BPN based on the conjugate gradient method is  also provided which is somewhat akin to the backpropagation algorithm.
A nonlinearity is required before matched filtering in minimum error  receivers when additive noise is present which is impulsive and highly  non-Gaussian. Experiments were performed to determine whether the  correct clipping nonlinearity could be provided by a single-input singleoutput multi-layer perceptron trained with back propagation. It was  found that a multi-layer perceptron with one input and output node, 20  nodes in the first hidden layer, and 5 nodes in the second hidden layer  could be trained to provide a clipping nonlinearity with fewer than 5,000  presentations of noiseless and corrupted waveform samples. A network  trained at a relatively high signal-to-noise (S/N) ratio and then used  as a front end for a linear matched filter detector greatly reduced the  probability of error. The clipping nonlinearity formed by this network  was similar to that used in current receivers designed for impulsive noise  and provided similar substantial improvements in performance.
A large fraction of recent work in artificial neural nets uses  multilayer perceptrons trained with the back-propagation  algorithm described by Rumelhart et. al. This algorithm  converges slowly for large or complex problems such as  speech recognition, where thousands of iterations may be  needed for convergence even with small data sets. In this  paper, we show that training multilayer perceptrons is an  identification problem for a nonlinear dynamic system which  can be solved using the Extended Kalman Algorithm.  Although computationally complex, the Kalman algorithm  usually converges in a few iterations. We describe the  algorithm and compare it with back-propagation using twodimensional examples.
Learning procedures that measure how random perturbations of unit activities correlate with changes in reinforcement are inefficient but simple  to implement in hardware. Procedures like back-propagation (Rumelhart,  Hinton and Williams, 1986) which compute how changes in activities affect the output error are much more efficient, but require more complex  hardware. GEMINI is a hybrid procedure for multilayer networks, which  shares many of the implementation advantages of correlational reinforcement procedures but is more efficient. GEMINI injects noise only at the  first hidden layer and measures the resultant effect on the output error.  A linear network associated with each hidden layer iteratively inverts the  matrix which relates the noise to the error change, thereby obtaining  the error-derivatives. No back-propagation is involved, thus allowing unknown non-linearities in the system. Two simulations demonstrate the  effectiveness of GEMINI.  OVERVIEW  Reinforcement learning procedures typically measure the effects of changes in local variables on a global reinforcement signal in order to determine sensible weight  changes. This measurement does not require the connections to be used backwards  (as in back-propagation), but it is inefficient when more than a few units are involved. Either the units must be perturbed one at a time, or, if they are perturbed  simultaneously, the noise from all the other units must be averaged away over a  large number of samples in order to achieve a reasonable signal to noise ratio. So  reinforcement learning is much less efficient than back-propagation (BP) but much  easier to implement in hardware.  GEMINI is a hybrid procedure which retains many of the implementation advantages of reinforcement learning but eliminates some of the inefficiency. GEMINI  uses the squared difference between the desired and actual output vectors as a  reinforcement signal. It injects random noise at the first hidden layer only, causing correlated noise at later layers. If the noise is sufficiently small, the resultant  1First Author's present address: Room 4G-332, AT&T Bell Laboratories, Crawfords Corner  Rd, Holmdel, NJ 07733  142 Le Cun, Galland and Hinton  change in the reinforcement signal is a linear function of the noise vector at any  given layer. A matrix inversion procedure implemented separately at each hidden  layer then determines how small changes in the activities of units in the layer affect  the reinforcement signal This matrix inversion gives a much more accurate estimate of the error-derivatives than simply averaging away the effects of noise and,  unlike the averaging approach, it can be used when the noise is correlated.  The matrix inversion at each layer can be performed iterative]y by a local linear  network that "learns" to predict the change in reinforcement from the noise vector at  that layer. For each input vector, one ordinary forward pass is performed, followed  by a number of forward passes each with a small amount of noise added to the total  inputs of the first hidden layer. After each forward pass, one iteration of an LMS  training procedure is run at each hidden layer in order to improve the estimate of  the error-derivatives in that layer. The number of iterations required is comparable  to the width of the largest hidden layer. In order to avoid singularities in the  matrix inversion procedure, it is necessary for each layer to have fewer units than  th preceding one.  In this hybrid approach, the computations that relate the perturbation vectors  to the reinforcement signal are all local to a layer. There is no detailed backpropagation of information, so that GEMINI is more amenable to optical or electronic implementations than BP. The additional time needed to run the gradientestimating inner loop, may be offset by the fact that only forward propagation is  required, so this can be made very efficient (e.g. by using analog or optical hardware).  TECHNIQUES FOR GRADIENT ESTIMATION  The most obvioua way to measure the derivative of the cost function w.r.t the  weights is to perturb the weights one at a time, for each input vector, and to  measure the effect that each weight perturbation has on the cost function, C. The  advantage of this technique is that it makes very few assumptions about the way  the network computes its output.  It is possible to use far fewer perturbations (Barto and Anandan, 1985) if we are  using "quasi-linear" units in which the output, yl, of unit i is a smooth non-linear  function, f, of'its total input, xi, and the total input is a linear function of the  incoming weights, wij and the activities, yj, of units in the layer below:  =  xi  wijyj  Instead of perturbing the weights, we perturb the total input, xi, received by each  unit, in order to measure OC/Oxi Once this derivative is known it is easy to  derive c9C/Owij for each of the unit's incoming weights by performing a simple local  computation:  Oc Oc  Ow-- = Oxi y  If the units are perturbed one at a time, we can approximate OC/Oxi by  143  C C  = +  where 5C is the variation of the cost function induced by a perturbation 5a:i of the  total input to unit i. This method is more efficient than perturbing the weights  directly, but it still requires as many forward passes as there are hidden units.  Reducing the number of perturbations required  If the network has a layered, feed-forward, architecture the state of any single layer  completely deterrjaines the output. This makes it possible to reduce the number of  required perturbations and forward passes still further. Perturbing units in the first  hidden layer will induce perturbations at the following layers, and we can use these  induced perturbations to compute the gradients for these layers. However, since  many of the units in a typical hidden layer will be perturbed simultaneously, and  since these induced perturbations will generally be correlated, it is necessary to do  some local computation within each layer in order to solve the credit assignment  problem of deciding how much of the change in the final cost function to attribute  to each of the simultaneous perturbations within the layer. This local computation  is relatively simple. Let x(k) be the vector of total inputs to units in layer k. Let  5x(k) be the perturbation vector of layer k at time t. It does not matter for the  following analysis whether the perturbations are directly caused (in the first hidden  layer) or are induced. For a given state of the network, we have:  OCT  6c, = + O(ll6xd)ll  To compute the gradient w.r.t. layer k we must solve the following system for g  6C, = gTSxt(k) t = 1...P  where P is the number of perturbations. Unless P is equal to the number of units  in layer k, and the perturbation vectors are linearly independent, this system will  be overor under-determined. In some network architectures it is impossible to  induce nl linearly independent perturbation vectors in a hidden layer, l containing  nl units. This happens when one of the preceding hidden layers, k, contains fewer  units because the perturbation vectors induced by a layer with n units on the  following layer generate at most n independent directions. So to avoid having to  solve an under-determined system, we require "convergent" networks in which each  hidden layer has no mbre units than the preceding layer.  Using a Special Unit to Allocate Credit within a Layer  Instead of directly solving for the OC/Oxi within each layer, we can solve the same  system iteratively by minimizing:  144 Le Curt, Galland and Hinton  linear  unit  linear  unit  ¸ ¸  input layer  Figure 1: A GEMINI network.  This can be done by a special unit whose inputs are the perturbations of layer  k and whose desired output is the resulting perturbation of the cost function 6C  (figure 1). When the LMS algorithm is used, the weight vector g of this special  unit converges to the gradient of C with respect to the vector of total inputs x(k).  If the components of the perturbation vector are uncorrelated, the convergence will  be fast and the number of iterations required should be of the order of the the  number of units in the layer. Each time a new input vector is presented to the main  network, the "inner-loop" minimization process that estimates the OC/Oxi must  be re-initialized by setting the weights of the special units to zero or by reloading  approximately correct weights from a table that associates estimates of the OC/Ox  with each input vector.  Summary of the Gemini Algorithm
This paper provides a systematic analysis of the recurrent backpropagation (RBP) algorithm, introducing a number of new results. The main  limitation of the RBP algorithm is that it assumes the convergence of  the network to a stable fixed point in order to backpropagate the error  signals. We show by experiment and eigenvalue analysis that this condition can be violated and that chaotic behavior can be avoided. Next we  examine the advantages of RBP over the standard backpropagation algorithm. RBP is sitown to build stable fixed points corresponding to the  input patterns. This makes it an appropriate tool for content addressable memories, one-to-many function learning, and inverse problems.
The issues of scaling and generalization have emerged as key issues in  current studies of supervised learning from examples in neural networks.  Questions such as how many training patterns and training cycles are  needed for a problem of a given size and difficulty, how to represent the  int!nt, and how to choose useful training exemplars, are of considerable  theoretical and practical importance. Several intuitive rules of thumb  have been obtained from empirical studies, but as ye there are few rigorous results. In this paper we summarize a study of generalization in  the simplest possible case-perceptron networks learning linearly separable functions. The task chosen was the majority function (i.e. return  a 1 if a majority of the input units are on), a predicate with a number of useful properties. We find that many aspects of.generaiization  in multilayer networks learning large, difficult tasks are reproduced in  this simple domain, in which concrete numerical results and even some  analytic understanding can be achieved.
An improved learning paradigm that offers a significant reduction in computation time during the supervised lewnlng phase is described. It is based on  extending the role that the neuron plays in artificial neural systems. Prior work  has regarded the neuron as a strictly passive, non-linear processing element, and  the synapse on the other hand as the primary source of information processing and  knowledge retention. In this work, the role of the neuron is extended insofar as Mlowing its pararaeters to adaptively participate in the learning phase. The temperature  of the sigmoid function is an exaraple of such a parameter. During learning, both the  synaptic interconnection weights w and the neuronal temperatures T/m are optimized so as to capture the knowledge contained within the training set. The method  allows each neuron to possess and update its own characteristic local temperature.  This algorithm has been applied to logic type of problems such as the XOR or parity  problem, resulting in a significant decrease in the required number of training cycles.
Rumelhart (1987), has proposed a method for choosing minimal or  "simple" representations during learning in Back-propagation  networks. This approach can be used to (a) dynamically select the  number of hidden units, Co) construct a representation that is  appropriate for the problem and (c) thus improve the generalization  ability of Back-propagation networks. The method Rumelhart suggests  involves adding penalty terms to the usual error function. In this paper  we introduce Rumelhart's minimal networks idea and compare two  possible biases on the weight search space. These biases are compared  in both simple counting problems and a speech recognition problem.  In general, the constrained search does seem to minimize the number of  hidden units required with an expected increase in local minima.
This paper addresses the problem of determining the weights for a  set of linear filters (model "cells") so as to maximize the  ensemble-averaged information that the cells' output values jointly  convey about their input values, given the statistical properties of  the ensemble of input vectors. The quantity that is maximized is the  Shannon information rate, or equivalently the average mutual  information between input and output. Several models for the role  of processing noise are analyzed, and the biological motivation for  considering them is described. For simple models in which nearby  input signal values (in space or time) are correlated, the cells  resulting from this optimization process include center-surround  cells and cells sensitive to temporal variations in input signal.
A number of learning models have recently been proposed which  involve calculations of temporal differences (or derivatives in  continuous-time models). These models, like most adaptive network  models, are formulated in terms of frequency (or activation), a useful  abstraction of neuronal firing rates. To more precisely evaluate the  implications of a neuronal model, it may be preferable to develop a  model which transmits discrete pulse-coded information. We point out  that many functions and properties of neuronal processing and learning  may depend, in subtle ways, on the pulse-coded nature of the information coding and transmission properties of neuron systems. When compared to formulations in terms of activation, computing with temporal  derivatives (or differences) as proposed by Kosko (1986), Klopf  (1988), and Sutton (1988), is both more stable and easier when reformulated for a more neuronally realistic pulse-coded system. In reformulating these models in terms of pulse-coding, our motivation has  been to enable us to draw further parallels and connections between  real-time behavioral models of learning and biological circuit models  of the substrates underlying learning and memory.
This paper is concerced with the use of error back-propagation  in phonetic classification. Our objective is to investigate the basic characteristics of back-propagation, and study how the framework of multi-layer perceptrons can be exploited in phonetic recognition. We explore issues such as integration of heterogeneous  sources of information, conditioq that can affect performance of  phonetic classification, internal representations, comparisons with  traditional pattern classification techniques, comparisons of different error metrics, and initialization of the network. Our investigation is performed within a set of experiments that attempts to recognize the 16 vowels in American English independent of speaker.  Our results are comparable to human performance.
In this paper 1 we show that neural networks for speech recognition can be constructed in  a modular fashion by exploiting the hidden structure of previously trained phonetic  subcategory networks. The performance of resulting larger phonetic nets was found to be  as good as the performance of the subcomponent nets by themselves. This approach  avoids the excessive learning times that would be necessary to Ixain larger networks and  allows for incremental learning. Large time-delay neural networks constructed  incrementally by applying these modular training techniques achieved a recognition  performance of 96.0% for all consonants.
Preliminary results on speaker-independant speech  recognition are reported. A method that combines expertise on  neural networks with expertise on speech recognition is used  to build the recognition systems. For transient sounds, eventdriven property extractors with variable resolution in the  time and frequency domains are used. For sonorant speech, a  model of the human auditory system is preferred to FFT as a  front-end module.
We propose a new neural network model and its learning  algorithm. The proposed neural network consists of four layers  input, hidden, output and final output layers. The hidden and  output layers are multiple. Using the proposed SICL(Spread  Pattern Information and Cooperative Learning) algorithm, it  is possible to learn analog data accurately and to obtain  smooth outputs. Using this neural network, we have developed  a speech production system consisting of a phonemic symbol  production subsystem and a speech parameter production  subsystem. We have succeeded in producing natural speech  waves with high accuracy.
SYREN is a connectionist model that uses temporal information  in a speech signal for syllable recognition. It classifies the rates  and directions of formant center transitions, and uses an adaptive  method to associate transition events with each syllable. The  system uses explicit spatial temporal representations through delay lines. SYREN uses implicit parametric temporal representations in formant transition classification through node activation  onset, decay, and transition delays in sub-networks analogous to  visual motion detector cells. SYREN recognizes 79% of six repetitions of 24 consonant-vowel syllables when tested on unseen  data, and recognizes 100% of its training syllables.
The Space Environment Laboratory in Boulder has collaborated  with the University of Colorado to construct a small expert  system for solar flare forecasting, called THEO. It performed as  well as a skilled human forecaster. We have constructed  TheoNet, a three-layer back-propagation connectionist network that learns to forecast flares as well as THEO does.  TheoNet's success suggests that a connectionist network can  perform the task of knowledge engineering automatically. A  study of the internal representations constructed by the network  may give insights to the "microstructure" of reasoning processes  in the human brain.
We discuss in this paper architectures for executing probabilistic rule-bases in a parallel manner, using as a theoretical basis recently introduced information-theoretic  models. We will begin by describing our (non-neural) learning algorithm and theory  of quantitative rule modelling, followed by a discussion on the exact nature of two  particular models. Finally we work through an example of our approach, going from  database to rules to inference network, and compare the network's performance with  the theoretical limits for specific problems.
A self-organizing Hopfield network has been  developed in the context of Vector Ouantiza-tion, aiming at compression of television  images. The metastable states of the spin  glass-like network are used as an extra  storage resource using the Minimal Overlap  learning rule (Krauth and Mezard 1987) to  optimize the organization of the attractors.  The sel f-organizing scheme that we have  devised results in the generation of an  adaptive codebook for any given TV image.  INllODUCTION  The ability of an Hopfield network (Little,1974;  Hopfield,1982,1986; Amir. and al., 1987; Personnaz and  al. 1985; Hertz, 1988) to behave as an associative memory  usually assumes a priori knowledge of the patterns to be  stored. As in many applications they are unknown, the aim  of this work is to develop a network capable to learn how  to select its attractors. TV image compression using  Vector Ouantization (V.Q.)(Gray, 19R4), a key issue for  HDTV transmission, is a typical case, since the non  neural algoritns which generate the list of codes (the  codebook) are suboptimal. As an alternative to the  promising neural compression techniques (Jackel et al.,  1987; Kohonen, 1988; Grossberg, 1987; Cottrel et al.,  1987) our idea is to use the metastability in a spin  glass-like net as an additional storage resource and to  derive after a "classical" clusterinq algorithm a  self-organizing sheme for generating adaptively the  codebook. We present the illustrative case of 2D-vectors.  * LEP : A member of the Philips Research Organization.  Neural Approach for TV Image Compression 265  In V.Q., the  of N pixel s  each vector  el ement of  ( figure 1).  NON NEURAL APPROACH  image is divided into blocks, named vectors,  (typically 4 x 4 pixels). Given the codebook,  is coded by associating it with the nearest  the list (Nearest Neighbout Classifier)  NCODR OCDOR  INPUT q  VECTOR  COMPRRE  INOEX  q ] RECONSTRUCTEO  INDEX CODEBOOK I VECTOR
The application of neural networks to the demodulation of  spread-spectrum signals in a multiple-access environment is  considered. This study is motivated in large part by the fact  that, in a multiuser system, the conventional (matched filter) receiver suffers severe performance degradation as the  relative powers of the interfering signals become large (the  "near-far" problem). Furthermore, the optimum receiver,  which alleviates the near-far problem, is too complex to be  of practical use. Receivers based on multi-layer percepttons  are considered as a simple and robust alternative to the optimum solution. The optimum receiver is used to benchmark  the performance of the neural net receiver; in particular, it is  proven to be instrumental in identifying the decision regions  of the neural networks. The back-propagation algorithm and  a modified version of it are used to train the neural net. An  importance sampling technique is introduced to reduce the  number of simulations necessary to evaluate the performance  of neural nets. In all examples considered the proposed neural net receiver significantly outperforms the conventional  receiver.
This study evaluates the performance of the multilayer-perceptron  and the frequency-sensitive competitive learning network in identifying five commercial aircraft from radar backscatter measurements. The performance of the neural network classifiers is compared with that of the nearest-neighbor and maximum-likelihood  classifiers. Our results indicate that for this problem, the neural  network classifiers are relatively insensitive to changes in the network topology, and to the noise level in the training data. While,  for this problem, the traditional algorithms outperform these simple neural classifiers, we feel that neural networks show the potential for improved performance.
A new class of neural network aimed at early visual processing is  described; we call it a Neural Analog Diffusion-Enhancement Layer or  "NADEL." The network consists of two levels which are coupled  through feedfoward and shunted feedback connections. The lower level  is a two-dimensional diffusion map which accepts visual features as  input, and spreads activity over larger scales as a function of time. The  upper layer is periodically fed the activity from the diffusion layer and  locates local maxima in it (an extreme form of contrast enhancement)  using a network of local comparators. These local maxima are fed back  to the diffusion layer using an on-center/off-surround shunting  anatomy. The maxima are also available as output of the network. The  network dynamics serves to cluster features on multiple scales as a  function of time, and can be used in a variety of early visual processing  tasks such as: extraction of comers and high curvature points along  edge contoms, line end detection, gap filling in contoms, generation of  fixation points, perceptual grouping on multiple scales, correspondence  and path impletion in long-range apparent motion, and building 2-D  shape representations that are invariant to location, orientation, scale,  and small deformation on the visual field.
We propose a parallel network of simple processors to find  color boundaries irrespective of spatial changes in illumination, and to spread uniform colors within marked regions.
ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer  back-propagation network designed for the task of road following. Curten fly ALVINN takes images from a camera and a laser range finder as input  and produces as output the direction the vehicle should travel in order to  follow the road. Training has been conducted using simulated road images.  Successful tests on the Carnegie Mellon autonomous navigation test vehicle  indicate that the network can effectively follow real roads under certain field  conditions. The tepresentation developed to perform the task differs dramatically when the network is trained under various conditions, suggesting  the possibility of a novel adaptive autonomous navigation system capable of  tailoring its processing to the conditions at hand.
Currently, the most complex spacecraft attitude determination  and control tasks are ultimately governed by ground-based  systems and personnel. Conventional on-board systems face  severe computational bottlenecks introduced by serial  microprocessors operating on inherently parallel problems. New  computer architectures based on the anatomy of the human brain  seem to promise high speed and fault-tolerant solutions to the  limitations of serial processing. This paper discusses the latest  applications of artificial neural networks to the problem of star  pattern recognition for spacecraft attitude determination.
This paper describes the construction of a system that recognizes hand-printed  digits, using a combination of classical techniques and neural-net methods. The  system has been trained and tested on real-world data, derived from zipcodes seen  on actual U.S. Mail. The system rejects a small percentage of the examples as  unclassifiable, and achieves a very low error rate on the remaining examples. The  system compares favorably with other state-of-the art recognizers. While some of  the methods are specific to this task, it is hoped that many of the techniques will  be applicable to a wide range of recognition tasks.  MOTIVATION  The problem of recognizing hand-written digits is of enormous practical and theoretical interest [Kahan, Pavlidis, and Baird 1987; Watanabe 1985; Pavlidis 1982].  This project has forced us to formulate and deal with a number of questions ranging from the basic psychophysics of human perception to analog integrated circuit  design.  This is a topic where "neural net" techniques are expected to be relevant, since  the task requires closely mimicking human performance, requires massively parallel  processing, involves confident conclusions based on low precision data, and requires  learning from examples. It is also a task that can benefit from the high throughput  potential of neural network hardware.  Many different techniques were needed. This motivated us to compare various classical techniques as well as modern neural-net techniques. This provided valuable  information about the strengths, weaknesses, and range of applicability of the numerous methods.  The overall task is extremely complex, so we have broken it down into a great  number of simpler steps. Broadly speaking, the recognizer is divided into the preprocessor and the classifier. The two main ideas behind the preprocessor are (1) to  remove meaningless variations (i.e. noise) and (2) to capture meaningful variations  (i.e. salient features).  Most of the results reported in this paper are based on a collection of digits taken  from hand-written Zip Codes that appeared on real U.S. Mail passing through the  324 Denker, et al  Figure 1: Typical Data  Buffalo, N.Y. poet office. Details will be discussed elsewhere [Denker et al., 1989].  Examples of such images are shown in figure 1. The digits were written by many  different people, using a great variety of writing styles and instruments, with widely  varying levels of care.  Important parts of the task can be handled nicely by our lab's custom analog  neural network VLSI chip [Graf et al., 1987; Graf  deVegvar, 1987], allowing us  to perform the necessary computations in a reasonable time. Also, since the chip  was not designed with image processing in mind, this provided a good test of the  chips' versatility.  THE PREPROCESSOR  Acquisition  The first step is to create a digital version of the image. One must find where on  the envelope the zipcode is, which is a hard task in itself [Wang and Srihari 1988].  One must also separate each digit from its neighbors. This would be a relatively  simple task if we could assume that a character is contiguous and is disconnected  from its neighbors, but neither of these assumptions holds in practice. It is also  common to find that there are meaningless stray marks in the image.  Acquisition, binarization, location, and preliminary segmentation were performed  by Postal Service contractors. In some images there were extraneous marks, so we  developed some simple heuristics to remove them while preserving, in most cases,  all segments of a split character.  Scaling and Deskewlng  At this point, the size of the image is typically 40 x 60 pixels, although the scaling  routine can accept images that are arbitrarily large, or as small as 5 x 13 pixels. A  translation and scale factor are then applied to make the image fit in a rectangle  Neural Network Recognizer for Hand-Written Zip Code Digits 325  20 x 32 pixels. The character is centered in the rectangle, and just touches either  the horizontal or vertical edges, whichever way fits. It is clear that any extraneous  marks must be removed before this step, lest the good part of the image be radically  compressed in order to make room for some wild mark. The scaling routine changes  the horizontal and vertical size of the image by the same factor, so the aspect ratio  of the character is preserved.  As shown in figure 1, images can differ greatly in the amount of skew, yet be  considered the same digit. This is an extremely significant noise source. To remove  this noise, we use the methods of [Casey 1970]; see also [Naylor 1971]. That is, we  calculate the XY and YY moments of the image, and apply a linear transformation  that drives the XY moment to zero. The transformation is a pure shear, not a  rotation, because we find that rotation is much less common than skew.  The operations of scaling and deskewing are performed in a single step. This yields  a speed advantage, and, more importantly, eliminates the quantization noise that  would be introduced by storing the intermediate images as pixel maps, were the  calculation carried out in separate steps.  Skeletonization  For the task of digit recognition, the width of the pen used to make the characters is  completely meaningless, and is highly variable. It is important to remove this noise  source. By deleting pixels at the boundaries of thick strokes. After a few iterations  of this process, each stroke will be as thin as possible. The idea is to remove as  many pixels as possible without breaking the connectivity. Connectivity is based  on the 8 nearest neighbors.  This can be formulated as a pattern matching problem -we search the image  looking for situations in which a pixel should be deleted. The decisions can be  expressed as a convolution, using a rather small kernel, since the identical decision  process is repeated for each location in the image, and the decision depends on the  configuration of the pixel's nearest and next-nearest neighbors.  Figure 2 shows an example of a character before (e) and after (f) skeletonization.  It also shows some of the templates we use for skeletonization, together with an  indication of where (in the given image) that template was active. To visualize the  convolution process, imagine taking a template, laying it over the image in each  possible place, and asking if the template is "active" in that place. (The template  is the convolution kernel; we use the two terms practically interchangeably.) The  portrayal of the template uses the following code: Black indicates that if the corresponding pixel in the image is ON, it will contribute +1 to the activity level of  this template. Similarly, gray indicates that the corresponding pixel, if ON, will  contribute -5, reducing the activity of this template. The rest of the pixels don't  matter. If the net activity level exceeds a predetermined threshold, the template  is considered active at this location. The outputs of all the skeletonizer templates  326 Denker, et al  b)  c)  d)  ½)  Figure 2: Skeletonization  are combined in a giant logical OR, that is, whenever any template is active, we  conclude that the pixel presently under the center of the template should be deleted.  The skeletonization computation involves six nested loops:  for each iteration I  for all X in the image (horizontal coordinate)  for all Y in the image (vertical coordinate)  for all T in the set of template shapes  for all P in the template (horizontal)  for all Q in the template (vertical)  compare image element(X +P, Y+Q)  with template(T) element(P, Q)  The inner three loops (the loops over T, P, and Q) are performed in parallel, in  a single cycle of our special-purpose chip. The outer three loops (I, X, and Y)  are performed serially, calling the chip repeatedly. The X and Y loops could be  performed in parallel with no change in the algorithms. The additional parallelism  would require a proportionate increase in hardware.  Neural Network Recognizer for Hand-Written Zip Code Digits 327  The purpose of template a is to detect pixels at the top edge of a thick horizontal  line. The three "should be OFF" (light grey shade in figure 2) template elements  enforce the requirement that this should be a boundary, while the three "should be  ON" (solid black shade in figure 2) template elements enforce the requirement that  the line be at least two pixels wide.  Template b is analogous to template a, but rotated 90 degrees. Its purpose is to  detect pixels at the left edge of a thick vertical line.  Template c is similar to, but not exactly the same as, template a rotated 180 degrees.  The distinction is necessary because all templates are applied in parallel. A stroke  that is only two pixels thick .must not be attacked from both sides at once, lest it be  removed entirely, changing the connectivity of the image. Previous convolutional  line-thinning schemes [Naccache 1984] used templates of size 3 x 3, and therefore  had to use several serial sub-stages. For parallel operation at least 3 x 4 kernels are  needed, and 5 x 5 templates are convenient, powerful, and flexible.  Feature Maps  Having removed the main sources of meaningless variation, we turn to the task of  extracting the meaningful information. It is known from biological studies [Hubel  and Wiesel 1962] that the human vision system is sensitive to certain features that  occur in images, particularly lines and the ends of lines. We therefore designed  detectors for such features. Previous artificial recognizers [Watanabe 1985] have  used similar feature extractors.  Once again we use a convolutional method for locating the features of interest -we  check each location in the image to see if each particular feature is present there.  Figure 3 shows some of the templates we use, and indicates where they become  active in an example image. The feature extractor templates are 7 x 7 pixels -slightly larger than the skeletonizer templates.  Feature b is designed to detect the right-hand end of (approximately) horizontal  strokes. This can be seen as follows: in order for the template to become active  at a particular point, the image must be able to touch the "should be ON" pixels  at the center of the template without touching the surrounding horseshoe-shaped  collection of "'must be OFF" pixels. Essentially the only way this can happen is at  the right-hand end of a stroke. (An isolated dot in the image will also activate this  template, but the images, at this stage, are not supposed to contain dots). Feature  d detects (approximately) horizontal strokes.  There are 49 different feature extractor templates. The output of each is stored  separately. These outputs are called feature maps, since they show what feature(s)  occurred where in the image. It is possible, indeed likely, that several different  features will occur in the same place.  Whereas the outputs of all the skeletonizer templates were combined in a very simple  way (a giant OR), the outputs of the feature extractor templates are combined in  328 Denker, et al  Figure 3: Feature Extraction  various artful ways. For example, feature b and a similar one are ORed to form a  single combined feature that responds to right-hand ends in general. Certain other  features are ANDed to form detectors for arcs (long curved strokes). There are 18  combined features, and these are what is passed to the next stage.  We need to create a compact representation, but starting from the skeletonized  image, we have, instead, created 18 feature maps of the same size. Fortunately, we  can now return to the theme of removing meaningless variation.  If a certain image contains a particular feature (say a left-hand stroke end) in the  upper left corner, it is not really necessary to specify the location of that feature  with great precision. To recognize the shaIe of the feature required considerable  precision at the input to the convolution, but the position of the feature does not  require so much precision at the output of the convolution. We call this Coarse  Blocking or Coarse Coding of the feature maps. We find that 3 x 5 is sufficent  resolution.  CLASSIFIERS  If the automatic recognizer is unable to classify a particular zip code digit, it may  be possible for the Post Office to determine the correct destination by other means.  This is costly, but not nearly so costly as a misclassification (substitution error) that  causes the envelope to be sent to the wrong destination. Therefore it is critically  Neural Network Recognizer for Hand-Written Zip Code Digits 329  important for the system to provide estimates of its confidence, and to reject digits  rather than misclassify them.  The objective is not simply to maximize the number of classified digits, nor to  minimize the number of errors. The objective is to minimize the cost of the whole  operation, and this involves a tradeoff between the rejection rate and the error rate.  Preliminary Investigations  Several different classifiers were tried, including Parzen Windows, K nearest neighbors, highly customized layered networks, expert systems, matrix associators, feature spins, and adaptive resonance. We performed preliminary studies to identify  the most promising methods. We determined that the top three methods in this  list were significantly better suited to our task than the others, and we performed  systematic comparisons only among thoe three.  Classical Clustering Methods  We used two classical clustering techniques, Parzen Windows (PW) and K Nearest Neighbors (KNN), which are nicely described in Duda and Hart [1973]. In  this application, we found (as expected) that they behaved similarly, although PW  consistently outperformed KNN by a small margin. These methods have many  advantages, not the least of which is that they are well motivated and easily understood in terms of standard Bayesian inference theory. They are well suited to  implementation on parallel computers and/or custom hardware. They provide excellent confidence information.  Unlike modern adaptive network methods, PW and KNN require no "learning  time", Furthermore the performance was reproducible and responded smoothly to  improvements in the preprocessor and increases in the size of the training set. This  is in contrast to the "noisy" performance of typical layered networks. This is convenient, indeed crucial, during exploratory work.  Adaptive Network Methods  In the early phases of the project, we found that neural network methods gave  rather mediocre results. Later, with a high-performance preprocessor, plus a large  training database, we found that a layered network gave the best results, surpassing  even Parzen Windows. We used a network with two stages of processing (i.e., two  layers of weights), with 40 hidden units and using a one-sided objective function (as  opposed to LMS) as described in [Denker and Wittner 1987]. The main theoretical  advantage of the layered network over the classical methods is that it can form  "higher order" features -conjunctions and disjunctions of the features provided  by our feature extractor. Once the network is trained, it has the advantage that the  classification of each input is very rapid compared to PW or KNN. Furthermore,  the weights represent a compact distillation of the training data and thus have a  smaller memory requirement. The network provides confidence information that is  330 Denker, et al  just as good as the classical methods. This is obtained by comparing the activation  level of the most active output against the runner-up unit(s).  To check on the effectiveness of the preprocessing stages, we applied these three  classification schemes (PW, KNN, and the two-layer network) on 256-bit vectors  consisting of raw bit maps of the images -with no skeletonization and no feature  extraction. For each classification scheme, we found the error rate on the raw bit  maps was at least a factor of 5 greater than the error rate on the feature vectors,  thus clearly demonstrating the utility of feature extraction.  TESTING  It is impossible to compare the performance of recognition systems except on identical databases. Using highly motivated "friendly" writers, it is possible to get a  dataset that is so clean that practically any algorithm would give outstanding results. On the other hand, if the writers are not motivated to write clearly, the result  will be not classifiable by machines of any sort (nor by humans for that matter).  It would have been much easier to classify digits that were input using a mouse or  bitpad, since the hnes in the such an image have zero thickness, and stroke-order  information is available. It would also have been much easier to recognize digits  from a single writer.  The most realistic test data we could obtain was provided by the US Postal Service.  It consists of approximately 10,000 digits (1000 in each category) obtained from the  zip codes on actual envelopes. The data we received had already been binarized  and divided into images of individual digits, rather than multi-digit zip codes, but  no further processing had been done.  On this data set, our best performance is as follows: if 14% of the images are rejected  as unclassifiable, only 1% of the remainder are misclassified. If no images are rejected, approximately 6% are misclassified. Other groups are working with the same  dataset, but their results have not yet been published. Informal communications  indicate that our results are among the best.  CONCLUSIONS  We have obtained very good results on this very difficult task. Our methods include  low-precision and analog processing, massively parallel computation, extraction of  biologically-motivated features, and learning from examples. We feel that this is,  therefore, a fine example of a Neural Information Processing System. We emphasize that old-fashioned engineering, classical pattern recognition, and the latest  learning-from-examples methods were all absolutely necessary. Without the careful  engineering, a direct adaptive network attack would not succeed, but by the same  token, without learning from a very large database, it would have been excruciating  to engineer a sufficiently accurate representation of the probability space.  Neural Network Recognizer for Hand-Written Zip Code Digits 331  Acknowledgements  It is a pleasure to acknowledge useful discussions with Patrick Gallinari and technical assistance from Roger Epworth. We thank Tim Barnum of the U.S. Postal  Service for making the Zip Code data available to us.  References
A neural network is applied to the problem of  recognizing Kanji characters. Using a b ac k  propagation network learning algorithm, a threelayered, feed-forward network is trained to  recognize similar handwritten Kanji characters. In  addition, two new methods are utilized to make  training effective. The recognition accuracy was  higher than that of conventional methods. An  analysis of connection weights showed that trained  networks can discern the hierarchical structure of  Kanji characters. This strategy of trained networks  makes high recognition accuracy possible. Our  results suggest that neural networks are very  effective for Kanji character recognition.
A pool of handwritten signatures is used to train a neural network for the task of deciding whether or not a given signature is a  forgery. The network is a feedforward net, with a binary image as  input. There is a hidden layer, with a single unit output layer. The  weights are adjusted according to the backpropagation algorithm.  The signatures are entered into a C software program through the  use of a Datacopy Electronic Digitizing Camera. The binary signatures are normalized and centered. The performance is examined  as a function of the training set and network structure. The best  scores are on the order of 2% true signature rejection with 2-4%  false signature acceptance.
MURPHY is a vision-based kinematic controller and path planner  based on a connectionist architecture, and implemented with a video  camera and Rhino XR-series robot arm. Imitative of the layout of sensory and motor maps in cerebral cortex, MURPHY'S internal representations consist of four coarse-coded populations of simple units representing both static and dynamic aspects of the sensory-motor environment.  In previously reported work [4], MURPHY first learned a direct kinematic  model of his camera-arm system during a period of extended practice,  and then used this "mental model" to heuristically guide his hand to  unobstructed visual targets. MURPHY has since been extended in two  ways: First, he now learns the inverse differential-kinematics of his arm  in addition to ordinary direct kinematics, which allows him to push his  hand directly towards a visual target without the need for search. Secondly, he now deals with the much more difficult problem of reaching in  the presence of obstacles.
Computing the inverse dynamics of a robot arm is an active area of research  in the control literature. We hope to learn the inverse dynamics by training  a neural network on the measured response of a physical ann. The input to  the network is a temporal window of measured positions; output is a vector  of torques. We train the network on data measured from the first two joints  of the CMU Direct-Drive Arm II as it moves through a randomly-generated  sample of "pick-and-place" trajectories. We then test generalization with  a new trajectory and compare its output with the torque measured at the  physical arm. The network is shown to generalize with a root mean square  error/standard deviation (RMSS) of 0.10. We interpreted the weights of the  network in terms of the velocity and acceleration filters used in conventional  control theory.
The barn owl has fused visual/auditory/motor representations of  space in its midbrain which are used to orient the head so that visual or auditory stimuli are centered in the visual field of view. We  present models and computer simulations of these structures which  address various problems, includi. g. the construction of a map of  space from auditory sensory info'lation, and the problem of driving the motor system from these maps. We compare the results  with biological data.
We have previously developed a simple mathematical model for formation of ocular dominance columns in  msmmalinn visual cortex. The model provides a common framework in which a variety of activity-dependent  biological machnnisms can be studied. Analytic and computational results together now reveal the following: if  inputs specific to each eye are locally correlated in their  firing, and are not anticorrelated within an arbor radius,  monocular cells will robustly form and be organized by  intra-cortical interactions into column. Broader correlations within each eye, or anti-correlations between the  eyes, create a more purely monocular cortex; positive correlation over an arbor radius yields an almost perfectly  monocular cortex. Most features of the model can be understood analytically through decomposition into eigenfunctions and linear stability analysis. This allows prediction of the widths of the coh,mns and other features from  measurable biological parameters.
We have used analog VLSI technology to model a class of small oscillating biological neural circuits known as central pattern generators (CPG). These circuits generate rhythmic patterns of activity  which drive locomotor behaviour in the animal. We have designed,  fabricated, and tested a model neuron circuit which relies on many  of the same mechanisms as a biological central pattern generator  neuron, such as delays and internal feedback. We show that this  neuron can be used to build several small circuits based on known  biological CPG circuits, and that these circuits produce patterns of  output which are very similar to the observed biological patterns. 
In modeling studies of memory based on neural networks, both the selective  enhancement and depression of synaptic strengths are required for efficient storage  of information (Sejnowski, 1977a, b; Kohonen, 1984; Bienenstock et al, 1982;  Sejnowski and Tesauro, 1989). We have tested this assumption in the hippocampus,  a cortical structure of the brain that is involved in long-term memory. A brief,  high-frequency activation of excitatory synapses in the hippocampus produces an  increase in synaptic strength known as long-term potentiation, or LTP (Bliss and  Lomo, 1973), that can last for many days. LTP is known to be Hebbian since it  requires the simultaneous release of neurotransmitter from presynaptic terminals  coupled with postsynaptic alepolarization (Kelso et al, 1986; Mannow and Miller,  1986; Gustaffson et al, 1987). However, a mechanism for the persistent reduction of  synaptic strength that could balance LTP has not yet been demonstrated. We studied the associative interactions between separate inputs onto the same dendritic  trees of hippocampal pyramidal cells of field CA1, and found that a low-frequency  input which, by itself, does not persistently change synaptic strength, can either  increase (associative LTP) or decrease in strength (associative long.term depression  or LTD) depending upon whether it is positively or negatively correlated in Ome  with a second, high-frequency bursting input. LTP of synaptic strength is Hebbian,  and LTD is anti.Hebbian since it is elicited by pairing presynaptic firing with postsynaptic hyperpolarization sufficient to block postsynaptic activity. Thus, associative LTP and associative LTD are capable of storing information contained in the  covariance between separate, converging hippocampal inputs.  * Present address: Departments of Neuroscience and Neurology, Albert Einstein College  of Medicine, 1410 Pelham Parkway South, Bronx, NY 10461 USA.  ?Present address: Computational Neurobiology Laboratory, The Salk Institute, P.O. Box  85800, San Diego, CA 92138 USA.  Storing Covariance by Synaptic Strengths in the Hippocampus 395
The olfactory bulb of mammals aids in the discrimination of  odors. A mathematical model based on the bulbar anatomy and  electrophysiology is described. Simulations produce a 35-60 Hz  modulated activity coherent across the bulb, mimicing the observed  field potentials. The decision states (for the odor information )  here can be thought of as stable cycles, rather than point stable  states typical of simpler neuro-computing models. Analysis and  simulations show that a group of coupled non-linear oscillators are  responsible for the oscillatory activities determined by the odor input, and that the bulb, with appropriate inputs from higher centers,  can enhance or suppress the sensitivity to particular odors. The  model provides a framework in which to understand the transform  between odor input and the bulbar output to olfactory cortex.
We present a new hypothesis that the cerebellum plays a key role in actively controlling the acquisition of sensory information by the nervous  system. In this paper we explore this idea by examining the function of  a simple cerebellar-related behavior, the vestibulo-ocular reflex or  VOR, in which eye movements are generated to minimize image slip  on the retina during rapid head movements. Considering this system  from the point of view of statistical estimation theory, our results suggest that the transfer function of the VOR, often regarded as a static or  slowly modifiable feature of the system, should actually be continuously and rapidly changed during head movements. We further suggest  that these changes are under the direct control of the cerebellar cortex  and propose experiments to test this hypothesis.
Most of the current neural networks use models which have only tenuous connections to the biological neural systems on which they purport to be based, and negligible input from the neuroscience/biophysics communities. This paper describes an ongoing effort which approaches neural net research in a program of close collaboration of neuroscientists and engineers. The effort is designed to elucidate associative learning in the marine snail Hermissenda crassicornis, in which Pavlovian conditioning has been observed. Learning has been isolated in the four neuron network at the convergence of the visual and vestibular pathways in this animal, and biophysical changes, specific to learning, have been observed in the membrane of the photoreceptor B cell. A basic charging capacitance model of a neuron is used and enhanced with biologically plausible mechanisms that are necessary to replicate the effect of learning at the cellular level. These mechanisms are non-linear and are, primarily, instances of second order control systems (e.g., fatigue, modulation of membrane resistance, time dependent rebound), but also include shunting and random background firing. The output of the model of the four-neuron network displays changes in the temporal variation of membrane potential similar to those observed in electrophysiological measurements. 
The weakly electric fish, Gnathonemus petersii, explores its environment by generating pulsed electric fields and detecting small perturbations in the fields resulting from  nearby objects. Accordingly, the fish detects and discriminates objects on the basis of a  sequence of electric "images" whose temporal and spatial properties depend on the timing of the fish's electric organ discharge and its body position relative to objects in its environment. We are interested in investigating how these fksh utilize timing and body-position during exploration to aid in object discrimination. We have developed a fmite-element simulation of the fish's self-generated electric fields so as to reconstruct the electrosensory consequences of body position and electric organ discharge timing in the fish.  This paper describes this finite-element simulation system and presents preliminary electric field measurements which are being used to tune the simulation.
tteiligenberg (1987) recently proposed a model to explain how sensory maps could enhance resolution through orderly arrangement of  broadly tuned receptors. We have extended this model to the general  case of polynomial weighting schemes and proved that the response  function is also a polynomial of the same order. We further demonstrated that the Hermitian polynomials are eigenfunctions of the system. Finally we suggested a biologically plausible mechanism for sensory representation of external stimuli with resolution far exceeding the  inter-receptor separation.
We have mathematically shown that cortical maps in the  primary sensory cortices can be reproduced by using three  hypotheses which have physiological basis and meaning.  Here, our main focus is on ocular.dominance column formation  in the primary visual cortex. Monte Carlo simulations on the  segregation of ipsilateral and contralateral afferent terminals  are carried out. Based on these, we show that almost all the  physiological experimental results concerning the ocular  dominance patterns of cats and monkeys reared under normal  or various abnormal visual conditions can be explained from a  viewpoint of the phase transition phenomena.  ROUGH SKETCH OF OUR THEORY  In order to describe the use-dependent self-organization of neural connections  {Singer, 1987 and Frank, 1987}, we have proposed a set of coupled equations  involving the electrical activities and neural connection density {Tanaka,  1988}, by using the following physiologically based hypotheses: (1) Modifiable  synapses grow or collapse due to the competition among themselves for some  trophic factors, which are secreted retrogradely from the postsynaptic side to  the presynaptic side. (2) Synapses also sprout or retract according to the  concurrence of presynaptic spike activity and postsynaptic local membrane  depolarization. (3) There already exist lateral connections within the layer,  into which the modifiable nerve fibers are destined to project, before the  synaptic modification begins. Considering this set of equations, we find that  the time scale of electrical activities is much smaller than time course  necessary for synapses to grow or retract. So we can apply the adiabatic  approximation to the equations. Furthermore, we identify the input electrical  activities, i.e., the firing frequency elicited from neurons in the projecting  neuronal layer, with the stochastic process which is specialized by the spatial  correlation function Cl;lc '. Here, k and k' represent the positions of the  neurons in the projecting layer. p stands for different pathways such as  ipsilateral or contralateral, on-center or off-center, colour specific or  nonspecific and so on. From these approximations, we have a nonlinear  452 Tanaka  stochastic differential equation for the connection density, which describes a  survival process of synapses within a small region, due to the strong  competition. Therefore, we can look upon an equilibrium solution of this  equation as a set of the Potts spin variables ojk's {Wu, 1982}. Here, if the  neuron k in the projecting layer sends the axon to the position j in the target  layer, ojk= 1 and if not, Ojl=0. The Potts spin variable has the following  property:  _ ojkp= 1  If we limit the discussion within such equilibrium solutions, the problem is  reduced to the thermodynamics in the spin system. The details of the  mathematics are not argued here because they are beyond the scope of this  paper {Tanaka}. We find that equilibrium behavior of the modifiable nerve  terminals can be described in terms of thermodynamics in the system in  which Hamiltonian H and fictitious temperature T are given by  H =-q r%ov,  jkp jkp j'k'p'  c  , (2)  'I;  $  where k and Ckp ;k' ' are the averaged firing frequency and the correlation  function, respectively. Vjj. describes interaction between synapses in the  target layer. q is the ratio of the total averaged membrane potential to the  averaged membrane potential induced through the modifiable synapses from  the projecting layer. c and us are the correlation time of the electrical  activities and the time course necessary for synapses to grow or collapse.  APPLICATION TO THE OCULAR DOMINANCE  COLUMN FORMATION  A specific cortical map structure is determined by the choice of the correlation  function and the synaptic interaction function. Now, let us neglect k  dependence of the correlation function and take into account only ipsilateral  and contralateral pathways denoted by p, for mathematical simplicity. In this  case, we can reduce the Potts spin variable into the Ising spin one through the  following transformation:  Theory of Self-Organization of Cortical Maps 453  Sj =  p oil p  kp  where j is the position in the layer 4 of the primary visual cortex, and sj takes  only 4-1 or -1, according to the ipsilateral or contralateral dominance. We  find that this system can be described by HamiltonJan:  H= -hZS j J  y  J J j'j  (3)  The first term of eq.(3) reflects the ocular dominance shift, while the second  term is essential to the ocular dominance stripe segregation.  Here, we adopt the following simplified funorion as Vii,:  qex qinh  ---..... 0 (tex-djj,) -" 0 (iaa-djj,)  V j j, nt,2 ,  ex ninh  (4)  where djj, is the distance between j and j'. ex and Jkin h are determined by the  extent of excitatory and inhibitory lateral connections, respectively. O is the  step function. q,x and q,a are propotional to the membrane potentials  induced by excitatory and inhibitory neurons {Tanaka}. It is not essential to  the qualitative discussion whether the interaction function is given by the use  of the step function, the Gaussian function, or others.  Next, we define 9+ 1 and T-1 as the average firing frequencies of ipsilateral  and contralateral retinal ganglion cells (RGCs), and [+1 v and [+ 1 s as their  fluctuations which originate in the visually stimulated and the spontaneous  firings of RGCs, respectively. These are used to calculate two new  parameters, r and a:   = (5)  )2 + ( s V (,v)2 + (s  '%/ (V+i +1 )2 -1 -1 )2 '  rl+l --rl_ 1   = _ _ (6)  rl +1 4. rl_  454 Tanaka  r is related to the correlation of firings elicited from the left and right RGCs.  If there are only spontaneous firings, there is no correlation between the left  and right RGCs' firings. On the other hand, in the presence of visual  stimulation, they will correlate, since the two eyes receive almost the same  images in normal animals. a is a function of the imbalance of firings of the left  and right RGCs. Now, J and h in eq.(3) can be expressed in terms ofr and a:  l_a2 )  J =b 1 1 -r --1 +a 2 '  (?)  where bl is a constant of the order of 1, and b2 is determined by average  membrane potentials.  Using the above equations, it will now be shown that patterns such as the  ones observed for the ocular dominance column of new-world monkeys and  cats can be explained. The patterns are very much dependent on three  parameters r, a and K which is the ratio of the membrane potentials (qinh/qex)  induced by the inhibitory and excitatory neurons.  RESULTS AND DISCUSSIONS  In the subsequent analysis by Monte Carlo simulations, we fix the values of  parameters: qex-l.0, hex=0.25, hinh=l.0, T=0.25, b=l.0, b2=0.1, and  dx = 0.1. dx is the diameter of a small area which is occupied by one spin. In  the computer simulations of Fig. l, we can see that the stripe patterns become  more segregated as the correlation strength r decreases. The similarity of the  pattern in Fig. lc to the well-known experimental evidence {Hubel and Wiesel,  1977} is striking. Furthermore, it is known that if the animal has been reared  under the condition where the two optic nerves are electrically stimulated  synchronously, stripes in the primary visual cortex are not formed {Stryker}.  This condition corresponds to r values close to 1 and again our theory predicts  these experimental results as can be seen in Fig. la. On the contrary, if the  strabismic animal has been reared under the normal condition {Wiesel and  Hubel, 1974}, r is effectively smaller than that of a normal animal. So we  expect that the ocular dominance stripe has very sharp delimitations as it is  observed experimentally. In the case of a binocularly deprived animal {Wiesel  and Hubel, 1974},i.e., +v=_v=0, it is reasonable to expect that the  situation is similar to the strabismic animal.  Theory of Self-Organization of Cortical Maps 455  Figure 1. Ocular dominance patterns given by the computer  simulations in the case of the large inhibitory connections  (K=I.0) and the balanced activities (a-0). The correlation  strength r is given in each case: r=0.9 for (a), r=0.6 for (b),  and r = 0.1 for (c).  In the case of a 0, we can get asymmetric stripe patterns such as one in  Fig.2a. Since this situation corresponds to the condition of the monocular  deprivation, we can also explain the experimental observation {Hubel et  a1.,1977} successfully. There are other patterns seen in Fig.2b, which we call  blob lattice patterns. The existence of such patterns has not been confirmed  physiologically, as far as we know. However, this theory on the ocular  dominance column formation predicts that the blob lattice patterns will be  found if appropriate conditions, such as the period of the monocular  Figure 2. Ocular dominance patterns given by the computer  simulations in the case of the large inhibitory connections  (K=I.0) and the imbalanced activities: a=0.2 for (a) and  a-= 0.4 for (b). The correlation strength r is given by r= 0.1 for  both (a) and (b).  456 Tanaka  deprivation, are chosen.  We find that the straightness of the stripe pattern is controlled by the  parameter K. Namely, if K is large, i.e. inhibitory connections are more  effective than excitatory ones, the pattern is straight. However if  is small  the pattern has many branches and ends. This is illustrated in Fig. 3c. We  can get a pattern similar to the ocular dominance pattern of normal cats  {Anderson et al., 1988}, if is small and r-rc (Fig. 3b). The meaning of rc will  be discussed in the following paragraphs. We further get a labyrinth pattern  by means of r smaller than rc and the same . We can think  value is specific  to the animal under consideration because of its definition. Therefore, this  theory also predicts that the ocular dominance pattern of the strabismic cat  will be sharply delimitated but not a straight stripe in contrast to the pattern  of monkey.  Figure 3. Ocular dominance patterns given by the computer  simulations in the case of the small inhibitory connections  (K-0.3) and the balanced activities(a=0). The correlation  strength r is given in each case: r = 0.9 for (a), r = 0.6 for (b) and  r = 0.1 for (c).  Having seen specific examples, let us now discuss the importance of  parameters r and a, which stand for the correlation strength and the  imbalance of firings. According to qualitative difference of patterns obtained  from our simulations, we classify the parameter space (r, .a) into three regions  in Fig.4: In region (S), stripe patterns appear. The left-eye dominance and the  right-eye dominance bands are equal in width, for a-0. On the other hand,  they are not equal for non-zero value. In region (B), patterns are blob lattices.  In region (U), the patterns are uniform and we do not see any spatial  modulation. A uniform pattern whose a value is close to 0 is a random  pattern, while if a is close to 1 or -1 either ipsilateral or contralateral nerve  terminals are present. On the horizontal axis, (S) and (U) regions are devided  by the critical point rc. In practice if we define the order parameter as the  Theory of SeW-Organization of Cortical Maps 457  ensemble-averaged amplitude of the dominant Fourier component of spatial  patterns, and the susceptibility as the variance of the amplitude, then we can  observe their singular behavior near rrc.  Various conditions where animals have been reared correspond positions in  the parameter space of Fig.4: normal (N), synchronized electrical stimulation  (SES), strabismus (S), binocular deprivation (BD), long-term monocular  deprivation (LMD) and short-term monocular deprivation (SMD). If an  animal is kept under the monocular deprivation for a long period, the absolute  value of is close to 1 and r value is 0, considering eqs.(5) and (6). For a shortterm monocular deprivation, the corresponding point falls on anywhere on the  line from N to LMD, because relaxation from the symmetric stripe pattern to  the open-eye dominant uniform pattern is incomplete. The position on this  line is, therefore, determined by this relaxation period, in which the animal is  kept under the monocular deprivation.
A new learning algorithm for the storage of static  and periodic attractors in biologically inspired  recurrent analog neural networks is introduced.  For a network of n nodes, n stati, c or n/2 periodic  attractors may be stored. The aigorithm ailows  programming of the network vector fieid independent of the patterns to be stored. Stability of  patterns, basin geometry, and rates of convergence  may be controlled. For orthonormal patterns, the  legming operation reduces to a kind of periodic  outer product ruie that allows iocal, additive,  commutative, incremental learning. Standing or  traveiing wave cycles may be stored to mimic the  kind of osciilating spatial patterns that appear  in the neural activity of the olfactory bulb and  prepyriform cortex during inspiration and suffice,  in the buib, to predict the pattern recognition  behavior of rabbits in ciassical conditioning experiments. These attractors arise, during simuIated inspiration, through a muItipIe Hopf bifurcation, which can act as a criticaI "decision point"  for their selection by a very smaIi input pattern.
The primate visual system learns to recognize the true direction of  pattern motion using local detectors only capable of detecting the  component of motion perpendicular to the orientation of the  moving edge. A multilayer feedforward network model similar to  Linsker's model was presented with input patterns each consisting  of randomly oriented contours moving in a particular direction.  Input layer units are granted component direction and speed tuning  curves similar to those recorded from neurons in primate visual  area V1 that project to area MT. The network is trained on many  such patterns until most weights saturate. A proportion of the  units in the second layer solve the aperture problem (e.g., show the  same direction-tuning curve peak to plaids as to gratings),  resembling pattern-direction selective neurons, which first appear  in area MT.
We analyze a mathematical model for retinal directionally selective  cells based on recent electrophysiological data, and show that its  computation of motion direction is robust against noise and speed.
We have developed a graphically oriented, general purpose  simulation system to facilitate the modeling of neural networks.  The simulator is implemented under UNIX and X-windows and is  designed to support simulations at many levels of detail.  Specifically, it is intended for use in both applied network  modeling and in the simulation of detailed, realistic, biologicallybased models. Examples of current models developed under this  system include mammalian olfactory bulb and cortex, invertebrate  central pattern generators, as well as more abstract connectionist  simulations.
We consider a 2-layer, 3-node, n-input neural network whose nodes  compute linear threshold functions of their inputs. We show that it  is NP-complete to decide whether there exist weights and thresholds  for the three nodes of this network so that it will produce output consistent with a given set of training examples. We extend the result  to other simple networks. This result suggests that those looking for  perfect training algorithms cannot escape inherent computational  difficulties just by considering only simple or very regular networks.  It also suggests the importance, given a training problem, of finding  an appropriate network and input encoding for that problem. It is  left as an open problem to extend our result to nodes with non-linear  functions such as sigmoids.
Hidden Markov models are widely used for automatic speech recognition. They inherently incorporate the sequential character of the  speech signal and are statistically trained. However, the a-priori  choice of the model topology limits their flexibility. Another drawback of these models is their weak discriminating power. Multilayer  perceptrons are now promising tools in the connectionist approach  for classification problems and have already been successfully tested  on speech recognition problems. However, the sequential nature of  the speech signal remains difficult to handle in that kind of machine. In this paper, a discriminant hidden Markov model is defined and it is shown how a particular multilayer perceptron with  contextual and extra feedback input units can be considered as a  general form of such Markov models.
The Boltzmann Machine has been introduced as a means to perform  global optimization for multimodal objective functions using the  principles of simulated annealing. In this paper we consider its utility  as a spurious-free content-addressable memory, and provide bounds on  its performance in this context. We show how to exploit the machine's  ability to escape local minima, in order to use it, at a constant  temperature, for unambiguous associative pattern-retrieval in noisy  environments. An association rule, which creates a sphere of influence  around each stored pattern, is used along with the Machine's dynamics  to match the machine's noisy input with one of the pre-stored patterns.  Spurious fixed points, whose ragions of attraction are not recognized by  the rule, are skipped, due to the Machine's finite probability to escape  from any state. The results apply to the Boltzmann machine and to the  asynchronous net of binary threshold elements (*rlopfield model'). They  provide the network designer with worst-case and best-case bounds for  the network's performance, and allow polynomial-time tradeoff studies  of design parameters.
This paper presents a variation of the back-propagation algorithm that makes optimal use of a network hidden units by decreasing an "nergy" term written as a function of the squared  activations of these hidden units. The algorithm can automatically find optimal or nearly optimal architectures necessary to  solve known Boolean functions, facfiitate the interpretation of  the activation of the remaining hidden units and automatically  estimate the complexity of architectures appropriate for phonetic  labeling problems. The general principle of the algorithm can  also be adapted to different tasks: for example, it can be used to  eliminate the [0, 0] local minimum of the [-1, +1] logistic activation function while preserving a much faster convergence and  forcing binary activations over the set of hidden units.  PRINCIPLE  This paper describes an algorithm which makes optimal use of the hidden units in  a network using the standard back-propagation algorithm (Rumelhart, Hinton &  Williams, 1986). Optimality is defined as the minimization of a function of the  "energy" spent by the hidden units throughtout the network, independently of  the chosen architecture, and where the energy is written as a function of the  squared activations of the hidden units.  The standard back-propagation algorithm is a gradient descent algorithm on the  following cost function:  P O  c -j i  where d is the desired output of an output unit, o the actual output, and where  the sum is taken over the set of output units 0 for the set of training patterns P.  520 Chauvin  The following algorithm implements a gradient descent on the following cost function:  P 0 P H  C= !er Z Z (dij-oij) 2 + !en Z Z e(oj) [21  j i j i  where e is a positive monotonic function and where the sum of the second term is  now taken over a set or subset of the hidden units H. The first term of this cost  function will be called the error term, the second, the energy term.  In principle, the theoretical minimum of this function is found when the desired  activations are equal to the actual activations for all output units and all presented  patterns and when the hidden units do not "spend any energy". In practical  cases, such a minimum cannot be reached and the hidden units have to "spend  some energy" to solve a given problem. The quantity of energy will be in part  determined by the relative importance given to the error and energy terms during  gradient descent. In principle, if a hidden unit has a constant activation whatever  the pattern presented to the network, it contributes to the energy term only and  will be "suppressed" by the algorithm. The precise energy distribution among the  hidden units will depend on the actual energy function e.  ANAI.YSIS  ALGORITHM IMPLEMENTATION  We can write the total cost function that the algorithm tries to minimize as a  weighted sum of an error and energy term:  C = laerEer + laenEen  [3]  The first term is the error term used with the standard back-propagation algorithm in Rumelhart et al. If we have h hidden layers, we can write the total  energy term as a sum of all the energy terms corresponding to each hidden layer:  h H  [4]  To decrease the energy of the uppermost hidden layer Hh, we can compute the  derivative of the energy function with respect to the weights. This derivative will  be null for any weight "above" the considered hidden layer. For any weight just  below the considered hidden layer, we have (using Rumelhart et al. notation):  A Back-Propagation Algorithm 521  OEen OEen Oneti Oneti  [51  Oe(o) Oe(ot 2.) 0o OOi .. 2e'oif i(neti) [6]  where the derivative of e is taken with respect to the "energy" of the unit i and  where f corresponds to the logistic function. For any hidden layer below the  considered layer h, the chain rule yields:  J  This is just. standard back-propagation with a different back-propagated term. If  we minimize both the error at the output layer and the energy of the hidden layer  h, we can compute the complete weight change for any connection below layer h:  = t en = tOlOtert[ r +/ttent[ n) = tOlt c  Awtl a/tter rO1 al ten t O1  [8]  where 6c is now the delta accumulated for error and energy that we can write as  a function of the deltas of the upper layer:  t}Ic = f'l(nett) Z Oterr + lten{}[n)wil = f'l(rleti) Z }?wit  i i  This means that instead of propagating the delta for both energy and error, we  can compute an accumulated delta for hidden layer h and propagate it back  throughout the network. If we minimize the energy of the layers h and h-I, the  new accumulated delta will equal the previously accumulated delta added to a  new delta energy on layer h-1. The procedure can be repeated throughout the  complete network. In short, the back-propagated error signal used to change the  weights of each layer is simply equal to the back-propagated signal used in the  previous layer augmented with the delta energy of the current hidden layer. (The  algorithm is local and easy to implement).  ENERGY FUNCTION  The algorithm is sensitive to the energy function e being minimized. The functions used in the simulations described below have the following derivative with  522 Chauvin  respect to the squared activations/energy (only this derivative is necessary to implement the algorithm, see Equation [6]):  e' Oe(øZ)  = = . [10]  where n is an integer that determines the precise shape of the energy function  (see Table 1) and modulates the behavior of the algorithm in the following way.  For n = O, e is a linear function of the energy: "high and low energy" units are  equally penalized. For n = 1, e is a logarithmic function and "low energy" units  become more penalized than "high energy" units, in proportion to the linear  case. For n = 2, the energy penalty may reach an asymptote as the energy increases: "high energy" units are not penalized more than "middle energy" units.  In the simulations, as expected, it appears that higher values of n tend to suppress  "low energy" units. (For n > 2, the behavior of the algorithm was not significantly different from n = 2, for the tests described below).  TABLE 1: Energy Functions.  I 'l
I will describe my recent results on the automatic development of fixedwidth recursive distributed representations of variable-sized hierarchal data  structures. One implication of this work is that certain types of AI-style  data-structures can now be represented in fixed-width analog vectors. Simple  inferences can be performed using the type of pattern associations that  neural networks excel at. Another implication arises from noting that these  representations become self-similar in the limit. Once this door to chaos is  opened, many interesting new questions about the representational basis of  intelligence emerge, and can (and will) be discussed.
The Parsing and Learning System(PALS) is a massively  parallel self-tuning context-free parser. It is capable of  parsing sentences of unbounded length mainly due to its  parse-tree representation scheme. The system is capable  of improving its parsing performance through the  presentation of training examples.
This paper introduces a means to handle the critical problem of nonlocal role-bindings in 1ocalist spreading-activation networks. Every  conceptual node in the network broadcasts a stable, uniquely-identifying  activation pattern, called its signature. A dynamic role-binding is created when a role's binding node has an activation that matches the  bound concept's signature. Most importantly, signatures are propagated  across long paths of nodes to handle the non-local role-bindings necessary for inferencing. Our 1ocalist network model, ROBIN (ROle  Binding and Inferencing Network), uses signature activations to robustly represent schemata role-bindings and thus perform the inferencing, plan/goal analysis, schema instantiation, word-sense disambiguation, and dynamic re-interpretation portions of the natural language understanding process. 
One a.tt.empt a.t explaining human inferencing is that of spreading activation, particularly in the structured connectionist paradigm. This ha.s resulted in the building of systems with semantically nameable nodes which perform inferencing by examining  the patterns of activation spread. In this paper we demonstrate  that simple st.ruct. ured network inferencing can be performed by  passing act.ivation over the weights learned by a distributed a.lgorit, hm. Thus, an account is provided which explains a wellbehaved relationship between structured and distributed connectionist approaches.
A new model of a controlled neuron oscillator,  proposed earlier {Kryukov et al, 1986} for the  interpretation of the neural activity in various  parts of the central nervous system, may have  important applications in eineering and in the  theory of brain functions. The oscillator has a  good stability of the oscillation period, its  frequency is regulated linearly in a wide range  and it can exhibit arbitrarily long oscillation  periods without changing the time constants of  its elements. The latter is achieved by using  the critical slowdown in the dynamics arising in  a network of nonformal excitatory neurons  {Kovalenko et al, 1984, Kryukov, 1984}. By  changing the parameters of the oscillator one  can obtain various functional modes which are  necessary to develop a model of higher brain  function.  Or oscillator comprises several hundreds of modelled  excitatory neurons (located at the sites of a plane lattice)  and one inhibitory neuron. The latter receives output  signals from all the excitatory neurons and its own output  is transmitted via fccdback to every excitatory neuron (Fig.  1). Each excitmtory neuron is connected bilaterally with its  four nearest neighhours.  Each neuron has a threshold r(t) decaying exponentially to a  A Model of Neural Oscillator for a Unified Submodule 561  value r e or r (for an excitatory or inhibitory neuron). A  Gaussian noise with zero mean and standard deviation ( is  added to a threshold. A membrane potential of a neuron is  the sum of input impulses decaying exponentially when there  are no input. If the membrane potential excccds the  threshold, the neuron fires and sends impulses to the  neighbouring neurons. An impulse from excitatory neuron to  excitatory one increases the membrane potential of the  latter by aee, from the excitatory to the inhibitory by  aei, and from the inhibitory to the excitatory decreases  the membrane potential by aie. We consider a discrete time  model, the time step being equal to the absolute refractory  neuron.  We associate a variable xi(t) with each excitatory  If the l-th neuron fires at step t, we take xi(t)=l;  if it  does not, then x i(t)=0. The mean g(t)=l/N x i(t) will be  referred to as the network activity, where N is the number  of excitatory neurons.  A  Figure 1. Aneuron, Bscheme of interconnections  Let us consider a situation when inhibitory fcdback is cut  off. Then such a model exhibits a critical slowdown of the  dynamics {Kovalenko et al, 1984, Kryukov, 1984}. Namely, if  the interconnections and parameters of neurons are chosen  appropriately, initial pattern of activated neurons has an  unusually long lifetime as compared with the time of membrane  potential decay. In this mode g(t) is slowly increasing and  562 Kirillov, et al  causes the inhibitory neuron to fire.  Now, if we urn on the negative fccdback, output impulse  from inhibitory neuron sharply decreases membrane potentials  of excitatory neurons. As a a consequence, E(t) falls down  and process starts from the beginning.  We studied this oscillator by means of  There are 400 excitatory neurons (20*20  inhibitory neuron in our model.  simulation model.  lattice) and one  a. When the thresholds of excitatory neurons are high  enough, the inhibitory neuron does not fire and there are no  A  Tcp49 + 3 t  ............... 6 ..... /b '  B  11 I I I I I I I I I I [ I I 1  I.! I ß I ß I1 I I I I ! I [I 11 t z  [ I I I I I ! I I I I I I II  Ill  _. 1_ I __ ______j  [11 Itl 11 !llll II I 'rLa  Figure 2. Oscillatory mode. A network activity,  Bneuron spike trains  oscillations.  b. At lower values of r the network activity E(t) changes  periodically and excitatory neurons generate bursts of  spikes (Fig. 2). The inhibitory neuron generates regular  periodical spike trains.  c. If the parameters are chosen appropriately, the mean  oscillation period is mch greater than the mean interspike  interval of a network neuron. The frequency of oscillations  is regulated by r (Fig. 3A) or, which is the same, by the  A Model of Neural Oscillator for a Unified Submodule 563  intensity of the input flow. The min'nnum period is  determined by the decay rate of the inhibi*ry input, the  maximum by the lifetime of the metastable state.  6O  5O  4O  3O  o  IO  A B  9. I0. II. 12. 13. 7,,  4C  ILC I,'C LCC :Z  Fu 3. A oscillation frequency 1/T vs. threshold r e,  B coefficient of variation of the period K vs. period  d. The coefficient of variation of the period is of the  order of several percent, but it increases at low  frequencies (Fig. 3B). The stability of oscillations can be  increased by introducing some inhomogeneity in the network,  for example, when a part of excitatory neurons will receive  no inhibitory signals.  CCILITO UNDER  STATION  In this section we consider first the neural network without  the inhibitory neuron. But we imitate a periodic input to  the network by slowly varying the thresholds r(t) of the  excitatory neurons. Namely, we add to r(t) a value  Ar=-A, sin(lt) and fire a part of the network at some phase of  the sine wave. Then we look at the time nccded for the  network to restore its background activity. There are  specific values of a phase for which this time is rather big  (Fig. 4A). Now consider the full ocsillator with an  oscillation period T (in this section T=-85+_2.5 time steps).  We stimulate the oscillator by periodical (with  tst<35) sharp increase of membrane potential  excitatory neuron by a value ast. As the  procccds, the oscillation period  T--5 to some value Tst, remaining  the period  of each  stimulation  gradually decreases from  then equal to Tst. The  564 Kirillov, et al  value of Tst depends on the stimulation intensity ast:  gets greater, Tst tends to the stimulation period tst.  as a t  A 0  ß '" B  10  0  10 20 tst  Figure 4. A threshold modulation, Bduration of the  network responce vs. phase of threshold modulation,  critical stimulation intensity vs. stimulation period  For every stimulation period tst there is cb2racteristic  value a 0 of the stimulation intensity ast, such that with  ast>aO the value of Tst is equal to the stimulation period  tst. The dependence between a 0 and tst is close to a linear  one (Fig. 4B). The usual relaxation oscillator also exibits  a linear dependence between a and tst. At the same time, we  did not find in our oscillator any resonance phenomena  essential to a linear oscillator.  In a further development of the neural oscillator we tried  to build a model that will be more adequate to the  biological counterpart. To this end, we changed the  structure of interconnections and tried to define more  correctly the noise component of the input signal coming to  an excitatory neuron. In the model described above we  A Model of Neural Oscillator for a Unified Submodule 565  imitated the sum of inputs from distant neurons by  independent Gaussian noise. Here we used real noise produced  by the network.  In order to simulate this internal noise, we randomly choose  16 distant neighbours for every exitatory neuron . Then we  assume that the network elements are adjusted to work in a  certain noise environment. This means that a 'mean' internal  noise would provide conditions for the neuron to be the most  sensitive for the information coming from its nearest  neighbors.  So, for every neuron i we calculate the sum ki=xj(t), where  summation is over all distant neighbors of this neuron, and  compare it with the mean internal noise k=l/N Rk.. The  internal noise for the neuron i now is ni--C(ki-k), where  is a constant.  We choose model parameters in such a way that the noise  component is of the order of several percent of the membrane  potential. Nevertheless, the network exhibits in this case a  dramatic increase of the lifetime of initial pattern of  activated neurons, as compared with the network with  independent Gaussian noise. A range of parameters, for which  this slowdown of the dynamics is observed, is also  considerably irireased. Hence, longer periods and better  period stability could be obtained for our generator if we  use internal noise.  THE CHAIN OF THREE SUBMODULES: A MODEL OF COLUMN OSCILLATOR  Now we consider a small system constituted of three  oscillator submodules, A, B and C, connected consecutively  so that submodule A can transmit excitation to submodule B,  B to C, and C to A. The excitation can only be transmitted  when the total activity of the submodule reaches its  threshold level, i.e. when the corresponding inhibitory  neuron fires. After the inhibitory neuron has fired, the  activity of its submodule is set to be small enough for the  submodule not to be active with large probability until the  excitation from another submodule comes. Therefore, we  expect A, B and C to work consecutively. In fact, in our  simulation experiments we observed such behavior of the  566 Kirillov, et al  S(T)  2O  A T  ........... 15  10 12  10 12  Figure5. Chain of thrcc submodules. Period of  oscillations (A) and its standard deviation (B) vs.  noise amplitude  closed chain of 3 basic submodules. The activity of the  whole system is nearly periodic. Figure 5A displays the  period T vs. the noise amplitude O. The scale of O is chosen  so that 0.5 corresponds approximately to the resting  potential. An interesting feature of the chain is that the  standard deviation $(T) of the period (Fig. 5B) is small  enough, even for the oscillator of relatively small size.  The upper lines in Fig. 5 correspond to square 10.10  network, middle to 9*9, lower to 8*8 one. One can scc  that the loss of 36 percent of elements only causes a  reduction of the working range without the loss of  stability.  CONCLUSION  Though we have not considered all the interesting modes of  the oscillator, we believe that, owing to the phenomenon of  metastability, the same oscillator exhibits different  behaviour under slightly different threshold parameters and  the same and/or different inputs.  Let us enumerate the most  possibilities of the oscillator,  obtained from our results.  interesting functional  which can be easily  1.Pacemaker with the frequency regulated in a wide range and  with a high period stability, as compared with the neuron  (Fig. 3B).  2. Integrator (input=threshold, output=phase) with a wide  A Model of Neural Oscillator for a Unified Submodule 567  range of linear regulation (see Fig. 3A).  3.Generator of damped oscillations (for discontinuous input).  4.Delay device controlled by an external signal.  5. Phase comparator (see Fig. 4A).  We have already used these functions for the interpretation  of electrical activity of several functionally different  neural structures {Kryukov et al, 1986}. The other functions  will be used in a system model of attention {Kryukov, 1989}  presented in this volume. All these considerations justify  the name of our neural oscillator a unified submodule for  a 'resonance' neurocomter.  References
A time delay in the response of the neurons in a network can  induce sustained oscillation and chaos. We present a stability  criterion based on local stability analysis to prevent sustained  oscillation in symmetric delay networks, and show an  example of chaotic dynamics in a non-symmetric delay  network.
Research in artificial neural networks has generally emphasized  homogeneous architectures. In conu'ast, the nervous systems of natural  animals exhibit gmat heterogeneity in both their elements and patterns  of interconnection. This heterogeneity is crucial to the flexible  generation of behavior which is essential for survival in a complex,  dynamic environment. It may also provide powerful insights into the  design of artificial neural networks. In this paper, we describe a  heterogeneous neural network for controlling the walking of a  simulated insect. This controller is inspired by the neuroethological  and neurobiological literature on insect locomotion. It exhibits a  variety of statically stable gaits at different speeds simply by varying  the tonic activity of a single cell. It can also adapt to perturbations as a  natural consequence of its design.
A new viewpoint of the processing performed by Kanerva's sparse  distributed memory (SDM) is presented. In conditions of nearor  overcapacity, where the associative-memory behavior of the model breaks down, the processing performed by the model can be interpreted as that of a statistical predictor. Mathematical results are  presented which serve as the framework for a new statistical viewpoint of sparse distributed memory and for which the standard formulation of SDM is a special case. This viewpoint suggests possible enhancements to the SDM model, including a procedure for  improving the predictiveness of the system based on Holland's  work with 'Genetic Algorithms', and a method for improving the  capacity of SDM even when used as an associative memory. 
A new optimization strategy, Mean Field Annealing, is presented.  Its application to MAP restoration of noisy range images is derived  and experimentally verified.
This research involves a method for finding global maxima  in constraint sa.fi. sfacfion networks. I.t is an annea.h.'..'ng  process but, unlike most others, reqmres no annealing  schedule. Temperature is instead determined locally by  units at each update, and thus all processing is done at the  unit level. There are two major practical benefits to  processing this way: 1) processing can continue in 'bad'  areas of the network, while 'good' areas remain stable, and  2) processing continues in the 'bad' areas, as long as the  constraints remain poorly satisfied (i.e. it does not stop  after some predetermined number of cycles). As a result,  this method not only avoids the kludge of requiring an  externally determined annealing schedule, but it also finds  global maxima more quickly and consistently than  externally scheduled systems (a comparison to the  Boltzmann machine (Ackley et al, 1985) is made). Finally,  implementation of this method is computationally trivial.
A most important consequence of our theory of  phase tr'ansitions in the brain {Kryukov et al   1986]. is the prediction that CNS contains a  phase-lockecl trac:king system for controlling  attention and memory in the frequency range of  alphaand theta-rhythms. This paper describes a  simplified model of such a system and discusses a  basic: integro-cliffer'ential equation for its  functioning which is almost identical to the  ecluation for the well-known in communication  phase-locked loop (PLL) .Dynamical properties of  this system are sl-or't].y disc:ussecl to account for  the experimental data which are difficult to  interpret in terms of the existing moclels.  THE PROBLEM OF ATTENTION  By attention we mean a psychophysiological  consisting simultaneously of two components, namely  and synthesis. The first c:omponent is taking one of  simultaneously possible objects or trains of  process  nalysis  several  thought.  Foc:alization and concentration are of its  closesst analogy is a searchlight {Crick, 1984}.  component is a process of c:ombining several  features (modalities) into single object. The  Tr ei s!arl ......  analogy is a glue  ß , Gelade, 1o}  The major problem of modelling attention is usually  essence. The  The second  clistinct  simplest  thought  as follows: if a model obtainss mixed signals from  different sources, it should be able to recognize any  component of the mixture. But most difficult part of the  problem is probably a moda;ity and submodality integration.  Papers conc:erned with modelling attention are st11  relatively few {Crick 1984; Fukushima, I986; Grossberg,    ,86. They are all connectionism'  1,8; Malsburg, Schneider,  eurolocatoF', A Model of Attention 611  None of them makes e,,,'plicit use of the following ideas which  we believe crucial for understanding the functic:n of  attention.
We introduce an optimization approach for solving problems in computer vision that involve multiple levels of abstraction. Our objective  functions include compositional and specialization hierarchies. We cast  vision problems as inexact graph matching problems, formulate graph  matching in terms of constrained optimization, and use analog neural  networks to perform the optimization. The method is applicable to perceptual grouping and model matching. Preliminary experimental results  are shown.
DCPS (the Distributed Connectionist Production System) is a neural  network with complex dynamical properties. Visualizing the energy  landscapes of some of its component modules leads to a better intuitive  understanding of the model, and suggests ways in which its dynamics  can be controlled in order to improve performance on difficult cases.
We present and rigorously analyze a generalization of the WinnerTake-All Network: the K-Winners-Take-All Network. This network identifies the K largest of a set of N real numbers. The  network model used is the continuous Hopfield model.
We explore a network architecture introduced by Elman (1988) for  predicting successive elements of a sequence. The network uses the  pattern of activation over a set of hidden units from time-step t-l,  together with element t, to predict element t+l. When the network is  mined with strings from a particular finite-state grammar, it can learn  to be a perfect finite-state recognizer for the grammar. Cluster analyses  of the hidden-layer patterns of activation showed that they encode  prediction-relevant information about the entire path traversed through  the network. We illustrate the phases of learning with cluster analyses  performed at different points during training. 
We describe an adaptive network, TIN 2, that learns the transition  function of a sequential system from observations of its behavior. It  integrates two subnets, TIN-1 (Winter, Ryan and Turner, 1987) and  TIN-2. TIN-2 constructs state representations from examples of  system behavior, and its dynamics are the main topics of the paper.  TIN-1 abstracts transition functions from noisy state representations  and environmental data during training, while in operation it produces  sequences of transitions in response to variations in input. Dynamics  of both nets are based on the Adaptive Resonance Theory of Carpenter  and Grossberg (1987). We give results from an experiment in which  TIN 2 learned the behavior of a system that recognizes strings with an  even number of l's.
Edwin Lewis  Dept. Elect. Eng.  U.C. Berkeley  We present a simplified model of the micromechanics of the human  cochlea, realized with electrical elements. Simulation of the model  shows that it retains four signal processing features whose importance  we argue on the basis of engineering logic and evolutionary evidence.  Furthermore, just as the cochlea does, the model achieves massively  parallel signal processing in a stmcturally economic way, by means of  shared elements. By extracting what we believe are the five essential  features of the cochlea, we hope to design a useful front-end filter to  process acoustic images and to obtain a better understanding of the  auditory system.
We describe pulse stream firing integrated circuits that implement asynchronous analog neural networks. Synaptic weights are  stored dynamically, and weighting uses time-division of the  neural pulses from a signalling neuron to a receiving neuron.  MOS transistors in their "ON" state act as variable resistors to  control a capacitive discharge, and time-division is thus achieved  by a small synapse circuit cell. The VLSI chip set design uses  2.5xm CMOS technology.
This paper describes a CMOS artificial neuron. The circuit is  directly derived from the voltage-gated channel model of neural  membrane, has low power dissipation, and small layout geometry.  The principal motivations behind this work include a desire for high  performance, more accurate neuron emulation, and the need for  .higher density in practical neural network implementations.
Reconstructing a surface from sparse sensory data is a well-known  problem in computer vision. This paper describes an experimental  analog VLSI chip for smooth surface interpolation from sparse depth  data. An eight-node 1D network was designed in 3/m CMOS and  successfully tested. The network minimizes a second-order or "thinplate" energy of the surface. The circuit directly implements the coupled depth/slope model of surface reconstruction (Harris, 1987). In  addition, this chip can provide Gaussian-like smoothing of images.
An extremely compact, all analog and fully parallel implementation of a class of shunting recurrent neural networks that is applicable to a wide variety of FET-based integration technologies is  proposed. While the contrast enhancement, data compression, and  adaptation to mean input intensity capabilities of the network are  well suited for processing of sensory information or feature extraction for a content addressable memory (CAM) system, the network  also admits a global Liapunov function and can thus achieve stable  CAM storage itself. In addition the model can readily function as  a front-end processor to an analog adaptive resonance circuit.
We have designed, fabricated, and tested a series of compact CMOS  integrated circuits that realize the winner-take-all function. These  analog, continuous-time circuits use only O{n) of interconnect to  perform this function. We have also modified the winner-take-all  circuit, realizing a circuit that computes local nonlinear inhibition.  Two general types of inhibition mediate activity in neural systems: subtractive inhibition, which sets a zero level for the computation, and multiplicative (nonlinear)  inhibition, which regulates the gain of the computation. We report a physical realization of general nonlinear inhibition in its extreme form, known as winner-take-all.  We have designed and fabricated a series of compact, completely functional CMOS  integrated circuits that realize the winner-take-all function, using the full analog  nature of the medium. This circuit has been used successfully as a component  in several VLSI sensory systems that perform auditory localization (Lazzaro and  Mead, in press) and visual stereopsis (Mahowald and Delbruck, 1988). Winnertake-all circuits with over 170 inputs function correctly in these sensory systems.  We have also modified this global winner-take-all circuit, realizing a circuit that  computes local nonlinear inhibition. The circuit allows multiple winners in the network, and is well suited for use in systems that represent a feature space topographically and that process several features in parallel. We have designed, fabricated,  and tested a CMOS integrated circuit that computes locally the winner-take-all  function of spatially ordered input. 
This report describes the design of a programmable general  purpose analog neural computer and simulator. It is intended primarily  for real-word real-time computations such as analysis of visual or  acoustical patterns, robotics and the development of special purpose  neural nets. The machine is scalable and composed of interconnected  modules containing arrays of neurons, modifiable synapses and switches.  It runs entirely in analog mode but connection architecture, synaptic  gains and time constants as well as neuron parameters are set digitally.  Each neuron has a limited number of inputs and can be connected to any  but not all other neurons. For the determination of synaptic gains and the  implementation of learning algorithms the neuron outputs are  multiplexer, A/D converted and stored in digital memory. Even at  moderate size of 10  to l0 s neurons computational speed is expected to  exceed that of any current digital computer.  OVERVIEW  The machine described in this paper is intended to serve as a general purpose  programmable neuron analog computer and simulator. Its architecture is loosely based on  the cerebral cortex in the sense that there are separate neurons, axons and synapses and that  each neuron can receive only a limited number of inputs. However, in contrast to the  biological system, the connections can be modified by external control permitting  exploration of different architectures in addition to adjustment of synaptic weights and  neuron parameters.  The general architecture of the computer is shown in Fig. 1. The machine contains  large numbers of the following separate elements: neurons, synapses, routing switches  and connection lines. Arrays of these elements are fabricated on VLSI chips which are  mounted on planar chip carriers each of which forms a separate module. These modules  are connected directly to neighboring modules. Neuron arrays are arranged in rows and  columns and are surrounded by synaptic and axon arrays.  A Programmable Analog Neural Computer and Simulator 713  The machine runs entirely in analog mode. However, connection architectures,  synaptic gains and neuron parameters such as thresholds and time constants are set by a  digital computer. For determining synaptic weights in a learning mode, time segments of  the outputs from neurons are multiplexed, digitized and stored in digital memory.  The modular design allows expansion to any degree and at moderate to large size,  i.e. 103 to 105 neurons, operational speed would exceed that of any currently available  digital computer.  I I  SWITCHES LINES  SYNAPSES NEURONS  Figure 1. Layout and general architecture. The machine is composed of different  modules shown here as squares. Each module contains on a VLSI chip an array of  components (neurons, synapses or switches) and their control circuits. Our prototype  design calls for 50 neuron modules for a total of 800 neurons each having 64 synapses.  The insert shows the direction of data flow through the modules. Outputs from  each neuron leave north and south and are routed through the switch modules east and west  and into the synapse modules from north and south. They can also bypass the synapse  modules north and south. Input to the neurons through the synapses is from east and west.  Power and digital control lines run north and south.  THE NEURON MODULES  Each neuron chip contains 16 neurons, an analog multiplexer and control logic.  (See Figs. 2 & 3.)  Input-output relations of the neurons are idealized versions of a typical biological  neuron. Each unit has an adjustable threshold (bias), an adjustable minimum output value  at threshold and a maximum output (See Fig. 4). Output time constants are selected on the  switch chips. The neuron is based on an earlier design which used discrete components  (Mueller and Lazzaro, 1986).  714 Mueller, et al  Inputs to each neuron come from synapse chips east and west (SIR, SIL), outputs  (NO) go to switch chips north and south. Each neuron has a second input that sets the  minimum output at threshold which is common for all neurons on the chip and selected  through a separate synapse line. The threshold is set from one of the synapses connected  to a fixed voltage. An analog multiplexer provides neuron output to a common line, OM,  which connects to an A/D converter.  CK  SIL  SIL  SIL  ORI  !I2  SIR  SIR  SIR  Figure 2. Block diagram of the neuron chip containing 16 neurons.  Figure 3. Photograph of a test chip containing 5 neurons. A more recent version has  only one output sign.  A Programmable Analog Neural Computer and Simulator 715  tn 4  SUM OF' !NPUTS/VOLTS  Figure 4. Transfer characteristic obtained from a neuron on the chip shown in Fig.3.  Each unit has an adjustable threshold, Vwhich was set here to 1.5V, a linear transfer  region above threshold, an adjustable minimum output at threshold E set to 1V and a  maximum output,  THE SYNAPSE MODULES  Each synapse chip contains a 32 * 16 array of synapses. The synaptic gain of each  synapse is setby serial input from the computer and is storedat each synapse. Dynamic range  of the synapse gains covers the range from 0 to 10 with 5 bit resolution, a six th bit determines  the sign. The gains are implemented by current mirrors which scale the neuron output after  it has been converted from a voltage to a current.  The modifiable synapse designs reported in the literature use either analog or  digital signals to set the gains (Schwartz, et. al., 1989, Raffel, et. al, 1987, Alspector and  Allen, 1987). We chose the latter method because of its greater reproducibility and because  direct analog setting of the gains from the neuron outputs would require a prior knowledge  of and commitment to a particular learning algorithm. Layout and performance of the  synapse module are shown in Figs. 5-7. As seen in Fig. 7a, the synaptic transfer function  is linear from 0 to 4 V.  The use of current mirrors permits arbitrary scaling of the synaptic gains (weights)  with trade off between range and resolution limited to 5 bits. Our current design calls for  a minimum gain of 1/32 and a maximum of 10. The lower end of the dynamic range is  determined by the number of possible inputs per neuron which when active should not drive  the neuron output to its limit, whereas the high gain values are needed in situations where  a single or very few synapses must be effective such as in the copying of activity from one  neuron to another or for veto inhibition. The digital nature of the synaptic gain control does  not allow straight forward implementation of a logarithmic gain scale. Fig. 7b. shows two  possible relations between digital code and synaptic gain. In one case the total gain is the  sum of 5 individual gains each controlled by one bit. This leads inevitably to jumps in the  gain curve. In a second case a linear 3 bit gain is multiplied by four different constants  716 Mueller, et al  controlled by the 4th and 5th bit. This scheme affords a better approximation to a  logarithmic scale. So far we have implemented only the first scheme.  Although the resolution of an individual synapse is limited to 5 bits, several  synapses driven by one neuron can be combined through switching, permitting greater  resolution and dynamic range.  SO  <  8016  Nit  N131  o o  o o  o o  o o  o o  o o  ooo  --ro, I  T?  EN EN CI,K  z N132  >  S016  >  DATA  Figure 5. Diagram of the synapse module. Each synapse gain is set by a 5 bit word  stored in local memory. The memory is implemented as a quasi dynamic shift register  that reads the gain data during the programming phase. Voltage to current converters  transform the neuron output (NI) into a current. I Conv are current mirrors that scale  the currents with 5 bit resolution. The weighted currents are summed on a common  line to the neuron input (SO).  Figure 6. Photograph of a synapse test chip.  A Programmable Analog Neural Computer and Simulator 717
We describe an electronic photoreceptor circuit that is sensitive to  small changes in incident light intensity. The sensitivity to changes  in the intensity is achieved by feeding back to the input a filtered  version of the output. The feedback loop includes a hysteretic element. The circuit behaves in a manner reminiscent of the gain  control properties and temporal responses of a variety of retinal  cells, particularly retinal bipolar cells. We compare the thresholds  for detection of intensity increments by a human and by the circuit. Both obey Weber's law and for both the temporal contrast  sensitivities are nearly identical.  We previously described an electronic photoreceptor that outputs a voltage that is  logarithmic in the light intensity (Mead, 1985). This report describes an extension  of this circuit which was based on a suggestion by Frank Werblin that biological  retinas may achieve greater sensitivity to changes in the illumination by feeding  back a filtered version of the output.  OPERATION OF THE CIRCUIT  The circuit (Figure 1) consists of a phototransistor (P), exponential feedback to  P (Q1, Q2, and Q3), a transconductance amplifier (A), and the hysteretic element  (Q4 and Q5). In general terms the operation of the circuit consists of two stages of  amplification with hysteresis in the feedback loop. The light falls on the parasitic  bipolar transistor P. (The rest of the circuit is shielded by metal.) P's collector  is the substrate and the base is an isolated well. P and Q form the first stage of  amplification. The light produces a base current IB for P. The emitter current Is  is 19I, neglecting collector resistance for now. /9 is typically a few hundred. The  feedback current IQ is set by the gate voltage on Q/Q2, which is set by the current  through Q3, which is set by the feedback voltage Vlb. In equilibrium Vlb will be  such that IQ = Is and some voltage Vt, will be the output of the first stage. The  An Electronic Photoreceptor Sensitive to Small Changes 721  negative feedback through the transconductance amplifier A will make V,  Vfb.  This voltage is logarithmic in the light intensity, since in subthreshold operation  the currents through Q2 and Q3 are exponential in their gate to source voltages.  The DC output of the circuit will be Vou  V.b = Vdd -(2kT/q) log It, neglecting  the back-gate effect for Q2. Figure 5a (DC output) shows that the assumption of  subthreshold operation is valid over about 4 orders of magnitude.  Q Vou  c  Figure 1. The photoreceptor circuit.  Now what happens when the intensity increases a bit? Figure 2a shows the current  through P and Q as a function of the voltage V,. Both P and Q act like current  sources in parallel with a resistance, where the value of the current is set, respectively, by the light intensity and by the feedback voltage V/b. When the intensity  increases a bit the immediate result is that the curve labeled Ir in Figure 2a will  shift upwards a little to the curve labeled I. But IQ won't change right away it is set by the delayed feedback. The effect on V, will be that V, will drop by the  amount of the shift in the intersection of the curves in Figure 2a, to Vl. Because  interesting gain control properties arise here we will analyze this before going on  with the rest of the circuit.  In Figure 2b, we model P and Q as current sources with associated drain/collector  resistances. Now,  rp + rQx  722 Delbrilck and Mead  r, and rQ physically arise from the familiar Early effect, a variation of depletion  region thickness causing a variation in the channel length or base thickness. It is  a reasonable approximation to model the drain or collector resistance due to the  Early effect as r = Ve/I, where Ve is the Early voltage and is typically tens of volts,  and I is the value of the current source.  Figure 2. The first stage of amplification. a: The curves show the current through  the phototransistor P and feedback transistor Q as a function of the voltage V,.  Since I, = IQ the intersection gives the voltage V/,. b: An equivalent circuit model  for these transistors in the linear region. The Early effect leads to drain/collector  resistances inversely proportional to the value of the current source.  Substituting this approximation for r, and r into the above expression for  and letting 5I = 5IB, we obtain  =  where V,e and V, are the Early voltages associated with the phototransistor and  the feedback transistor Q, respectively. In other words, the change in Ve is just  proportional to the 'contrast'I/I. Figure 4a shows test results which support  this model.  A detector which encodes the intensity logarithmically (so that the output V in  response to an input I is V = log I) would also give 5V = I/I. Our in our circuit  the gain control properties for transients arise from an unrelated property of the  conductances of the sensor and the feedback element. Comparing the gains for DC  and for transients in our circuit and using the expression for the DC output given  earlier, we find that the ratio of the gains is  transient gain Ve,,    200  DC gain 2kT/q  An Electronic Photoreceptor Sensitive to Small Changes 723  assuming V,rlIV,, = 10V and kT/q = 25mV.  Finally, let us consider the operation of the rest of the circuit. The second stage of  amplification is done by the transconductance amplifier A. A produces a current  which is pr,o, portional to the tanh of the difference between the two inputs, I -G tanh( 2kT/q I' When the output of the amplifier is taken as a voltage, the voltage  gain is typically a few hundred. Following the transconductance amplifier there is  a pair of diode connected transistors, Q4 and Q5 (Figure 3a}, which we call the  hysteretic element. This pair of transistors has an I-V characteristic which is similar  to that of Figure 3. The hysteretic element conducts very little until the voltage  across it becomes substantial. Thus the transconductance amplifier works in a dual  voltage-output/current-output mode. Small changes in the output voltage result in  little change in the feedback voltage. Larger changes in the output voltage cause  current to flow through the hysteretic element, completing the feedback loop. This  represents a form of memory, or hysteresis, for the past state of the output and a  sensitivity to small changes in the input around the past history of the input.  I v I  a b  Figure 3. a: The hysteretic element. b: IV characteristic.  COMPARISON OF CIRCUIT AND RETINAL CELLS  We felt that since the circuit was motivated by biology it might be interesting to  compare the operational characteristics of the circuit and of retinal cells. Since the  circuit has no spatial extent it cannot model any of the spatially mediated effects  (such as center-surround) seen in retinas. Nonetheless we had hoped to capture  some of the temporal effects seen in retinal cells. In Figure 4 we compare the  responses of the circuit and responses of a retinal bipolar cell to diffuse flashes of  light. The circuit has response characteristics closest to those of retinal bipolar  The circuit's gain control properties are very similar to those of bipolar cells. Figure  5 shows that both the circuit and bipolar cells tend to control their gain so that  they maintain a constant output amplitude for a given change in the log of the  intensity.  724 DelbrQck and Mead  The response characteristics of the circuit differ from those of bipolar cells in the  following ways. First, the gain of the circuit for transients is much larger than that  of the bipolar cell, as can be seen in Figure 5, with concomitantly much smaller  dynamic range. The dynamic range of the bipolar cell is about 1.5 2 log units  around the steady intensity, while for the circuit the dynamic range is only about  0.1 log unit.  Input 2.5 BACKGROUND  .0 background i\  '  0.2ms  (2 decades attenuated)  15  20m Noe level  I  a b  mV  Figure 4. The responses of the circuit compared with responses of a retinal bipolar  cell. a: The output of the circuit in response to changes in the intensity. The  background levels refer to the same scale as shown in Figure 5. The bottom curve  shows the noise level; from this one can see that a detection criterion of signal/noise  ratio equals 2 is satisfied for increments of 12%, in agreement with Figure 6. Note  that a 2 decade attenuation hardly changes the response amplitude but the time  constant increases by a factor of a hundred. b: The response of a bipolar cell (from  Werblin, 1974). The numbers next to the responses are the log of the intensity of  the flash substituted for the intial value of the intensity. Note the bidirectionality  of the response compared to the circuit.  An Electronic Photoreceptor Sensitive to Small Changes 725  log(Intensity)  (mV)  4  .4 ß  log(Intensity)  b  Figure 5. The operating curves of the circuit (a) compared with retinal bipolar  cells (b) (adapted from Werblln, 1974). The curves show the height of the peak of  the response to flashes substituted for the initial intensity. The initial intensity is  given by the intersection of the curves with the abscissa. Note the difference of the  gain and the dynamic range. The squares show the DC responses. The slope of  the DC response for the circuit is less than expected, probably because there is a  leakage current through the hysteretic element.  Second, the response of bipolar cells is symmetrical for increases and decreases in  the intensity. This can probably be trced to the symmetrical responses of the cones  from which they receive direct input. The circuit, on the other hand, only responds  strongly to increases in the light intensity. The response in our circuit only becomes  symmetrical for output voltage swings comparable to kT/q, probably because the  limiting process is recombination in the base of the phototransistor.  Third, the control of time constants is dramatically different. In Figure 4a the top  set of responses is on a time scale 100 times expanded relative to the bottom scale.  The circuit's time constant, in other words, is roughly inversely proportional to the  light intensity. This is not the case for bipolar cells. Although we do not show  it here, the time constant of the responses of bipolar cells hardly varies with light  intensity over at least 4 orders of magnitude (Werblln, 1974).  The circuit's action differs much more from that of photoreceptors, amacrine, or  ganglion cells. Cones show a much larger sustained response relative to their transient response. Amacrine and ganglion cells spike; our circuit does not. And the  circuit differs from on/off amacrine and ganglion cells in the asymmetry of its response to increases and decreases in light intensity.  726 Delbrilck and Mead  EYE rs. CHIP  We compared the sensitivity to small changes in the light intensity for one of us and  for the circuit in order to get an idea of the performance of the circuit relative to a  subjective scale. The thresholds for detection of intensity increments are shown in  Figure 6.  10'  9  8  log(Increment) 7  6  5  Human 1.6%  Photoreceptor
A digital realisation of two-dimensional self-organising feature  maps is presented. The method is based on subspace  classification using an n-tuple technique. Weight vector  approximation and orthogonal projections to produce a winnertakes-all network are also discussed. Over one million effective  binary weights can be applied in 25ms using a conventional  microcomputer. Details of a number of image recognition tasks,  including character recognition and object centring, are  described.
A design for a fully analog version of a self-organizing feature map neural  network has been completed. Several parts of this design are in fabrication.  The feature map algorithm was modified to accommodate circuit solutions  to the various computations required. Performance effects were measured  by simulating the design as part of a frontend for a speech recognition  system. Circuits are included to implement both activation computations and  weight adaption or learning. External access to the analog weight values is  provided to facilitate weight initialization, testing and static storage. This  fully analog implementation requires an order of magnitude less area than  a comparable digital/analog hybrid version developed earlier.
We have fabricated a test chip in 2 micron CMOS that can perform supervised  learning in a manner similar to the Boltzmann machine. Patterns can be  presented to it at 100,000 per second. The chip learns to solve the XOR  problem in a few milliseconds. We also have demonstrated the capability to  do unsupervised competitive learning with it. The functions of the chip  components are examined and the performance is assessed.
MOS charge storage has been demonstrated as an effective method to store  the weights in VLSI implementations of neural network models by several  workers 2. However, to achieve the full power of a VLSI implementation of  an adaptive algorithm, the learning operation must built into the circuit. We  have fabricated and tested a circuit ideal for this purpose by connecting a  pair of capacitors with a CCD like structure, allowing for variable size weight  changes as well as a weight decay operation. A 2.5/ CMOS version achieves  better than 10 bits of dynamic range in a 140/ x 350/ area. A 1.25/ chip  based upon the same cell has 1104 weights on a 3.5ram x 6.0ram die and is  capable of peak learning rates of at least 2 x 109 weight changes per second.
We propose a new neural network structure that is compatible  with silicon technology and has built-in learning capability. The  thrust of this network work is a new synapse function. The  synapses have the feature that the learning parameter is embodied in the thresholds of MOSFET devices and is local in character. The network is shown to be capable of learning by  example as well as exhibiting the desirable features of the  Hopfield type networks.  The thrust of what we want to discuss is a new synapse function for an artificial  neuron to be used in a neural network. We choose the synapse function to be  readily implementable in VLSI technology, rather than choosing a function which  is either our best guess for the function used by real synapses or mathematically  the most tractable. In order to demonstrate that this type of synapse function  provides interesting behavior in a neural network, we imbed this type of function  in a Hopfield {Hopfield, 1982} type network and provide the synapses with a  Hebbian {Hebb, 1949] learning capability. We then show that this type of network functions in much the same way as a Hopfield network and also learns by  example. Some of this work has been discussed previously {Hartstein, 1988}.  Most neural networks, which have been described, use a multiplicative function  for the synapses. The inputs to the neuron are multiplied by weighting factors  and then the results are summed in the neuron. The result of the sum is then put  into a hard threshold device or a device with a sigmoid output. This is not the  easiest function for a MOSFET to perform although it can be done. Over a large  range of parameters, a MOSFET is a linear device with the output current being  a linear function of the input voltage relative to a threshold voltage. If one could  directly utilize these characteristics, one would be able to design a neural network  more compactly.  770 Hartstein and Koch  We propose that we directly use MOSFETs as the input devices for the neurons  in the network, utilizing their natural characteristics. We assume the following  form for the input of each neuron in our network:  where l] is the output, l? are the inputs and T,/are the larned threshold voltages.  In this network we use a representation in which both the V's and the T's range  from 0 to + 1. The result of the summation is fed into a non-linear sigmoid function (o). All of the neurons in the network are interconnected, the outputs of  each neuron feeding the inputs of every other neuron. The functional form of Eq.  I might, for instance, represent several n-channel and p-channel MOSFETs in  parallel.  The memories in this network are contained in the threshold voltages, T,/. We  implement learning in this network using a simple linear Hebbian {Hebb, 1949}  learning rule. We use a rule which locally reinforces the state of each input node  in a neuron relative to the output of that neuron. The equation governing this  learning algorithm is:  (2)  where Ti are the initial threshold voltages and ,/are the new threshold voltages  after a time, At. Here  is a small learning parameter related to this time period,  and the offset factor 0.5 is needed for symmetry. Additional saturation constraints are imposed to ensure that T u remain in the interval 0 to + 1.  This learning rule is one which is linear in the difference between each input and  output of a neuron. This is an enhancing/inhibiting rule. The thresholds are adjusted in such a way that the output of the neuron is either pushed in the same  direction as the input (enhancing), or pushed in the opposite direction (inhibiting). For our simple simulations we started the network with all thresholds at 0.5  and let learning proceed until some saturation occurred. The somewhat more sophisticated method of including a relaxation term in Eq. 2 to slowly push the values toward 0.5 over time was also explored. The results are essentially the same  as for our simple simulations.  The interesting question is if we form a network using this type of neuron, what  will the overall network response be like7 Will the network learn multiple states  or will it learn a simple average over all of the states it sees7 In order to probe the  functioning of this network, we have performed simulations of this network on a  digital computer. Each simulation was divided into two phases. The first was a  learning phase in which a fixed number of random patterns were presented to the  network sequentially for some period of time. During this phase the threshold  A Self-Learning Neural Network 771  voltages were allowed to change using the rule in Eq. 2. The second was a testing  phase in which learning was turned off and the memories established in the network were probed to determine the essential features of these learned memories.  In this way we could test how well the network was able to learn the initial test  patterns, how well the network could reconstruct the learned patterns when presented with test patterns containing errors, and how the network responded to  random input patterns.  We have simulated this network using N fully interconnected neurons, with N in  the range of 10 to 200. M random patterns were chosen and sequentially presented to the network for learning. M typically ranged up to N/3. After the  learning phase, the nature of the stable states in the network was tested. In general we found that the network is capable of learning all of the input patterns as  long as M is not too large. The network also learns the inverse patterns (1's and  O's interchanged) due to the inherent symmetry of the network. Additional extraneous patterns are learned which have no obvious connection to the intended  learned states. These may be analogous to either the spin glass states or the mixed  pattern states discussed for the multiplicative network lamir, 1985 ].  Fig. 1 shows the capacity of a 100 neuron network. We attempted to teach the  network M states and then probed the network to see how many of the states  were successfully learned. This process was repeated many times until we  achieved good statistics. We have defined successful learning as 100% accuracy.  A more relaxed definition would yield a qualitatively similar curve with larger  capacity.  The functional form of the learning is peaked at a fixed value of the number of  input patterns. For a small number of input patterns, the network essentially  learns all of the patterns. Deviations from perfect learning here generally mean 1  bit of information was learned incorrectly. Near the peak the results become  more noisy for different learning attempts. Most errors are still only 1 or 2 bits,  but the learning in this region becomes marginal as the capacity of the network is  approached. For larger values of the number of input patterns the network becomes overloaded and it becomes incapable of learning most of the input states.  Some small number of patterns are still learned, but the network is clearly not  functioning well. Many of the errors in this region are large, showing little correlation with the intended learned states.  This functional form for the learning in the network is the same for all of the network sizes tested. We define the capacity of the network as the average value of  the peak number of patterns which can be successfully learned. The inset to Fig.  1 shows the memory capacity of a number of tested networks as a function of the  size of the network. The network capacity is seen to be a linear function of the  network size. The capacity is proportional to the number of Tfs specified. In this  772 Hartstein and Koch  example the network capacity was found to be about 8 % of the maximum possible for binary information. This rather low figure results from a trade-off of capacity for the particttlar types of functions that a neural network can perform. It  is possible to construct simple memories with 100% capacity.  N  0 100 200  Figure 1. The number of successfully learned patterns as a function of the number of input patterns for a 100 neuron network.  The dashed curve is for perfect learning. The inset shows the  memory capacity of a threshold neural network as a function of  the size of the network.  Some important measures of learning in the network are the dintribution of stable  states in the network after learning has taken place, and the basin of attraction  for each stable point. One can gain a handle on these parameters by probing the  network with random test patterns after the network has learned M states. Fig.  2 shows the averaged results of such tests for a 100 neuron network and varying  numbers of learned states. The figure shows the probability of finding particular  states, both learned and extraneous. The states are ordered first by decreasing  A Self-Learning Neural Network 773  probability for the learned states, followed by decreasing probability for the extraneous states. It is clear from the figure that both types of stable states are  present in the network. It is also clear that the probabilities of finding different  patterns are not equal. Some learned states are more robust than others, that is  they have larger basins of attraction. This network model does not partition the  available memory space equally among the input patterns. It also provides a large  amount of memory space for the extraneous states. Clearly, this is not the optimum situation.  0.8  0.6  0.4  0.2  0.0  eorned (o)  k. Extroneous   I I I I  0.6 (b)
Hardware implementation of neuromorphic algorithms is hampered by  high degrees of connectivity. Functionally equivalent feedforward  networks may be formed by using limited fan-in nodes and additional  layers, but this complicates procedures for determining weight  magnitudes. No direct mapping of weights exists between fully and  limited-interconnect nets. Low-level nonlinearities prevent the  formation of internal representations of widely separated spatial  features and the use of gradient descent methods to minimize output  error is hampered by error magnitude dissipation. The judicious use  of linear summations or collection units is proposed as a solution.
We discuss synthetic receptors for haptic sensing. These are based on  magnetic field sensors (Hall effect structures) fabricated using standard  CMOS technologies. These receptors, biased with a small permanent  magnet can detect the presence of ferro or ferri-magnefic objects in the  vicinity of the sensor. They can also detect the magnitude and direction  of the magnetic field.
While we are waiting for the ultimate biophysics of cell membranes and synapses  to be completed, we may speculate on the shapes of neurons and on the patterns of  their connections. Much of this will be significant whatever the outcome of future  physiology.  Take as an example the isotropy, anisotropy and periodicity of different kinds of  neural networks. The very existence of these different types in different parts of  the brain (or in different brains) defeats explanation in terms of embryology; the  mechanisms of development are able to make one kind of network or another. The  reasons for the difference must be in the functions they perform. The tasks which  they solve in one case apparently refer to some space which is intrinsically isotropic,  in another to a situation in which different coordinates mean different things. In  the periodic case, the tasks obviously refer to some kind of modules and to their  relations. 
Birds sing to communicate. Male birds use song to advertise their territories and  attract females. Each bird species has a unique song or set of songs. Song conveys  both species and individual identity. In most species, young birds learn some features of adult song. Song develops gradually from amorphous to fixed patterns of  vocalization as if crystals form out of liquid. Learning of a song proceeds in two  steps; birds commit the song to memory in the first stage and then they vocally  reproduce it in the second stage. The two stages overlap each other in some species,  while they are separated by several months in other species. The ability of a bird to  commit a song to memory is restricted to a period known as the sensitive phase. Vocal reproduction of the memorized song requires auditory feedback. Birds deafened  before the second stage cannot reproduce the memorized song. Birds change vocal  output until it matches with the memorized song, which thus serves as a template.  Birds use a built-in template when a tutor model is not available. Exposure to a  tutor model modifies this innate template. 
Automatic Speech Recognition (ASR) is an artificial perception problem: the input  is raw, continuous patterns (no symbols!) and the desired output, which may be  words, phoneroes, meaning or text, is symbolic. The most successful approach to  automatic speech recognition is based on stochastic models. A stochastic model is  a theoretical system whose internal state and output undergo a series of transformations governed by probabilistic laws [1]. In the application to speech recognition  the unknown patterns of sound are treated as if they were outputs of a stochastic  system [18,2]. Information about the classes of patterns is encoded as the structure  of these "laws" and the probabilities that govern their operation. The most popular  type of SM for ASR is also known as a "hidden Markov model."  There are several reasons why the SM approach has been so successful for ASR.  It can describe the shape of the spectrum, and has a principled way of describing temporal order, together with variability of both. It is compatible with the  hierarchical nature of speech structure [20,18,4], there are powerful algorithms for  decoding with respect to the model (recognition), and for adapting the model to fit  significant amounts of example data (learning). Firm theoretical (mathematical)  foundations enable extensions to be accommodated smoothly (e.g. [3]).  There are many deficiencies however. In a typical system the speech signal is first  described as a sequence of acoustic vectors (spectrum cross sections or equivalent)  at a rate of say 100 per second. The pattern is assumed to consist of a sequence of  segments corresponding to discrete states of the model. In each segment the acoustic  vectors are drawn from a distribution characteristic of the state, but otherwise  independent of one another and of the states before and after. In some systems there  is a controlled relationship between states and the phonernes or phones of speech  science, but most of the properties and notions which speech scientists assume are  important are ignored.  Most SM approaches are also deficient at a pattern-recognition theory level: The  parameters of the models are usually adjusted (using the Baum-Welch re-estimation  method [5,2]) so as to maximise the likelihood of the data given the model. This  is the right thing to do if the form of the model is actually appropriate for the  data, but if not the parameter-optimisation method needs to be concerned with  Speech Recognition 797  discrimination between classes (phonemes, words, meanings,...) [28,29,30].  A HMM recognition algorithm is designed to find the best explanation of the input in  terms of the model. It tracks scores for all plausible current states of the generator  and throws away explanations which lead to a current state for which there is a  better explanation (Bellman's Dynamic Programming). It may also throw away  explanations which lead to a current state much worse than the best current state  (score pruning), producing a Beam Search method. (It is important to keep many  hypotheses in hand, particularly when the current input is ambiguous.)  Connectionist (or "Neural Network") approaches start with a strong pre-conception  of the types of process to be used. They can claim some legitimacy by reference  to new (or renewed) theories of cognitive processing. The actual mechanisms used  are usually simpler than those of the SM methods, but the mathematical theory  (of what can be learnt or computed for instance) is more difficult, particularly for  structures which have been proposed for dealing with temporal structure.  One of the dreams for connectionist approaches to speech is a network whose inputs  accept the speech data as it arrives, it would have an internal state which contains all  necessary information about the past input, and the output would be as accurate  and early as it could be. The training of networks with their own dynamics is  particularly difficult, especially when we are unable to specify what the internal state  should be. Some are working on methods for training the fixed points of continuousvalued recurrent non-hnear networks [15,16,27]. Prager [6] has attempted to train  various types of network in a full state-feedback arrangement. Watrous [9] limits  his recurrent connections to self-loops on hidden and output units, but even so the  theory of such recursive non-linear filters is formidable.  At the other extreme are systems which treat a whole time-frequency-amplitude  array (resulting from initial acoustic analysis) as the input to a network, and require  a label as output. For example, the performance that Peeling et al. [7] report  on multi-speaker small-vocabulary isolated word recognition tasks approach those  of the best HMM techniques available on the same data. Invariance to temporal  position was trained into the network by presenting the patterns at random positions  in a fixed time-window. Waibel et al. [8] use a powerful compromise arrangement  which can be thought of either as the replication of smaller networks across the timewindow (a time-spread network [19]) or as a single small network with internal delay  lines (a Time-Delay Neural Network [8]). There are no recurrent links except for  trivial ones at the output, so training (using Backpropagation) is no great problem.  We may think of this as a finite-impulse-response non-linear filter. Reported results  on consonant discrimination are encouraging, and better than those of a HMM  system on the same data. The system is insensitive to position by virtue of its  construction.  Kohonen has constructed and demonstrated large vocabulary isolated word [12]  and unrestricted vocabulary continuous speech transcription [13] systems which are  inspired by neural network ideas, but implemented as algorithms more suitable for  798 Bridle  current programmed digital signal processor and CPU chips. Kohonen's phonotopic  map technique can be thought of as an unsupervised adaptive quantiser constrained  to put its reference points in a non-linear low-dimensional sub-space. His learning  vector quantiser technique used for initial labeling combines the advantages of the  classic nearest-neighbor method and discriminant training.  Among other types of network which have been applied to speech we must mention  an interesting class based not on correlations with weight vectors (dot-product) but  on distances from reference points. Radial Basis Function theory [22] was developed  for multi-dimensional interpolation, and was shown by Broomhead and Lowe [23]  to be suitable for many of the jobs that feed-forward networks are used for. The  advantage is that it is not difficult to find useful positions for the reference points  which define the first, non-linear, transformation. If this is followed by a linear  output transformation then the weights can be found by methods which are fast and  straightforward. The reference points can be adapted using methods based on backpropagation. Related methods include potential functions [24], Kernel methods [25]  and the modified Kanerva network [26].  There is much to be gained form a careful comparison of the theory of stochastic  model and neural network approaches to speech recognition. If a NN is to perform speech decoding in a way anything like a SM algorithm it will have a state  which is not just one of the states of the hypothetical generarive model; the state  must include information about the distribution of possible generator states given  the pattern so far, and the state transition function must update this distribution  depending on the current speech input. It is not clear whether such an internal representation and behavior can be 'learned' from scratch by an otherwise unstructured  recurrent network.  Stochastic model based algorithms seem to have the edge at present for dealing with  temporal sequences. Discrimination-based training inspired by NN techniques may  make a significant difference in performance.  It would seem that the area where NNs have most to offer is in finding non-linear  transformations of the data which take us to a space (perhaps related to formant or  articu]atory parameters) where comparisons are more relevant to phonetic decisions  than purely auditory ones (e.g., [17,10,11]). The resulting transformation could also  be viewed as a set of 'feature detectors'. Or perhaps the NN should deliver posterior  probabilities of the states of a SM directly [14].  The art of applying a stochastic model or neural network approach is to choose  a class of models or networks which is realistic enough to be likely to be able to  capture the distinctions (between speech sounds or words for instance) and yet  have a structure which makes it amenable to algorithms for building the detail of  the models based on examples, and for interpreting particular unknown patterns.  Future systems will need to exploit the regularities described by phonetics, to allow  the construction of high-performance systems with large vocabularies, and their  adaptation to the characteristics of each new user.  Speech Recognition 799  There is no doubt that the Stochastic model based methods work best at present,  but current systems are generally far inferior to humans even in situations where the  usefulness of higher-level processing in minimal. I predict that the next generation  of ASR systems will be based on a combination of connectionist and SM theory and  techniques, with mainstream speech knowledge used in a rather soft way to decide  the structure. It should not be long before the distinction I have been making will  disappear [29].  References [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9]  [lO]  [11]  [12]  D. R. Cox and H. D. Millar, "The Theory of Stochastic Processes", Methuen,  1965. pp. 721-741.
A great deal of interest has recently been focused on theories concerning  parallel distributed processing in central nervous systems. In particular,  many researchers have become very interested in the structure and function  of "computational maps" in sensory systems. As defined in a recent review  (Knudsen et al, 1987), a "map" is an array of nerve cells, within which there  is a systematic variation in the "tuning" of neighboring cells for a particular  parameter. For example, the projection from retina to visual cortex is a relatively simple topographic map; each cortical hypercolumn itself contains a  more complex "computational" map of preferred line orientation representing the angle of tilt of a simple line stimulus.  
The echolocating bat, Eptesicus fuscus, perceives the distance to  sonar targets from the delay of echoes and the shape of targets  from the spectrum of echoes. However, shape is perceived in  terms of the target's range profile. The time separation of echo  components from parts of the target located at different distances  is reconstructed from the echo spectrum and added to the  estimate of absolute delay already derived from the arrival-time  of echoes. The bat thus perceives the distance to targets and  depth within targets along the same psychological range  dixnension, which is computed. The image corresponds to the  crosscorrelation function of echoes. Fusion of physiologically  distinct timeand frequency-domain representations into a fmal,  common time-domain image illustrates the binding of withinmodality features into a unified, whole image. To support the  structure of images along the dimension of range, bats can  perceive echo delay with a hyperacuity of 10 nanoseconds.  Acoustic-Imaging Computations by Echolocating Bats 3  THE SONAR OF BATS  Bats are flying mammals, whose lives are largely noctumal. They have evolved  the capacity to orient in darkness using a biological sonar called echolocation,  which they use to avoid obstacles to flight and to detect, identify, and track flying  insects for interception (Griffin, 1958). Echolocating bats emit brief, mostly  ultrasonic sonar sounds and perceive objects from echoes that return to their ears.  The bat's auditory system acts as the sonar receiver, processing echoes to  reconstruct images of the objects themselves. Many bats emit frequencymodulated (FM) signals; the big brown bat, Eptesicus fuscus, transmits sounds  with durations of several milliseconds containing frequencies from about 20 to  100 kltz arranged in two or three harmonic sweeps (Fig. 1). The images that  Eptesicus ultimately perceives retain crucial features of the original sonar wave100[  , 60  ' 40  g .  2  I msec  Figure 1: Spectrogram of a  sonar sound emitted by the  big brown bat, Eptesicus  fuscus (Simmons, 1989).  forms, thus revealing how echoes are processed to reconstruct a display of the  object itself. Several important general aspects of perception are embodied in  specific echo-processing operations in the bat's sonar. By recognizing constraints  imposed when echoes are encoded in terms of neural activity in the bat's auditory  system, recent experiments have identified a novel use of timeand frequencydomain techniques as the basis for acoustic imaging in FM echolocation. The  intrinsically reciprocal properties of timeand frequency-domain representations  are exploited in the neural algorithms wlfich the bat uses to unify disparate  features into whole images.  IMAGES OF SINGI,E-GLINT 'FARGETS  A simple sonar target consists of a single reflecting point, or glint, located at a  discrete range and reflecting a single replica of the incident sonar signal. A  complex target consists of several glints at slightly different ranges. It thus reflects  compound echoes composed of individual replicas of the incident sound arriving  4 Simmons  at slightly different delays. To determine the distance to a target, or target range,  echolocating bats estimate the delay of echoes (Sinmons, 1989). The bat's image  of a single-glint target is constructed around its estimate of echo delay, and the  shape of the image can be measured behaviorally. The performance of bats  trained to discriminate between echoes that jitter in delay and echoes that are  stationary in delay yields a graph of the hnage itself (Altes, 1989), together with  an indication of the accuracy of the delay estimate that underlies it (Simmons,  1979; Simmons, Ferragamo, Moss, Stevenson, & Altos, in press). Fig. 2 shows  Jitter Performance  Crasscorrelatian Function  -50 -40 -30 -20 -tO 0 tO 20 30 40 50  Time (m,croseconds)  e--e / j ' ' 'x./ \  -0-;'0-50-0-;0 6 1'0 2'0 3'0 i0 5'0  Time (microseconds)  Figure 2: Graphs showing the bat's image of a single-glint target  from jitter discrimination experhnents (left) for comparison with  the crosscorrelation function of echoes (riglt). The zero pabst  on each tine axis corresponds to the objective arrival-time of the  echoes (about 3 msec in this experiment; Sinmons, Ferragamo,  et al., in press).  the image of a single-glint target perceived by Eptesicus, expressed in terms of  echo delay (58 gsec/cm of range). From the bat's jitter discrimination  performance, the target is perceived at its true range. Also, the image has a fine  structure consisting of a central peak corresponding to the location of the target  and two prominent side-peaks as ghost images located about 35 [tsec or 0.6 cxn  nearer and farther than the main peak. This image fme structure reflects the  composition of the waveform of the echoes themselves; it approximates the  crosscorrelation function of echoes (Fig. 2).  The discovery that the bat perceives an image corresponding to the crosscorrelation function of echoes provides a view of the hidden machinery of the  bat's sonar receiver. The bat's estimate of echo delay evidently is based upon a  capacity of the auditory system to represent virtually all of the information  available in echo waveforms that is relevant to determining delay, including the  phase of echoes relative to emissions (Simnons, Ferragamo, et al, in press). The  bat's initial auditory representation of these FM signals resembles spectragrams  Acoustic-Imaging Computations by Echolocating Bats 5  that consist of neural impulses marking the time-of-occurrence of successive  frequencies in the FM sweeps of the sounds (Fig. 3). Each nerve im8O  6O   50  -- 40  25  2O  15  150  120  IO0  ';  ,.  o  I I  5  time (msec)  Figure 3: Neural spectrograms  representing a sonar emission  (left) and an echo from a target  located about 1 m away (fight).  The individual dots are neural  impulses conveying the  instantaneous frequency of the  FM sweeps (see Fig. 1). The 6msec time separation of the two  spectrograms indicates target  range in the bat's sonar receiver  (Simmons & Kick, 1984).  pulse travels in a "channel" that is tuned to a particular excitatory frequency  (Bodenhamer & Pollak, 1981) as a consequence of the fi'equency analyzing  properties of the cochlea.. The cochlear filters are followed by rectification and  low-pass filtering, so in a conventional sense the phase of the filtered signals is  destroyed in the course of forming the spectrograms. Itowever, Fig. 2 shows that  the bat is able to reconstruct the crosscorrelation function of echoes from its  spcctrogram-like auditory representation. The individual neural "oints"in the  spectrogram signify instantaneous frequency, and the recovery of the fme  structure in the image may exploit properties of instantaneous frequency when  the images are assembled by integrating numerous separate delay measurements  across different frequencies. The fact that the crosscorrelation function emerges  from these neural computations is provocative from theoretical and technological  viewpoints--the bat appears to employ novel real-time algorithms that can  transform echoes into spectrograms and then into the sonar ambiguity function  itself.  The range-axis image of a single-glint target has a fine structure surrounding a  central peak that constitutes the bat's estimate of echo tielay (Fig. 2). The width  of this peak corresponds to the liniting accuracy of the bat's delay estimate,  allowing for the ambiguity represented by the side-peaks located about 35 pscc  away. In Fig. 2, tile data-points are spaced 5 psec apart along the time axis  (approximately the Nyquist smnpling interval for the bat's signals), aid the true  width of the central peak is poorly shown. Fig. 4 shows the performance of three  Eptesicus in an experiment to measure Illis width with smaller delay steps. The  6 Simmons  loo  9o  õ 80  70   60   o  0 5 10 15 20 25 30 25 40 45 50 55 60  Tme (nanoseconds)  Figure 4: A graph of the  performance of Eptesicus  discriminating echo-delay  jitters that change in small  steps. The bats' limiting  acuity is about 10 nsec for  75 % correct responses  (Simmons, Ferragamo, et al.,  in press).  bats can detect a shift of as little as 10 nsec as a hyperacuity (Altes, 1989) for  echo delay in the jitter task. In estimating echo delay, the bat must integrate  spectrogram delay estimates across separate frequencies in the FM sweeps of  emissions and echoes (see Fig. 3), and it arrives at a very accurate composite  estimate indeed. Timing accuracy in the nanosecond range is a previously  unsuspected capability of the nervous system, and it is likely that more complex  algorithms than just integration of information across frequencies lie behind this  fine acuity (see below on amplitude-latency trading and perceived delay).  IMAGES OF TWO-GLINT TARGETS  Complex targets such as airborne insects reflect echoes composed of several  replicas of the incident sound separated by short intervals of time (Simmons &  Chen, 1989). For insect-sized targets, with dimensions of a few centimeters, this  time separation of echo conponents is unlikely to exceed 100 to 150 [zsec.  Because the bat's signals are several milliseconds long, the echoes from complex  targets thus will contain echo components that largely overlap. The auditory  system of Eptesicu, has an integration-time of about 350 lzsec for reception of  sonar echoes (Simmons, Freedman, et aL, 1989). Two echo components that  arrive together within this integration-time will merge together into a single  compound echo having an arrival-time as a whole that indicates the delay of the  first echo component, and having a series of notches in its spectrum that indicates  the time separation of the first and second components. In the bat's auditory  representation, echo delay corresponds to the time separation of the enission and  echo spectrograms (see Fig. 3), while the notches in the compound echo  spectrum appear as "holes" in the spectrogram--that is, as frequencies that fail to  appear in echoes. The location and spacing of these notches or holes in  frequency is related to the separation of the two echo components in time. The  crucial point is that the constraint inposed by the 350-[tsec integration-time for  echo reception disperses the information required to reconstruct the detailed range  Acoustic-Imaging Computations by Echolocating Bats 7  structure of the complex target into both the time and the frequency dimensions  of the neural spectrograms.  Eptesicus extracts an estimate of the overall delay of the waveform of compound  echoes from two-glint targets. This time estimate leads to a range-axis image of  the closer of the two glints in the target (the target's leading edge). This part of  the image exhibits the same properties as the image of a single-glint target--it is  encoded by the time-of-occurrence of neural discharges in the spectrogrmns and it  resembles the crosscorrelation function for the first echo component (Simmons,  Moss, & Ferragamo, 1990; Simnons, Ferragamo, et al., in press; see Simmons,  1989). The bat also perceives a range-axis image of the thrthcr of the two glints  (the target's trailing edge). This inage is located at a perceived distance that  corresponds to the baffs estimate of the time separation of the two echo  components that make up the compound echo. Fig. 5 shows the performance of  Eptesicus in a jitter discrimination experiment in wlfich one of the  a + a  a a'  3ø r)[
The midbrain of the barn owl contains a map-like representation of  sound source direction which is used to precisely orient the head toward targets of interest. Elevation is computed from the interaural  difference in sound level. We present models and computer simulations of two stages of level difference processing which qualitatively  agree with known anatomy and physiology, and make several striking predictions.
The pyloric Central Pattern Generator of the crustacean stomatogastric  ganglion is a well-defined biological neural network. This 14-neuron  network is modulated by many inputs. These inputs reconfigure the  network to produce multiple output patterns by three simple  mechanisms: 1) determining which cells are active; 2) modulating the  synaptic efficacy; 3) changing the intrinsic response properties of  individual neurons. The importance of modifiable intrinsic response  properties of neurons for network function and modulation is discussed.
Interneurons in leech ganglia receive multiple sensory inputs and make synaptic contacts with many motor neurons. These "hidden" units coordinate several different behaviors. We used physiological and anatomical constraints to construct a model of the local bending reflex. Dynamical networks were trained on experimentally derived input-output patterns using recurrent back-propagation. Units in the model were modified to include electrical synapses and multiple synaptic time constants. The properties of the hidden units that emerged in the simulations matched those in the leech. The model and data support distributed rather than 1ocalist representations in the local bending reflex. These results also explain counterintuitive aspects of the local bending circuitry. 
Traditional inethods of studying neural coding characterize the cncoding of known stimuli in average neural responses. Organisms  face nearly the opposite task -decoding short segments of a spike  train to extract information about an unknown, time-varying stimulus. Here we present strategies for characterizing the neural code  from the point of view of the organism, culminating in algorithms  for real-time stimulus reconstruction based on a single sample of  the spike train. These methods are applied to the design and analysis of experiments on an identified movement-sensitive neuron in  the fly visual system. As far as we know this is the first instance in  which a direct "reading" of the neural code has been accomplished.
Most complex behaviors appear to be governed by internal motivational states or drives that modify an animal's responses to its  environment. It is therefore of considerable interest to understand  the neural basis of these motivational states. Drawing upon work  on the neural basis of feeding in the marine mollusc Aplysia, we  have developed a heterogeneous artificial neural network for controlling the feeding behavior of a simulated insect. We demonstrate  that feeding in this artificial insect shares many characteristics with  the motivated behavior of natural animals.
The brain represents the skin surface as a topographic map in the  somatosensory cortex. This map has been shown experimentally to  be modifiable in a use-dependent fashion throughout life. We  present a neural network simulation of the competitive dynamics  underlying this cortical plasticity by detailed analysis of receptive  field properties of model neurons during simulations of skin coactivation, cortical lesion, digit amputation and nerve section.
It is well-known that neural responses in particular brain regions  are spatially organized, but no general principles have been developed that relate the structure of a brain map to the nature of  the associated computation. On parallel computers, maps of a sort  quite similar to brain maps arise when a computation is distributed  across multiple processors. In this paper we will discuss the relationship between maps and computations on these computers and  suggest how similar considerations might also apply to maps in the  brain.
A generic model of oscillating cortex, which assumes "minimal"  coupling justified by known anatomy, is shown to function as an  sociative memory, using previously developed theory. The network  has explicit excitatory neurons with local inhibitory interneuron  feedback that forms a set of nonlinear oscillators coupled only by  long range excitatogy connections. Using a local Hebb-like learning  rule for primary and higher order synapses at the ends of the long  range connections, the system learns to store the kinds of oscillation amplitude patterns observed in olfactory and visual cortex.  This rule is derived from a more general "projection algorithm"  for recurrent analog networks, that analytically guarantees content  addressable memory storage of continuous periodic sequences -capacity: N/2 Fourier components for an N node network -no  "spurious" attractors.
The firing patterns of populations of cells in the cat visual cortex can exhibit oscillatory responses in the range of 35 85 Hz.  Furthermore, groups of neurons many tom's apart can be highly  synchronized as long as the cells have similar orientation tuning.  We investigate two basic network architectures that incorporate either nearest-neighbor or global feedback interactions and conclude  that non-local feedback plays a fundamental role in the initial synchronization and dynamic stability of the oscillations.
It has been known for many years that specific regions of the working cerebral cortex display periodic variations in correlated cellular  activity. While the olfactory system has been the focus of much of  this work, similar behavior has recently been observed in primary  visual cortex. We have developed models of both the olfactory  and visual cortex which replicate the observed oscillatory properties of these networks. Using these models we have examined the  dependence of oscillatory behavior on single cell properties and network architectures. We discuss the idea that the oscillatory events  recorded from cerebral cortex may be intrinsic to the architecture  of cerebral cortex as a whole, and that these rhythmic patterns  may be important in coordinating neuronal activity during sensory  processing.
We outline a computational model of the development and regeneration of specific eye-brain circuits. The model comprises a self-organizing map-forming network which uses local Hebb rules, constrained by  molecular markers. Various simulations of the development of eyebrain maps in fish and frogs are described.
At the level of individual neurons, catecholamine release increases the  responsivity of cells to excitatory and inhibitory inputs. We present a  model of catecholamine effects in a network of neural-like elements.  We argue that changes in the responsivity of individual elements do  not affect their ability to detect a signal and ignore noise. However,  the same changes in cell responsivity in a network of such elements do  improve the signal detection performance of the network as a whole. We  show how this result can be used in a computer simulation of behavior  to account for the effect of CNS stimulants on the signal detection  performance of human subjects.
We study networks of spiking neurons in which spikes are fired as  a Poisson process. The state of a cell is determined by the instantaneous firing rate, and in the limit of high firing rates our model  reduces to that studied by Hopfield. We find that the inclusion  of spiking results in several new features, such as a noise-induced  asymmetry between "on" and "off" states of the cells and probability currents which destroy the usual description of network dynamics in terms of energy surfaces. Taking account of spikes also allows us to calibrate network parameters such as "synaptic weights"  against experiments on real synapses. Realistic forms of the post  synaptic response alters the network dynamics, which suggests a  novel dynamical learning mechanism.
This paper presents the results of a simulation of the spatial relationship  between the inferior olivary nucleus and folium crus IIA of the lateral  hemisphere of the rat cerebellum. The principal objective of this  modeling effort was to resolve an apparent conflict between a proposed  zonal organization of olivary projections to cerebellar cortex suggested  by anatomical tract-tracing experiments (Brodal & Kawamura 1980;  Campbell & Armstrong 1983) and a more patchy organization apparent  with physiological mapping (Robertson 1987). The results suggest that  several unique features of the olivocerebellar circuit may contribute to  the appearance of zonal organization using anatomical techniques, but  that the detailed patterns of patchy tactile projections seen with  physiological techniques are a more accurate representation of the  afferent organization of this region of cortex.
In the mammalian visual cortex, orientation-selective 'simple cells'  which detect straight lines may be adapted to detect curved lines  instead. We test a biologically plausible, Hebbian, single-neuron  model, which learns oriented receptive fields upon exposure to unstructured (noise) input and maintains orientation selectivity upon  exposure to edges or bars of all orientations and positions. This  model can also learn arc-shaped receptive fields upon exposure  to an environment of only circular rings. Thus, new experiments  which try to induce an abnormal (curved) receptive field may provide insight into the plasticity of simple cells. The model suggests  that exposing cells to only a single spatial frequency may induce  more striking spatial frequency and orientation dependent effects  than heretofore observed.
The existence of modularity in the organization of nervous systems  (e.g. cortical columns and olfactory glomeruli) is well known. We  show that localized activity patterns in a layer of cells, collective  excitations, can induce the formation of modular structures in the  anatomical connections via a Hebbian learning mechanism. The  networks are spatially homogeneous before learning, but the spontaneous emergence of localized collective excitations and subsequently modularity in the connection patterns breaks translational  symmetry. This spontaneous symmetry breaking phenomenon is  similar to those which drive pattern formation in reaction-diffusion  systems. We have identified requirements on the patterns of lateral  connections and on the gains of internal units which are essential  for the development of modularity. These essential requirements  will most likely remain operative when more complicated (and biologically realistic) models are considered.
Spiking neurons which integrate to threshold and fire were used  to study the transmission of frequency modulated (FM) signals  through layered networks. Firing correlations between cells in the  input layer were found to modulate the transmission of FM signals under certain dynamical conditions. A tonic level of activity  was maintained by providing each cell with a source of Poissondistributed synaptic input. When the average membrane depolarization produced by the synaptic input was sufficiently below  threshold, the firing correlations between cells in the input layer  could greatly amplify the signal present in subsequent layers. When  the depolarization was sufficiently close to threshold, however, the  firing synchrony between cells in the initial layers could no longer  effect the propagation of FM signals. In this latter case, integrateand-fire neurons could be effectively modeled by simpler analog  elements governed by a linear input-output relation.
The input/output properties of a 2 compartment model neuron are systematically  explored. Taken from the work of MacGregor (MacGregor, 1987), the model neuron  compartments contain several active conductances, including a potassium conductance in  the dendritic compartment driven by the accumulation of intradendritic calcium.  Dynamics of the conductances and potentials are governed by a set of coupled first order  differential equations which are integrated numerically. There are a set of 17 internal  parameters to this model, specificying conductance rate constants, time constants,  thresholds, etc.  To study parameter sensitivity, a set of trials were run in which the input driving the  neuron is kept fixed while each internal parameter is varied with all others left fixed.  To study the input/output relation, the input to the rendrite (a square wave) was varied  (in frequency and magnitude) while all internal parameters of the system were left fixed,  and the resulting output firing rate and bursting rate was counted.  The input/output relation of the model neuron studied turns out to be much more  sensitive to modulation of certain dendritic potassium current parameters than to  plasticity of synapse efficacy per se (the amount of current influx due to synapse  activation). This would in turn suggest, as has been recently observed experimentally,  that the potassium current may be as or more important a focus of neural plasticity than  synaptic efficacy.
Analytic solutions to the information-theoretic evolution equation of the connection strength of a three-layer feedforward neural  net for visual information processing are presented. The results  are (1} the receptive fields of the feature-analysing cells correspond to the eigenvector of the maximum eigenvalue of the Fredholm integral equation of the first kind derived from the evolution  equation of the connection strength; (2} a symmetry-breaking  mechanism {parity-violation} has been identified to be responsible for the changes of the morphology of the receptive field;  (3} the conditions for the formation of different morphologies are  explicitly identified.
Eight neural net and conventional pattern classifiers (Bayesianunimodal Gaussian, k-nearest neighbor, standard back-propagation,  adaptive-stepsize back-propagation, hypersphere, feature-map, learning vector quantizer, and binary decision tree) were implemented  on a serial computer and compared using two speech recognition  and two artificial tasks. Error rates were statistically equivalent on  almost all tasks, but classifiers differed by orders of magnitude in  memory requirements, training time, classification time, and ease  of adaptivity. Nearest-neighbor classifiers trained rapidly but required the most memory. Tree classifiers provided rapid classification but were complex to adapt. Back-propagation classifiers typically required long training times and had intermediate memory  requirements. These results suggest that classifier selection should  often depend more heavily on practical considerations concerning  memory and computation resources, and restrictions on training  and classification times than on error rate.  *This work was sponsored by the Department of the Air Force and the Air Force Office of  Scientific Research.  Practical Characteristics of Neural Network 169
It is well known that when an automatic learning algorithm is applied  to a fixed corpus of data, the size of the corpus places an upper bound  on the number of degrees of freedom that the model can contain if  it is to generalize well. Because the amount of hardware in a neural  network typically increases with the dimensionality of its inputs, it  can be challenging to build a high-performance network for classifying  large input patterns. In this paper, several techniques for addressing this  problem are discussed in the context of an isolated word recognition  task.
We are developing a phoneme based, speaker-dependent continuous  speech recognition system embedding a Multilayer Perceptton (MLP)  (i.e., a feedforward Artificial Neural Network), into a Hidden Markov  Model (HMM) approach. In [Bourlard & Wellekens], it was shown that  MLPs were approximating Maximum a Posteriori (MAP) probabilities  and could thus be embedded as an emission probability estimator in  HMMs. By using contextual information from a sliding window on the  input frames, we have been able to improve frame or phoneme classiftcation performance over the corresponding performance for simple  Maximum Likelihood (ML) or even MAP probabilities that are estimated without the benefit of context. However, recognition of words in  continuous speech was not so simply improved by the use of an MLP,  and several modifications of the original scheme were necessary for  getting acceptable performance. It is shown here that word recognition  performance for a simple discrete density HMM system appears to be  somewhat better when MLP methods are used to estimate the emission  probabilities.
Two approaches were explored which integrate neural net classifiers  with Hidden Markov Model (HMM) speech recognizers. Both attempt to improve speech pattern discrimination while retaining the  temporal processing advantages of ltMMs. One approach used neural nets to provide second-stage discrimination following an ItMM  recognizer. On a small vocabulary task, Radial Basis Function  (RBF) and back-propagation neural nets reduced the error rate  substantially (from 7.9% to 4.2% for the RBF classifier). In a larger  vocabulary task, neural net classifiers did not reduce the error rate.  They, however, outperformed Gaussian, Gaussian mixture, and knearest neighbor (KNN) classifiers. In another approach, neural  nets functioned as low-level acoustic-phonetic feature extractors.  When classifying phonemes based on single 10 msec. frames, discriminant RBF neural net classifiers outperformed Gaussian mixture classifiers. Performance, however, differed little when classifying phones by accumulating scores across all frames in phonetic  segments using a single node ItMM recognizer.  *This work was sponsored by the Department of the Air Force and the Air Force Office of  Scientific Research  HMM Speech Recognition with Neural Net Discrimination 195  Cepstral Sequence  Second Stage  Classifier  Node Averages  Viterbi  Segmentation  Figure 1: Second stage discrimination system. ItMM recognition is based on the  accumulated scores from each node. A second stage classifier can adjust the weights  from each node to provide improved discrimination.
We present a number of Time-Delay Neural Network (TDNN) based  architectures for multi-speaker phoneme recognition (fo,d,g/task). We  use speech of two females and four males to compare the performance  of the various architectures against a baseline recognition rate of 95.9%  for a single TDNN on the six-speaker fo,d,g/task. This series of modular designs leads to a highly modular multi-network architecture capable  of performing the six-speaker recognition task at the speaker dependent  rate of 98.4%. In addition to its high recognition rate, the so-called  "Meta-Pi" architecture learns -without direct supervision -to recognize the speech of one particular male speaker using internal models  of other male speakers exclusively.
One of the attractions of neural network approaches to pattern  recognition is the use of a discrimination-based training method.  We show that once we have modified the output layer of a multilayer perceptron to provide mathematically correct probability distributions, and replaced the usual squared error criterion with a  probability-based score, the result is equivalent to Maximum Mutual Information training, which has been used successfully to improve the performance of hidden Markov models for speech recognition. If the network is specially constructed to perform the recognition computations of a given kind of stochastic model based classifier then we obtain a inethod for discrimination-based training of  the parameters of the models. Examples include an HMM-based  word discriminator, which we call an 'Alphanet'.
We attempt to combine neural networks with knowledge from  speech science to build a speaker independent speech recognition system. This knowledge is utilized in designing the  preprocessing, input coding, output coding, output supervision  and architectural constraints. To handle the temporal aspect  of speech we combine delays, copies of activations of hidden  and output units at the input level, and Back-Propagation for  Sequences (BPS), a learning algorithm for networks with local  self-loops. This strategy is demonstrated in several experiments, in particular a nasal discrimination task for which the  application of a speech theory hypothesis dramatically improved generalization.
The effects of parameter modifications imposed by hardware constraints on a self-organizing feature map algorithm were examined.  Performance was measured by the error rate of a speech recognition system which included this algorithm as part of the front-end  processing. System parameters which were varied included weight  (connection strength) quantization, adaptation quantization, distance measures and circuit approximations which include device  characteristics and process variability. Experiments using the T[  isolated word database for 16 speakers demonstrated degradation in  performance when weight quantization fell below 8 bits. The competitive nature of the algorithm relaxes constraints on uniformity  and linearity which makes it an excellent candidate for a fully analog circuit implementation. Prototype circuits have been fabricated  and characterized following the constraints established through the  simulation efforts.
Acoustic speech recognition degrades in the presence of noise. Compensatory information is available from the visual speech signals  around the speaker's mouth. Previous attempts at using these  visual speech signals to improve automatic speech recognition systems have combined the acoustic and visual speech information at a  symbolic level using heuristic rules. In this paper, we demonstrate  an alternative approach to fusing the visual and acoustic speech  information by training feedforward neural networks to map the  visual signal onto the corresponding short-term spectral amplitude  envelope (STSAE) of the acoustic signal. This information can  be directly combined with the degraded acoustic STSAE. Significant improvements are demonstrated in vowel recognition from  noise-degraded acoustic signals. These results are compared to the  performance of humans, as well as other pattern matching and estimation algorithms.
Distinctive electrocardiogram (ECG) patterns are created when the heart  is beating normally and when a d_angerous arrhythmia is present. Some  devices which monitor the ECG and react to arrhythmias parameterize  the ECG signal and make a diagnosis based on the parameters. The  author discusses the use of a neural network to classify the ECG signals  directly, without parameterization. The input to such a network must  be translation-invariant, since the distinctive features of the ECG may  appear anywhere in an arbritrarily-chosen ECG segment. The input  must also be insensitive to the episode-to-episode and patient-to-patient  variability in the rhythm pattern.
This paper describes a neural network algorithm that (1) performs  temporal pattern matching in real-time, (2) is trained on-line, with  a single pass, (3) requires only a single template for training of each  representative class, (4) is continuously adaptable to changes in  background noise, (5) deals with transient signals having low signalto-noise ratios, (6) works in the presence of non-Gaussian noise, (7)  makes use of context dependencies and (8) outputs Bayesian probability estimates. The algorithm has been adapted to the problem of  passive sonar signal detection and classification. It runs on a Connection Machine and correctly classifies, within 500 ms of onset,  signals embedded in noise and subject to considerable uncertainty.
In our effort to develop a modular neural system for invariant learning and recognition of 3D objects, we introduce here a new module  architecture called an aspect network constructed around adaptive  axo-axo-dendritic synapses. This builds upon our existing system  (Seibert & Waxman, 1989) which processes 2D shapes and classifies  them into view categories (i.e., aspects) invariant to illumination,  position, orientation, scale, and projective deformations. From a  sequence'of views, the aspect network learns the transitions between these aspects, crystallizing a graph-like structure from an  initially amorphous network. Object recognition emerges by accumulating evidence over multiple views vhich activate competing  object hypotheses.
We describe a model that can recognize two-dimensional shapes in  an unsegmented image, independent of their orientation, position,  and scale. The model, called TRAFFIC, efficiently represents the  structural relation between an object and each of its component  features by encoding the fixed viewpoint-invariant transformation  from the feature's reference frame to the object's in the weights of a  connectionist network. Using a hierarchy of such transformations,  with increasing complexity of features at each successive layer, the  network can recognize multiple objects in parallel. An implementation of TRAFFIC is described, along with experimental results  demonstrating the network's ability to recognize constellations of  stars in a viewpoint-invariant manner.
We demonstrate the ability of a two-layer network of thresholded  summation units to support representation of 3D objects in which  several distinct 2D views are stored for each object. Using unsupervised Hebbian relaxation, the network learned to recognize ten  objects from different viewpoints. The training process led to the  emergence of compact representations of the specific input views.  When tested on novel views of the same objects, the network exhibited a substantial generalization capability. In simulated psychophysical experiments, the network's behavior was qualitatively  similar to that of human subjects.
Contour maps provide a general method for  recognizing two-dimensional shapes. All but  blank images give rise to such maps, and people  are good at recognizing objects and shapes  from them. The maps are encoded easily in  long feature vectors that are suitable for  recognition by an associative memory. These  properties of contour maps suggest a role for  them in early visual perception. The prevalence  of direction-sensitive neurons in the visual  cortex of mammals supports this view.
We have constructed a two axis camera positioning system which  is roughly analogous to a single human eye. This Artificial-Eye (Aeye) combines the signals generated by two rate gyroscopes with  motion information extracted from visual analysis to stabilize its  camera. This stabihzation process is similar to the vestibulo-ocular  response (VOR); hke the VOR, A-eye learns a system model that  can be incrementally modified to adapt to changes in its structure,  performance and environment. A-eye is an example of a robust sensory system that performs computations that can be of significant  use to the designers of mobile robots.
To achieve high-rate image data compression  while maintainig a high quality reconstructed  image, a good image model and an efficient  way to represent the specific data of each  image must be introduced. Based on the  physiological knowledge of multichannel  characteristics and inhibitory interactions  between them in the human visual system,  a mathematically coherent parallel architecture  for image data compression which utilizes the  Markov random field image model and  interactions between a vast number of filter  banks, is proposed.
In this paper, we discuss a current attempt at applying the organizational principle Edelman calls Neuronal Group Selection to the  control of a real, two-link robotic manipulator. We begin by motivating the need for an alternative to the position-control paradigm  of classical robotics, and suggest that a possible avenue is to look  at the primitive animal limb 'neurologically ballistic' control mode.  We have been considering a selectionist approach to coordinating  a simple perception-action task.
This paper explores the use of a model neural network for motor  learning. Steinbuch and Taylor presented neural network designs to  do nearest neighbor lookup in the early 1960s. In this paper their  nearest neighbor network is augmented with a local model network,  which fits a local model to a set of nearest neighbors. The network  design is equivalent to local regression. This network architecture  can represent smooth nonlinear functions, yet has simple training  rules with a single global optimum. The network has been used  for motor learning of a simulated arm and a simulated running  machine.
The forward modeling approach is a methodology for learning control when data is available in distal coordinate systems. We extend  previous work by considering how this methodology can be applied  to the optimization of quantities that are distal not only in space  but also in time.  In many learning control problems, the output variables of the controller are not  the natural coordinates in which to specify tasks and evaluate performance. Tasks  are generally more naturally specified in "distal" coordinate systems (e.g., endpoint  coordinates for manipulator motion) than in the "proximal" coordinate system of  the controller (e.g., joint angles or torques). Furthermore, the relationship between  proximal coordinates and distal coordinates is often not known a priori and, if  known, not easily inverted.  The forward modeling approach is a methodology for learning control when training data is available in distal coordinate systems. A forward model is a network  that learns the transformation from proximal to distal coordinates so that distal  specifications can be used in training the controller (Jordan & Rumelhart, 1990).  The forward model can often be learned separately from the controller because it  depends only on the dynamics of the controlled system and not on the closed-loop  dynamics.  In previous work, we studied forward models of kinematic transformations (Jordan,  1988, 1990) and state transitions (Jordan & Rumelhart, 1990). In the current paper,  Learning to Control an Unstable System with Forward Modeling 325  we go beyond the spatial credit assignment problems studied in those papers and  broaden the application of forward modeling to include cases of temporal credit  assignment (cf. Barto, Sutton,  Anderson, 1983; Werbos, 1987). As discussed  below, the function to be modeled in such cases depends on a time integral of the  closed-loop dynamics. This fact has two important implications. First, the data  needed for learning the forward model can no longer be obtained solely by observing  the instantaneous state or output of the plant. Second, the forward model is no  longer independent of the controller: If the parameters of the controller are changed  by a learning algorithm, then the closed-loop dynamics change and so does the  mapping from proximal to distal variables. Thus the learning of the forward model  and the learning of the controller can no longer be separated into different phases.
The CMAC storage scheme has been used as a basis  for a software implementation of an associative  memory system AMS, which itself is a major part  of the learning control loop LENAS. A major  disadvantage of this eMAC-concept is that the  degree of local generalization (area of interpolation) is fixed. This paper deals with an algorithm for self-organizing variable generalization for the AMS, based on ideas of T. Kohonen.
1  The performance sensitivity of Albus' CMAC network was studied for  the scenario in which faults are introduced into the adjustable weights  after training has been accomplished. It was found that fault sensitivity  was reduced with increased generalization when "loss of weight" faults  were considered, but sensitivity was increased for "saturated weight"  faults.
Given a set of input-output training samples, we describe a procedure for determining the time sequence of weights for a dynamic  neural network to model an arbitrary input-output process. We  formulate the input-output mapping problem as an optimal control problem, defining a performance index to be minimized as a  function of time-varying weights. We solve the resulting nonlinear two-point-boundary-value problem, and this yields the training  rule. For the performance index chosen, this rule turns out to be a  continuous time generalization of the outer product rule earlier suggested heuristically by Hopfield for designing associative memories.  Learning curves for the new technique are presented.
A nonlinear neural framework, called the Generalized Hopfield  network, is proposed, which is able to solve in a parallel distributed  manner systems of nonlinear equations. The method is applied to the  general nonlinear optimization problem. We demonstrate GHNs  implementing the three most important optimization algorithms,  namely the Augmented Lagrangian, Generalized Reduced Gradient and  Successive Quadratic Programming methods. The study results in a  dynamic view of the optimization problem and offers a straightforward  model for the parallelization of the optimization computations, thus  significantly extending the practical limits of problems that can be  formulated as an optimization problem and which can gain from the
We present a novel, modular, recurrent connectionist network architecture which learns to robustly perform incremental parsing of complex  sentences. From sequential input, one word at a time, our networks  learn to do semantic role assignment, noun phrase attachment, and  clause saucture recognition for sentences with passive consauctions and  center embedded clauses. The networks make syntactic and semantic  predictions at every point in time, and previous predictions are revised  as expectations are affirmed or violated with the arrival of new infomarion. Our networks induce their own "grammar rules" for dynamically  transforming an input sequence of words into a syntactic/semantic interpretafion. These networks generalize and display tolerance to input  which has been corrupted in ways common in spoken language.
The phonological structure of human languages is intricate, yet highly  constrained. Through a combination of connectionist modeling and  linguistic analysis, we are attempting to develop a computational basis  for the nature of phonology. We present a connectionist architecture  that performs multiple simultaneous insertion, deletion, and mutation  operations on sequences of phonemes, and introduce a novel additional  primitive, clustering. Clustering provides an interesting alternative to  both iterative and relaxation accounts of assimilation processes such as  vowel harmony. Our resulting model is efficient because it processes  utterances entirely in parallel using only feed-forward circuitry.
order single layer recursive network easily learns to  a deterministic finite state machine and recognize regular  grammars. When an enhanced version of this neural net state machine  is connected through a common error term to an external analog stack  memory, the combination can be interpreted as a neural net pushdown  automata. The neural net finite state machine is given the primitives,  push and pop, and is able to read the top of the stack. Through a  gradient descent learning rule derived from the common error  function, the hybrid network learns to effectively use the stack  actions to manipulate the stack memory and to learn simple contextfree grammars.
In this paper we develop a Bayes criterion which includes the Rissanen  complexity, for inferring regular grammar models. We develop two  methods for regular grammar Bayesian infexemce. The fu'st method is  based on treating the regular grammar as a 1-dimensional Markov  source, and the second is based on the combinatoric characteristics of  the regular grammar itseft. We apply the resulting Bayes criteria to a  particular example in order to show the efficiency of each method.
We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was  required, but architecture of the network was highly constrained  and specifically designed for the task. The input of the network  consists of normalized images of isolated digits. The method has  1% error rate and about a 9% reject rate on zipcode digits provided  by the U.S. Postal Service.
We are developing a hand-printed character recognition system using a multilayered neural net trained through backpropagation. We report on results of  training nets with samples of hand-printed digits scanned off of bank checks  and hand-printed letters interactively entered into a computer through a stylus digitizer. Given a large training set, and a net with sufficient capacity to  achieve high performance on the training set, nets typically achieved error  rates of 4-5% at a 0% reject rate and 1-2% at a 10% reject rate. The topology  and capacity of the system, as measured by the number of connections in the  net, have surprisingly little effect on generalization. For those developing  practical pattern recognition systems, these results suggest that a large and  representative training sample may be the single, most important factor in  achieving high recognition accuracy. From a scientdic standpoint, these resuits raise doubts about the relevance to backpropagation of learning models  that estimate the likelihood of high generalization from estimates of capacity.  Reducing capacity does have other benefits however, especially when the reduction is accomplished by using local receptive fields with shared weights.  In this latter case, we find the net evolves feature detectors resembling those  in visual cortex and Linsker's orientation-selective nodes.  Practical interest in hand-printed character recognition is fueled by two current technology trends: one toward systems that interpret hand-printing on hard-copy documents and one toward notebook-like computers that replace the keyboard with a stylus  digitizer. The stylus enables users to write and draw directly on a fiat panel display.  In this paper, we report on results applying multi-layered neural nets trained through  backpropagation (Rumelhart, Hinton, & Williams, 1986) to both cases.  Developing pattern recognition systems is typically a two-stage process. First, intuition  and experimentation are used to select a set of features to represent the raw input pattern. Then a variety of well-developed techniques are used to optimize the classdier  system that assumes this learural representation. Most applications of backpropagation learning to character recognition use the learning capabilities only for this latter  406 Martin and Pittman  stage--developing the classifier system (Burr, 1986; Denker, Gardner, Graf, Henderson, Howard, Hubbard, Jackel, Baird, & Guyon, 1989; Mori & Yokosawa, 1989; Weideman, Manry, & Yau, 1989). However, backpropagation learning affords the opportunity to optimize feature selection and pattern classification simultaneously. We avoid  using pre-determined features as input to the net in favor of using a presegmented,  size-normalized grayscale array for each character. This is a first step toward the goal  of approximating the raw input projected onto the human retina, in that no pre-processing of the input is required.  We report on results for both hand-printed digits and letters. The hand-printed digits  come from a set of 40,000 hand-printed digits scanned from the numeric amount region  of "real-world" bank checks. They were pre-segmented and size-normalized to a  15x24 grayscale array. The test set consists of 4,000 samples and training sets varied  from 100 to 35,200 samples. Although it is always difficult to compare recognition rates  arising from different pattern sets, some appreciation for the difficulty of categorization can be gained using human performance data as a benchmark. An independent  person categorizing the test set of pre-segmented, size-normalized digits achieved an  error rate of 3.4%. This figure is considerably below the near-perfect performance of  operators keying in numbers directly from bank checks, because the segmentation algorithm is flawed.  Working with letters, as well as digits, enables tests of the generality of results on a  different pattern set having more than double the number of output categories. The  hand-printed letters come from a set of 8,600 upper-case letters collected from over  110 people writing with a stylus input device on a flat panel display. The stylus collects  a sequence of x-y coordinates at 200 points per second at a spatial resolution of 1000  points per inch. The temporal sequence for each character is first converted to a sizenormalized bitmap array, keeping aspect ratio constant. We have found that recognition accuracy is significantly improved if these bitmaps are blurred through convolution  with a gaussian distnlaution. Each pattern is represented as a 15x24 grayscale image.  A test set of 2,368 samples was extracted by selecting samples from 18 people, so that  training sets were generated by people different from those generating the test set.  Training set sizes ranged from 500 to roughly 6,300 samples.
We propose a new way to construct a large-scale neural network for  3,000 handwritten Kanji characters recognition. This neural network  consists of 3 parts: a collection of small-scale networks which are  trained individually on a small number of Kanji characters; a network  which integrates the output from the small-scale networks, and a  process to facilitate the integration of these neworks. The recognition  rate of the total system is comparable with those of the small-scale  networks. Our results indicate that the proposed method is effective for  constructing a large-scale network without loss of recognition  performance.
In order to detect the presence and location of immunoglobulin (Ig) domains from amino acid sequences we built a system  based on a neural network with one hidden layer trained with  back propagation. The program was designed to efficiently  identify proteins exhibiting such domains, characterized by a  few localized conserved regions and a low overall homology.  When the National Biomedical Research Foundation (NBRF)  NEW protein sequence database was scanned to evaluate the  program's performance, we obtained very low rates of false  negatives coupled with a moderate rate of false positives.
We present two connectionist architectures for chunking of symbolic  rewrite rules. One uses backpropagation learning, the other competitive  learning. Although they were developed for chunking the same sorts  of rules, the two differ in their representational abilities and learning  behaviors.
Consider a robot wandering around an unfamiliar environmere, performing actions and sensing the resulting environmental states. The robot's task is to construct an internal model of its environment, a model that will allow it to predict  the consequences of its actions and to deumnine what sequences of actions to  take to reach particular goal states. Rivest and Schapire (19879., 1987b;  Schapire, 1988) have studied this problem and have designed a symbolic algorithm to strategically explore and infer the structure of "finite state" environments. The heart of this algorithm is a clever representation of the environment  called an update graph. We have developed a connectionist implementation of  the update graph using a highly-specialized network architecture. With back  propagation learning and a uivial exploration strategy -choosing random  tions -the connectiordst network can outperform the Rivest and Schapire algorithm on simple problems. The network has the additional strength that it  can accommodate stochastic environments. Perhaps the greatest virtue of the  connectiordst appwach is that it suggests generalizations of the update graph  representation that do not arise from a traditional, symbolic perspective.
We present a general and systematic method for neural network  design based on the genetic algorithm. The technique works in  conjunction with network learning rules, addressing aspects of  the network's gross architecture, connectivity, and learning rule  parameters. Networks can be optimized for various applicationspecific criteria, such as learning speed, generalization, robustness  and connectivity. The approach is model-independent. We  describe a prototype system, NeuroGENES¾S, that employs the  backpropagation learning rule. Experiments on several small  problems have been conducted. In each case, NeuroGENESYS  has produced networks that perform significantly better than the  randomly generated networks of its initial population. The computational feasibility of our approach is discussed.
Kanerva's sparse distributed memory (SDM) is an associative-memory model based on the mathematical properties of high-dimensional  binary address spaces. Holland's genetic algorithms are a search technique for high-dimensional spaces inspired by evolutionary processes  of DNA. "Genetic Memory" is a hybrid of the above two systems,  in which the memory uses a genetic algorithm to dynamically reconfigure its physical storage locations to reflect correlations between  the stored addresses and data. For example, when presented with  raw weather station data, the Genetic Memory discovers specific features in the weather data which correlate well with upcoming rain,  and reconfigures the memory to utilize this information effectively.  This architecture is designed to maximize the ability of the system  to scale-up to handle real-world problems.
We have developed graphics to visualize static and dynamic information in layered neural network learning systems. Emphasis was  placed on creating new visuals that make use of spatial arrangements, size information, animation and color. Wc applied these  tools to the study of back-propagation learning of simple Boolean  predicates, and have obtained new insights into the dynamics of  the learning process.
The goal in this work has been to identify the neuronal elements  of the cortical column that are most likely to support the learning  of nonlinear associative maps. We show that a particular style of  network learning algorithm based on locally-tuned receptive fields  maps naturally onto cortical hardware, and gives coherence to a  variety of features of cortical anatomy, physiology, and biophysics  whose relations to learning remain poorly understood.
In this paper we present upper bounds for the learning rates for  hybrid models that employ a combination of both self-organized  and supervised learning, using radial basis functions to build  receptive field representations in the hidden units. The learning  performance in such networks with nearest neighbor heuristic can  be improved upon by multiplying the individual receptive field  widths by a suitable overlap factor. We present results indicat.ing  optimal values for such overlap factors. We also present a new  algorithm for determining receptive field centers. This method  negotiates more hidden units in the regions of the input space as a  function of the output and is conducive to better learning when the  number of patterns (hidden units) is small.
If neurons sum up their inputs in a non-linear way, as some simulations suggest, how is this distributed fine-grained non-linearity exploited during learning? How are all the small sigmoids in synapse,  spine and dendritic tree lined up in the right areas of their respective  input spaces? In this report, I show how an abstract atemporal highly  nested tree snucture with a quadratic transfer function associated  with each branchpoint, can self organise using only a single global  reinforcement scalar, to perform binary classification tasks. The procedure works well, solving the 6-multiplexer and a difficult phoneme  classification task as well as back-propagation does, and faster.  Furthermore, it does not calculate an error gradient, but uses a statistical scheme to build moving models of the reinforcement signal.
A methodology for faster supervised learning in dynamical nonlinear neural networks is presented. It exploits the concept of adjoint  operators to enable computation of changes in the network's response due to perturbations in all system parameters, using the solution of a single set of appropriately constructed linear equations.  The lower bound on speedup per learning iteration over conventional methods for calculating the neuromorphic energy gradient is  O(N2), where N is the number of neurons in the network.
A new form of the deterministic Boltzmann machine (DBM) learning procedure is presented which can efficiently train network modules to discriminate between input vectors according to some criterion. The new technique directly utilizes the free energy of these  "mean field modules" to represent the probability that the criterion  is met, the free energy being readily manipulated by the learning  procedure. Although conventional deterministic Boltzmann learning fails to extract the higher order feature of shift at a network  bottleneck, combining the new mean field modules with the mutual information objective function rapidly produces modules that  perfectly extract this important higher order feature without direct  external supervision.
A new learning algorithm, Learning by Choice of Internal Represetations (CHIR), was recently introduced. Whereas many algorithms reduce the learning process to minimizing a cost function  over the weights, our method treats the internal representations as  the fundamental entities to be determined. The algorithm applies  a search procedure in the space of internal representations, and a  cooperative adaptation of the weights (e.g. by using the perceptton
Cascade-Correlation is a new architecture and supervised learning algorithm for artificial neural networks. Instead of just adjusting the weights  in a network of fixed topology, Cascade-Correlation begins with a minimal network, then automatically trains and adds new hidden units one  by one, creating a multi-layer structure. Once a new hidden unit has  been added to the network, its input-side weights are frozen. This unit  then becomes a permanent feature-detector in the network, available for  producing outputs or for creating other, more complex feature detectors. The Cascade-Correlation architecture has several advantages over  existing algorithms: it learns very quickly, the network.determines its  own size and topology, it retains the structures it has built even if the  training set changes, and it requires no back-propagation of error signals  through the connections of the network.
A central problem in connectionist modelling is the control of  network and architectural resources during learning. In the present  approach, weights reflect a coarse prediction history as coded by a  distribution of values and parameterized in the mean and standard  deviation of these weight distributions. Weight updates are a  function of both the mean and standard deviation of each  connection in the network and vary as a function of the error signal  ("stochastic delta rule"; Hanson, 1990). Consequently, the weights  maintain information on their central tendency and their  "uncertainty" in prediction. Such information is useful in  establishing a policy concerning the size of the nodal complexity of  the network and growth of new nodes. For example, during  problem solving the present network can undergo "meiosis",  producing two nodes where there was one "overtaxed" node as  measured by its coefficient of variation. It is shown in a number of  benchmark problems that meiosis networks can find minimal  architectures, reduce computational complexity, and overall increase  the efficiency of the representation learning interaction.  Also a member of the Cognitive Science Laboratory, Princeton University, Princeton, NJ 08542  534 Hanson
This work introduces a new method called Self Organizing Neural  Network (SONN) algorithm and compares its performance with Back  Propagation in a signal separation application. The problem is to  separate two signals; a modem data signal and a male speech signal,  added and transmitted through a 4 khz channel. The signals are sampled at 8 khz, and using supervised learning, an attempt is made to  reconstruct them. The SONN is an algorithm that constructs its own  network topology during training, which is shown to be much smaller  than the BP network, faster to trained, and free from the trial-anderror network design that characterize BP.
In associative reinforcement learning, an environment generates input  vectors, a learning system generates possible output vectors, and a reinforcement function computes feedback signals from the input-output  pairs. The task is to discover and remember input-output pairs that  generate rewards. Especially difficult cases occur when rewards are  rare, since the expected time for any algorithm can grow exponentially  with the size of the problem. Nonetheless, if a reinforcement function  possesses regularities, and a learning algorithm exploits them, learning  time can be reduced below that of non-generalizing algorithms. This  paper describes a neural network algorithm called complementary reinforcement back-propagation (CRBP), and reports simulation results  on problems designed to offer differing opportunities for generalization.
A simple method for training the dynamical behavior of a neural network is derived. It is applicable to any training problem  in discrete-time networks with arbitrary feedback. The algorithm  resembles back-propagation in that an error function is minimized  using a gradient-based method, but the optimization is carried out  in the hidden part of state space either instead of, or in addition to  weight space. Computational results are presented for some simple  dynamical training problems, one of which requires response to a  signal 100 time steps in the past.
"Selective sampling" is a form of directed search that can greatly  increase the ability of a connectionist network to generalize accurately. Based on information from previous batches of samples, a  network may be trained on data selectively sampled from regions  in the domain that are unknown. This is realizable in cases when  the distribution is known, or when the cost of drawing points from  the target distribution is negligible compared to the cost of labeling them with the proper classification. The approach is justified  by its applicability to the problem of training a network for power  system security analysis. The benefits of selective sampling are  studied analytically, and the results are confirmed experimentally.
One popular class of unsupervised algorithms are competitive algorithms. In the traditional view of competition, only one competitor,  the winner, adapts for any given case. I propose to view competitive adaptation as attempting to fit a blend of simple probability  generators (such as gaussians) to a set of data-points. The maximum likelihood fit of a model of this type suggests a "softer" form  of competition, in which all competitors adapt in proportion to  the relative probability that the input came from each competitor.  I investigate one application of the soft competitive model, placement of radial basis function centers for function interpolation, and  show that the soft model can give better performance with little  additional computational cost.
A new concept for unsupervised learning based upon examples introduced to the neural network is proposed. Each example is considered as an interpolation node of the velocity field in the phase  space. The velocities at these nodes are selected such that all the  streamlines converge to an attracting set imbedded in the subspace  occupied by the cluster of examples. The synaptic interconnections  are found from learning procedure providing selected field. The  theory is illustrated by examples.  This paper is devoted to development of a new concept for unsupervised learning  based upon examples introduced to an artificial neural network. The neural network  is considered as an adaptive nonlinear dissipative dynamical system described by  the following coupled differential equations:  N  iti + gui = E}1g(u1) + Ii i = 1,2,... ,N (1)  j=l  in which u is an N-dimensional vector, function of time, representing the neuron  activity, T is a constant matrix whose elements represent synaptic interconnections  between the neurons, g is a monotonic nonlinear function, Ii is the constant exterior  input to each neuron, and  is a positive constant.  584 Zak and Toomarian  Let us consider a pattern vector 5 represented by its end point in an n-dimensional  phase space, and suppose that this pattern is introduced to the neural net in the  form of a set of vectors examples u(k),k -1,2...K (Fig. 1). The difference  between these examples which represent the same pattern can be caused not only  by noisy measurements, but also by the invariance of the pattern to some changes  in the vector coordinates (for instance, to translations, rotations etc.). If the set  of the points u © is sufficiently dense, it can be considered as a finite-dimensional  approximation of some subspace O(t).  Now the goal of this study is formulated as following: find the synaptic interconnections T/i and the input to the network Ii such that any trajectory which is  originated inside of 0 © will be entrapped there. In such a performance the subspace 0 (t) practically plays the role of the basin of attraction to the original pattern  . However, the position of the attractor itself is not known in advance: the neural  net has to create it based upon the introduced representative examples. Moreover,  in general the attractor is not necessarily static: it can be periodic, or even chaotic.  The achievement of the goal formulated above would allow one to incorporate into  a neural net a set of attractors representing the corresponding clusters of patterns,  where each cluster is imbedded into the basin of its attractor. Any new pattern  introduced to such a neural net will be attracted to the "closest" attractor. Hence,  the neural net would learn by examples to perform content-addressable memory  and pattern recognition.  Fig. 1: Two-Dimensional Vectors as Examples, u }, and Formation of Clusters 0.  Unsupervised Learning in Neurodynamics 585  Our approach is based upon the utilization of the original clusters of the example  points u (k) as interpolation nodes of the velocity field in the phase space. The  assignment of a certain velocity to an example point imposes a corresponding constraint upon the synaptic interconnections 7]j and the input Ii via Eq. (1). After  these unknowns are found, the velocity field in the phase space is determined by Eq.  (1). Hence, the main problem is to assign velocities at the point examples such that  the required dynamical behavior of the trajectories formulated above is provided.  One possibility for the velocity selection based upon the geometrical center approach  was analyzed by M. Zak, (1989). In this paper a "gravitational attraction" approach  to the same problem will be introduced and discussed.  Suppose that each example-point u © is attracted to all the other points u(')(k    k) such that its velocity is found by the same rule as a gravitational force:  v?)= Vo  t= [ Z-j=I \ j  in which vo is a constant scale coefficient.  Actual velocities at the same points are defined by Eq. (1) rearranged as:  v i1,2,...,N  ?)=ET/.g(u')-Uoi)-(u? )-uoi) k= l,2,...,K (3)  j=l  The objective is to find synaptic interconnections T/i and center of gravity Uoi such  that they minimize the distance between the assigned velocity (Eq. 2) and actual  calculated velocities (Eq. 3).  Introducing the energy:  K N  =  k=l i=1  one can find 7] 1 and Uoi from the condition:  i.e., as the static attractor of the dynamical system:  itoi '---o? OE  Ouoi (Sa)  oqj  in which a is a time scale parameter for learning. By appropriate selection of this  parameter the convergence of the dynamical system can be considerably improved  (J. Barhen, S. Gulati, and M. Zak, 1989).  586 Zak and Toomarian  Obviously, the static attractor of Eqs. (5) is unique. As follows from Eq. (3)  0?_2 ):  Ou k) du ) '  (i # j) (6)  dg (? )  Since g(u) is a monotonic function, sgn d-. is constant which in turn implies that  sgn Ou  ) const  (i  j) (7)  Applying this result to the boundary of the cluster one concludes that the velocity  at the boundary is directed inside of the cluster (Fig. 2).  For numerical illustration of the new learning concept developed above, we select  6 points in the two dimensional space, (i.e., two neurons) which constructs two  separated clusters (Fig. 3, points 1-3 and 16-18 (three points are the minimum  to form a cluster in two dimensional space)). Coordinates of the points in Fig.  3 are given in Table 1. The assigned velocity vf calculated based on Eq. 2 and  Vo = 0.04 are shown in dotted line. For a random initialization of T/j and Uoi,  the energy decreases sharply from an initial value of 10.608 to less than 0.04 in  about 400 iterations and at about 2000 iterations the final value of 0.0328 has been  achieved, (Fig. 4). To carry out numerical integration of the differential equations,  first order Euler numerical scheme with time step of 0.01 has been used. In this  simulation the scale parameter a 2 was kept constant and set to one. By substituting  the calculated Tj and Uoi into Eq. (3) for point u }, (k = 1,2,3, 16, 17, 18), one  will obtain the calculated velocities at these points (shown as dashed lines in Fig.  3). As one may notice, the assigned and calculated velocities are not exactly the  same. However, this small difference between the velocities are of no importance as  long as the calculated velocities are directed toward the interior of the cluster. This  directional difference of the velocities is one of the reasons that the energy did not  vanish. The other reason is the difference in the value of these velocities, which is  of no importance either, based on the concept developed.  Fig. 2: Velocities at Boundaries are directed Toward Inside of the Cluster.  Unsupervised Learning in Neurodynamics 587  In order to show that for different initial conditions, Eq. 3 will converge to an  attractor which is inside one of the two clusters, this equation was started from different points (4-15, 19-29). In all points, the equation converges to either (0.709,0.0)  or (-0.709,0.0). However, the line x = 0 in this case is the dividing line, and all the  points on this line will converge to Uo.  The decay coefficient c and the gain of the hyperbolic tangent were chosen to be
A method for storing analog vectors in Hopfield's continuous feedback model is proposed. By analog vectors we mean vectors whose  components are real-valued. The vectors to be stored are set as  equilibria of the network. The network model consists of one layer  of visible neurons and one layer of hidden neurons. We propose  a learning algorithm, which results in adjusting the positions of  the equilibria, as well as guaranteeing their stability. Simulation  results confirm the effectiveness of the method.
We have used information-theoretic ideas to derive a class of practical and nearly optimal schemes for adapting the size of a neural  network. By removing unimportant weights from a network, several improvements can be expected: better generalization, fewer  training examples required, and improved speed of learning and/or  classification. The basic idea is to use second-derivative information to make a tradeoff between network complexity and training  set error. Experiments confirm the usefulness of the methods on a  real-world application.
We have calculated, both analytically and in simulations, the rate  of convergence at long times in the backpropagation learning algoritlun for networks with and without hidden units. Our basic  finding for units using the standard sigrnoid transfer function is 1It  convergence of the error for large t, with at most logarithmic corrections for networks with hidden units. Other transfer functions  may lead to a slower polynomial rate of convergence. Our analytic  calculations were presented in (Tesauro, He & Ahamd, 1989). Here  we focus in more detail on our empirical measurements of the convergence rate in numerical simulations, which corm our analytic  results.
ht the development of an image segmentation system for real time  image processing applications, we apply the classical decision analysis paradigan by viewing inmge segmentation as a pixel classification task. We use supervised training to derive a classifier for our  system from a set of examples of a particular pixel classification  problem. In this study, we test the suitability of a connectionist method against two statistical methods, Gaussian maximum  likelihood classifier and first, second, and third degree polynomial  classifiers, for the solution of a "real world" image segmentation  problem taken from combustion research. Classifiers are derived  using aH three methods, and the performance of all of the classifiers on the training data set as well as on 3 separate entire test  images is measured.
Multi-layer percepttons and trained classification trees are two very  different techniques which have recently become popular. Given  enough data and time, both methods are capable of performing arbitrary non-linear classification. We first consider the important  differences between multi-layer percepttons and classification trees  and conclude that there is not enough theoretical basis for the clearcut superiority of one technique over the other. For this reason, we  performed a number of empirical tests on three real-world problems  in power system load forecasting, power system security prediction,  and speaker-independent vowel identification. In all cases, even for  piecewise-linear trees, the multi-layer perceptron performed as well  as or better than the trained classification trees.  Performance Comparisons 623
We have done an empirical study of the relation of the number of  parameters (weights) in a feedforward net to generalization performance. Two experiments are reported. In one, we use simulated data  sets with well-controlled parameters, such as the signal-to-noise ratio  of continuous-valued data. In the second, we train the network on  vector-quantized mel cepstm from real speech samples. In each case,  we use back-propagation to train the feedforward net to discriminate in  a multiple class pattern classification problem. We report the results of  these studies, and show the application of cross-validation techniques  to prevent overfitting.
Recurrent nets are more powerful than feedforward nets because they allow simulation of dynamical systems. Everything from sine wave generators through computers to the brain are potential candidates, but to use recurrent nets to emulate dynamical system s we need learning algorithms to program them. Here I describe a new twist on an old algorithm for recurrent nets and compare it to its predecessors. 
The learning dynamics of the back-propagation algorithm are investigated when complexity constraints are added to the standard  Least Mean Square (LMS) cost function. It is shown that loss of  generalization performance due to overtraining can be avoided  when using such complexity constraints. Furthermore, "energy," hidden representations and weight distributions are observed and  compared during learning. An attempt is made at explaining the  results in terms of linear and non-linear effects in relation to the  gradient descent learning algorithm.
The properties of a cluster of multiple back-propagation (BP) networks  are examined and compared to the performance of a single BP network. The underlying idea is that a synergistic effect within the cluster  improves the performance and fault tolerance. Five networks were initially trained to perform the same input-output mapping. Following  training, a cluster was created by computing an average of the outputs  generated by the individual networks. The output of the cluster can be  used as the desired output during training by feeding it back to the individual networks. In comparison to a single BP network, a cluster of  multiple BP's generalization and significant fault tolerance. It appear  that cluster advantage follows from simple maxim "you can fool some  of the single BP's in a cluster all of the time but you cannot fool all of  them all of the time" {Lincoln}
In recent years many researchers have investigated the use of Markov  Random Fields (MRFs) for computer vision. They can be applied  for example to reconstruct surfaces from sparse and noisy depth  data coming from the output of a visual process, or to integrate  early vision processes to label physical discontinuities. In this paper we show that by applying mean field theory to those MRFs  models a class of neural networks is obtained. Those networks can  speed up the solution for the MRFs models. The method is not  restricted to computer vision.
A rigorous analysis on the finite precision computational spects of  neural network as a pattern classifier via a probabilistic approach  is presented. Even though there exist negative results on the capability of perceptron, we show the following positive results: Given  n pattern vectors each represented by cn bits where c > 1, that are  uniformly distributed, with high probability the perceptron can  perform all possible binary classifications of the patterns. Moreover, the resulting neural network requires a vanishingly small proportion O(log n/n) of the memory that would be required for complete storage of the patterns. Further, the perceptron algorithm  takes O(n 2) arithmetic operations with high probability, whereas  other methods such as linear programming takes O(n 3'5) in the  worst case. We also indicate some mathematical connections with  VLSI circuit testing and the theory of random matrices.
Within the context of Valiant's protocol for learning, the Perceptron  algorithm is shown to learn an arbitrary half-space in time O(¾r) if D, the probability distribution of examples, is taken uniform over the unit sphere $n. Here  is  the accuracy parameter. This is surprisingly fast, as "standard" approaches involve  solution of a linear programming problem involving () constraints in n dimensions. A modification of Valiant's distribution independent protocol for learning  is proposed in which the distribution and the function to be learned may be chosen by adversaries, however these adversaries may not communicate. It is argued  that this definition is more reasonable and applicable to real world learning than  Valiant's. Under this definition, the Perceptron algorithm is shown to be a distribution independent learning algorithm. In an appendix we show that, for uniform  distributions, some classes of infinite V-C dimension including convex sets and a  class of nested differences of convex sets are learnable.
Decision making tasks that involve delayed consequences are very  common yet difficult to address with supervised learning methods.  If there is an accurate model of the underlying dynamical system,  then these tasks can be formulated as sequential decision problems  and solved by Dynamic Programming. This paper discusses reinforcement learning in terms of the sequential decision framework  and shows how a learning algorithm similar to the one implemented  by the Adaptive Critic Element used in the pole-balancer of Barto,  Sutton, and Anderson (1983), and further developed by Sutton  (1984), fits into this framework. Adaptive neural networks can  play significant roles as modules for approximating the functions  required for solving sequential decision problems.
Linsker has reported the development of centre-surround receptive  fields and oriented receptive fields in simulations of a Hebb-type  equation in a linear network. The dynamics of the learning rule  are analysed in terms of the eigenvectors of the covariance matrix  of cell activities. Analytic and computational results for Linsker's  covariance matrices, and some general theorems, lead to an explanation of the emergence of centre-surround and certain oriented  structures.  Linsker [Linsker, 1986, Linsker, 1988] has studied by simulation the evolution of  weight vectors under a Hebb-type teacherless learning rule in a feed-forward linear  network. The equation for the evolution of the weight vector w of a single neuron,  derived by ensemble averaging the Hebbian rule over the statistics of the input  patterns, is: 1  0  = kl + (Q,j +  subject to --Wma x _< W i <__ Wma x  (1)
Experimental evidence has shown analog neural networks to be extremely fault-tolerant; in particular, their performance does not appear to be significantly impaired when precision is limited. Analog  neurons with limited precision essentially compute k-ary weighted  multilinear threshold functions, which divide R n into k regions with  k-1 hyperplanes. The behaviour of k-ary neural networks is investigated. There is no canonical set of threshold values for k>3,  although they exist for binary and ternary neural networks. The  weights can be made integers of only O ((z +k)log (z +k)) bits, where  z is the number of processors, without increasing hardware or running time. The weights can be made +1 while increasing running  time by a constant multiple and hardware by a small polynomial in z  and k. Binary neurons can be used if the running time is allowed to  increase by a larger constant multiple and the hardware is allowed to  increase by a slightly larger polynomial in z and k. Any symmetric  k-ary function can be computed in constant depth and size  0 (n'-/(k-2)!), and any k-ary function can be computed in constant  depth and size O (nk"). The alternating neural networks of Olafsson  and Abu-Mostafa, and the quantized neural networks of Fleisher are  closely related to this model.  Analog Neural Networks of Limited Precision I 703
A comparison of algorithms that minimize error functions to train the  trajectories of recurrent networks, reveals how complexity is traded off for  causality. These algorithms are also related to time-independent  formalisms. It is suggested that causal and scalable algorithms are  possible when the activation dynamics of adaptive neurons is fast  compared to the behavior to be learned. Standard continuous-time  recurrent backpropagation is used in an example.
The paper suggests a statistical framework for the parameter estimation problem associated with unsupervised learning in a neural  network, leading to an exploratory projection pursuit network that  performs feature extraction, or dimensionality reduction.
Minimization of energy or error functions has proved to be a useful principle in the design and analysis of neural networks and neural algorithms. A brief list of examples include: the back- propagation algorithm, the use of optimization methods in computational vision, the application of analog networks to the approximate solution of NP complete problems and the Hopfield model of associative memory. 
We introduce a cost function for learning in feed-forward neural  networks which is an explicit function of the internal representation in addition to the weights. The learning problem can then  be formulated as two simple perceptrons and a search for internal  representations. Back-propagation is recovered as a limit. The  frequency of successful solutions is better for this algorithm than  for back-propagation when weights and hidden units are updated  on the same timescale i.e. once every learning step.
The vestibulo-ocular reflex (VOR) is the primary mechanism that  controls the compensatory eye movements that stabilize retinal images during rapid head motion. The primary pathways of this system are feed-forward, with inputs from the semicircular canals and  outputs to the oculomotor system. Since visual feedback is not  used directly in the VOR computation, the system must exploit  motor learning to perform correctly. Lisberger(1988) has proposed  a model for adapting the VOR gain using image-slip information  from the retina. We have designed and tested analog very largescale integrated (VLSI) circuitry that implements a simplified version of Lisberger's adaptive VOR model.
The long-term goal of our laboratory is the development of analog  resistive network-based VLSI implementations of early and intermediate vision algorithms. We demonstrate an experimental circuit for smoothing and segmenting noisy and sparse depth data  using the resistive fuse and a 1-D edge-detection circuit for computing zero-crossings using two resistive grids with different spaceconstants. To demonstrate the robustness of our algorithms and  of the fabricated analog CMOS VLSI chips, we are mounting these  circuits onto small mobile vehicles operating in a real-time, laboratory environment.
1024 distributed-neuron synapses have been integrated in an active  area of 6.1mm x 3.3mm using a 0.9ttm, double-metal, single-poly,  n-well CMOS technology. The distributed-neuron synapses are arranged in blocks of 16, which we call '4 x 4 tiles ' Switch matrices  are interleaved between each of these tiles to provide programmability of interconnections. With a small area overhead (15 %), the  1024 units of the network can be rearranged in various configurations. Some of the possible configurations are, a 12-32-12 network,  a 16-12-12-16 network, two 12-32 networks etc. (the numbers separated by dashes indicate the number of units per layer, including  the input layer). Weights are stored in analog form on MOS capacitors. The synaptic weights are usable to a resolution of 1% of  their full scale value. The limitation arises due to charge injection  from the access switch and charge leakage. Other parameters like  gain and shape of nonlinearity are also programmable.
Cascadable, CMOS synapse chips containing a cross-bar array of  32x32 (1024) programmable synapses have been fabricated as  'uilding blocks" for fully parallel implementation of neural  networks. The synapses are based on a hybrid digital-analog  design which utilizes on-chip 7-bit data latches to store quantized  weights and two-quadrant multiplying DAC's to compute weighted  outputs. The synapses exhibit 6-bit resolution and excellent  monotonicity and consistency in their transfer characteristics. A  64-neuron hardware incorporating four synapse chips has been  fabricated to investigate the performance of feedback networks in  optimization problem solving. In this study, a 7x7, one-to-one  assignment net and the Hopfield-Tank 8-city traveling salesman  problem net have been implemented in the hardware. The  network's ability to obtain optimum or near optimum solutions in  real time has been demonstrated.
This paper explores whether analog circuitry can adequately perform constrained optimization. Constrained optimization circuits  are designed using the differential multiplier method. These circuits fulfill time-varying constraints correctly. Example circuits include a quadratic programming circuit and a constrained flip-flop.
We announce new CMOS synapse circuits using only three  and four MOSFETs/synapse. Neural states are asynchronous  pulse streams, upon which arithmetic is performed directly.  Chips implementing over 100 fully programmable synapses  are described and projections to networks of hundreds of  neurons are made.
In this paper we describe the VLSI design and testing of a high  capacity associative memory which we call the exponential correlation associative memory (ECAM). The prototype 3p-CMOS  programmable chip is capable of storing 32 memory patterns of  24 bits each. The high capacity of the ECAM is partly due to the  use of special exponentiation neurons, which are implemented via  sub-threshold MOS transistors in this design. The prototype chip  is capable of performing one associative recall in 3
In this paper, we present a novel implementation of the widely used  Back-propagation neural net learning algorithm on the Connection  Machine CM-2 a general purpose, massively parallel computer  with a hypercube topology. This implementation runs at about 180  million interconnections per second (IPS) on a 64K processor CM2. The main interprocessor communication operation used is 2D  nearest neighbor communication. The techniques developed here  can be easily extended to implement other algorithms for layered  neural nets on the CM-2, or on other massively parallel computers  which have 2D or higher degree connections among their processors.
The mapping of the back-propagation and mean field theory  learning algorithms onto a generic 2-D SIMD computer is  described. This architecture proves to be very adequate for these  applications since efficiencies close to the optimum can be  attained. Expressions to find the learning rates are given and  then particularized to the DAP array procesor.
Dataflow architectures are general computation engines optimized for  the execution of frae-grain parallel algorithms. Neural networks can be  simulated on these systems with certain advantages. In this paper, we  review dataflow architectures, examine neural network simulation  performance on a new generation dataflow machine, compare that  performance to other simulation alternatives, and discuss the benefits  and drawbacks of the dataflow approach.
A short account is given of various investigations of neural network  properties, beginning with the classic work of McCulloch & Pitts.  Early work on neurodynamics and statistical mechanics, analogies with  magnetic materials, fault tolerance via parallel distributed processing,  memory, learning, and pattern recognition, is described.
We describe a computational model of the development and regeneration of specific eye-brain circuits. The model comprises a self-organizing map-forming network which uses local Hebb rules, constrained by  (genetically determined) molecular markers. Various simulations of  the development and regeneration of eye-brain maps in fish and frogs  are described, in particular successful simulations of experiments by  Schmidt-Cicerone-Easter; Meyer; and Yoon.
Feature selective cells in the primary visual cortex of several species are organized in hierarchical topographic maps of stimulus features like "position  in visual space", "orientation" and "ocular dominance". In order to understand and describe their spatial structure and their development, we investigate a self-organizing neural network model based on the feature map  algorithm. The model explains map formation as a dimension-reducing  mapping from a high-dimensional feature space onto a two-dimensional  lattice, such that "similarity" between features (or feature combinations)  is translated into "spatial proximity" betveen the corresponding feature  selective cells. The model is able to reproduce several aspects of the spatial  structure of cortical maps in the visual cortex.
The development of projections from the retinas to the cortex is  mathematically analyzed according to the previously proposed  thermodynamic formulation of the self-organization of neural networks.  Three types of submodality included in the visual afferent pathways are  assumed in two models: model (A), in which the ocularity and retinotopy  are considered separately, and model (B), in which on-center/off-center  pathways are considered in addition to ocularity and retinotopy. Model (A)  shows striped ocular dominance spatial patterns and, in ocular dominance  histograms, reveals a dip in the binocular bin. Model (B) displays  spatially modulated irregular patterns and shows single-peak behavior in  the histograms. When we compare the simulated results with the observed  results, it is evident that the ocular dominance spatial patterns and  histograms for models (A) and (B) agree very closely with those seen in  monkeys and cats.
Simple classical spin models well-known to physicists as the ANNNI  and Heisenberg XY Models, in which long-range interactions occur in  a pattern given by the Mexican Hat operator, can generate many of the  structural properties characteristic of the ocular dominance columns  and iso-orientation patches seen in cat and primate visual cortex.
A three-layered neural network model was used to explore the organization of  the vestibulo-ocular reflex (VOR). The dynamic model was trained using  recurrent back-propagation to produce compensatory, long duration eye muscle  motoneuron outputs in response to short duration vestibular afferent head  velocity inputs. The network learned to produce this response prolongation,  known as velocity storage, by developing complex, lateral inhibitory interactions among the interneurons. These had the low baseline, long time constant,  rectified and skewed responses that are characteristic of real VOR interneurons. The model suggests that all of these features are interrelated and  result from lateral inhibition.
We are exploring the significance of biological complexity for neuronal  computation. Here we demonstrate that Hebbian synapses in realistically-modeled hippocampal pyramidal cells may give rise to two novel  forms of self-organization in response to structured synaptic input. First,  on the basis of the electrotonic relationships between synaptic contacts,  a cell may become tuned to a small subset of its input space. Second, the  same mechanisms may produce clusters of potentiated synapses across  the space of the dendrites. The latter type of self-organization may be  functionally significant in the presence of nonlinear dendritic conductanceso
Combining neuropharmacological experiments with computational modeling, we have shown that cholinergic modulation may enhance associative  memory function in pitiform (olfactory) cortex. We have shown that the  acetylcholine analogue carbachol selectively suppresses synaptic transmission between cells within pitiform cortex, while leaving input connections  unaffected. When tested in a computational model of piriform cortex,  this selective suppression, applied during learning, enhances associative  memory performance.
We have devised a scheme to reduce the complexity of dynamical  systems belonging to a class that includes most biophysically realistic  neural models. The reduction is based on transformations of variables  and perturbation expansions and it preserves a high level of fidelity to  the original system. The techniques are illustrated by reductions of the  Hodgkin-Huxley system and an augmented Hodgkin-Huxley system.
The main point of this paper is that stochastic neural networks have a  mathematical structure that corresponds quite closely with that of  quantum field theory. Neural network Liouvillians and Lagrangians  can be derived, just as can spin Hamiltonians and Lagrangians in QFT.  It remains to show the efficacy of such a description.
The self-organization of recurrent feature-discovery networks is studied  from the perspective of dynamical systems. Bifurcation theory reveals parameter regimes in which multiple equilibria or limit cycles coexist with the  equilibrium at which the networks perform principal component analysis.
We present a new way to derive dissipative, optimizing dynamics from  the Lagrangian formulation of mechanics. It can be used to obtain both  standard and novel neural net dynamics for optimization problems. To  demonstrate this we derive standard descent dynamics as well as nonstandard variants that introduce a computational attention mechanism.
The Hopfield network (Hopfield, 1982,1984) provides a simple model of an  associative memory in a neuronal structure. This model, however, is based  on highly artificial assumptions, especially the use of formal-two state neurons (Hopfield, 1982) or graded-response neurons (Hopfield, 1984). What  happens if we replace the formal neurons by 'real' biological neurons? We  address this question in two steps. First, we show that a simple model of  a neuron can capture all relevant features of neuron spiking, i.e., a wide  range of spiking frequencies and a realistic distribution of interspike intervals. Second, we construct an associative memory by linking these neurons  together. The analytical solution for a large and fully connected network  shows that the Hopfield solution is valid only for neurons with a short refractory period. If the refractory period is longer than a critical duration  7c, the solutions are qualitatively different. The associative character of  the solutions, however, is preserved.
A simple architecture and algorithm for analytically guaranteed associative memory storage of analog patterns, continuous sequences, and chaotic  attractors in the same network is described. A matrix inversion determines  network weights, given prototype patterns to be stored. There are N units  of capacity in an N node network with 3N 2 weights. It costs one unit per  static attractor, two per Fourier component of each sequence, and four per  chaotic attractor. There are no spurious attractors, and there is a Liapunov function in a special coordinate system which governs the approach  of transient states to stored trajectories. Unsupervised or supervised incremental learning algorithms for pattern classification, such as competitive  learning or bootstrap Widrow-Hoff can easily be implemented. The architecture can be "folded" into a recurrent network with higher order weights  that can be used as a model of cortex that stores oscillatory and chaotic  attractors by a Hebb rule. Hierarchical sensory-motor control networks  may be constructed of interconnected "cortical patches" of these network  modules. Network performance is being investigated by application to the  problem of real time handwritten digit recognition.
We show analytically how the stability of two-dimensional lateral  inhibition neural networks depends on the local connection topology.  For various network topologies, we calculate the critical time delay for  the onset of oscillation in continuous-time networks and present  analytic phase diagrams characterizing the dynamics of discrete-time  networks.
Bernard Victorri  ELSAP  Universit de Caen  14032 Caen Cedex  France  Fully recurrent (asymmetrical) networks can be thought of as dynamic  systems. The dynamics can be shaped to perform content addressable  memories, recognize sequences, or generate trajectories. Unfortunately  several problems can arise: First, the convergence in the state space is  not guaranteed. Second, the learned fixed points or trajectories are not  necessarily stable. Finally, there might exist spurious fixed points and/or  spurious "attracting" trajectories that do not correspond to any patterns.  In this paper, we introduce a new energy function that presents solutions  to all of these problems. We present an efficient gradient descent algorithm  which directly acts on the stability of the fixed points and trajectories and  on the size and shape of the corresponding basin and valley of attraction.  The results are illustrated by the simulation of a small content addressable  memory.
The development of learning algorithms is generally based upon the minimization of an energy function. It is a fundamental requirement to compute the gradient of this energy function with respect to the various parameters of the neural architecture, e.g., synaptic weights, neural gain,etc.  In principle, this requires solving a system of nonlinear equations for each  parameter of the model, which is computationally very expensive. A new  methodology for neural learning of time-dependent nonlinear mappings is  presented. It exploits the concept of adjoint operators to enable a fast  global computation of the network's response to perturbations in all the  systems parameters. The importance of the time boundary conditions of  the adjoint functions is discussed. An algorithm is presented in which  the adjoint sensitivity equations are solved smultaneously (i.e., forward  in time) along with the nonlinear dynamics of the neural networks. This  methodology makes real-time applications and hardware implementation  of temporal learning feasible.
Coherent oscillatory activity in large networks of biological or artificial neural units may be a useful mechanism for coding information  pertaining to a single perceptual object or for detailing regularities  within a data set. We consider the dynamics of a large array of  simple coupled oscillators under a variety of connection schemes.  Of particular interest is the rapid and robust phase-locking that  results from a "sparse" scheme where each oscillator is strongly  coupled to a tiny, randomly selected, subset of its neighbors.
This paper studies dynamical aspects of neural systems with delayed negative feedback modelled by nonlinear delay-differential equations. These  systems undergo a Hopf bifurcation from a stable fixed point to a stable limit cycle oscillation as certain parameters are varied. It is shown  that their frequency of oscillation is robust to parameter variations and  noisy fluctuations, a property that makes these systems good candidates  for pacemakers. The onset of oscillation is postponed by both additive  and parametric noise in the sense that the state variable spends more time  near the fixed point than it would in the absence of noise. This is also the  case when noise affects the delayed variable, i.e. when the system has a  faulty memory. Finally, it is shown that a distribution of delays (rather  than a fixed delay) also stabilizes the fixed point solution.
We show that a simple spin system biased at its critical point can encode spatial characteristics of external signals, such as the dilnensions of  "objects" in the visual field, in the temporal correlation functions of individual spins. Qualitative arguments suggest that regularly firing neurons  should be described by a planar spin of unit length, and such XY models  exhibit critical dynamics over a broad range of paralneters. We show how  to extract these spins from spike trains and then measure the interaction  Hamiltonia. n using simulations of small clusters of cells. Static correlations among spike trains obtained kom silnulations of large arrays of cells  are in agreement with the predictions from these Hamiltonians, and dynamic correlations display the predict. ed encoding of spatial inforlnation.  We suggest that this novel representation of object, dilnensions in temporal  correlations may be relevant to recent experiments on oscillatory neural  firing in the visual cortex.
Multi-layered neural networks have recently been proposed for nonlinear prediction and system modeling. Although proven successful  for modeling time invariant nonlinear systems, the inability of neural  networks to characterize temporal variability has so far been an  obstacle in applying them to complicated nonstationary signals, such  as speech. In this paper we present a network architecture, called  "Hidden Control Neural Network" (HCNN), for modeling signals  generated by nonlinear dynamical systems with restricted time  variability. The approach taken here is to allow the mapping that is  implemented by a multi layered neural network to change with time  as a function of an additional control input signal. This network is  trained using an algorithm that is based on "back-propagation" and  segmentation algorithms for estimating the unknown control together  with the network's parameters. The HCNN approach was applied to  several tasks including modeling of time-varying nonlinear systems  and speaker-independent recognition of connected digits, yielding a  word accuracy of 99.1%.
In this work we describe a new method that adjusts time-delays and the widths of  time-windows in artificial neural networks automatically. The input of the units  are weighted by a gaussian input-window over time which allows the learning  rules for the delays and widths to be derived in the same way as it is used for the  weights. Our results on a phoneme classification task compare well with results  obtained with the TDNN by Waibel et al., which was manually optimized for the  same task.
We present a new neural network model for processing of temporal  patterns. This model, the gamma neural model, is as general as a  convolution delay model with arbitrary weight kernels w(t). We  show that the gamma model can be formulated as a (partially  prewired) additive model. A temporal hebbian learning rule is  derived and we establish links to related existing models for  temporal processing.
The goal has been to construct a supervised artificial neural network that  learns incrementally an unknown mapping. As a result a network consisting of a combination of ART2 and backpropagation is proposed and  is called an "ART2/BP" network. The ART2 network is used to build  and focus a supervised backpropagation network. The ART2/BP network  has the advantage of being able to dynamically expand itself in response  to input patterns containing new information. Simulation results show  that the ART2/BP network outperforms a classical maximum likelihood  method for the estimation of a discrete dynamic and nonlinear transfer  function.
We study the representation of static patterns and temporal associations in neural networks with a broad distribution of signal delays.  For a certain class of such systems, a simple intuitive understanding  of the spatio-temporal computation becomes possible with the help  of a novel Lyapunov functional. It allows a quantitative study of  the asymptotic network behavior through a statistical mechanical  analysis. We present analytic calculations of both retrieval quality  and storage capacity and compare them with simulation results.
This work extends computational learning theory to situations in which concepts  vary over time, e.g., system identification of a time-varying plant. We have  extended formal definitions of concepts and learning to provide a framework  in which an algorithm can track a concept as it evolves over time. Given  this framework and focusing on memory-based algorithms, we have derived  some PAC-style sample complexity results that determine, for example, when  tracking is feasible. We have also used a similar framework and focused on  incremental tracking algorithms for which we have derived some bounds on  the mistake or error rates for some specific concept classes.
Recurrent Cascade-Correlation (RCC) is a recurrent version of the CascadeCorrelation learning architecture of Fahlman and Lebiere [Fahlman, 1990]. RCC  can learn from examples to map a sequence of inputs into a desired sequence of  outputs. New hidden units with recurrent connections are added to the network  as needed during training. In effect, the network builds up a finite-state machine  tailored specifically for the current problem. RCC retains the advantages of  Cascade-Correlation: fast learning, good generalization, automatic construction  of a near-minimal multi-layered network, and incremental training.
We present a large vocabulary, continuous speech recognition system based  on Linked Predictive Neural Networks (LPNN's). The system uses neural networks as predictors of speech frames, yielding distortion measures  which are used by the One Stage DTW algorithm to perform continuous  speech recognition. The system, already deployed in a Speech to Speech  Translation system, currently achieves 95%, 58%, and 39% word accuracy  on tasks with perplexity 5, 111, and 402 respectively, outperforming several simple HMMs that we tested. We also found that the accuracy and  speed of the LPNN can be slightly improved by the judicious use of hidden  control inputs. We conclude by discussing the strengths and weaknesses  of the predictive approach.
A neural network architecture was designed for locating word boundaries and  identifying words from phoneme sequences. This architecture was tested in  three sets of studies. First, a highly redundant corpus with a restricted  vocabulary was generated and the network was trained with a limited number of  phonemic variations for the words in the corpus. Tests of network performance  on a transfer set yielded a very low error rate. In a second study, a network was  trained to identify words from expert transcriptions of speech. On a transfer  test, error rate for correct simultaneous identification of words and word  boundaries was 18%. The third study used the output of a phoneme classifier as  the input to the word and word boundary identification network. The error rate  on a transfer test set was 49% for this task. Overall, these studies provide a first  step at identifying words in connected discourse with a neural network.
Previous work has shown the ability of Multilayer Perceptrons  (MLPs) to estimate emission probabilities for Hidden Markov Models (HMMs). The advantages of a speech recognition system incorporating both MLPs and HMMs are the best discrimination and  the ability to incorporate multiple sources of evidence (features,  temporal context) without restrictive assumptions of distributions  or statistical independence. This paper presents results on the  speaker-dependent portion of DARPA's English language Resource  Management database. Results support the previously reported  utility of MLP probability estimation for continuous speech recognition. An additional approach we are pursuing is to use MLPs as  nonlinear predictors for autoregressive HMMs. While this is shown  to be more compatible with the HMM formalism, it still suffers  from several limitations. This approach is generalized to take account of time correlation between successive observations, without  any restrictive assumptions about the driving noise.
Through the use of neural network classifiers and careful feature selection,  we have achieved high-accuracy speaker-independent spoken letter recognition. For isolated letters, a broad-category segmentation is performed  Location of segment boundaries allows us to measure features at specific  locations in the signal such as vowel onset, where important information  resides. Letter classification is performed with a feed-forward neural network. Recognition accuracy on a test set of 30 speakers was 96%. Neural network classifiers are also used for pitch tracking and broad-category  segmentation of letter strings. Our research has been extended to recognition of names spelled with pauses between the letters. When searching  a database of 50,000 names, we achieved 95% first choice name retrieval.  Work has begun on a continuous letter classifier which does frame-by-frame  phonetic classification of spoken letters.
The Neural Prediction Model is the speech recognition model based on  pattern prediction by multilayer percepttons. Its effectiveness was confirmed by the speaker-independent digit recognition experiments. This  paper presents an improvement in the model and its application to large  vocabulary speech recognition, based on subword units. The improvement
Stephen J. Cox  British Telecom Research Labs.  Ipswich  UK IP5 7RE  A particular form of neural network is described, which has terminals  for acoustic patterns, class labels and speaker parameters. A method of  training this network to "tune in" the speaker parameters to a particular  speaker is outlined, based on a trick for converting a supervised network  to an unsupervised mode. We describe experiments using this approach  in isolated word recognition based on whole-word hidden Markov models.  The results indicate an improvement over speaker-independent performance and, for unlabelled data, a performance close to that achieved on  labelled data.
A novel unsupervised neural network for dimensionality reduction which  seeks directions emphasizing multimodality is presented, and its connection to exploratory projection pursuit methods is discussed. This leads to  a new statistical insight to the synaptic modification equations governing  learning in Bienenstock, Cooper, and Munro (BCM) neurons (1982).  The importance of a dimensionality reduction principle based solely on  distinguishing features, is demonstrated using a linguistically motivated  phoneme recognition experiment, and compared with feature extraction  using back-propagation network.
In this paper, we will describe several extensions to our earlier work, utilizing a segment-based approach. We will formulate our segmental framework  and report our study on the use of multi-layer perceptrons for detection  and classification of phoneroes. We will also examine the outputs of the  network, and compare the network performance with other classifiers. Our  investigation is performed within a set of experiments that attempts to  recognize 38 vowels and consonants in American English independent of  speaker. When evaluated on the TIMIT database, our system achieves an  accuracy of 56%.
Spoken language is one of the mot natural, efficient, flexible, and economical means of communication among humans. As computers play an ever  increasing role in our lives, it is important that we address the issue of  providing a graceful human-machine interface through spoken language.  In this paper, we will describe our recent efforts in moving beyond the  scope of speech recognition into the realm of spoken-language understanding. Specifically, we report on the development of an urban navigation and  exploration system called VOYAGER, an application which we have used as  a basis for performing research in spoken-language understanding.
This paper is a summary of SPRINT project aims and results. The project  focus on the use of neuro-computing techniques to tackle various problems that  remain unsolved in speech recognition. First results concern the use of feedforward nets for phonetic units classification, isolated word recognition, and  speaker adaptation.
We have been studying the performance of a bottlenosed dolphin on  a delayed matching-to-sample task to gain insight into the processes and  mechanisms that the animal uses during echolocation. The dolphin  recognizes targets by emitting natural sonar signals and listening to the  echoes that return. This paper describes a novel neural network  architecture, called an integrator gateway network, that we have developed to account for this performance. The integrator gateway  network combines information from multiple echoes to classify targets  with about 90% accuracy. In contrast, a standard backpropagation  network performed with only about 63% accuracy.
Signal processing capabilities of biological neurons are  investigated. Temporally coded signals in neurons can be  multiplexed to increase the transmission capacity.  Multiplexing of signal is suggested in bi-threshold neurons with  "high-threshold" and "low-threshold" for switching firing  modes. To extract the signal embedded in the interspikeintervals of firing, the encoded signal are demultiplexed and  multiplexed by a network of neurons with delayed-line  circuitry for signal processing. The temporally coded input  signal is transformed spatially by mapping the firing intervals  topographically to the output of the network, thus decoding  the specific firing interspike-intervals. The network also  provides a band-pass filtering capability where the  variability of the timing of the original signal can be decoded.
Although color TV is an established technology, there are a number of  longstanding problems for which neural networks may be suited. Impulse  noise is such a problem, and a modular neural network approach is presented in this paper. The training and analysis was done on conventional  computers, while real-time simulations were performed on a massively parallel computer called the Princeton Engine. The network approach was  compared to a conventional alternative, a median filter. Real-time simulations and quantitative analysis demonstrated the technical superiority of  the neural system. Ongoing work is investigating the complexity and cost  of implementing this system in hardware.  1  THE POTENTIAL FOR NEURAL NETWORKS IN  CONSUMER ELECTRONICS  Neural networks are most often considered for application in emerging new technologies, such as speech recognition, machine vision, and robotics. The fundamental  ideas behind these technologies are still being developed, and it will be some time  before products containing neural networks are manufactured. As a result, research  in these areas will not drive the development of inexpensive neural network hardware which could serve as a catalyst for the field of neural networks in general.  In contrast, neural networks are rarely considered for application in mature technologies, such as consumer electronics. These technologies are based on established  principles of information processing and communication, and they are used in millions of products per year. The embedding of neural networks within such mass289  290 Pearson, Spence, and Sverdlove  market products would certainly fuel the development of low-cost network hardware,  as economics dictates rigorous cost-reduction in every component.  2 IMPULSE NOISE IN TV  The color television signaling standard used in the U.S. was adopted in 1953 (McI1wain and Dean, 1956; Pearson, 1975). The video information is first broadcast as an  amplitude modulated (AM) radio-frequency (RF) signal, and is then demodulated  in the receiver into what is called the composite video signal. The composite signal  is comprised of the high-bandwidth (4.:2 MHz) luminance (black and white) signal  and two low-bandwidth color signals whose amplitudes are modulated in quadrature  on a 3.58 MHz subcarrier. This signal is then further decoded into the red, green  and blue signals that drive the display. One image "frame" is formed by interlacing  two successive "fields" of 262.5 horizontal lines.  Electric sparks create broad-band RF emissions which are transformed into oscillatory waveforms in the composite video signal, called AM impulses. See Figure 1.  These impulses appear on a television screen as short, horizontal, multi-colored  streaks which clearly stand out from the picture. Such sparks are commonly created by electric motors. There is little spatial (within a frame) or temporal (between  frames) correlation between impulses.  General considerations suggest a two step approach for the removal of impulses from  the video signal detect which samples have been corrupted, and replace them with  values derived from their spatio-temporal neighbors. Although impulses are quite  visible, they form a small fraction of the data, so only those samples detected as  corrupted should be altered. An interpolated average of some sort will generally be a  good estimate of impulse-corrupted samples because images are generally smoothly  varying in space and time.  There are a number of difficulties associated with this detection/replacement approach to the problem. There are many impulse-like waveforms present in normal  video, which can cause "false positives" or "false alarms". See Figure 2. The algorithms that decode the composite signal into RGB spread impulses onto neighboring  lines, so it is desirable to remove the impulses in the composite signal. However,  the color encoding within the composite signal complicates matters. The subcarrier  frequency is near the ringing frequency of the impulses and tends to hide the impulses. Furthermore, the replacement function cannot simply average the nearest  Figure 1: Seven Representative AM Impulse Waveforms. They have been digitized  and displayed at the intervals used in digital receivers (8 bits, .07 usec). The largest  amplitude impulses are 20-30 samples wide, approximately 3% of the width of one  line of active video (752 samples).  Applications of Neural Networks in Video Signal Processing 291  +128  -128  0 752  Figure 2: Corrupted Video Scan Line. (Top) Scan line of a composite video signal  containing six impulse waveforms. (Bottom) The impulse waveforms, derived by  subtracting the uncorrupted signal from the corrupted signal. Note the presence of  many impulse-like features in the video signal.  samples, because they represent different color components. The impulses also have  a wide variety of waveforms (Figure 1), including some variation caused by clipping  in the receiver.  3 MODULAR NEURAL NETWORK SYSTEM  The impulse removal system incorporates three small multi-layer perceptron networks (Rumelhart and McClelland, 1986), and all of the processing is confined to  one field of data. See Figure 3. The replacement function is performed by one  network, termed the i-net ("i" denotes interpolation). Its input is 5 consecutive  samples each from the two lines above and the two lines below the current line.  The network consists of 10 units in the first hidden layer, 5 in the second, and' one  output node trained to estimate the center sample of the current line.  The detection function employs 2 networks in series. (A single network detector  has been tried, but it has never performed as well as this two-stage detector.) The  inputs to the first network are 9 consecutive samples from the current line centered  on the sample of interest. It has 3 nodes in the first layer, and one output node  trained to compute a moving average of the absolute difference between the clean  and noisy signals of the current inputs. It is thus trained to function as a filter for  impulse energy, and is termed the e-net. The output of the e-net is then low-pass  filtered and sub-sampled to remove redundant information.  The inputs to the second network are 3 lines of 5 consecutive samples each, drawn  from the post-processed output of the e-net, centered on the sample of interest.  This network, like the e-net, has 3 nodes in the first layer and one output node. It  is trained to output 1 if the sample of interest is contaminated with impulse noise,  and 0 otherwise. It is thus an impulse detector, and is called the d-net.  The output of the d-net is then fed to a binary switch, which passes through to the  final system output either the output of the i-net or the original signal, depending  on whether the input exceeds an adjustable threshold.  292 Pearson, Spence, and Sverdlove  small  impulse  'pseudo,mpuise'  'edge'  big impulse  Origlnal Dlrty Picture  ve. potential.f.alse  s  potential false negative  potential true , m  positive  I 1 tap  Interpolated Original  4x5 taps IL switch  true positive ß false negative  mama
Using an unsupervised learning procedure, a network is trained on an ensemble of images of the same two-dimensional object at different positions,  orientations and sizes. Each half of the network "sees" one fragment of  the object, and tries to produce as output a set of 4 parameters that have  high mutual information with the 4 parameters output by the other half of  the network. Given the ensemble of training patterns, the 4 parameters on  which the two halves of the network can agree are the position, orientation,  and size of the whole object, or some recoding of them. After training,  the network can reject instances of other shapes by using the fact that the  predictions made by its two halves disagree. If two competing networks  are trained on an unlabelled mixture of images of two objects, they cluster  the training cases on the basis of the objects' shapes, independently of the  position, orientation, and size.
The model-based neural vision system presented here determines the position and identity of three-dimensional objects. Two stereo images of  a scene are described in terms of shape primitives (line segments derived  from edges in the scenes) and their relational structure. A recurrent neural  matching network solves the correspondence problem by assigning corresponding line segments in right and left stereo images. A 3-D relational  scene description is then generated and matched by a second neural network against models in a model base. The quality of the solutions and  the convergence speed were both improved by using mean field approximations.
A second-order architecture is presented here for translation, rotation and  scale invariant processing of 2-D images mapped to n input units. This  new architecture has a complexity of O(n) weights as opposed to the O(n 3)  weights usually required for a third-order, rotation invariant architecture.  The reduction in complexity is due to the use of discrete frequency information. Simulations show favorable comparisons to other neural network  architectures.
Previous work (M.I. Sereno, 1989; cf. M.E. Sereno, 1987) showed that a  feedforward network with area Vl-like input-layer units and a Hebb rule  can develop area MT-like second layer units that solve the aperture  problem for pattern motion. The present study extends this earlier work  to more complex motions. Saito et al. (1986) showed that neurons with  large receptive fields in macaque visual area MST are sensitive to  different senses of rotation and dilation, irrespective of the receptive field  location of the movement singularity. A network with an MT-like  second layer was trained and tested on combinations of rotating, dilating,  and translating patterns. Third-layer units learn to detect specific senses  of rotation or dilation in a position-independent fashion, despite having  position-dependent direction selectivity within their receptive fields.
This paper presents a neural network (NN) approach to the problem of  stereopsis. The correspondence problem (finding the correct matches  between the pixels of the epipolar lines of the stereo pair from amongst all  the possible matches) is posed as a non-iterative many-to-one mapping. A  two-layer feed forward NN architecture is developed to learn and code this  nonlinear and complex mapping using the back-propagation learning rule  and a training set. The important aspect of this technique is that none of  the typical constraints such as uniqueness and continuity are explicitly  imposed. All the applicable constraints are learned and internally coded  by the INN enabling it to be more flexible and more accurate than the  existing methods. The approach is successfully tested on several randomdot stereograms. It is shown that the net can generalize its learned mapping to cases outside its training set. Advantages over the Marr-Poggio  Algorithm are discussed and it is shown that the INN performance is superior.
Shimon Ullman  We describe in this paper a network that performs grouping of image contours. The input to the net are fragments of image contours, and the  output is the partitioning of the fragments into groups, together with a  saliency measure for each group. The grouping is based on a measure of  overall length and curvature. The network decomposes the overall optimization problem into independent optimal pairing problems performed  at each node. The resulting computation maps into a uniform locally  connected network of simple computing elements.
A neural network model of motion segmentation by visual cortex is described. The model clarifies how preprocessing of motion signals by a  Motion Oriented Contrast Filter (MOC Filter) is joined to long-range cooperative motion mechanisms in a motion Cooperative Competitive Loop  (CC Loop) to control phenomena such as as induced motion, motion capture, and motion aftereffects. The total model system is a motion Boundary Contour System (BCS) that is computed in parallel with a static BCS  before both systems cooperate to generate a boundary representation for  three dimensional visual form perception. The present investigations clarify how the static BCS can be modified for use in motion segmentation problems, notably for analyzing how ambiguous local movements (the aperture  problem) on a complex moving shape are suppressed and actively reorganized into a coherent global motion signal.  1
We demonstrate a multiscale adaptive network model of motion  computation in primate area MT. The model consists of two stages: (1)  local velocities are measured across multiple spatio-temporal channels,  and (2) the optical flow field is computed by a network of directionselective neurons at multiple spatial resolutions. This model embeds  the computational efficiency of Multigrid algorithms within a parallel  network as well as adaptively computes the most reliable estimate of  the flow field across different spatial scales. Our model neurons show  the same nonclassical receptive field properties as Allman's type I MT  neurons. Since local velocities are measured across multiple channels,  various channels often provide conflicting measurements to the  network. We have incorporated a veto scheme for conflict resolution.  This mechanism provides a novel explanation for the spatial frequency  dependency of the psychophysical phenomenon called Motion Capture.
Exact structure from motion is an ill-posed computation and therefore  very sensitive to noise. In this work I describe how a qualitative shape  representation, based on the sign of the Gaussian curvature, can be computed directly from motion disparities, without the computation of an  exact depth map or the directions of surface normals. I show that humans  can judge the curvature sense of three points undergoing 3D motion from  two, three and four views with success rate significantly above chance. A  simple RBF net has been trained to perform the same task.
We formulate the problem of optimizing the sampling of natural images  using an array of linear filters. Optimization of information capacity is  constrained by the noise levels of the individual channels and by a penalty  for the construction of long-range interconnections in the array. At low  signal-to-noise ratios the optimal filter characteristics correspond to bound  states of a SchrSdinger equation in which the signal spectrum plays the  role of the potential. The resulting optimal filters are remarkably similar  to those observed in the mammalian visual cortex and the retinal ganglion  cells of lower vertebrates. The observed scale invariance of natural images  plays an essential role in this construction.  363  364 Bialek, Ruderman, and Zee
A system for color correction has been designed, built, and tested successfully; the essential components are three custom chips built using subthreshold analog CMOS VLSI. The system, based on Land's Retinex theory of color constancy, produces colors similar in many respects to those  produced by the visual system. Resistive grids implemented in analog  VLSI perform the smoothing operation central to the algorithm at video  rates. With the electronic system, the strengths and weaknesses of the  algorithm are explored.
The dark-adapted visual system can count photons with a reliability limited by thermal noise in the rod photoreceptors -the processing circuitry  between the rod cells and the brain is essentially noiseless and in fact may  be close to optimal. Here we design an optimal signal processor which  estimates the time-varying light intensity at the retina based on the rod  signals. We show that the first stage of optimal signal processing involves  passing the rod cell output through a linear filter with characteristics determined entirely by the rod signal and noise spectra. This filter is very  general; in fact it is the first, stage in any visual signal processing task  at, low photon flux. We identifv the output of this first-stage filter with  the intracellular voltage response of the bipolar cell, the first anatomical  stage in retinal signal processing. From recent data on tiger salamander  photoreceptors we extract the relevant spectra and make parameter-free,  quantitative predictions of the bipolar cell response to a dim, diffuse flash.  Agreement with experiment is essentially perfect. As far as we know this  is the first successtiff predictive theory for neural dynamics.
In salamander retina, the response of On-Off ganglion cells to a central  flash is reduced by movement in the receptive field surround. Through  computer simulation of a 2-D model which takes into account their  anatomical and physiological properties, we show that interactions  between four neuron types (two bipolar and two amacrine) may be  responsible for the generation and lateral conductance of this change  sensitive inhibition. The model shows that the four neuron circuit can  account for previously observed movement sensitive reductions in  ganglion cell sensitivity and allows visualization and prediction of the  spatio-temporal pattern of activity in change sensitive retinal cells.
Light adaptation (LA) allows cone vision to remain functional between  twilight and the brightest time of day even though, at any one time, their  intensity-response (I-R) characteristic is limited to 3 log units of the stimulating light. One mechanism underlying LA, was localized in the outer segment of an isolated cone (1,2). We found that by adding annular illtmination,  an I-R characteristic of a cone can be shifted along the intensity domain.  Neural network involving feedback synapse from horizontal cells to cones is  involved to be in register with ambient light level of the periphery. An  equivalent electrical circuit with three different transmembrane channels  leakage, photocurrent and feedback was used to model static behavior of a  cone. SPICE simulation showed that interactions between feedback synapse  and the light sensitive conductance in the outer segment can shift the I-R  curves along the intensity domain, provided that phototransduction mechanism is not saturated during maximally hyperpolarizcd light response.
We have designed and tested a one-dimensional 64 pixel, analog CMOS  VLSI chip which localizes intensity edges in real-time. This device exploits  on-chip photoreceptors and the natural filtering properties of resistive networks to implement a scheme similar to and motivated by the Difference  of Gaussians (DOG) operator proposed by Marr and Hildreth (1980). Our  chip computes the zero-crossings associated with the difference of two exponential weighting functions. If the derivative across this zero-crossing  is above a threshold, an edge is reported. Simulations indicate that this  technique will extend well to two dimensions.
Inspired by a visual motion detection model for the rabbit retina  and by a computational architecture used for early audition in the  barn owl, we have designed a chip that employs a correlation model  to report the one-dimensional field motion of a scene in real time.  Using subthreshold analog VLSI techniques, we have fabricated and  successfully tested a 8000 transistor chip using a standard MOSIS  process.
We present a generic neural network architecture capable of controlling non-linear plants. The network is composed of dynamic,  parallel, linear maps gated by non-linear switches. Using a recurrent form of the back-propagation algorithm, control is achieved  by optimizing the control gains and task-adapted switch parameters. A mean quadratic cost function computed across a nominal  plant trajectory is minimized along with performance constraint  penalties. The approach is demonstrated for a control task consisting of landing a commercial aircraft in difficult wind conditions.  We show that the network yields excellent performance while remaining within acceptable damping response constraints.
We describe a real time robot navigation system based on three VLSI  neural network modules. These are a resistive grid for path planning, a  nearest-neighbour classifier for localization using range data from a timeof-flight infra-red sensor and a sensory-motor associative network for dynamic obstacle avoidance.
The ALVINN (Autonomous Land Vehicle In a Neural Network) project addresses  the problem of training artificial neural networks in real time to perform difficult  perception tasks. ALVINN,is a back-propagation network that uses inputs from a  video camera and an imaging laser rangefinder to drive the CMU Naylab, a modified  Chevy van. This paper describes training techniques which allow ALVINN to learn  in under 5 minutes to autonomously control the Naylab by watching a human driver's  response to new situations. Using these techniques, ALVINN has been trained  to drive in a variety of circumstances including single-lane paved and unpaved  roads, multilane lined and unlined roads, and obstacle-ridden onand off-road  environments, at speeds of up to 20 miles per hour.
We propose a new parallel-hierarchical neural network model to enable motor  learning for simultaneous control of both trajectory and force, by integrating  Hogan's control method and our previous neural network control model using a  feedback-error-learning scheme. Furthermore, two hierarchical control laws  which apply to the model, are derived by using the Moore-Penrose pseudoinverse matrix. One is related to the minimum muscle-tension-change trajectory  and the other is related to the minimum motor-command-change trajectory. The  human arm is redundant at the dynamics level since joint torque is generated by  ag0nist and antagonist muscles. Therefore, acquisition of the inverse model is  an ill-posed problem. However, the combination of these control laws and  feedback-error-learning resolve the ill-posed problem. Finally, the efficiency of  the parallel-hierarchical neural network model is shown by learning experiments  using an artificial muscle arm and computer simulations.
We have used a neural network to compute corrections for images written  by electron beams to eliminate the proximity effects caused by electron  scattering. Iterative methods are effective, but require prohibitively  computation time. We have instead trained a neural network to perform  equivalent corrections, resulting in a significant speed-up. We have  examined hardware implementations using both analog and digital  electronic networks. Both had an acceptably small error of 0.5% compared  to the iterative results. Additionally, we verified that the neural network  correctly generalized the solution of the problem to include patterns not  contained in its training set. We have experimentally verified this approach  on a Cambridge Instruments EBMF 10.5 exposure system.
We present a new connectionist planning method [TML90]. By interaction  with an unknown environment, a world model is progressively constructed using gradient descent. For deriving optimal actions with respect to  future reinforcement, planning is applied in two steps: an experience network proposes a plan which is subsequently optimized by gradient descent  with a chain of world models, so that an optimal reinforcement may be  obtained when it is actually run. The appropriateness of this method is  demonstrated by a robotics application and a pole balancing task.
A novel learning control architecture is used for navigation. A sophisticated test-bed is used to simulate a cylindrical robot with a sonar belt  in a planar environment. The task is short-range homin 8 in the presence of obstacles. The robot receives no global information and assumes  no comprehensive world model. Instead the robot receives only sensory  information which is inherently limited. A connectionist architecture is  presented which incorporates a large amount of a priori knowledge in the  form of hard-wired networks, architectural constraints, and initial weights.  Instead of hard-wiring static potential fields from object models, my architecture learns sensor-based potential fields, automatically adjustin 8 them  to avoid local minima and to produce efficient homing trajectories. It does  this without object models using only sensory information. This research  demonstrates the use of a large modular architecture on a difficult task.
Barto, Sutton and Watkins [2] introduced a grid task as a didactic example of temporal difference planning and asynchronous dynamical programming. This paper considers the effects of changing the coding of the  input stimulus, and demonstrates that the self-supervised learning of a  particular form of hidden unit representation improves performance.
This is a summary of results with Dyna, a class of architectures for intelligent systems based on approximating dynamic programming methods.  Dyna architectures integrate trial-and-error (reinforcement) learning and  execution-time planning into a single process operating alternately on the  world and on a learned forward model of the world. We describe and  show results for two Dyna architectures, Dyna-AHC and Dyna-Q. Using a  navigation task, results are shown for a simple Dyna-AHC system which  simultaneously learns by trial and error, learns a world model, and plans  optimal routes using the evolving world model. We show that Dyna-Q  architectures (based on Watkins's Q-learning) are easy to adapt for use in  changing environments.
We present an algorithm based on reinforcement and state recurrence  learning techniques to solve control scheduling problems. In particular, we  have devised a simple learning scheme called "handicapped learning", in  which the weights of the associative search element are reinforced, either  positively or negatively, such that the system is forced to move towards the  desired setpoint in the shortest possible trajectory. To improve the learning  rate, a variable reinforcement scheme is employed: negative reinforcement  values are varied depending on whether the failure occurs in handicapped or  normal mode of operation. Furthermore, to realize a simulated annealing  scheme for accelerated learning, if the system visits the same failed state  successively, the negative reinforcement value is increased. In examples  studied, these learning schemes have demonstrated high learning rates, and  therefore may prove useful for in-situ learning.
This paper examines a class of neuron based  learning systems for dynamic control that rely on  adaptive range coding of sensor inputs. Sensors are  assumed to provide binary coded range vectors that  coarsely describe the system state. These vectors are  input to neuron-like processing elements. Output  decisions generated by these "neurons" in turn  affect the system state, subsequently producing new  inputs. Reinforcement signals from the  environment are received at various intervals and  evaluated. The neural weights as well as the range  boundaries determining the output decisions are  then altered with the goal of maximizing future  reinforcement from the environment. Preliminary  experiments show the promise of adapting "neural  receptive fields" when learning dynamical control.  The observed performance with this method exceeds  that of earlier approaches.  486  Adaptive Range Coding 487
A feedforward layered network implements a mapping required to control an  unknown stochastic nonlinear dynamical system. Training is based on a  novel approach that combines stochastic approximation ideas with backpropagation. The method is applied to control admission into a queueing system operating in a time-varying environment.
This work addresses three problems with reinforcement learning and adaptive neuro-control: 1. Non-Markovian interfaces between learner and environment. 2. On-line learning based on system realization. 3. Vectorvalued adaptive critics. An algorithm is described which is based on system  realization and on two interacting fully recurrent continually running networks which may learn in parallel. Problems with parallel learning are  attacked by 'adaptive randomness'. It is also described how interacting  model/controller systems can be combined with vector-valued 'adaptive  critics' (previous critics have been scalar).
In response to a puff of wind, the American cockroach turns away and runs.  The circuit underlying the initial turn of this escape response consists of  three populations of individually identifiable nerve cells and appears to employ distributed representations in its operation. We have reconstructed  several neuronal and behavioral properties of this system using simplified  neural network models and the backpropagation learning algorithm constrained by known structural characteristics of the circuitry. In order to  test and refine the model, we have also compared the model's responses to  various lesions with the insect's responses to similar lesions.
Neural network simulations of the dragonfly flight neurocontrol system  have been developed to understand how this insect uses complex,  unsteady aerodynamics. The simulation networks account for the  ganglionic spatial distribution of cells as well as the physiologic  operating range and the stochastic cellular firing history of each neuron.  In addition the motor neuron firing patterns, "flight command  sequences", were utilized. Simulation training was targeted against both  the cellular and flight motor neuron firing patterns. The trained  networks accurately resynthesized the intraganglionic cellular firing  patterns. These in turn controlled the motor neuron firing patterns that  drive wing musculature during flight. Such networks provide both  neurobiological analysis tools and first generation controls for the use  of "unsteady" aerodynamics.
Three-dimensional (3D) structures of protein backbones have been predicted using neural networks. A feed forward neural network was trained  on a class of functionally, but not structurally, homologous proteins, using backpropagation learning. The network generated tertiary structure  information in the form of binary distance constraints for the C, atoms  in the protein backbone. The binary distance between two C, atoms was  0 if the distance between them was less than a certain threshold distance,  and 1 otherwise. The distance constraints predicted by the trained neural network were utilized to generate a folded conformation of the protein  backbone, using a steepest descent minimization approach.
Jude W. Shavlik  Computer Sciences  University of Wisconsin  Madison, WI 53706  We describe the application of a hybrid symbolic/connectionist machine  learning algorithm to the task of recognizing important genetic sequences.  The symbolic portion of the KBANN system utilizes inference rules that  provide a roughly-correct method for recognizing a class of DNA sequences  known as eukar!]otic splice-junctions. We then map this "domain theory"  into a neural network and provide training examples. Using the samples,  the neural network's learning algorithm adjusts the domain theory so that  it properly classifies these DNA sequences. Our procedure constitutes  a general method for incorporating preexisting knowledge into artificial  neural networks. We present an experiment in molecular genetics that  demonstrates the value of doing so.
Diagnosis of faults in complex, real-time control systems is a  complicated task that has resisted solution by traditional methods. We  have shox that neural networks can be successfully employed to  diagnose faults in digitally controlled powertrain systems. This paper  discusses the means we use to develop the appropriate databases for  training and testing in order to select the optimum network architectures  and to provide reasonable estimates of the classification accuracy of  these networks on new samples of dam. Recent work applying neural  nets to adaptive control of an active suspension system is presented.
This study has demonstrated how artificial neural networks (ANNs) can  be used to characterize seismic sources using high-frequency regional  seismic data. We have taken the novel approach of using AN-Ns as a  research tool for obtaining seismic source information, specifically  depth of focus for earthquakes and ripple-fire characteristics for  economic blasts, rather than as just a feature classifier between  earthquake and explosion populations. Overall, we have found that  ANNs have potential applications to seismic event characterization and  identification, beyond just as a feature classifier. In future studies, these  techniques should be applied to actual data of regional seismic events  recorded at the new regional seismic arrays. The results of this study  indicates that an ANN should be evaluated as part of an operational  seismic event identification system.
An Artificial Neural Network (ANN) is trained to  recognize a buy/sell (long/short} pattern for a  particular commodity future contract. The BackPropagation of errors algorithm was used to encode  the relationship between the Long/Short desired  output and 18 fundamental variables plus 6 (or 18)  technical variables into the  year of past data the ANN  long/short market positions for  future that would have made  investment of less than $1000.  ANN. Trained on one  is able to predict  9 months in the  $10,301 profit on an  1
Wee-Kheng Leow  MCC and  University of Texas  Austin, TX 78759  Neural network algorithms have proven useful for recognition of individual, segmented characters. However, their recognition accuracy has been  limited by the accuracy of the underlying segmentation algorithm. Conventional, rule-based segmentation algorithms encounter difficulty if the  characters are touching, broken, or noisy. The problem in these situations  is that often one cannot properly segment a character until it is recognized yet one cannot properly recognize a character until it is segmented.  We present here a neural network algorithm that simultaneously segments  and recognizes in an integrated system. This algorithm has several novel  features: it uses a supervised learning algorithm (backpropagation), but is  able to take position-independent information as targets and self-organize  the activities of the units in a competitive fashion to infer the positional  information. We demonstrate this ability with overlapping hand-printed  numerals.
The dimensionality of a set of 160 face images of i0 male and 10  female subjects is reduced from 4096 to 40 via an autoencoder  network. The extracted features do not correspond to the features used  in previous face recognition systems (Kanade, 1973), such as ratios of  distances between facial elements. Rather, they are whole-face  features we call holons. The holons are given to 1 and 2 layer back  propagation networks that are trained to classify the input features for  identity, feigned emotional state and gender. The automatically  extracted holons provide a sufficient basis for all of the gender  discriminations, 99% of the identity discriminations and several of the  emotion discriminations among the training set. Network and human  judgements of the emotions are compared, and it is found that the  networks tend to confuse more distant emotions than humans do.
Sex identification in animals has biological importance. Humans are good  at making this determination visually, but machines have not matched  this ability. A neural network was trained to discriminate sex in human  faces, and performed as well as humans on a set of 90 exemplars. Images  sampled at 30x30 were compressed using a 900x40x900 fully-connected  back-propagation network; activities of hidden units served as input to a  back-propagation "SexNet" trained to produce values of i for male and  0 for female faces. The network's average error rate of 8.1% compared  favorably to humans, who averaged 11.6%. Some SexNet errors mimicked  those of humans.
This paper proposes a fuzzy neural expert system (FNES) with the  following two functions: (1) Generalization of the information derived  from the training data and embodiment of knowledge in the form of the  fuzzy neural network; (2) Extraction of fuzzy '-?hen rules with  linguistic relative importance of each proposition in an antecedent  ('-part) from a trained neural network. This paper also gives a  method to extract automatically fuzzy If-Then rules from the trained  neural network. To prove the effectiveness and validity of the proposed  fuzzy neural expert system, a fuzzy neural expert system for medical  diagnosis has been developed.
Analog neural networks with feedback can be used to implement KWinner-Take-All (KWTA) networks. In turn, KWTA networks can be  used as decoders of a class of nonlinear error-correcting codes. By interconnecting such KWTA networks, xve can construct decoders capable  of decoding more powerful codes. We consider several families of interconnected KWTA networks, analyze their performance in terms of coding  theory metrics, and consider the feasibility of embedding such networks in  VLSI technologies.  1
Harmonic grammar (Legendre, et al., 1990) is a connectionist theory of linguistic well-formedness based on the assumption that the well-formedness  of a sentence can be measured by the harmony (negative energy) of the  corresponding connectionist state. Assuming a lower-level connectionist  network that obeys a few general connectionist principles but is otherwise  unspecified, we construct a higher-level network with an equivalent harmony function that captures the most linguistically relevant global aspects  of the lower level network. In this paper, we extend the tensor product  representation (Smolensky 1990) to fully recursire representations of recursively structured objects like sentences in the lower-level network. We  show theoretically and with an example the power of the new technique  for parallel distributed structure processing.
A network was trained by back propagation to map locative expressions  of the form "noun-preposition-noun" to a semantic representation, as in  Cosic and Munro (1988). The network's performance was analyzed  over several simulations with training sets in both English and  German. Translation of prepositions was attempted by presenting a  locative expression to a network trained in one language to generate a  semantic representation; the semantic representation was then presented  to the network trained in the other language to generate the appropriate  preposition.
Despite its successes, Rumelhart and McClelland's (1986) well-known approach to the learning of morphophonemic rules suffers from two deficiencies: (1) It performs the artificial task of associating forms with forms  rather than perception or production. (2) It is not constrained in ways  that humans learners are. This paper describes a model which addresses  both objections. Using a simple recurrent architecture which takes both  forms and "meanings" as inputs, the model learns to generate verbs in  one or another "tense", given arbitrary meanings, and to recognize the  tenses of verbs. Furthermore, it fails to learn reversal processes unknown  in human language.
In a previous paper (Touretzky & Wheeler, 1990a) we showed how adding a  clustering operation to a connectionist phonology model produced a parallel processing account of certain "itemfive" phenomena. In this paper we show how the  addition of a second structuring primitive, syllabification, greatly increases the  power of the model. We present examples from a non-Indo-European language  that appear to require rule ordering to at least a depth of four. By adding syllabification circuitry to structure the model's perception of the input string, we are  able to handle these examples with only two derivational steps. We conclude that  in phonology, derivation can be largely replaced by structuring.
A higher order recurrent neural network architecture learns to recognize and  generate languages after being "trained" on categorized exemplars. Studying  these networks from the perspective of dynamical systems yields two  interesting discoveries: First, a longitudinal examination of the learning  process illustrates a new form of mechanical inference: Induction by phase  transition. A small weight adjustment causes a "bifurcation" in the limit  behavior of the network. This phase transition corresponds to the onset of the  network's capacity for generalizing to arbitrary-length strings. Second, a  study of the automata resulting from the acquisition of previously published  languages indicates that while the architecture is NOT guaranteed to find a  minimal finite automata consistent with the given exemplars, which is an  NP-Hard problem, the architecture does appear capable of generating nonregular languages by exploiting fractal and chaotic dynamics. I end the paper  with a hypothesis relating linguistic generafive capacity to the behavioral  regimes of non-linear dynamical systems.
Competitive learning is an unsupervised algorithm that classifies input patterns into mutually exclusive clusters. In a neural net framework, each cluster is represented by a processing unit that competes with others in a winnertake-all pool for an input pattern. I present a simple extension to the algorithm that allows it to construct discrete, distributed representations. Discrete  representations are useful because they are relatively easy to analyze and  their information content can readily be measured. Distributed representations are useful because they explicitly encode similarity. The basic idea is  to apply competitive learning iteratively to an input pattern, and after each  stage to subtract from the input pattern the component that was captured in  the representation at that stage. This component is simply the weight vector  of the winning unit of the competitive pool. The subtraction procedure forces  competitive pools at different stages to encode different aspects of the input.  The algorithm is essentially the same as a traditional data compression technique known as multistep vector quantization, although the neural net perspective suggests potentially powerful extensions to that approach.
For lack of alternative models, search and decision processes have provided the  dominant paradigm for human memory access using two or more cues, despite  evidence against search as an access process (Humphreys, Wiles & Bain, 1990).  We present an alternative process to search, based on calculating the intersection  of sets of targets activated by two or more cues. Two methods of computing  the intersection are presented, one using information about the possible targets,  the other constraining the cue-target strengths in the memory matrix. Analysis  using orthogonal vectors to represent the cues and targets demonstrates the  competence of both processes, and simulations using sparse distributed  representations demonstrate the performance of the latter process for tasks  involving 2 and 3 cues.
This work presents an Attractor Neural Network (ANN) model of Recall and Recognition. It is shown that an ANN model can qualitatively  account for a wide range of experimental psychological data pertaining  to the these two main aspects of memory access. Certain psychological  phenomena are accounted for, including the effects of list-length, wordfrequency, presentation time, context shift, and aging. Thereafter, the  probabilities of successful Recall and Recognition are estimated, in order  to possibly enable further quantitative examination of the model.
ALCOVE is a connectionist model of human category learning that fits a  broad spectrum of human learning data. Its architecture is based on wellestablished psychological theory, and is related to networks using radial  basis functions. From the perspective of cognitive psychology, ALCOVE can  be construed as a combination of exemplar-based representation and errordriven learning. From the perspective of connectionism, it can be seen as  incorporating constraints into back-propagation networks appropriate for  modelling human learning.
Spherical Units can be used to construct dynamic reconfigurable  consequential regions, the geometric bases for Shepard's (1987) theory of  stimulus generalization in animals and humans. We derive from Shepard's  (1987) generalization theory a particular multi-layer network with dynamic  (centers and radii) spherical regions which possesses a specific mass function  (Cauchy). This learning model generalizes the configural-cue network model  (Gluck & Bower 1988): (1) configural cues can be learned and do not require  pre-wiring the power-set of cues, (2) Consequential regions are continuous  rather than discrete and (3) Competition amoungst receptive fields is shown  to be increased by the global extent of a particular mass function (Cauchy).  We compare other common mass functions (Gaussian; used in models of  Moody & Darken; 1989, Krushke, 1990) or just standard backpropogation  networks with hyperplane/logistic hidden units showing that neither fare as  well as models of human generalization and learning.
Empirically, generalization between a training and a test stimulus falls off in  close approximation to an exponential decay function of distance between the  two stimuli in the "stimulus space" obtained by multidimensional scaling. Mathematically, this result is derivable from the assumption that an individual takes  the training stimulus to belong to a "consequential" region that includes that  stimulus but is otherwise of unknown location, size, and shape in the stimulus  space (Shepard, 1987). As the individual gains additional information about the  consequential region--by finding other stimuli to be consequential or not the  theory predicts the shape of the generalization function to change toward the  function relating actual probability of the consequence to location in the stimulus  space. This paper describes a natural connectionist implementation of the theory,  and illustrates how implications of the theory for generalization, discrimination,  and classification learning can be explored by connectionist simulation.
A network based on splines is described. It automatically adapts the number of units, unit parameters, and the architecture of the network for each  application.
Multi-layer percepttons are often slow to learn nonlinear functions  with complex local structure due to the global nature of their function  approximations. It is shown that standard multi-layer percepttons are  actually a special case of a more general network formulation that  incorporates B-splines into the node computations. This allows novel  spline network architectures to be developed that can combine the  generalization capabilities and scaling properties of global multi-layer  feedforward networks with the computational efficiency and learning  speed of local computational paradigms. Simulation results are  presented for the well known spiral problem of Weiland and of Lang  and Witbrock to show the effectiveness of the Spline Net approach.
A new class of data structures called "bumptrees" is described. These  structures are useful for efficiently implementing a number of neural  network related operations. An empirical comparison with radial basis  functions is presented on a robot arm mapping learning task. Applications to density estimation, classification, and constraint representation  and learning are also outlined.
Local variable selection has proven to be a powerful technique for approximating functions in high-dimensional spaces. It is used in several  statistical methods, including CART, ID3, C4, MARS, and others (see the  bibliography for references to these algorithms). In this paper I present  a tree-structured network which is a generalization of these techniques.  The network provides a framework for understanding the behavior of such  algorithms and for modifying them to suit particular applications.
We examine the ability of radial basis functions (RBFs) to generalize. We  compare the performance of several types of RBFs. We use the inverse dynamics of an idealized two-joint arm as a test case. We find that without  a proper choice of a norm for the inputs, RBFs have poor generalization  properties. A simple global scaling of the input variables greatly improves  performance. We suggest some efficient methods to approximate this distance metric.
We have created a radial basis function network that allocates a  new computational unit whenever an unusual pattern is presented  to the network. The network learns by allocating new units and  adjusting the parameters of existing units. If the network performs  poorly on a presented pattern, then a new unit is allocated which  memorizes the response to the presented pattern. If the network  performs well on a presented pattern, then the network parameters  are updated using standard LMS gradient descent. For predicting  the Mackey Glass chaotic time series, our network learns much  faster than do those using back-propagation and uses a comparable  number of synapses.
We develop a sequential adaptation algorithm for radial basis function  (RBF) neural networks of Gaussian nodes, based on the method of succesrove '-Projections. This method makes use of each observation efficiently  in that the network mapping function so obtained is consistent with that  information and is also optimal in the least La-norm sense. The RBF  network with the '-Projections adaptation algorithm was used for predicting a chaotic time-series. We compare its performance to an adaptation scheme based on the method of stochastic approximation, and show  that the '-Projections algorithm converges to the underlying model much  faster.
We introduce oriented non-radial basis function networks (ONRBF)  as a generalization of Radial Basis Function networks (RBF)wherein  the Euclidean distance metric in the exponent of the Gaussian is replaced by a more general polynomial. This permits the definition of  more general regions and in particularhyper-ellipses with orientations. In the case of hyper-surface estimation this scheme requires a  smaller number of hidden units and alleviates the "curse of dimensionality" associated kernel type approximators.In the case of an image, the hidden units correspond to features in the image and the  parameters associated with each unit correspond to the rotation, scaling and translation properties of that particular "feature". In the context of the ONBF scheme, this means that an image can be  represented by a small number of features. Since, transformation of an  image by rotation, scaling and translation correspond to identical  transformations of the individual features, the ONBF scheme can be  used to considerable advantage for the purposes of image recognition  and analysis.
We consider feed-forward neural networks with one non-linear hidden layer  and linear output units. The transfer function in the hidden layer are either bell-shaped or sigmoid. In the bell-shaped case, we show how Bernstein polynomials on one hand and the theory of the heat equation on the  other are relevant for understanding the properties of the corresponding  networks. In particular, these techniques yield simple proofs of universal  approxhnation properties, i.e. of the fact that any reasonable function can  be approximated to any degree of precision by a linear combination of bellshaped functions. In addition, in this framework the problem of learning  is equivalent to the problem of reversing the time course of a diffusion process. The results obtained in the bell-shaped case can then be applied to  the case of sigmoid transfer functions in the hidden layer, yielding similar  universality results. A conjecture related to the problem of generalization  is briefly examined.
In this paper we show that discrete affine wavelet transforms can provide  a tool for the analysis and synthesis of standard feedforward neural networks. It is shown that wavelet frames for L2(I) can be constructed based  upon sigmoids. The spatio-spectral localization property of wavelets can  be exploited in defining the topology and determining the weights of a  feedforward network. Training a network constructed using the synthesis procedure described here involves minimization of a convex cost functional and therefore avoids pitfalls inherent in standard backpropagation  algorithms. Extension of these methods to L2(I N) is also discussed.
Bruno Caprile  I.R.S.T.  Povo, Italy, 38050  Learning an input-output mapping fi'om a set of examples can be regarded  as synthesizing an approxilnation of a lnulti-dilnensional fimction. Front  this point of view, this form of learning is closely related to regula. rization  theory, and we have previously shown (Poggio and Girosi, 1990a, 1990b)  the equivalence between regularization and a. class of three-layer networks  that we call regularization networks. In this note, we extend the theory  by introducing ways of dealing with two aspects of learning: learning in  presence of unreliable examples or outliers, and learning fi'om positive and  negative examples.
Stephen M. Omohundro  ICSI  1947 Center St., Suite 600  Berkeley, CA 94704  We identify the three principle factors affecting the performance of learning by networks with localized units: unit noise, sample density, and the  structure of the target function. We then analyze the effect of unit receptive field parameters on these factors and use this analysis to propose a  new learning algorithm which dynamically alters receptive field properties  during learning.
We describe a multi-network, or modular, connectionist architecture that  captures that fact that many tasks have structure at a level of granularity  intermediate to that assumed by local and global function approximation  schemes. The main innovation of the architecture is that it combines  associative and competitive learning in order to learn task decompositions.  A task decomposition is discovered by forcing the networks comprising the  architecture to compete to learn the training patterns. As a result of the  competition, different networks learn different training patterns and, thus,  learn to partition the input space. The performance of the architecture on  a "what" and "where" vision task and on a multi-payload robotics task  are presented.
We compare the performance of the modular architecture, composed of  competing expert networks, suggested by Jacobs, Jordan, Nowlan and  Hinton (1991) to the performance of a single back-propagation network  on a complex, but low-dimensional, vowel recognition task. Simulations  reveal that this system is capable of uncovering interesting decompositions  in a complex task. The type of decomposition is strongly influenced by  the nature of the input to the gating network that decides which expert  to use for each case. The modular architecture also exhibits consistently  better generalization on many variations of the task.
We introduce a framework for training architectures composed of several  modules. This framework, which uses a statistical formulation of learning  systems, provides a unique formalism for describing many classical  connectionist algorithms as well as complex systems where several  algorithms interact. It allows to design hybrid systems which combine the  advantages of connectionist algorithms as well as other learning algorithms.
We describe a recurrent connectionist network, called CONCERT, that uses a  set of melodies written in a given style to compose new melodies in that  style. CONCERT is an extension of a traditional algorithmic composition technique in which transition tables specify the probability of the next note as a  function of previous context. A central ingredient of CONCERT is the use of a  psychologically-grounded representation of pitch.
Genetic algorithms were used to select and create features and to select  reference exemplar patterns for machine vision and speech pattern classification tasks. For a complex speech recognition task, genetic algorithms  required no more computation time than traditional approaches to feature  selection but reduced the number of input features required by a factor of  five (from 153 to 33 features). On a difficult artificial machine-vision task,  genetic algorithms were able to create new features (polynomial functions  of the original features) which reduced classification error rates from 19%  to almost 0%. Neural net and k nearest neighbor (KNN) classifiers were  unable to provide such low error rates using only the original features. Genetic algorithms were also used to reduce the number of reference exemplar  patterns for a KNN classifier. On a 338 training pattern vowel-recognition  problem with 10 classes, genetic algorithms reduced the number of stored  exemplars from 338 to 43 without significantly increasing classification error rate. In all applications, genetic algorithms were easy to apply and  found good solutions in many fewer trials than would be required by exhaustive search. Run times were long, but not unreasonable. These results  suggest that genetic algorithms are becoming practical for pattern classification problems as faster serial and parallel computers are developed.
Learning can increase the rate of evolution of a population of  biological organisms (the Baldwin effect). Our simulations  show that in a population of artificial neural networks  solving a pattern recognition problem, no learning or too  much learning leads to slow evolution of the genes whereas  an intermediate amount is optimal. Moreover, for a given  total number of training presentations, fastest evoution  occurs if different individuals within each generation receive  different numbers of presentations, rather than equal  numbers. Because genetic algorithms (GAs) help avoid  local minima in energy functions, our hybrid learning-GA  systems can be applied successfully to complex, highdimensional pattern recognition problems.
The three problems that concern us are identifying a natural domain of  pattern classification applications of feedforward neural networks, selecting an appropriate feedforward network architecture, and assessing the  tradeoff between network complexity, training set size, and statistical reliability as measured by the probability of incorrect classification. We close  with some suggestions, for improving the bounds that come from VapnikChervonenkis theory, that can narrow, but not close, the chasm between  theory and practice.
Given some training data how should we choose a particular network classifier from a family of networks of different complexities? In this paper  we discuss how the application of stochastic complexity theory to classifier  design problems can provide some insights into this problem. In particular  we introduce the notion of admissible models whereby the complexity of  models under consideration is affected by (among other factors) the class  entropy, the amount of training data, and our prior belief. In particular  we discuss the implications of these results with respect to neural architectures and demonstrate the approach on real data from a medical diagnosis  task.
We introduce a method for the efficient design of a Boltzmann machine (or  a Hopfield net) that computes an arbitrary given Boolean function f. This  method is based on an efficient simulation of acyclic circuits with threshold  gates by Boltzmann machines. As a consequence we can show that various  concrete Boolean functions f that are relevant for classification problems  can be computed by scalable Boltzmann machines that are guaranteed  to converge to their global maximum configuration with high probability  after constantly many steps.
We present and compare learning rate schedules for stochastic gradient  descent, a general algorithm which includes LMS, on-line backpropagation and k-means clustering as special cases. We introduce "search-thenconverge" type schedules which outperform the classical constant and  "running average" (l/t) schedules both in speed of convergence and quality  of solution.
In this paper, we prove that the vectors in the LVQ learning algorithm  converge. We do this by showing that the learning algorithm performs  stochastic approximation. Convergence is then obtained by identifying  the appropriate conditions on the learning rate and on the underlying  statistics of the classification problem. We also present a modification to  the learning algorithm which we argue results in convergence of the LVQ  error to the Bayesian optimal error as the appropriate parameters become  large.
David E. Van den Bout  North Carolina State University  Box 7914  Raleigh, NC 27695-7914  We apply the theory of Tishby, Levin, and Solla (TLS) to two problems.  First we analyze an elementary problem for which we find the predictions  consistent with conventional statistical results. Second we numerically  examine the more realistic problem of training a competitive net to learn  a probability density from samples. We find TLS useful for predicting  average training behavior.
The outputs of a typical multi-output classification network do not  satisfy the axioms of probability; probabilities should be positive and sum  to one. This problem can be solved by treating the trained network as a  preprocessor that produces a feature vector that can be further processed,  for instance by classical statistical estimation techniques. (2) We present a  method for computing the first two moments of the probability distribution  indicating the range of outputs that are consistent with the input and the  training data. It is particularly useful to combine these two ideas: we  implement the ideas of section i using Parzen windows, where the shape  and relative size of each window is computed using the ideas of section 2.  This allows us to make contact between important theoretical ideas (e.g.  the ensemble formalism) and practical techniques (e.g. back-prop). Our  results also shed new light on and generalize the well-known "softmax"  scheme.
This paper explores the effect of initial weight selection on feed-forward  networks leaming simple functions with the back-propagation  technique. We first demonstrate, through the use of Monte Carlo  techniques, that the magnitude of the initial condition vector (in weight  space) is a very significant parameter in convergence time variability. In  order to further understand this result, additional deterministic  experiments were performed. The results of these experiments  demonstrate the extreme sensitivity of back propagation to initial weight  configuration.
We describe a closed-form technique for mapping the output of a trained  backpropagation network into input activity space. The mapping is an inverse mapping in the sense that, when the image of the mapping in input  activity space is propagated forward through the normal network dynamics, it reproduces the output used to generate that image. When more  than one such inverse mappings exist, our inverse mapping is special in  that it has no projection onto the nullspace of the activation flow operator for the entire network. An important by-product of our calculation,  when more than one inverse lnappings exist, is an orthogonal basis set of  a significant portion of the activation flow operator nullspace. This basis  set can be used to obtain an alternate inverse mapping that is optimized  for a particular real-world application.
Inspired by the information theoretic idea of minimum description length, we add  a term to the back propagation cost function that penalizes network complexity.  We give the details of the procedure, called weight-elimination, describe its  dynamics, and clarify the meaning of the parameters involved. From a Bayesian  perspective, the complexity term can be usefully interpreted as an assumption  about prior distribution of the weights. We use this procedure to predict the  sunspot time series and the notoriously noisy series of currency exchange rates.
Robustness is a commonly bruited property of neural networks; in particular, a folk theorem in neural computation asserts that neural networks--in  contexts with large interconnectivity--continue to function efficiently, albeit with some degradation, in the presence of component damage or loss.  A second folk theorem in such contexts asserts that dense interconnectivity between neural elements is a sine qua non for the efficient usage of  resources. These premises are formally examined in this communication  in a setting that invokes the notion of the "devil" 1 in the network as an  agent that produces sparsity by snipping connections.
For a simple linear case, a mathematical analysis of the training and generalization (validation) performance of networks trained by gradient descent  on a Least Mean Square cost function is provided as a function of the learning parameters and of the statistics of the training data base. The analysis  predicts that generalization error dynamics are very dependent on a priori initial weights. In particular, the generalization error might sometimes  weave within a computable range during extended training. In some cases,  the analysis provides bounds on the optimal number of training cycles for  minimal validation error. For a speech labeling task, predicted weaving  effects were qualitatively tested and observed by computer simulations in  networks trained by the linear and non-linear back-propagation algorithm.
We study the evolution of the generalization ability of a simple linear perceptron with N inputs which learns to imitate a "teacher perceptron". The  system is trained on p = aN binary example inputs and the generalization ability measured by testing for agreement with the teacher on all 2 N  possible binary input patterns. The dynamics may be solved analytically  and exhibits a phase transition from imperfect to perfect generalization  at a = 1. Except at this point the generalization ability approaches its  asymptotic value exponentially, with critical slowing down near the transition; the relaxation time is o< (1x/) -2. Right at the critical point,  1  the approach to perfect generalization follows a power law o< t-5. In  the presence of noise, the generalization ability is degraded by an amount  o< (x/rX)- just above a = 1.
While the network loading problem for 2-layer threshold nets is  NP-hard when learning from examples alone (as with backpropagation), (Baum, 91) has now proved that a learner can employ queries  to evade the hidden unit credit assignment problem and PAC-load  nets with up to four hidden units in polynomial time. Empirical  tests show that the method can also learn far more complicated  functions such as randomly generated networks with 200 hidden  units. The algorithm easily approximates Wieland's 2-spirals function using a single layer of 50 hidden units, and requires only 30  minutes of CPU time to learn 200-bit parity to 99.7% accuracy.
We tiescribe a series of careful nulnerical experiments which measure tile  average geueraliza.tion capability of neural networks trained on a variety of  simple functions. These experiments are designed to test whether average  generalization performance can surpass the worst-case bounds obtained  from formal learning theory using the Vapnik-Chervonenkis dilnension  (Blumer et al., 1989). We indeed find that, in some cases, the average  generalization is significantly better than the VC bound: the approach to  perfect performance is exponential in the number of examples m, rather  than the 1/m result of the bound. In other cases, we do find the  behavior of the VC bound, and in these cases, the numerical prefactor is  closely related to prefactor contained in the bound.
Sara A. Solla  AT&T Bell Laboratories  Crawfords Corner Rd.  Holmdel, NJ 07733, USA  The learning time of a simple neural network model is obtained through an  analytic computation of the eigenvalue spectrum for the Hessian matrix,  which describes the second order properties of the cost function in the  space of coupling coefficients. The form of the eigenvalue distribution  suggests new techniques for accelerating the learning process, and provides  a theoretical justification for the choice of centered versus biased state  variables.
Ronald Rosenfeld  School of Computer Science  Carnegie Mellon University  Pittsburgh, PA 15213  We present a unified framework for a number of different ways of failing  to generalize properly. During learning, sources of random information  contaminate the network, effectively augmenting the training data with  random information. The complexity of the function computed is therefore  increased, and generalization is degraded. We analyze replicated networks,  in which a number of identical networks are independently trained on the  same data and their results averaged. We conclude that replication almost  always results in a decrease in the expected complexity of the network, and  that replication therefore increases expected generalization. Simulations  confirming the effect are also presented.
If patterns are drawn from an n-dimensional feature space according to a  probability distribution that obeys a weak smoothness criterion, we show  that the probability that a random input pattern is misclassified by a  nearest-neighbor classifier using M random reference patterns asymptotically satisfies  a  PM(error) ~ Po(error) +  for sufficiently large values of M. Here, Poo(error) denotes the probability  of error in the infinite sample limit, and is at most twice the error of a  Bayes classifier. Although the value of the coefficient a depends upon the  underlying probability distributions, the exponent of M is largely distribution free. We thus obtain a concise relation between a classifier's ability  to generalize from a finite reference sample and the dimensionality of the  feature space, as well as an analytic validation of Bellman's well known  "curse of dimensionality."
We consider different types of single-hidden-layer feedforward nets: with  or without direct input to output connections, and using either threshold or sigmoidal activation functions. The main results show that direct  connections in threshold nets double the recognition but not the interpolation power, while using sigmoids rather than thresholds allows (at least)  doubling both. Various results are also given on VC dimension and other  measures of recognition capabilities.
We develop a new feedforward neural network representation of Lipschitz  functions from [0, p]"' into [0, 1] based on the level sets of the function. We  show tha.t  npLl ( n)/pL '  +  is an upper bound on tile nulnber of nodes needed to represent f to within  uniform error st, where L is the Lipschitz constant. ;Ve also show that the  number of bits needed to represent the weights in the network in order to  achieve this approximation is given by  VZe conapare this bound with the e-entropy of the functional class under  consideration.
We introduce a geometric approach for investigating the power of threshold  circuits. Viewing n-variable boolean functions as vectors in ", we invoke  tools from linear algebra and linear programming to derive new results on  the realizability of boolean functions using threshold gates.  Using this approach, one can obtain: (1) upper-bounds oil the number of  spurious memories in IIopfield networks, and on the number of functions  implementable by a depth-d threshold circuit; (2) a lower bound on the  number of orthogonal input fuuctions required to ilnplement a threshold  function; (3) a necessary condition for all arbitrary set of input fimctions to  implement a threshold filnction; (4) a lower bound on the error introduced  in approximating boolean functions using sparse polynomials; (5) a limit  on the effectiveness of the only known lower-bound technique (based on  computing correlations among booleall fimctions) for the depth of threshold circuits implementing boolean fimctions, and (6) a constructive proof  that every boolean function f of n input variables is a threshold function  of polynomially many input functions, none of which is significantly correlated with f. Some of these restilts lead to genera. lizations of key restilts  concerning threshold circuit complexity, particularly those that are based  on tile so-called spectral or IIarmonic analysis approach. Moreover, our  geometric approach yields simple proofs, based on elementary resnlts fi'om  linear algebra, for many of these earlier results.  953  954 Roychowdhury, Orlitsky, Siu, and Kailath
In this paper, after some introductory remarks into the classification problem as considered in various research communities, and some discussions  concerning some of the reasons for ascertaining the performances of the  three chosen algorithms, viz., CART (Classification and Regression Tree),  C4.5 (one of the more recent versions of a popular induction tree technique known as ID3), and a multi-layer perceptron (MLP), it is proposed  to compare the performances of these algorithms under two criteria: classification and generalisation. It is found that, in general, the MLP has better  classification and generalisation accuracies compared with the other two  algorithms.
Richard P. Lippmann  Lincoln Laboratory, MIT  Lexington, MA 02173-9108  Seven different pattern classifiers were implemented on a serial computer  and compared using artificial and speech recognition tasks. Two neural  network (radial basis function and high order polynomial GMDH network)  and five conventional classifiers (Gaussian mixture, linear tree, K nearest  neighbor, KD-tree, and condensed K nearest neighbor) were evaluated.  Classifiers were chosen to be representative of different approaches to pattern classification and to complement and extend those evaluated in a  previous study (Lee and Lippmann, 1989). This and the previous study  both demonstrate that classification error rates can be equivalent across  different classifiers when they are powerful enough to form minimum error decision regions, when they are properly tuned, and when sufficient  training data is available. Practical characteristics such as training time,  classification time, and memory requirements, however, can differ by orders of magnitude. These results suggest that the selection of a classifier  for a particular task should be guided not so much by small differences in  error rate, but by practical considerations concerning memory usage, computational resources, ease of implementation, and restrictions on training  and classification times.
The performance of seven minimization algorithms are compared on five  neural network problems. These include a variable-step-size algorithm,  conjugate gradient, and several methods with explicit analytic or numerical  approximations to the Hessian.
The problem of color clustering is defined and shown to be a problem of  assigning a large number (hundreds of thousands) of 3-vectors to a  small number (256) of clusters. Finding those clusters in such a way that  they best represent a full color image using only 256 distinct colors is a  burdensome computational problem. In this paper, the problem is solved  using "classical" techniques -k-means clustering, vector quantization  (which tums out to be the same thing in this application), competitive  learning, and Kohonen self-organizing feature maps. Quality of the  result is judged subjectively by how much the pseudo-color result  resembles the true color image, by RMS quantization error, and by run  time. The Kohonen map provides the best solution.
A large number of VLSI implementations of neural network models  have been reported. The diversity of these implementations is  noteworthy. This paper attempts to put a group of representative  VLSI implementations in perspective by comparing and contrasting them. Design trade-offs are discussed and some suggestions for the  direction of future implementation efforts are made.
We are focusing on the development of a highly compact neural net weight  function based on the use of EEPROM devices. These devices have already  proven useful for analog weight storage, but existing designs rely on the  use of conventional voltage multiplication as the weight function, requiring  additional transistors per synapse. A parasitic capacitance between the  floating gate and the drain of the EEPROM structure leads to an unusual  I-V characteristic which can be used to advantage in designing a compact  synapse. This novel behavior is well characterized by a model we have  developed. A single-device circuit results in a 1-quadrant synapse function  which is nonlinear, though monotonic. A simple extension employing 2  EEPROMs results in a 2 quadrant function which is much more linear.  This approach offers the potential for more than a ten-fold increase in the  density of neural net implementations.
We have produced a VLSI circuit capable of learning to approximate arbitrary smooth of a single variable using a technique closely related to  splines. The circuit effectively has 512 knots space on a uniform grid and  has full support for learning. The circuit also can be used to approximate  multi-variable functions as sum of splines.  An interesting, and as of yet, nearly untapped set of applications for VLSI implementation of neural network learning systems can be found in adaptive control and  non-linear signal processing. In most such applications, the learning task consists  of approximating a real function of a small number of continuous variables from  discrete data points. Special purpose hardware is especially interesting for applications of this type since they generally require real time on-line learning and there  can be stiff constraints on the power budget and size of the hardware. Frequently,  the already difficult learning problem is made more complex by the non-stationary  nature of the underlying process.  Conventional feed-forward networks with sigmoidal units are clearly inappropriate  for applications of this type. Although they have exhibited remarkable performance  in some types of time series prediction problems (for example, Wiegend, 1990 and  Atlas, 1990), their learning rates in general are too slow for on-line learning. On-line  performance can be improved most easily by using networks with more constrained  architecture, effectively making the learning problem easier by giving the network a  hint about the learning task. Networks that build local representations of the data,  such as radial basis functions, are excellent candidates for these type of problems.  One great advantage of such networks is that they require only a single layer of  units. If the position and width of the units are fixed, the learning problem is linear  1008  An Analog VLSI Splining Network 1009  in the coefficients and local. By local we mean the computation of a weight change  requires only information that is locally available to each weight, a highly desirable  property for VLSI implementation. If the learning algorithm is allowed to adjust  both the position and width of the units then many of the advantages of locally  tuned units are lost.  A number of techniques have been proposed for the determination of the width  and placement of the units. One of the most direct is to center a unit at every  data point and to adjust the widths of the units so the receptive fields overlap  with those of neighboring data points ( Broomhea!, 1989 ). The proliferation of  units can be limited by using unsupervised clustering techniques to clump the data  followed by the allocation of units to fit the clumps (Moody, 1989). Others have  advocated assigning new units only when the error on a new data point is larger than  a threshold and otherwise making small adjustments in the weights and parameters  of the existing units (Platt, 1990). All of these methods suffer from the common  problem of requiring an indeterminate quantity of resources in contrast with the  fixed resources available from most VLSI circuits. Even worse, when used with  non-stationary processes a mechanism is needed to deallocate units as well as to  allocate them. The resource allocation/deallocation problem is a serious barrier to  implementing these algorithms as autonomous VLSI microsystems.  A Splining Network  To avoid the resource allocation problem we propose a network that uses all of  its weights and units regardless of the problem. We avoid over parameterization  of the training data by building constraints on smoothness into the network, thus  reducing the number of degrees of freedom available to the training process. In  its simplest guise, the network approximates arbitrary 1-d smooth functions with a  linear superposition of locally tuned units spaced on a uniform grid,  (1)  where a is the radius of the unit's receptive field and the wi are the weights. J'o is a  bump of width a such as a gaussian or a cubic spline basis function. Mathematically  the network is closely related to function approximation using B-splines (Lancaster,  1986) with uniformly spaced knots. However, in B-spline interpolation the overlap  of the basis functions is normally determined by the degree of the spline whereas  we use the degree of overlap as a free parameter to constrain the smoothness of  the network's output. As mentioned earlier, the network is linear in its weights  so gradient descent with a quadratic cost function (LMS) is an effective training  procedure.  The weights needed for this network can easily be implemented in CMOS with an  array of transconductance amplifiers. The amplifiers are wired as voltage followers  with their outputs tied together and the weights are represented by voltages I  at the non-inverting inputs of the amplifiers. If the outputs of the locally tuned  units are represented by unipolar currents Ii these currents can be used to bias the  1010 Schwarfz and Samalam  transconductance amplifiers and the result is (Mead,1989)  Vo,. =  provided that care is taken to control the non-linearities of the amplifiers. However,  while the weights have a simple implementation in analog VLSI circuitry, the input  units do not. A number of circuits exist whose transfer characteristics can be shaped  to be a suitable bump but none of those known to the authors allow the width of  the bump to be adjusted over a wide range without the use of resistors.  (enerating the Receptive Fields  Input units with tunable receptive fields can be generated quite efficiently by breaking them up into two layers of circuitry as shown in figure 1. The input layer place  encodes the input signal i.e. only one or perhaps a small cluster of units is active  at a time. The output of the place encoding units either injects or controls the  output  []  /  Input  ] []  \ /\  weight  spreading  layer  place  encoding  Figure 1: An architecture that allows the width and shape of the receptive fields to  be varied over a wide range. The elements of the 'spreading layer' are passive and  can sink current to ground.  injection of current into the laterally connected spreading layer. The elements in  the spreading layer all contain ground terminals and the current sunk by each one  determines the bias current applied to the associated weight. Clearly, the distribution of currents flowing to ground through the spreading layer form a smooth bump  such that when excitation is applied to tap j of the spreading layer,  ii = lof(ij)  where f,(i) is the bump called for by equation 1. In our earliest realizations of  this network the input layer was a crude flash A-to-D converter and the input  to the circuit was analog. In the current generation the input is digital with the  place encoding performed by a conventional address decoder. If desired, input  quantization can be avoided by using a layer of amplifiers that generate smooth  bumps of fixed width to generate the input place encoding.  An Analog VLSI Splining Network 1011  The simplest candidate to implement the spreading layer in conventional CMOS  is a set of diode connected n-channel transistors laterally connected by n-channel  pass transistors. The gate voltages of the diode connected transistors determine  the bias currents Ii of the weights. Ignoring the body effect and assuming weak  inversion in the current sink, this type of networks tends to gives bumps with rather  sharp peaks, Ii ' }'. Ioe -l'il, where [j[ is the distance from the point where the  excitation is applied. Figure 2 shows a more sophisticated version of this circuit  in which the output of the place encoding units applies excitation to the spreading  network through a p-channel transistor. The shape of the bumps can be softened by  to weights  _ r.I-L   bias  voltages  T Y T  from place encoder  Figure 2: A schematic of a section of the spreading layer. Roughly speaking, the  n-channel pass transistor controls the extent of the tails of the bumps and the  p-channel pass transistor and the cascode transistor control its width.  limiting the amount of current drawn by the current sinks with an n-channel cascode  transistor in series with the current sink. Some experimental results for this type of  circuit are shown in figure 3a. More control can be obtained by using complementary  pass transistors. The use of p-channel pass transistors alone unexpectedly results  in bumps that are nearly square (figure 3b). These can be smoothed by using a  using both flavors of pass transistor simultaneously (figure 3c).  The Weights  As described earlier, the implementation of the output weights is based on the  computation of means by the well known follower-aggregation circuit. With typical  transconductance amplifiers, this averaging is linear only when the voltages being  averaged are distributed over a voltage range of no more than a few time UQ = kT/e  in weak inversion. In the circuits described here the linear range has been widened  to nearly a volt by reducing the transconductance of the readout amplifiers through  the combination of low width to length ratio input transistors and relatively large  tail currents.  The weights I are stored on MOS capacitors and are programmed by the gated  transconductance amplifier shown in figure 4. Since this amplifier computes the  1012 Schwartz and Samalam  ß II  ; I I  i Il I
Feedback connections are required so that the teacher signal on the output  neurons can modify weights during supervised learning. Relaxation methods  are needed for learning static patterns with full-time feedback connections.  Feedback network learning techniques have not achieved wide popularity  because of the still greater computational efficiency of back-propagation. We  show by simulation that relaxation networks of the kind we are implementing in  VLSI are capable of learning large problems just like back-propagation  networks. A microchip incorporates deterministic mean-field theory learning as  well as stochastic Boltzmann learning. A multiple-chip electronic system  implementing these networks will make high-speed parallel learning in them  feasible in the future.
A high speed implementation of the CMAC neural network was designed  using dedicated CMOS logic. This technology was then used to implement  two general purpose CMAC associative memory boards for the VME bus.  Each board implements up to 8 independent CMAC networks with a total  of one million adjustable weights. Each CMAC network can be configured  to have from I to 512 integer inputs and from I to 8 integer outputs.  Response times for typical CMAC networks are well below I millisecond,  making the networks sufficiently fast for most robot control problems, and  many pattern recognition and signal processing problems.
The Adaptive Solutions CNAPS architecture chip is a general purpose  neurocomputer chip. It has 64 processors, each with 4 K bytes of local  memory, running at 25 megahertz. It is capable of implementing most  current neural network algorithms with on chip learning. This paper discusses the implementation of the Back Propagation algorithm on an array  of these chips and shows performance figures from a clock accurate hardware simulator. An eight chip configuration on one board can update 2.3  billion connections per second in learning mode and process 9.6 billion  connections per second in feed forward mode.
We describe a CMOS neural net chip with a reconfigurable network architecture. It contains 32,768 binary, programmable connections arranged in  256 'building block' neurons. Several 'building blocks' can be connected to  form long neurons with up to 1024 binary connections or to form neurons  with analog connections. Singleor multi-layer networks can be implemented with this chip. We have integrated this chip into a board system  together with a digital signal processor and fast memory. This system is  currently in use for image processing applications in which the chip extracts  features such as edges and corners from binary and gray-level images.
The neocognitron is a neural network for pattern recognition and feature  extraction. An analog CCD parallel processing architecture developed  at Lincoln Laboratory is particularly well suited to the computational requirements of shared-weight networks such as the neocognitron, and implementation of the neocognitron using the CCD architecture was simulated.  A modification to the neocognitron training procedure, which improves  network performance under the limited arithmetic precision that would be  imposed by the CCD architecture, is presented.
A massively parallel, all-digital, stochastic architecture -TInMAN hi -is  described which performs competitive and Kohonen types of learning. A  VLSI design is shown for a TlnMAhihl neuron which fits within a small,  inexpensive MOSIS TinyChip frame, yet which can be used to build larger  networks of several hundred neurons. The neuron operates at a speed of  15 MHz which allows the network to process 290,000 training examples  per second. Use of level sensitive scan logic provides the chip with 100%  fault coverage, permitting very reliable neural systems to be built.
During waking and sleep, the brain and mind undergo a tightly linked and  precisely specified set of changes in state. At the level of neurons, this  process has been modeled by variations of Volterra-Lotka equations for  cyclic fluctuations of brainstem cell populations. However, neural network  models based upon rapidly developing knowledge of the specific population  connectivities and their differential responses to drugs have not yet been  developed. Furthermore, only the most preliminary attempts have been  made to model across states. Some of our own attempts to link rapid eye  movement (REM) sleep neurophysiology and dream cognition using neural  network approaches are summarized in this paper.
Based on a general non-stationary point process model, we computed estimates of  the synaptic coupling strength (efficacy) as a function of time after stimulus onset  between an inhibitory interneuron and its target postsynaptic cell in the feline dorsal  cochlear nucleus. The data consist of spike trains from pairs of neurons responding  to brief tone bursts recorded in vivo. Our results suggest that the synaptic efficacy is  non-stationary. Further, synaptic efficacy is shown to be inversely and  approximately linearly related to average presynaptic spike rate. A second-order  analysis suggests that the latter result is not due to non-linear interactions. Synaptic  efficacy is less strongly correlated with postsynaptic rate and the correlation is not  consistent across neural pairs.  1
Recently Linsker [2] and MacKay and Miller [3, 4] have analysed Hebbian  correlational rules for synaptic development in the visual system, and  Miller [5, 8] has studied such rules in the case of two populations of fibres  (particularly two eyes). Miller's analysis has so far assumed that each of  the two populations has exactly the same correlational structure. Relaxing  this constraint by considering the effects of small perturbative correlations  within and between eyes permits study of the stability of the solutions.  We predict circumstances in which qualitative changes are seen, including  the production of binocularly rather than monocularly driven units.
We develop a model-independent method for characterizing the reliability  of neural responses to brief stimuli. This approach allows us to measure  the discriminability of similar stimuli, based on the real-time response of a  single neuron. Neurophysiological data were obtained from a movementsensitive neuron (H1) in the visual system of the blowfly CaIIiphora erythrocephaIa. Furthermore, recordings were made from blowfly photoreceptor cells to quantify the signal to noise ratios in the peripheral visual  system. As photoreceptors form the input to the visual system, the reliability of their signals ultimately determines the reliability of any visual  discrimination task. For the case of movement detection, this limit can  be computed, and compared to the H1 neuron's reliability. Under favorable conditions, the performance of the H1 neuron closely approaches the  theoretical limit, which means that under these conditions the nervous  system adds little noise in the process of computing movement from the  correlations of signals in the photoreceptor array.
Are single neocortical neurons as powerful as multi-layered networks? A  recent compartmental modeling study has shown that voltage-dependent  membrane nonlinearities present in a complex dendritic tree can provide  a virtual layer of local nonlinear processing elements between synaptic inputs and the final output at the cell body, analogous to a hidden layer  in a multi-layer network. In this paper, an abstract model neuron is introduced, called a clusteron, which incorporates aspects of the dendritic  "cluster-sensitivity" phenomenon seen in these detailed biophysical modeling studies. It is shown, using a clusteron, that a Hebb-type learning  rule can be used to extract higher-order statistics from a set of training patterns, by manipulating the spatial ordering of synaptic connections  onto the dendritic tree. The potential neurobiological relevance of these  higher-order statistics for nonlinear pattern discrimination is then studied  within a full compartmental model of a neocortical pyramidal cell, using  a training set of 1000 high-dimensional sparse random patterns.
Single nerve cells with static properties have traditionally been viewed  as the building blocks for networks that show emergent phenomena. In  contrast to this approach, we study here how the overall network activity  can control single cell parameters such as input resistance, as well as time  and space constants, parameters that are crucial for excitability and spariotemporal integration. Using detailed computer simulations of neocortical  pyramidal cells, we show that the spontaneous background firing of the  network provides a means for setting these parameters. The mechanism  for this control is through the large conductance change of the membrane  that is induced by both non-NMDA and NMDA excitatory and inhibitory  synapses activated by the spontaneous background activity.
The dendritic trees of cortical pyramidal neurons seem ideally suited to  perform local processing on inputs. To explore some of the implications  of this complexity for the computational power of neurons, we simulated  a realistic biophysical model of a hippocampal pyramidal cell in which a  "cold spot"--a high density patch of inhibitory Ca-dependent K channels  and a colocalized patch of Ca channels--was present at a dendritic  branch point. The cold spot induced a nonmonotonic relationship between the strength of the synaptic input and the probability of neuronal  fn-ing. This effect could also be interpreted as an analog stochastic XOR.
Ion channels are the dynamical systems of the nervous system. Their  distribution within the membrane governs not only communication of information between neurons, but also how that information is integrated  within the cell. Here, an argument is presented for an 'anti-Hebbian' rule  for changing the distribution of voltage-dependent ion channels in order  to fiatten voltage curvatures in dendrites. Simulations show that this rule  can account for the self-organisation of dynamical receptive field properties  such as resonance and direction selectivity. It also creates the conditions  for the faithful conduction within the cell of signals to which the cell has  been exposed. Various possible cellular implementations of such a learning rule are proposed, including activity-dependent migration of channel  proteins in the plane of the membrane.
We consider a noisy bistable single neuron model driven by a periodic  external modulation. The modulation introduces a correlated switching  between states driven by the noise. The information flow through the system from the modulation to the output switching events, leads to a succession of strong peaks in the power spectrum. The signal-to-noise ratio (SNR)  obtained from this power spectrum is a measure of the information content  in the neuron response. With increasing noise intensity, the SNR passes  through a maximum, an effect which has been called stochastic resonance.  We treat the problem within the framework of a recently developed approximate theory, valid in the limits of weak noise intensity, weak periodic forcing and low forcing frequency. A comparison of the results of this theory  with those obt6ned from a linear system FFT is also presented.
In single cells of the cat striate cortex, lateral inhibition across orientation and/or spatial frequency is found to enhance pre-existing biases. A  contrast-dependent but spatially non-selective inhibitory component is also  found. Stimulation with ascending and descending contrasts reveals the  latter as a response hysteresis that is sensitive, powerful and rapid, suggesting that it is active in day-to-day vision. Both forms of inhibition are  not recurrent but are rather network properties. These findings suggest  two fundamental inhibitory mechanisms: a global mechanism that limits  dynamic range and creates spatial selectivity through thresholding and a  local mechanism that specifically refines spatial filter properties. Analysis  of burst patterns in spike trains demonstrates that these two mechanisms  have unique physiological origins. 
Recently, high resolution images of the simultaneous representation of  orientation preference, orientation selectivity and ocular dominance have  been obtained for large areas in monkey striate cortex by optical imaging  [1-3]. These data allow for the first time a "local" as well as "global"  description of the spatial patterns and provide strong evidence for correlations between orientation selectivity and ocular dominance.  A quantitative analysis reveals that these correlations arise when a fivedimensional feature space (two dimensions for retinotopic space, one each  for orientation preference, orientation specificity, and ocular dominance) is  mapped into the two available dimensions of cortex while locally preserving  topology. These results provide strong evidence for the concept of topology  preserving maps which have been suggested as a basic design principle of  striate cortex [4-7].
During visual development, projections from retinal ganglion cells  (RGCs) to the lateral geniculate nucleus (LGN) in cat are refined to  produce ocular dominance layering and precise topographic mapping.  Normal development depends upon activity in RGCs, suggesting a key  role for activity-dependent synaptic plasticity. Recent experiments on  prenatal retina show that during early development, "waves" of activity  pass across RGCs (Meister, et al., 1991). We provide the first  simulations to demonstrate that such retinal waves, in conjunction with  Hebbian synaptic competition and early arrival of contralateral axons,  can account for observed patterns of retinogeniculate projections in  normal and experimentally-treated animals.
To test whether the known connectivies of neurons in the lamprey spinal  cord are sufficient to account for locomotor rhytbmogenesis, a "connectionist" neural network simulation was done using identical cells connected according to experimentally established patterns. It was demonstrated that  the network oscillates in a stable manner with the same phase relationships among the neurons as observed in the lamprey. The model was then  used to explore coupling between identical oscillators. It was concluded  that the neurons can have a dual role as rhythm generators and as coordinators between oscillators to produce the phase relations observed among  segmental oscillators during swimming.
Animal locomotion patterns are controlled by recurrent neural networks  called central pattern generators (GPGs). Although a GPG can oscillate  autonomously, its rhythm and phase must be well coordinated with the  state of the physical system using sensory inputs. In this paper we propose  a learning algorithm for synchronizing neural and physical oscillators with  specific phase relationships. Sensory input connections are modified by the  correlation between cellular activities and input signals. Simulations show  that the learning rule can be used for setting sensory feedback connections  to a GPG as well as coupling connections between GPGs.  1  CENTRAL AND SENSORY MECHANISMS IN  LOCOMOTION CONTROL  Patterns of animal locomotion, such as walking, swimming, and flying, are generated  by recurrent neural networks that are located in segmental ganglia of invertebrates  and spinal cords of vertebrates (Barnes and Gladden, 1985). These networks can  produce basic rhythms of locomotion without sensory inputs and are called central  pattern generators (CPGs). The physical systems of locomotion, such as legs, fins,  and wings combined with physical environments, have their own oscillatory characteristics. Therefore, in order to realize efficient locomotion, the frequency and  the phase of oscillation of a GPG must be well coordinated with the state of the  physical system. For example, the bursting patterns of motoneurons that drive a  leg muscle must be coordinated with the configuration of the leg, its contact with  the ground, and the state of other legs. 109  1 10 Doya and Yoshizawa  The oscillation pattern of a CPG is largely affected by proprioceptive inputs. It has  been shown in crayfish (Siller et al., 1986) and lamprey (Grillnet et al, 1990) that the  oscillation of a CPG is entrained by cyclic stimuli to stretch sensory neurons over a  wide range of frequency. Both negative and positive feedback pathways are found in  those systems. Elucidation of the function of the sensory inputs to GPGs requires  computational studies of neural and physical dynamical systems. Algorithms for  the learning of rhythmic patterns in recurrent neural networks have been derived by  Doya and Yoshizawa (1989), Pearlmutter (1989), and Williams and Zipset (1989).  In this paper we propose a learning algorithm for synchronizing a neural oscillator  to rhythmic input signals with a specific phase relationship.  It is well known that a coupling between nonlinear oscillators can entrainment their  frequencies. The relative phase between oscillators is determined by the parameters  of coupling and the difference of their intrinsic frequencies. For example, either  in-phase or anti-phase oscillation results from symmetric coupling between neural  oscillators with similar intrinsic frequencies (Kawato and Suzuki, 1980). Efficient  locomotion involves subtle phase relationships between physical variables and motor  commands. Accordingly, our goal is to derive a learning algorithm that can finely  tune the sensory input connections by which the relative phase between physical  and neural oscillators is kept at a specific value required by the task.  2 LEARNING OF SYNCHRONIZATION  We will deal with the following continuous-time model of a CPG network.  d c s  = + + v,,y,(t),  j-m1 k=l  (1)  where x,(t) and g,(xi(t)) (i = 1,..., C) represent the states and the outputs of CPG  neurons and y(t) (k = 1, ...,$) represents sensory inputs. We assume that the  connection weights W = {wij ) are already established so that the network oscillates  without sensory inputs. The goal of learning is to find the input connection weights  V = {vii} that make the network state x(t) = (x(t), ...,xc(t))  entrained to the  input signal y(t) = (y(t), ... ,ys(t))  with a specific relative phase.  2.1 AN OBJECTIVE FUNCTION FOR PHASE-LOCKING  The standard way to derive a learning algorithm is to find out an objective function  to be minimized. If we can approximate the waveforms of xi(t) and y(t) by sine  waves, a linear relationship  x(t) = Py(t)  specifies a phase-locked oscillation of x(t) and y(t). For example, if we have y =  1 1  sinwt and Y2 = coswt, then a matrix P = ( vrg)specifies  = x/sin(wt+r/4)and  2 = 2 sin(wt + /3). Even when the wavefor are not sinusoidal, nimization of  an objective function   1 {xiCt)piYCt))  (2)  Z(t): ilx(t)Py(t)ll 2:   i=1 k=l  Adaptive Synchronization of Neural and Physical Oscillators 111  determines a specific relative phase between x(t) and y(t). Thus we call P = {Pit }  a phase-lock matrix.  2.2 LEARNING PROCEDURE  Using the above objective function, we will derive a learning procedure for phaselocked oscillation of x(t) and y(t). First, an appropriate phase-lock matrix P is  identified while the relative phase between x(t) and y(t) changes gradually in time.  Then, a feedback mechanism can be applied so that the network state x(t) is kept  close to the target waveform P y(t).  Suppose we actually have an appropriate phase relationship between x(t) and y(t),  then the phase-lock matrix P can be obtained by gradient descent of E(t) with  respect to Pit as follows (Widrow and Stearns, 1985).  d OE(t) s  Pit = --rl O-i = rl {xi(t) -ZPisYS(t))yt(t)'  j--1  (3)  If the coupling between x(t) and y(t) are weak enough, their relative phase changes  in time unless their intrinsic frequencies are exactly equal and the systems are  completely noiseless. By modulating the learning coefficient /by some performance  index of the total system, for example, the speed of locomotion, it is possible to  obtain a matrix P that satisfies the requirement of the task.  Once a phase-lock matrix is derived, we can control x(t) close to P y(t) using the  gradient of E(t) with respect to the network state  s  OE(t) = xi(t)Zpityt(t).  kml  The simplest feedback algorithm is to add this term to the CPG dynamics as follows.  d c s  ri d-xi(t) = -xi(t) + Z wljgJ(xJ(t)) a{xi(t) Zpityt(t)}.  j=l k=l  The feedback gain a (> O) must be set small enough so that the feedback term  does not destroy the intrinsic oscillation of the CPG. In that case, by neglecting the  small additional decay term axi(t), we have  d c $  rix,(t) = -xi(t) + Z wisgs(xs(t)) + Z apityt(t),  j=l k=l  (4)  which is equivalent to the equation (1) with input weights vii = apit.  112  Doya and Yoshizawa  3 DELAYED SYNCHRONIZATION  We tested the above learning scheme on a delayed synchronization task; to find  coupling weights between neural oscillators so that they synchronize with a specific  time delay. We used the following coupled CPG model.  c c  -Zx (t) =  ri,y, (t),  j=l k=l  (5)  y(t) = g(x(t)), (i = 1,...,C),  where superscripts denote the indices of two CPGs (n = 1,2). The goal of learning  was to synchronize the waveforms yl(t) and y(t) with a time delay AT. We used  as the performance index. The learning coefficient U of equation (3) was modulated  by the deviation of z(t) from its running average 2(t) using the following equations.  ,(t) = ,o (z(t) (t)},  '" t (t) = -(t) + (t).  (6)  a  b  yl  y2  O. 0 4. 0 8. 0 12. 0 16. 0 20. 0 24. 0 28. 0 32. 0  y2 '"' '" ""  0. 0 4. 0 8. 0 12. 0 16.  c  y2  d  0.0 4.0 8.0 12.0 16.0  0.0 4.0 8.0 12.0 16.0  0.0 4.0 8.0 12.0 16.0  Figure 1: Learning of delayed synchronization of neural oscillators. The dotted and  solid curves represent y(t) and y(t) respectively. a:without coupling. b:AT 0.0.  c:AT 1.0. c:AT = 2.0. d:AT = 3.0.  Adaptive Synchronization of Neural and Physical Oscillators 113  First, two CPGs were trained independently to oscillate with sinusoidal waveforms  of period T = 4.0 and T9 = 5.0 using continuous-time back-propagation learning  (Doya and Yoshizawa, 1989). Each CPG was composed of two neurons (C = 2) with  time constants r = 1.0 and output functions g() = tanh(). Instead of following  the two step procedure described in the previous section, the network dynamics (5)  and the learning equations (3) and (6) were simulated concurrently with parameters  a = 0.1, Uo = 0.2, and ra = 20.0.  Figure 1 a shows the oscillation of two CPGs without coupling. Figures 1 b through  e show the phase-locked waveforms after learning for 200 time units with different  desired delay times.  4 ZERO-LEGGED LOCOMOTION  Next we applied the learning rule to the simplest locomotion system that involves a critical phase-lock between the state of the physical system and the motor  command--a zero-legged locomotion system as shown in Figure 2 a.  The physical system is composed of a wheel and a weight that moves back and  forth on a track fixed radially in the wheel. It rolls on the ground by changing its  balance with the displacement of the weight. In order to move the wheel in a given  direction, the weight must be moved at a specific phase with the rotation angle of  the wheel. The motion equations are shown in Appendix.  First, a CPG network was trained to oscillate with a sinusoidal waveform of period  T = 1.0 (Doya and Yoshizawa, 1989). The network consisted of one output and  two hidden units (C = 3) with time constants ri = 0.2 and output functions gi( ) =  tanh(). Next, the output of the CPG was used to drive the weight with a force  f -fmax g(Xl (t)). The position r and the velocity  of the weight and the rotation  angle (cos0, sin0) and the angular velocity of the wheel J were used as sensory  feedback inputs yi(t) (k = 1,..., 5) after scaling to [-1, 1].  In order to eliminate the effect of biases in x(t) and y(t), we used the following  learning equations.  (7)  The rotation speed of the wheel was employed as the performance index z(t) after  smoothing by the following equation.  d  r,z(t) = -z(t) + t(t).  The learning coefficient /was modulated by equations (6). The time constants were  rt = 4.0, ry = 1.0, rs = 1.0, and ra = 4.0. Each training run was started from a  random configuration of the wheel and was finished after ten seconds.  1 14 Doya and Yoshizawa  a  b  _d2  0.0 1.0 2.0 3.0 4.0 5.0 6.0 0.0 1.0 2.0 3.0 4.0 5.0 6.0  c  -O. 5 0.0 O. 5  0.0 1.0 2.0 :3.0 4.0 5.0 6.0 0.0 1.0 2.0 :3.0 4.0 5.0 6.0  -0.5  0.0 O. 5  Figure 2: Learning of zero-legged locomotion.  Adaptive Synchronization of Neural and Physical Oscillators 115  Figure 2 b is an example of the motion of the wheel without sensory feedback.  The rhythms of the CPG and the physical system were not entrained to each other  and the wheel wandered left and right. Figure 2 c shows an example of the wheel  motion after 40 runs of training with parameters /0 = 0.1 and a = 0.2. At first, the  oscillation of the CPG was slowed down by the sensory inputs and then accelerated  with the rotation of the wheel in the right direction.  We compared the patterns of sensory input connections made after learning with  wheels of different sizes. Table I shows the connection weights to the output unit.  The positive connection from sin 0 forces the weight to the right-hand side of the  wheel and stabilize clockwise rotation. The negative connection from cos 0 with  smaller radius fastens the rhythm of the CPG when the wheel rotates too fast and  the weight is lifted up. The positive input from r with larger radius makes the  weight stickier to both ends of the track and slows down the rhythm of the CPG.  Table 1: Sensory input weights to the output unit (pt; k = 1,..., 5).  radius  2cm  4cm  6cm  8cm  10cm  r  cos 0 sin 0 J  0.15 -0.53 -1.35 1.32 0.07  0.28 -0.55 -1.09 1.22 0.01  0.67 -0.21 -0.41 0.98 0.00  0.70 -0.33 -0.40 0.92 0.03  0.90 -0.12 -0.30 0.93 -0.02  5 DISCUSSION  The architectures of CPGs in lower vertebrates and invertebrates are supposed to  be determined by genetic information. Nevertheless, the way an animal utilizes the  sensory inputs must be adaptive to the characteristics of the physical environments  and the changing dimensions of its body parts.  Back-propagation through forward models of physical systems can also be applied  to the learning of sensory feedback (Jordan and Jacobs, 1990). However, learning of  nonlinear dynamics of locomotion systems is a difficult task; moreover, multi-layer  back-propagation is not appropriate as a biological model of learning. The learning  rule (7) is similar to the covariance learning rule (Sejnowski and Stanton, 1990),  which is a biological model of long term potentiation of synapses.  Acknowledgements  The authors thank Allen Se]verston, Peter Rowat, and those who gave comments  to our poster at NIPS Conference. This work was partly supported by grants from  the Ministry of Education, Culture, and Science of Japan.  1 16 Doya and Yoshizawa  References  Barnes, W. J.P. & Gladden, M. H. (1985) Feedback and Motor Control in Invertebrates and Vertebrates. Beckenham, Britain: Croom Helm.  Doya, K. & Yoshizawa, S. (1989) Adaptive neural oscillator using continuous-time  back-propagation learning. Neural Networks, 2, 375-386.  Grillnet, S. & Matsushima, T. (1991) The neural network underlying locomotion in  Lamprey--Synaptic and cellular mechanisms. Neuron, ?(July), 1-15.  Jordan, M. I. & Jacobs, R. A. (1990) Learning to control an unstable system with  forward modeling. In Touretzky, D. S. (ed.), Advances in Neural Information Processing Systems 2. San Mateo, CA: Morgan Kaufmann.  Kawato, M. & Suzuki, R. (1980) Two coupled neural oscillators as a model of the  circadian pacemaker. Journal of Theoretical Biology, 86,547-575.  Pearlmutter, B. A. (1989) Learning state space trajectories in recurrent neural networks. Neural Computation, 1,263-269.  Sejnowski, T. J. & Stanton, P. K. (1990) Covariance storage in the Hippocampus.
The dynamic behavior of a network model consisting of all-to-all excitatory  coupled binary neurons with global inhibition is studied analytically and  numerically. We prove that for random input signals, the output of the  network consists of synchronized bursts with apparently random intermissions of noisy activity. Our results suggest that synchronous bursts can be  generated by a simple neuronal architecture which amplifies incoming coincident signals. This synchronization process is accompanied by dampened  oscillations which, by themselves, however, do not play any constructive  role in this and can therefore be considered to be an epiphenomenon.
We investigate a model in which excitatory neurons have dynamical thresholds which display both fatigue and potentiation. The fatigue property  leads to oscillatory behavior. It is responsible for the ability of the model  to perform segmentation, i.e., decompose a mixed input into staggered  oscillations of the activities of the cell-assemblies (memories) affected by  it. Potentiation is responsible for sustaining these staggered oscillations  after the input is turned off, i.e. the system serves as a model for short  term lnemory. It has a limited STM capacity, reminiscent of the magical  number 7 + 2.
We present the "Multi-State Time Delay Neural Network" (MS-TDNN) as an  extension of the TDNN to robust word recognition. Unlike most other hybrid  methods, the MS-TDNN embeds an alignment search procedure into the connectionist architecture, and allows for word level supervision. The resulting  system has the ability to manage the sequential order of subword units, while  optimizing for the recognizer performance. In this paper we present extensive  new evaluations of this approach over speaker-dependent and speaker-independent connected alphabet.
The focused gamma network is proposed as one of the possible  implementations of the gamma neural model. The focused gamma  network is compared with the focused backpropagation network and  TDNN for a time series prediction problem, and with ADALINE in  a system identification problem.  1
Recently, much interest has been generated regarding speech  recognition systems based on Hidden Markov Models (HMMs) and  neural network (NN) hybrids. Such systems attempt to combine the  best features of both models: the temporal structure of HMMs and  the discriminative power of neural networks. In this work we define  a time-warping (TW) neuron that extends the operation of the formal  neuron of a back-propagation network by warping the input pattern to  match it optimally to its weights. We show that a single-layer  network of TW neurons is equivalent to a Gaussian nsity HMMbased recognition system, and we propose to unprove the  discriminative power of this system by using back-propagation  discriminative training, and/or by generalizing the structure of the  recognizer to a multi-layered net. The performance of the proposed  network was evaluated on a highly confusable, isolated word, multi  speaker recognition task. The results indicate that not only does the  recognition performance improve, but the separation between classes  is enhanced also, allowing us to set up a rejection criterion to  improve the confidence of the system.
A high performance speaker-independent isolated-word hybrid speech recognizer was developed which combines Hidden Markov Models (HMMs)  and Radial Basis Function (RBF) neural networks. In recognition experiments using a speaker-independent E-set database, the hybrid recognizer had an error rate of 11.5% compared to 15.7% for the robust  unimodal Gaussian HMM recognizer upon which the hybrid system was  based. These results and additional experiments demonstrate that RBF  networks can be successfully incorporated in hybrid recognizers and suggest that they may be capable of good performance with fewer parameters  than required by Gaussian mixture classifiers. A global parameter optimization method designed to minimize the overall word error rather than  the frame recognition error failed to reduce the error rate.
Issues relating to the estimation of hidden Markov model (HMM) local  probabilities are discussed. In particular we note the isomorphism of radial basis functions (RBF) networks to tied mixture density modelling;  additionally we highlight the differences between these methods arising  from the different training criteria employed. We present a method in  which connectionist training can be modified to resolve these differences  and discuss some preliminary experiments. Finally, we discuss some outstanding problems with discriminative training.
The subject of this paper is the integration of multi-layered Artificial Neural Networks (ANN) with probability density functions such as Gaussian  mixtures found in continuous density Hidden Markov Models (HMM). In  the first part of this paper we present an ANN/HMM hybrid in which  all the parameters of the the system are simultaneously optimized with  respect to a single criterion. In the second part of this paper, we study  the relationship between the density of the inputs of the network and the  density of the outputs of the networks. A few experiments are presented  to explore how to perform density estimation with ANNs.
We present JANUS, a speech-to-speech translation system that utilizes  diverse processing strategies, including connectionist learning, traditional AI knowledge representation approaches, dynamic programming,  and stochastic techniques. JANUS translates continuously spoken  English and German into German, English, and Japanese. JANUS currently achieves 87% translation fidelity from English speech and 97%  from German speech. We present the JANUS system along with comparative evaluations of its interchangeable processing components, with  special emphasis on the connectionist modules.  *Also with University of Karlsruhe, Karlsruhe, Gemany.  *Now with Aliiant Techsystems Research and Technology Center, Hopkins, Minnesota.  183  184 Waibel, et al.
We propose a paradigm for modeling speech production based on neural  networks. We focus on characteristics of the musculoskeletal system. Using  real physiological data articulator movements and EMG from muscle activity a neural network learns the forward dynamics relating motor commands to  muscles and the ensuing articulator behavior. After learning, simulated  perturbations, were used to asses properties of the acquired model, such as natural  frequency, damping, and interarticulator couplings. Finally, a cascade neural  network is used to generate continuous motor commands from a sequence of  discrete articulatory targets.
A recognition system is reported which recognizes names spelled over the  telephone with brief pauses between letters. The system uses separate  neural networks to locate segment boundaries and classify letters. The  letter scores are then used to search a database of names to find the best  scoring name. The speaker-independent classification rate for spoken letters is 89%. The system retrieves the correct name, spelled with pauses  between letters, 91% of the time from a database of 50,000 names.
This paper presents PARSEC--a system for generating connectionist  parsing networks from example parses. PARSEC is not based on formal  grammar systems and is geared toward spoken language tasks. PARSEC  networks exhibit three strengths important for application to speech processing: 1) they learn to parse, and generalize well compared to handcoded grammars; 2) they tolerate several types of noise; 3) they can  learn to use multi-modal input. Presented are the PARSEC architecture  and performance analyses along several dimensions that demonstrate  PARSEC's features. PARSEC's performance is compared to that of traditional grammar-based parsing systems.
This paper considers the problem of expressing predicate calculus in connectionist networks that are based on energy minimization. Given a firstorder-logic knowledge base and a bound k, a symmetric network is constructed (like a Boltzman machine or a Hopfield network) that searches  for a proof for a given query. If a resolution-based proof of length no  longer than k exists, then the global minima of the energy function that  is associated with the network represent such proofs. The network that  is generated is of size cubic in the bound k and linear in the knowledge  size. There are no restrictions on the type of logic formulas that can be  represented. The network is inherently fault tolerant and can cope with  inconsistency and nonmonotonicity.
We use connectionist modeling to develop an analysis of stress systems in terms  of ease of learnability. In traditional linguistic analyses, learnability arguments  determine default parameter settings based on the feasibilty of logically deducing  correct settings from an initial state. Our approach provides an empirical alternative to such arguments. Based on perceptron learning experiments using data  from nineteen human languages, we develop a novel characterization of stress  patterns in terms of six parameters. These provide both a partial description of the  stress pattern itself and a prediction of its learnability, without invoking abstract  theoretical constructs such as metrical feet. This work demonstrates that machine learning methods can provide a fresh approach to understanding linguistic  phenomena.
We present a Parallel Distributed Semantic (PDS) Network architecture  that addresses the problems of sequencing and ambiguity resolution in  natural language understanding. A PDS Network stores phrases and their  meanings using multiple PDP networks, structured in the form of a semantic net. A mechanism called Propagation Filters is employed: (1) to  control communication between networks, (2) to properly sequence the  components of a phrase, and (3) to resolve ambiguities. Simulation results  indicate that PDS Networks and Propagation Filters can successfully represent high-level knowledge, can be trained relatively quickly, and provide  for parallel inferencing at the knowledge level.
We have developed a four-language automatic language identification system for high-quality speech. The system uses a neural network-based  segmentation algorithm to segment speech into seven broad phonetic categories. Phonetic and prosodic features computed on these categories are  then input to a second network that performs the language classification.  The system was trained and tested on separate sets of speakers of American English, Japanese, Mandarin Chinese and Tamil. It currently performs  with an accuracy of 89.5% on the utterances of the test set.
I present a modular network architecture and a learning algorithm based  on incremental dynamic programming that allows a single learning agent  to learn to solve multiple Markovian decision tasks (MDTs) with significant transfer of learning across the tasks. I consider a class of MDTs,  called composite tasks, formed by temporally concatenating a number of  simpler, elemental MDTs. The architecture is trained on a set of composite and elemental MDTs. The temporal structure of a composite task is  assumed to be unknown and the architecture learns to produce a temporal decomposition. It is shown that under certain conditions the solution  of a composite MDT can be constructed by computationally inexpensive  modifications of the solutions of its constituent elemental MDTs.
This paper examines whether temporal difference methods for training  connectionist networks, such as Suttons's TD() algorithm, cn be successfully applied to complex real-world problems. A number of important  practical issues are identified and discussed from a general theoretical perspective. These practical issues are then examined in the context of a case  study in which TD() is applied to learning the game of backgammon  from the outcome of self-play. This is apparently the first application of  this algorithm to a complex nontrivial task. It is found that, with zero  knowledge built in, the network is able to learn from scratch to play the  entire game at a fairly strong intermediate level of performance, which is  clearly better than conventional commercial programs, and which in fact  surpasses comparable networks trained on a massive human expert data  set. The hidden units in these network have apparently discovered useful  features, a longstanding goal of computer games research. Furthermore,  when a set of hand-crafted features is added to the input representation,  the resulting networks reach a near-expert level of performance, and have  achieved good results against world-class human play.
HARMONET, a system employing connectionist networks for music processing, is presented. After being trained on some dozen Bach chorales  using error backpropagation, the system is capable of producing four-part  chorales in the style of J.S.Bach, given a one-part melody. Our system  solves a musical real-world problem on a performance level appropriate  for musical practice. HARMONET's power is based on (a) a new coding  scheme capturing musically relevant information and (b) the integration of  backpropagation and symbolic algorithms in a hierarchical system, combining the advantages of both.
Learning structure in temporally-extended sequences is a difficult computational problem because only a fraction of the relevant information is  available at any instant. Although variants of back propagation can in  principle be used to find structure in sequences, in practice they are not  sufficiently powerful to discover arbitrary contingencies, especially those  spanning long temporal intervals or involving high order statistics. For  example, in designing a connectionist network for music composition, we  have encountered the problem that the net is able to learn musical structure that occurs locally in time e.g., relations among notes within a musical phrase but not structure that occurs over longer time periods e.g.,  relations among phrases. To address this problem, we require a means  of constructing a reduced description of the sequence that makes global  aspects more explicit or more readily detectable. I propose to achieve this  using hidden units that operate with different time constants. Simulation  experiments indicate that slower time-scale hidden units are able to pick  up global structure, structure that simply can not be learned by standard  back propagation.  Many patterns in the world are intrinsically temporal, e.g., speech, music, the unfolding of events. Recurrent neural net architectures have been devised to accommodate time-varying sequences. For example, the architecture shown in Figure 1  can map a sequence of inputs to a sequence of outputs. Learning structure in  temporally-extended sequences is a difficult computational problem because the input pattern may not contain all the task-relevant information at any instant. Thus,  275  276 Mozer  OUTPUT  co  Figure 1: A generic recurrent network architecture for processing input and output  sequences. Each box corresponds to a layer of units, each line to full connectivity  between layers.  the context layer must hold on to relevant aspects of the input history until a later  point in time at which they can be used.  In principle, variants of back propagation for recurrent networks (Rumelhart, Hinton, & Williams, 1986; Williams & Zipset, 1989) can discover an appropriate representation in the context layer for a particular task. In practice, however, back  propagation is not sufficiently powerful to discover arbitrary contingencies, especially those that span long temporal intervals or that involve high order statistics  (e.g., Mozer, 1989; Robwet, 1990; Schmidhuber, 1991).  Let me present a simple situation where back propagation fails. It involves remembering an event over an interval of time. A variant of this task was first studied  by Schmidhuber (1991). The input is a sequence of discrete symbols: 1, B, ½, D,  ß .., I, ¾. The task is to predict the next symbol in the sequence. Each sequence  begins with either an I or a Y . call this the trigger symbol--and is followed by a  fixed sequence such as IBCDE, which in turn is followed by a second instance of the  trigger symbol, i.e., IIBODE][ or or YIBCDEY. To perform the prediction task, it is  necessary to store the trigger symbol when it is first presented, and then to recall  the same symbol five time steps later.  The number of symbols intervening between the two triggers call this the gap  can be varied. By training different networks on different gaps, we can examine  how difficult the learning task is as a function of gap. To better control the experiments, all input sequences had the same length and consisted of either I or Y  followed by IBCDEFGHIJK. The second instance of the trigger symbol was inserted  at various points in the sequence. For example, IIBCDIEFGHIJK represents a gap of  4, YABCDEFGHYIJK a gap of 8.  Each training set consisted of two sequences, one with X and one with Y. Different  networks were trained on different gaps. The network architecture consisted of one  input and output unit per symbol, and ten context units. Twenty-five replications  of each network were run with different random initial weights. If the training set  was not learned within 10000 epochs, the replication was counted as a "failure."  The primary result was that training sets with gaps of 4 or more could not be  learned reliably, as shown in Table 1.  Induction of Multiscale Temporal Structure 277  Table 1: Learning contingencies across gaps  gap ailures mean # epochs  to arn  2 0 408  4 36 7406  6 92 9830  8 100 10000  10 100 10000  The results are suprisingly poor. My general impression is that back propagation  is powerful enough to learn only structure that is fairly local in time. For instance,  in earlier work on neural net music composition (Mozer & Soukup, 1991), we found  that our network could master the rules of composition for notes within a musical  phrase, but not rules operating at a more global levelmrules for how phrases are  interrelated.  The focus of the present work is on devising learning algorithms and architectures  for better handling temporal structure at more global scales, as well as multiscale  or hierarchical structure. This difficult problem has been identified and studied by  several other researchers, including Miyata and Burr (1990), Robwet (1990), and  Schmidhuber (1991).
A network model with temporal sequencing and state-dependent modulatory features is described. The model is motivated by neurocognitive data  characterizing different states of waking and sleeping. Computer studies  demonstrate how unique states of sequencing can exist within the same  network under different aminergic and cholinergic modulatory influences.  Relationships between state-dependent modulation, memory, sequencing  and learning are discussed.
Do you want your neural net algorithm to learn sequences? Do not limit yourself to conventional gradient descent (or approximations thereof).  Instead, use your sequence learning algorithm (any will do) to implement  the following method for history compression. No matter what your final goals are, train a network to predict its next input from the previous  ones. Since only unpredictable inputs convey new information, ignore all  predictable inputs but let all unexpected inputs (plus information about  the time step at which they occurred) become inputs to a higher-level  network of the same kind (working on a slower, self-adjusting time scale).  Go on building a hierarchy of such networks. This principle reduces the  descriptions of event sequences without loss of information, thus easing  supervised or reinforcement learning tasks. Alternatively, you may use  two recurrent networks to collapse a multi-level predictor hierarchy into a  single recurrent net. Experiments show that systems based on these principles can require less computation per time step and many fewer training  sequences than conventional training algorithms for recurrent nets. Finally you can modify the above method such that predictability is not defined  in a yes-or-no fashion but in a continuous fashion.  291  292  Schmidhuber
There exist large classes of time series, such as those with nonlinear moving  average components, that are not well modeled by feedforward networks  or linear models, but can be modeled by recurrent networks. We show that  recurrent neural networks are a type of nonlinear autoregressive-moving  average (NARMA) model. Practical ability will be shown in the results of  a competition sponsored by the Puget Sound Power and Light Company,  where the recurrent networks gave the best performance on electric load  forecasting.
Second-order recurrent networks that recognize simple finite state languages over {0,1)* are induced from positive and negative examples. Using the complete gradient of the recurrent network and sufficient training  examples to constrain the definition of the language to be induced, solutions are obtained that correctly recognize strings of arbitrary length. A  method for extracting a finite state automaton corresponding to an optimized network is demonstrated.
Simple second-order recurrent networks are shown to readily learn small known  regular grammars when trained with positive and negative strings examples. We  show that similar methods are appropriate for learning unknown grmnmars from  examples of their strings. The training algorithm is an incremental real-time, recurrent learning (RTRL) method that computes the complete gradient and updates  the weights at the end of each string. After or during training, a dynamic clustering  algorithm extracts the production rules that the neural network has learned. The  methods are illustrated by extracting rules from unknown deterministic regular  grammars. For many cases the extracted grammar outperforms the neural net from  which it was extracted in conectly classifying unseen strings.
We present a framework for programming the hidden unit representations of  simple recurrent networks based on the use of hint units (additional targets at  the output layer). We present two ways of analysing a network trained within  this framework: Input patterns act as operators on the information encoded by  the context units; symmetrically, patterns of activation over the context units  act as curried functions of the input sequences. Simulations demonstrate that a  network can learn to represent three different functions simultaneously and  canonical discriminant analysis is used to investigate how operators and curried  functions are represented in the space of hidden unit activations.
The two well known learning algorithms of recurrent neural networks are  the back-propagation (Rumelhart & eL al., Werbos) and the forward propagation (Williams and Zipset). The main drawback of back-propagation is its  off-line backward path in time for error cumulation. This violates the on-line  requirement in many practical applications. Although the forward propagation algorithm can be used in an on-line manner, the annoying drawback is  the heavy computation load required to update the high dimensional sensitivity matrix (O(N") operations for each time step). Therefore, to develop a fast  forward algorithm is a challenging task. In this paper wl proposed a forward  learning algorithm which is one order faster (only O(N ø) operations for each  time step) than the sensitivity matrix algorithm. The basic idea is that instead  of integrating the high dimensional sensitivity dynamic equation we solve  forward in time for its Green's function to avoid the redundant computations,  and then update the weights whenever the error is to be corrected.  A Numerical example for classifying state trajectories using a recurrent  network is presented. It substantiated the faster speed of the proposed algorithm than the Williams and Zipser's algorithm.
Winner-Take-All (WTA) networks, in which inhibitory interconnections are used to determine the most highly-activated of a pool of units,  are an important part of many neural network models. Unfortunately,  convergence of normal WTA networks is extremely sensitive to the  magnitudes of their weights, which must be hand-tuned and which generally only provide the right amount of inhibition across a relatively  small range of initial conditions. This paper presents DynamicallyAdaptive Winner-Take-All (DAWTA) networks, which use a regulatory  unit to provide the competitive inhibition to the units in the network.  The DAWTA regulatory unit dynamically adjusts its level of activation  during competition to provide the right amount of inhibition to differentiate between competitors and drive a single winner. This dynamic  adaptation allows DAWTA networks to perform the winner-take-all  function for nearly any network size or initial condition, using O(N)  connections. In addition, the DAWTA regulatory unit can be biased to  find the level of inhibition necessary to settle upon the K most highlyactivated units, and therefore serve as a K-Winners-Take-All network.
Because eye muscles never cocontract and do not deal with external  loads, one can write an equation that relates motoneuron firing rate to  eye position and velocity a very uncommon situation in the CNS.  The semicircular canals transduce head velocity in a linear manner by  using a high background discharge rate, imparting linearity to the  premotor circuits that generate eye movements. This has allowed  deducing some of the signal processing involved, including a neural  network that integrates. These ideas are often summarized by block  diagrams. Unfortunately, they are of little value in describing the  behavior of single neurons a finding supported by neural network  models.
We have investigated the properties of neurons in inferior temporal (IT)  cortex in monkeys performing a pattern matching task. Simple backpropagation networks were trained to discriminate the various stimulus  conditions on the basis of the measured neuronal signal. We also trained  networks to predict the neuronal response waveforms from the spatial patterns of the stimuli. The results indicate that IT neurons convey temporally encoded information about both current and remembered patterns,  as well as about their behavioral context.  356  Decoding of Neuronal Signals in Visual Pattern Recognition 357
Learning a map from an input set to an output set is similar to the problem of reconstructing hypersurfaces from sparse data (Poggio and Girosi,  1990). In this framework, we discuss the problem of automatically selecting "minimal" surface data. The objective is to be able to approximately  reconstruct the surface from the selected sparse data. We show that this  problem is equivalent to the one of compressing information by data removal and the one of learning how to teach. Our key step is to introduce a  process that statistically selects the data according to the model. During  the process of data selection (learning how to teach) our system (teacher)  is capable of predicting the new surface, the approximated one provided  by the selected data. We concentrate on piecewise smooth surfaces, e.g.  images, and use mean field techniques to obtain a deterministic network  that is shown to compress image data.
We have previously described an unsupervised learning procedure that  discovers spatially coherent properties of the world by maximizing the information that parameters extracted from different parts of the sensory  input convey about some common underlying cause. When given random  dot stereograms of curved surfaces, this procedure learns to extract surface depth because that is the property that is coherent across space. It  also learns how to interpolate the depth at one location from the depths  at nearby locations (Becker and Hinton. 1992). In this paper, we propose two new models which handle surfaces with discontinuities. The first  model attempts to detect cases of discontinuities and reject them. The  second model develops a mixture of expert interpolators. It learns to detect the locations of discontinuities and to invoke specialized, asymmetric  interpolators that do not cross the discontinuities.
We have constructed a recurrent network that stabilizes images of a moving  object on the retina of a simulated eye. The structure of the network  was motivated by the organization of the primate visual target tracking  system. The basic components of a complete target tracking system were  simulated, including visual processing, sensory-motor interface, and motor  control. Our model is simpler in structure, function and performance than  the primate system, but many of the complexities inherent in a complete  system are present.  380  Recurrent Eye Tracking Network Using a Distributed Representation of Image Motion 381  Visual  Processing  Retinotopic Eye  Maps Velocity  Motor  Interface  Estimate of  Retinal  Velocity  Motor  Conxol  I  Figure 1: The overall structure of the visual tracking model.  Target  J Eye
Networks for reconstructing a sparse or noisy function often use an edge  field to segment the function into homogeneous regions, This approach  assumes that these regions do not overlap or have disjoint parts, which is  often false. For example, images which contain regions split by an occluding object can't be properly reconstructed using this type of network. We  have developed a network that overcomes these limitations, using support  maps to represent the segmentation of a signal. In our approach, the support of each region in the signal is explicitly represented. Results from  an initial implementation demonstrate that this method can reconstruct  images and motion sequences which contain complicated occlusion.
Network vision systems must make inferences from evidential information across levels of representational abstraction, from low level invariants,  through intermediate scene segments, to high level behaviorally relevant  object descriptions. This paper shows that such networks can be realized  as Markov Random Fields (MRFs). We show first how to construct an  MRF functionally equivalent to a Hough transform parameter network,  thus establishing a principled probabilistic basis for visual networks. Second, we show that these MRF parameter networks are more capable and  flexible than traditional methods. In particular, they have a well-defined  probabilistic interpretation, intrinsically incorporate feedback, and offer  richer representations and decision capabilities.
It is shown that both changes in viewing position and illumination conditions can be compensated for, prior to recognition, using combinations  of images taken from different viewing positions and different illumination conditions. It is also shown that, in agreement with psychophysical  findings, the computation requires at least a sign-bit image as input  contours alone are not sufficient.
Neurons encoding simple visual features in area V1 such as orientation,  direction of motion and color are organized in retinotopic maps. However, recent physiological experiments have shown that the responses of  many neurons in V1 and other cortical areas are modulated by the direction of gaze. We have developed a neural network model of the visual  cortex to explore the hypothesis that visual features are encoded in headcentered coordinates at early stages of visual processing. New experiments  are suggested for testing this hypothesis using electrical stimulations and  psychophysical observations.
Visual attention is the ability to dynamically restrict processing to a subset  of the visual field. Researchers have long argued that such a mechanism is  necessary to efficiently perform many intermediate level visual tasks. This  paper describes VISIT, a novel neural network model of visual attention.  The current system models the search for target objects in scenes containing multiple distractors. This is a natural task for people, it is studied  extensively by psychologists, and it requires attention. The network's behavior closely matches the known psychophysical data on visual search  and visual attention. VISIT also matches much of the physiological data  on attention and provides a novel view of the functionality of a number of  visual areas. This paper concentrates on the biological plausibility of the  model and its relationship to the primary visual cortex, pulvinar, superior  colliculus and posterior parietal areas.
I exhibit a systematic way to derive neural nets for vision problems. It  involves formulating a vision problem as Bayesian inference or decision  on a comprehensive model of the visual domain given by a probabilistic  grammar.
Despite the fact that complex visual scenes contain multiple, overlapping  objects, people perform object recognition with ease and accuracy. One  operation that facilitates recognition is an early segmentation process in  which features of objects are grouped and labeled according to which object they belong. Current computational systems that perform this operation are based on predefined grouping heuristics. We describe a system  called MAOI½ that learns how to group features based on a set of presegmented examples. In many cases, MAOI½ discovers grouping heuristics  similar to those previously proposed, but it also has the capability of finding nonintuitive structural regularities in images. Grouping is performed  by a relaxation network that attempts to dynamically bind related features. Features transmit a complex-valued signal (amplitude and phase)  to one another; binding can thus be represented by phase locking related  features. MAGI½'S training procedure is a generalization of recurrent back  propagation to complex-valued units.  When a visual image contains multiple, overlapping objects, recognition is difficult  because features in the image are not grouped according to which object they belong.  Without the capability to form such groupings, it would be necessary to undergo a  massive search through all subsets of image features. For this reason, most machine  vision recognition systems include a component that performs feature grouping or  image segmentation (e.g., Gu.man, 1968; Lowe, 1985; Mart, 1982).  436  Learning to Segment Images Using Dynamic Feature Binding 437  A multitude of heuristics have been proposed for segmenting images. Gestalt psychologists have explored how people group elements of a display and have suggested  a range of grouping principles that govern human perception (Rock & Palmer, 1990).  Computer vision researchers have studied the problem from a more computational perspective. They have investigated methods of grouping elements of an image  based on nonaccidental regularitiet--feature combinations that are unlikely to occur  by chance when several objects are juxtaposed, and are thus indicative of a single  object (Kanade, 1981; Lowe & Binford, 1982).  In these earlier approaches, the researchers have hypothesized a set of grouping  heuristics and then tested their psychological validity or computational utility. In  our work, we have taken an adaptive approach to the problem of image segmentation in which a system learns how to group features based on a set of examples.  We call the system MA(IC, an acronym for multiple-object _adaptive grouping of  image components. In many cases MA(IC discovers grouping heuristic similar to  those proposed in earlier work, but it also has the capability of finding nonintuitive  structural regularities in images.  MAGIC is trained on a set of presegmented images containing multiple objects. By  "presegmented," we mean that each image feature is labeled as to which object it  belongs. MA(I½ learns to detect configurations of the image features that have a  consistent labeling in relation to one another across the training examples. Identifying these configurations allows MAGIC to then label features in novel, unsegmented  images in a manner consistent with the training examples.
A combined neural network and rule-based approach is suggested as a  general framework for pattern recognition. This approach enables unsupervised and supervised learning, respectively, while providing probability  estimates for the output classes. The probability maps are utilized for  higher level analysis such as a feedback for smoothing over the output label maps and the identification of unknown patterns (pattern "discovery").  The suggested approach is presented and demonstrated in the texture analysis task. A correct classification rate in the 90 percentile is achieved  for both unstructured and structured natural texture mosaics. The advantages of the probabilistic approach to pattern analysis are demonstrated.
Visual object recognition involves the identification of images of 3-D objects seen from arbitrary viewpoints. We suggest an approach to object  recognition in which a view is represented as a collection of points given  by their location in the image. An object is modeled by a set of 2-D views  together with the correspondence between the views. We show that any  novel view of the object can be expressed as a linear combination of the  stored views. Consequently, we build a linear operator that distinguishes  between views of a specific object and views of other objects. This operator can be implemented using neural network architectures with relatively  simple structures.
Intrator (1990) proposed a feature extraction method that is related to  recent statistical theory (Huber, 1985; Friedman, 1987), and is based on  a biologically motivated model of neuronal plasticity (Bienenstock et al.,  1982). This method has been recently applied to feature extraction in the  context of recognizing 3D objects from single 2D views (Intrator and Gold,  1991). Here we describe experiments designed to analyze the nature of the  extracted features, and their relevance to the theory and psychophysics of  object recognition.
The method of Structural Risk Minimization refers to tuning the capacity of the classifier to the available amount of training data. This capacity is influenced by several factors, including: (1) properties of the input space, (2) nature and structure of the classifier, and (3) learning algorithm. Actions based on these three factors are combined here to control the ca- pacity of linear classifiers and improve generalization on the problem of handwritten digit recognition. 
We developed a neural net architecture for segmenting complex  images, i.e., to localize two-dimensional geometrical shapes in a scene,  without prior knowledge of the objects' positions and sizes. A scale  variation is built into the network to deal with varying sizes. This algorithm has been applied to video images of railroad cars, to find their  identification numbers. Over 95% of the characters were located  correctly in a data base of 300 images, despite a large variation in lighting conditions and often a poor quality of the characters. A part of the  network is executed on a processor board containing an analog neural  net chip (Graf et al. 1991), while the rest is implemented as a software  model on a workstation or a digital signal processor.
We present a feed-forward network architecture for recognizing an unconstrained handwritten multi-digit string. This is an extension of previous  work on recognizing isolated digits. In this architecture a single digit recognizer is replicated over the input. The output layer of the network is  coupled to a Viterbi alignment module that chooses the best interpretation  of the input. Training errors are propagated through the Viterbi module.  The novelty in this procedure is that segmentation is done on the feature  maps developed in the Space Displacement Neural Network (SDNN) rather  than the input (pixel) space.
We present a neural network algorithm that simultaneously performs segmentation and recognition of input patterns that self-organizes to detect  input pattern locations and pattern boundaries. We demonstrate this neural network architecture on character recognition using the NIST database  and report on results herein. The resulting system simultaneously segments and recognizes touching or overlapping characters, broken characters, and noisy images with high accuracy.
This paper describes an approach, called centered object integrated segmentation and recognition (COISR), for integrating object segmentation and recognition within a single neural network. The application  is hand-printed character recognition. Two versions of the system are  described. One uses a backpropagation network that scans exhaustively over a field of characters and is trained to recognize whether  it is centered over a single character or between characters. When  it is centered over a character, the net classflies the cfiaracter. The  approach is tested on a dataset of hand-printed digits. Very low error  rates are reported. The second version, COISR-SACCADE, avoids  the need for exhaustive scans. The net is trained as before, but also  is trained to compute ballistic 'eye' movements that enable the input  window to jump from one character to the next.  The common model of visual processing includes multiple, independent stages. First,  filtering operations act on the raw image to segment or isolate and enhance to--be-recognized clumps. These clumps are normalized for factors such as size, and sometimes  simplified further through feature extraction. The results are then fed to one or more  classifiers. The operations prior to classification simplify the recognition task. Object  segmentation restricts the number of features considered for classification to those associated with a single object, and enables normalization to be applied at the individual  object level. Without such pre-processing, recognition may be an intractable problem.  However, a weak point of this sequential stage model is that recognition and segmentation decisions are often inter-dependent. Not only does a correct recognition decision  depend on first making a correct segmentation decision, but a correct segmentation  decision often depends on first making a correct recognition decision.  This is a particularly serious problem in character recognition applications. OCR systems use intervening white space and related features to segment a field of characters  into individual characters, so that classification can be accomplished one character at  a time. This approach fails when characters touch each other or when an individual  character is broken up by intervening white space. Some means of integrating the segmentation and recognition stages is needed.  This paper describes an approach, called centered object integrated segmentation and recognition (COISR), for integrating character segmentation and recognition within one  *Also with Eastman Kodak Company  Recognizing Overlapping Hand-Printed Characters 505  CENTERED  Net  I  I  NET'S OUTPUT  OVER TIME -..............__ .............. --NOT CENTERED  ;'?";'i '??;' ?;'?; '"?? "'" 7  9  Figure 1: The COISR Exhaustive Scan Approach.  neural network. The general approach builds on previous work in pre-segmented  character recognition (LeCun, Boser, Denker, Henderson, Howard, Hubbard, & Jackel, 1990; Martin & Pittman, 1990) and on the sliding window conception used in neural  network speech applications, such as NETtalk (Sejnowski & Rosenberg(1986) and  Time Delay Neural Networks (Wael, Sawai, & Shikano, 1988)?Two versions of the  approach are describbed. In both cases, a net is trained to recognize what is centered  in its input window as it slides along a character field. The window size is chosen to  be large enough to include more than one character.
Hand-printed digits can be modeled as splines that are governed by about  8 control points. For each known digit, the control points have preferred  "home" locations, and deformations of the digit are generated by moving  the control points away from their home locations. Images of digits can bc  produced by placing Gaussian ink generators uniformly along the spline.  Real images can be recognized by finding the digit model most likely to  have generated the data. For each digit model we use an elastic matching  algorithm to minimize an energy function that includes both the deformation energy of the digit model and the log probability that the model  would generate the inked pixels in the image. The model with the lowest  total energy wins. If a uniform noise process is included in the model of  image generation, some of the inked pixels can be rejected as noise as a  digit model is fitting a poorly segmented image. The digit models learn  by modifying the home locations of the control points.
A method is described for generating plan-like, reflexive, obstacle  avoidance behaviour in a mobile robot. The experiments reported here  use a simulated vehicle with a primitive range sensor. Avoidance  behaviour is encoded as a set of continuous functions of the perceptual  input space. These functions are stored using CMACs and trained by a  variant of Bano and Sutton's adaptive critic algorithm. As the vehicle  explores its surroundings it adapts its responses to sensory stimuli so  as to minimise the negative reinforcement arising from collisions.  Strategies for local navigation are therefore acquired in an explicitly  goal-driven fashion. The resulting trajectories form elegant collisionfree paths through the environment
Whenever an agent learns to control an unknown environment, two opposing principles have to be combined, namely: exploration (long-term optimization) and exploitation (short-term optimization). Many real-valued  connectionist approaches to learning control realize exploration by randomness in action selection. This might be disadvantageous when costs  are assigned to "negative experiences". The basic idea presented in this  paper is to make an agent explore unknown regions in a more directed  manner. This is achieved by a so-called competence map, which is trained  to predict the controller's accuracy, and is used for guiding exploration.  Based on this, a bistable system enables smoothly switching attention  between two behaviors exploration and exploitation depending on expected costs and knowledge gain.  The appropriateness of this method is demonstrated by a simple robot  navigation task.
A neural network solution is proposed for solving path planning problems  faced by mobile robots. The proposed network is a two-dimensional sheet  of neurons forming a distributed representation of the robot's workspace.  Lateral interconnections between neurons are "cooperative", so that the  network exhibits oscillatory behaviour. These oscillations are used to generate solutions of Bellman's dynamic programming equation in the context  of path planning. Simulation experiments imply that these networks locate  global optimal paths even in the presence of substantial levels of circuit  noise.
We present two neural network controller leaming schemes based on feedbackerror-learning and modular architecture for recognition and control of multiple  manipulated objects. In the first scheme, a Gating Network is trained to acquire  object-specific representations for recognition of a number of objects (or sets of  objects). In the second scheme, an Estimation Network is trained to acquire  function-specific, rather than object-specific, representations which directly estimate  physical parameters. Both recognition networks are trained to identify manipulated  objects using somatic and/or visual information. After learning, appropriate  motor commands for manipulation of each object are issued by the control  networks.
The KBANN approach uses neural networks to refine knowledge that can  be written in the form of simple propositional rules. We extend this idea  further by presenting the MANNCON algorithm by which the mathematical  equations governing a PID controller determine the topology and initial  weights of a network, which is further trained using backpropagation. We  apply this method to the task of controlling the outflow and temperature  of a water tank, producing statistically-significant gains in accuracy over  both a standard neural network approach and a non-learning PID controller. Furthermore, using the PID knowledge to initialize the weights of  the network produces statistically less variation in testset accuracy when  compared to networks initialized with small random numbers.
A method for transforming performance evaluation signals distal both in  space and time into proximal signals usable by supervised learning algorithms, presented in [Jordan & Jacobs 90], is examined. A simple observation concerning differentiation through models trained with redundant  inputs (as one of their networks is) explains a weakness in the original  architecture and suggests a modification: an internal world model that  encodes action-space exploration and, crucially, cancels input redundancy  to the forward model is added. Learning time on an example task, cartpole balancing, is thereby reduced about 50 to 100 times.
A large class of motor control tasks requires that on each cycle the controller is told its current state and must choose an action to achieve a  specified, state-dependent, goal behaviour. This paper argues that the  optimization of learning rate, the number of experimental control decisions before adequate performance is obtained, and robustness is of prime  importance--if necessary at the expense of computation per control cycle and memory requirement. This is motivated by the observation that  a robot which requires two thousand learning steps to achieve adequate  performance, or a robot which occasionally gets stuck while learning, will  always be undesirable, whereas moderate computational expense can be  accommodated by increasingly powerful computer hardware. It is not unreasonable to assume the existence of inexpensive 100 Mfiop controllers  within a few years and so even processes with control cycles in the low  tens of milliseconds will have millions of machine instructions in which to  make their decisions. This paper outlines a learning control scheme which  aims to make effective use of such computational power.
The backpropagation algorithm can be used for both recognition and generation of time trajectories. When used as a recognizer, it has been shown  that the performance of a network can be greatly improved by adding  structure to the architecture. The same is true in trajectory generation.  In particular a new architecture corresponding to a "reversed" TDNN is  proposed. Results show dramatic improvement of performance in the generation of hand-written characters. A combination of TDNN and reversed  TDNN for compact encoding is also suggested.
We introduce and demonstrate a bootstrap method for construction of an inverse function for the robot kinematic mapping using only sample configurationspace/workspace data. Unsupervised learning (clustering) techniques are used on  pre-image neighborhoods in order to learn to partition the configuration space  into subsets over which the kinematic mapping is invertible. Supervised learning is then used separately on each of the partitions to approximate the inverse  function. The ill-posed inverse kinematics function is thereby regularized, and  a global inverse kinematics solution for the wristless Puma manipulator is developed.
Accurate saccades require interaction between brainstem circuitry and the  cerebellum. A model of this interaction is described, based on Kawato's  principle of feedback-error-learning. In the model a part of the  brainstem (the superior colliculus) acts as a simple feedback controller  with no knowledge of initial eye position, and provides an error signal  for the cerebellum to correct for eye-muscle nonlinearities. This teaches  the cerebellum, modelled as a CMAC, to adjust appropriately the gain  on the brainstem burst-generator's internal feedback loop and so alter the  size of burst sent to the motoneurons. With direction-only errors the  system rapidly learns to make accurate horizontal eye movements from  any starting position, and adapts realistically to subsequent simulated  eye-muscle weakening or displacement of the saccadic target.
Vestibular compensation is the process whereby normal functioning is  rgained following destruction of one member of the pair of peripheral  vestibular receptors. Compensation was simulated by lesioning , dynamic  neural network model of the vestibulo-ocular rflex O/OR) and retraining it  using recurrent back-propagation. The model reproduced the paneam of VOR  neuron activity experimentally observed in compensated animals, but only if  connections hertofor considered uninvolved were allowed to be plastic.  Because the model incorporated nonlinear units, it was able to reconcile  previously conflicting, linear analyses of experimental results on the dynamic  properties of VOR neurons in normal and coted animals.
A neurophysiologica]ly-based model is presented that controls a simulated  kinematic arm during goal-directed reaches. The network generates a  quasi-feedforward motor command that is learned using training signals  generated by corrective movements. For each target, the network selects  and sets the output of a subset of pattern generators. During the movement, feedback from proprioceptors turns off the pattern generators. The  task facing individual pattern generators is to recognize when the arm  reaches the target and to turn off. A distributed representation of the motor command that resembles population vectors seen in io was produced  naturally by these simulations.
Using the double-step target displacement paradigm the mechanisms underlying arm trajectory modification were investigated. Using short (10110 msec) inter-stimulus intervals the resulting hand motions were initially  directed in between the first and second target locations. The kinematic  features of the modified motions were accounted for by the superposition  scheme, which involves the vectorial addition of two independent point-topoint motion units: one for moving the hand toward an internally specified  location and a second one for moving between that location and the final  target location. The similarity between the inferred internally specified locations and previously reported measured end-points of the first saccades  in double-step eye-movement studies may suggest similarities between perceived target locations in eye and hand motor control.
This work discusses various optimization techniques which were  proposed in models for controlling arm movements. In particular, the  minimum-muscle-tension-change model is investigated. A dynamic  simulator of the monkey's arm, including seventeen single and double  joint muscles, is utilized to generate horizontal hand movements. The  hand trajectories produced by this algorithm are discussed.
Current Inlxa-Cardia defibnllators make use of simple classification algorithms to determine patient conditions and subsequently to enable proper  therapy. The simplicity is primarily due to the constraints on power dissipation and area available for implememation. Sub-threshold implementation  of artificial neural networks offer potential classifiers with higher performance than commercially available defibrillators. In this paper we explore  several classifier architectures and discms micro-electromc implementation  issues.
Avascular necrosis (AVN) of the femoral head is a common yet potentially serious disorder which can be detected in its very early stages with  magnetic resonance imaging. We have developed multi-layer perceptron  networks, trained with conjugate gradient optimization, which diagnose  AVN from single magnetic resonance images of the fernoral head with  100% accuracy on training data and 97% accuracy on test data.
Automated monitoring of vigilance in attention intensive tasks such as  air trafiic control or sonar operation is highly desirable. As the operator monitors the instrument, the instrument would monitor the operator,  insuring against lapses. We have taken a first step toward this goal by using feedforward neural networks trained with backpropagation to interpret  event related potentials (El{Ps) and electroencephalogram (EEG) associated with periods of high and low vigilance. The accuracy of our system on  an ERP data set averaged over 28 minutes was 96%, better than the 83%  accuracy obtained using linear discriminant analysis. Practical vigilance  monitoring will require prediction over shorter time periods. We were able  to average the El{P over as little as 2 minutes and still get 90% correct  prediction of a vigilance measure. Additionally, we achieved similarly good  performance using segments of EEG power spectrum as short as 56 sec.
In a Bayesian framework, we give a principled account of how domainspecific prior knowledge such as imperfect analytic domain theories can be  optimally incorporated into networks of locally-tuned units: by choosing  a specific architecture and by applying a specific training regimen. Our  method proved successful in overcoming the data deficiency problem in  a large-scale application to devise a neural control for a hot line rolling  mill. It achieves in this application significantly higher accuracy than  optimally-tuned standard algorithms such as sigmoidal backpropagation,  and outperforms the state-of-the-art solution.
We describe in this paper a novel application of neural networks to system  health monitoring of a large antenna for deep space communications. The  paper outlines our approach to building a monitoring system using hybrid  signal processing and neural network techniques, including autoregressive  modelling, pattern recognition, and Hidden Markov models. We discuss  several problems which are somewhat generic in applications of this kind  -in particular we address the problem of detecting classes which were  not present in the training data. Experimental results indicate that the  proposed system is sufficiently reliable for practical implementation.
This paper deals with an application of Neural Networks to satellite  remote sensing observations. Because of the complexity of the  application and the large amount of data, the problem cannot be solved  by using a single method. The solution we propose is to build multimodules NN architectures where several NN cooperate together. Such  system suffer from generic problem for whom we propose solutions.  They allow to reach accurate performances for multi-valued function  approximations and probability estimations. The results are compared  with six other methods which have been used for this problem. We  show that the methodology we have developed is general and can be  used for a large variety of applications.  675  676 Thiria, Mejia, Badran, and Cr6pon
The notion of generalization ability can be defined precisely as the prediction risk, the expected performance of an estimator in predicting new  observations. In this paper, we propose the prediction risk as a measure  of the generalization ability of multi-layer perceptton networks and use it  to select an optimal network architecture from a set of possible architectures. We also propose a heuristic search strategy to explore the space of  possible architectures. The prediction risk is estimated from the available  data; here we estimate the prediction risk by v-fold cross-validation and  by asymptotic approximations of generalized cross-validation or Akaike's  final prediction error. We apply the technique to the problem of predicting  corporate bond ratings. This problem is very attractive as a case study,  since it is characterized by the limited availability of the data and by the  lack of a complete a priori model which could be used to impose a structure  to the network architecture.
We present an a. pproach for development of a decoder for any complex  binary error-correcting code (ECC) via training fi'om examples of decoded  received words. Our decoder is a connectionist architecture. We describe  two separate solutions: A systeln-level solution (the Cascaded Networks  Decoder); and the ECC-Enha.nced Decoder, a solution which simplifies  the mapping problem which nmst be solved for decoding. Although both  solutions meet our basic approach constraint for simplicity and compactness, only the ECC-Enhanced Decoder meets our second basic constraint  of being a generic solution.
In this paper, a tree based neural network viz. MARS (Friedman, 1991) for  the modelling of the yield strength of a steel rolling plate mill is described.  The inputs to the time series model are temperature, strain, strain rate,  and interpass time and the output is the corresponding yield stress. It  is found that the MARS-based model reveals which variable's functional  dependence is nonlinear, and significant. The results are compared with  those obtained by using a Kalman filter based online tuning method and  other classification methods, e.g. CART, C4.5, Bayesian classification. It  is found that the MARS-based method consistently outperforms the other  methods.
Five experiments were performed using several neural network architectures to  identify the location of a wave in the time ordered graphical results from a  medical test. Baseline results from the first experiment found correct  identification of the target wave in 85% of cases (n=20). Other experiments  investigated the effect of different architectures and preprocessing the raw data on  the results. The methods used seem most appropriate for time oriented graphical  data which has a clear starting point such as electrophoresis or spectrometry  rather than continuous tests such as ECGs and EEGs.
This paper briefly describes an artificial neural network for pre;ttentive  visual processing. The network is capable of dctermiuing image motion in  a type of stimulus which defeats most popular methods of lnotion detection  a subset of second-order visual motion stimuli known as drift-balanced  stimuli(DBS). The processing stages of the network described in this paper  are integratable into a model capable of simultaneous motion extraction.  edge detection, and the determination of occlusion.
A routing scheme that uses a neural network has been developed that can  aid in establishing point-to-point communication routes through multistage interconnection networks (MINs). The neural network is a network  of the type that was examined by Hopfield (Hopfield, 1984 and 1985).  In this work, the problem of establishing routes through random MINs  (RMINs) in a shared-memory, distributed computing system is addressed.  The performance of the neural network routing scheme is compared to two  more traditional approaches exhaustive search routing and greedy routing. The results suggest that a neural network router may be competitive  for certain RMINs.
We have created new networks to unmix signals which have been  mixed either with time delays or via filtering. We first show that  a subset of the Hrault-Jutten learning rules fulfills a principle of  minimum output power. We then apply this principle to extensions  of the Hdrault-Jutten network which have delays in the feedback  path. Our networks perform well on real speech and music signals  that have been mixed using time delays or filtering.
A CCD-based processor that we call the NNC2 is presented. The NNC2  implements a fully connected 192-input, 32-output two-layer network and  can be cascaded to form multilayer networks or used in parallel for additional input or output nodes. The device computes 1.92 x 10 e connections/see when clocked at 10 MHz. Network weights can be specified to six  bits of accuracy and are stored on-chip in programmable digital memories.  A neural network pattern recognition system using NNC2 and CCD image feature extractor (IFE) devices is described. Additionally, we report  a CCD output circuit that exploits inherent nonlinearities in the charge  injection process to realize an adjustable-threshold sigmoid in a chip area  of 40 x 80 ]1112.
A CCD based signal processing IC that computes a fully parallel single  quadrant vector-matrix multiplication has been designed and fabricated with a  2}.tm CCD/CMOS process. The device incorporates an array of Charge  Coupled Devices (CCD) which hold an analog matrix of charge encoding the  matrix elements. Input vectors are digital with 1 8 bit accuracy.
Biological retinas extract spatial and temporal features in an attempt to  reduce the complexity of performing visual tasks. We have built and tested  a silicon retina which encodes several useful temporal features found in vertebrate retinas. The cells in our silicon retina are selective to direction,  highly sensitive to positive contrast changes around an ambient light level,  and tuned to a particular velocity. Inhibitory connections in the null direction perform the direction selectivity we desire. This silicon retina is  on a 4.6 x 6.8ram die and consists of a 47 x 41 array of photoreceptors.
The goal of perception is to extract invariant properties of the underlying world. By computing contrast at edges, the retina reduces incident  light intensities spanning twelve decades to a twentyfold variation. In one  stroke, it solves the dynamic range problem and extracts relative reflectivity, bringing us a step closer to the goal. We have built a contrastsensitive silicon retina that models all major synaptic interactions in the  outer-plexiform layer of the vertebrate retina using current-mode CMOS  circuits: namely, reciprocal synapses between cones and horizontal cells,  which produce the antagonistic center/surround receptive field, and cone  and horizontal cell gap junctions, which determine its size. The chip has  90 x 92 pixels on a 6.8 x 6.9mm die in 2pm n-well technology and is fully  functional.
A board is described that contains the ANNA neural-network chip, and a  DSP32C digital signal processor. The ANNA (Analog Neural Network  Arithmetic unit) chip performs mixed analog/digital processing. The  combination of ANNA with the DSP allows high-speed, end-to-end execution of numerous signal-processing applications, including the preprocessing, the neural-net calculations, and the postprocessing steps. The  ANNA board evaluates neural networks 10 to 100 times faster than the  DSP alone. The board is suitable for implementing large (million connections) networks with sparse weight matrices. Three applications have  been implemented on the board: a convolver network for slant detection  of text blocks, a handwritten digit recognizer, and a neural network for  recognition-based segmentation.
Experimental research on Artificial Neural Network (ANN) algorithms requires  either writing variations on the same program or making one monolithic program  with many parameters and options. By using an object-oriented library, the size  of these experimental programs is reduced while making them easier to read,  write and modify. An efficient and flexible realization of this idea is Connectionist Layered Object-oriented Network Simulator (CLONES). CLONES runs on  UNIX  workstations and on the 100-1000 MFLOP Ring Array Processor (RAP)  that we built with ANN algorithms in mind. In this report we describe CLONES  and show how it is implemented on the RAP.
We use constrained optimization to select operating parameters for two  circuits: a simple 3-transistor square root circuit, and an analog VLSI  artificial cochlea. This automated method uses computer controlled measurement and test equipment to choose chip parameters which minimize  the difference between the actual circuit's behavior and a specified goal  behavior. Choosing the proper circuit parameters is important to compensate for manufacturing deviations or adjust circuit performance within  a certain range. As biologically-motivated analog VLSI circuits become  increasingly complex, implying more parameters, setting these parameters  by hand will become more cumbersome. Thus an automated parameter  setting method can be of great value [Fleischer 90]. Automated parameter  setting is an integral part of a goal-based engineering design methodology  in which circuits are constructed with parameters enabling a wide range  of behaviors, and are then "tuned" to the desired behaviors automatically.
A novel segmentation algorithm has been developed utilizing an absolutevalue Slnoothness penalty instead of the more common quadratic regularizer. This functional ilnposes a piece-wise constant constraint on the  segmented data. Since the lninilnized energy is guaranteed to be coilvex,  there are no problems with local lninima and no complex continuation  methods are necessary to find the unique global minimum. By interpreting the minimized energy as the generalized power of a nonlinear resistive  network, a continuous-time analog segmentation circuit was constructed.
We present experimental data from an analog CMOS LSI chip that implements the Herault-Jutten adaptive neural network. Testing procedures  and results in time and frequency-domain are described. These include  weight convergence trajectories, extraction of a signal in noise, and separation of statistically complex signals such as speech.
Many auditory theorists consider the temporal adaptation of the  auditory nerve a key aspect of speech coding in the auditory periphery. Experiments with models of auditory localization and pitch  perception also suggest temporal adaptation is an important element of practical auditory processing. I have designed, fabricated,  and successfully tested an analog integrated circuit that models  many aspects of auditory nerve response, including temporal adaptation.
We demonstrate a self-organizing system based on photorefractive ring oscillators. We employ the system in two ways that  can both be thought of as feature extractors; one acts on a set  of images exposed repeatedly to the system strictly as a linear  feature extractor, and the other serves as a signal demultiplexer for fiber optic communications. Both systems implement  unsupervised competitive learning embedded within the mode  interaction dynamics between the modes of a set of ring oscillators. After a training period, the modes of the rings become associated with the different image features or carrier  frequencies within the incoming data stream.
Learning is posed as a problem of function estimation, for which two principles of solution are considered: empirical risk minimization and structural  risk minimization. These two principles are applied to two different statements of the function estimation problem: global and local. Systematic  improvements in prediction power are illustrated in application to zip-code  recognition.
The Bayesian model comparison framework is reviewed, and the Bayesian  Occam's razor is explained. This framework can be applied to feedforward  networks, making possible (1) objective comparisons between solutions  using alternative network architectures; (2) objective choice of magnitude  and type of weight decay terms; (3) quantified estimates of the error bars  on network parameters and on network output. The framework also generates a measure of the effective number of parameters determined by the  data.  The relationship of Bayesian model comparison to recent work on prediction of generalisation ability (Guyon el ai., 1992, Moody, 1992) is discussed.
We present an analysis of how the generalization performance (expected  test set error) relates to the expected training set error for nonlinear learning systems, such as multilayer perceptrons and radial basis functions. The  principal result is the following relationship (computed to second order)  between the expected test set and training set errors:  (1)  2 is the effective noise  Here, n is the size of the training sample , O'eff  variance in the response variable(s),  is a regularization or weight decay  parameter, and p,ij(A) is the effective number of parameters in the nonlinear model. The expectations ( ) of training set and test set errors are  taken over possible training sets  and training and test sets f t respectively. The effective number of parameters p,ij, (A) usually differs from the  true number of model parameters p for nonlinear or regularized models;  this theoretical conclusion is supported by Monte Carlo experiments. In  addition to the surprising result that p,ii (A)  p, we propose an estimate  of (1) called the generalized prediction error(GPE) which generalizes well  established estimates of prediction risk such as Akaike's FPE and AIC,  Mallows Cp, and Barron's PSE to the nonlinear setting. 1  GPE and p,fi(A) were previously introduced in Moody (1991). 847  848 Moody
In this paper we investigate an average-case model of concept learning, and  give results that place the popular statistical physics and VC dimension  theories of learning curve behavior in a common framework.
The complexity of learning in shallow I-Dimensional neural networks has  been shown elsewhere to be linear in the size of the network. However,  when the network has a huge number of units (as cortex has) even linear  time might be unacceptable. Furthermore, the algorithm that was given to  achieve this time was based on a single serial processor and was biologically  implausible.  In this work we consider the more natural parallel model of processing  and demonstrate an expected-time complexity that is constant (i.e. independent of the size of the network). This holds even when inter-node  communication channels are short and local, thus adhering to more biological and VLSI constraints.
We report learning measurements from a system composed of a cascadable  learning chip, data generators and analyzers for training pattern presentation,  and an X-windows based software interface. The 32 neuron learning chip has  496 adaptive synapses and can perform Boltzmann and mean-field learning  using separate noise and gain controls. We have used this system to do learning  experiments on the parity and replication problem. The system set fling time  limits the learning speed to about 100,000 patterns per second roughly  independent of system size.
This paper applies the theory of Probably Approximately Correct (PAC)  learning to multiple output feedforward threshold networks in which the  weights conform to certain equivalences. It is shown that the sample size  for reliable learning can be bounded above by a formula similar to that  required for single output networks with no equivalences. The best previously obtained bounds are improved for all cases.
Batch gradient descent, Aw(/) --rldE/dw(t), converes to a minimum  of quadratic form with a time constant no better than Amax/Ami n where  Ami n and Amax are the minimum and maximum eigenvalues of the Hessian  matrix of E with respect to w. It was recently shown that adding a  momentum term Aw(t) ----rldE/dw(t ) q-cAw(t1) improves this to  ¬ X/Amax/Amin, although only in the batch case. Here we show that secondorder momentum, Aw(/) --rldE/dw(t ) qcAw(t1)qfiAw(t2), can  lower this no further. We then regard gradient descent with momentum  as a dynamic system and explore a nonquadratic error surface, showing  that saturation of the error accounts for a variety of effects observed in  simulations and justifies some popular heuristics.
In many machine learning applications, one has access, not only to training  data, but also to some high-level a priori knowledge about the desired behavior of the system. For example, it is known in advance that the output  of a character recognizer should be invariant with respect to small spatial distortions of the input images (translations, rotations, scale changes,  etcetera).  We have implemented a scheme that allows a network to learn the derivative of its outputs with respect to distortion operators of our choosing.  This not only reduces the learning time and the amount of training data,  but also provides a powerful language for specifying what generalizations  we wish the network to perform.
We define the concept of polynomial uniform convergence of relative  frequencies to probabilities in the distribution-dependent context. Let  X = {0, 1} , let P be a probability distribution on X and let F C 2 x'  be a family of events. The family {(X,,P,, F,)}>i has the property  of polynomial uniform convergence if the probability that the maximum  difference (over F) between the relative frequency and the probability of an event exceed a given positive e be at most 5 (0 < 5 < 1),  when the sample on which the frequency is evaluated has size polynomial  in n, 1/e,1/5. Given a t-sample (Xl,...,xt), let C(nt)(Xl,...,Xt) be the  Vapnik-Chervonenkis dimension of the family {{Xl,...,xt} FI f lf e Fn}  and M(n,t) the expectation E(C(nt)/t). We show that {(Xn,Pn, Fn)}n>i  has the property of polynomial uniform convergence iff there exists/ > 0  such that M(n,t) = O(n/t). Applications to distribution-dependent  PAC learning are discussed.
We study a particular type of Boltzmann machine with a bipartite graph structure called a harm  nium. Our interest is in using such a machine to model a probability distribution on binary input  vectors. We analyze the class of probability distributions that can be modeled by such machines,  showing that for each n _ I this class includes arbitrarily good apprximation to any distribution  on the set of all n-vectors of binary inputs. We then present two learning algorithms for these  machines.. The first learning algorithm is the standard gradient ascent heuristic for computing  maximum likelihood estimates for the parameters (i.e. weights and thresholds) of the model. Here  we give a closed form for this gradient that is significantly easier to compute than the corresponding  gradient for the general Boltzmann machine. The second learning algorithm is a greedy method  that creates the hidden units and computes their weights one at a time. This method is a variant  of the standard method for projection pursuit density estimation. We give experimental results for  these learning methods on synthetic data and natural data from the domain of handwritten digits.
We present a distribution-free model for incremental learning when concepts vary  with time. Concepts are caused to change by an adversary while an incremental  learning algorithm attempts to track the changing concepts by minimizing the  error between the current target concept and the hypothesis. For a single halfplane and the intersection of two half-planes, we show that the average mistake  rate depends on the maximum rate at which an adversary can modify the concept.  These theoretical predictions are verified with simulations of several learning  algorithms including back propagation.
A general relationship is developed between the VC-dimension and the  statistical lower epsilon-capacity which shows that the VC-dimension can  be lower bounded (in order) by the statistical lower epsilon-capacity of a  network trained with random samples. This relationship explains quantitatively how generalization takes place after memorization, and relates  the concept of generalization (consistency) with the capacity of the optimal  classifier over a class of classifiers with the same structure and the capacity  of the Bayesian classifier. Furthermore, it provides a general methodology  to evaluate a lower bound for the VC-dimension of feedforward multilayer  neural networks.  This general methodology is applied to two types of networks which are  important for hardware implementations: two layer (N 2L 1) networks with binary weights, integer thresholds for the hidden units and  zero threshold for the output unit, and a single neuron ((N1) networks) with binary weigths and a zero threshold. Specifically, we obtain  w , O(N). Here W is the total number  O(?WE ) _ d2 _ O(W) and dl ~  of weights of the (N 2L 1) networks. dl and d2 represent the VCdimensions for the (N1) and (N2L1) networks respectively.
This paper will address an important question in machine learning: What  kind of network architectures work better on what kind of problems? A  projection pursuit learning network has a very similar structure to a one  hidden layer sigmoidal neural network. A general method based on a  continuous version of projection pursuit regression is developed to show  that projection pursuit regression works better on angular smooth functions than on Laplacian smooth functions. There exists a ridge function  approximation scheme to avoid the curse of dimensionality for approximating functions in
An important issue in neural computation is the dynamic range of weights  in the neural networks. Many experimental results on learning indicate  that the weights in the networks can grow prohibitively large with the  size of the inputs. Here we address this issue by studying the tradeoffs  between the depth and the size of weights in polynomial-size networks  of linear threshold elements (LTEs). We show that there is an efficient  way of simulating a network of LTEs with large weights by a network  of LTEs with small weights. In particular, we prove that every depth-d,  polynomial-size network of LTEs with e:ponentially large integer weights  can be simulated by a depth-(2d + 1), polynomial-size network of LTEs  with polynomially bounded integer weights. To prove these results, we  use tools from harmonic analysis of Boolean functions. Our technique is  quite general, it provides insights to some other problems. For example,  we are able to improve the best known results on the depth of a network  of linear threshold elements that computes the COMPARISON, SUM  and PRODUCT of two n-bits numbers, and the MAXIMUM and the  SORTING of n n-bit numbers.
It has been observed in numerical simulations that a weight decay can improve generalization in a feed-forward neural network. This paper explains  why. It is proven that a weight decay has two effects in a linear network.  First, it suppresses any irrelevant components of the weight vector by  choosing the smallest vector that solves the learning problem. Second, if  the size is chosen right, a weight decay can suppress some of the effects of  static noise on the targets, which improves generalization quite a lot. It  is then shown how to extend these results to networks with hidden layers  and non-linear units. Finally the theory is confirmed by some numerical  simulations using the data from NetTalk.
"Best-first model merging" is a general technique for dynamically  choosing the structure of a neural or related architecture while avoiding overtilting. It is applicable to both learning and recognition tasks  and often generalizes significantly better than fixed structures. We demonstrate the approach applied to the tasks of choosing radial basis functions for function learning, choosing local affine models for curve and  constraint surface modelling, and choosing the structure of a baHtree or  bumptree to maximize efficiency of access.
We describe a neural network, called RuleNet, that learns explicit, symbolic condition-action rules in a formal string manipulation domain.  RuleNet discovers functional categories over elements of the domain,  and, at various points during learning, extracts rules that operate on  these categories. The rules are then injected back into RuleNet and  training continues, in a process called iterative projection. By incorporating rules in this way, RuleNet exhibits enhanced learning and generalization performance over alternative neural net approaches. By  integrating symbolic rule learning and subsymbolic category learning,  RuleNet has capabilities that go beyond a purely symbolic system. We  show how this architecture can be applied to the problem of case-role  assignment in natural language processing, yielding a novel rule-based  solution.
We propose and empirically evaluate a method for the extraction of expertcomprehensible rules from trained neural networks. Our method operates in  the context of a three-step process for learning that uses rule-based domain  knowledge in combination with neural networks. Empirical tests using realworlds problems from molecular biology show that the rules our method extracts  from trained neural networks: closely reproduce the accuracy of the network  from which they came, are superior to the rules derived by a learning system that  directly refines symbolic rules, and are expert-comprehensible.
In this paper we present a neural network architecture that discovers a  recursive decomposition of its input space. Based on a generalization of the  modular architecture of Jacobs, Jordan, Nowlan, and Hinton (1991), the  architecture uses competition among networks to recursively split the input  space into nested regions and to learn separate associative mappings within  each region. The learning algorithm is shown to perform gradient ascent  in a log likelihood function that captures the architecture's hierarchical  structure.
One way of simpli'ing neural networks so they generalize better is to add  an extra term Io the error function that will penalize complexity. We  propose a new penalty term in which the distribution of weight values  is modelled as a mixture of multiple gaussians. Under this model, a set  of weights is simple if the weights can be clustered into subsets so that  the weights in each cluster have similar values. We allow the parameters  of the mixture model to adapt at t. he same time as the network learns.  Simulations demonstrate that this complexity term is more effective than  previous complexity terms.
An alternative to the typical technique of selecting training examples  independently from a fixed distribution is formulated and analyzed, in  which the current example is presented repeatedly until the error for that  item is reduced to some criterion value, [; then, another item is randomly selected. The convergence time can be dramatically increased or  decreased by this heuristic, depending on the task, and is very sensitive  to the value of [.
Stochastic gradient descent is a general algorithm which includes LMS,  on-line backpropagation, and adaptive k-means clustering as special cases.  The standard choices of the learning rate /(both adaptive and fixed functions of time) often perform quite poorly. In contrast, our recently proposed class of "search then converge" learning rate schedules (Darken and  Moody, 1990) display the theoretically optimalasymptotic convergence rate  and a superior ability to escape from poor local minima. However, the user  is responsible for setting a key parameter. We propose here a new methodology for creating the first completely automatic adaptive learning rates  which achieve the optimal rate of convergence.
Although the detection of invariant structure in a given set of input patterns is  vital to many recognition tasks, connectionist learning rules tend to focus on  directions of high variance (principal components). The prediction paradigm is  often used to reconcile this dichotomy; here we suggest a more direct approach  to invariant learning based on an anti-Hebbian learning rule. An unsupervised  two-layer network implementing this method in a competitive setting learns to  extract coherent depth information from random-dot stereograms.
Several parallel analogue algorithms, based upon mean field theory (MFT)  approximations to an underlying statistical mechanics formulation, and requiring an externally prescribed annealing schedule, now exist for finding  approximate solutions to difficult combinatorial optimisation problems.  They have been applied to the Travelling Salesman Problem (TSP), as  well as to various issues in computational vision and cluster analysis. I  show here that any given MFT algorithm can be combined in a natural  way with notions from the areas of constrained optimisation and adaptive  simulated annealing to yield a single homogenous and efficient parallel relaxation technique, for which an externally prescribed annealing schedule  is no longer required. The results of numerical simulations on 50-city and  100-city TSP problems are presented, which show that the ensuing algorithms are typically an order of magnitude faster than the MFT algorithms  alone, and which also show, on occasion, superior solutions as well.
One method proposed for improving the generalization capability of a feedforward network trained with the backpropagation algorithm is to use  artificial training vectors which are obtained by adding noise to the original training vectors. We discuss the connection of such backpropagation  training with noise to kernel density and kernel regression estimation. We  compare by simulated examples (1) backpropagation, (2) backpropagation  with noise, and (3) kernel regression in mapping estimation and pattern  classification contexts.
Connections between spline approximation, approximation with rational  functions, and feedforward neural networks are studied. The potential  improvement in the degree of approximation in going from single to two  hidden layer networks is examined. Some results of Bitman and So]omjak  regarding the degree of approximation achievable when knot positions are  chosen on the basis of the probability distribution of examples rather than  the function values are extended.
Feedforward networks composed of units which compute a sigmoidal function of a weighted sum of their inputs have been much investigated. We  tested the approximation and estimation capabilities of networks using  functions more complex than sigmoids. Three classes of functions were  tested: polynomials, rational functions, and flexible Fourier series. Unlike sigmoids, these classes can fit non-monotonic functions. They were  compared on three problems: prediction of Boston housing prices, the  sunspot count, and robot arm inverse dynamics. The complex units attained clearly superior performance on the robot arm problem, which is  a highly non-monotonic, pure approximation problem. On the noisy and  only mildly nonlinear Boston housing and sunspot problems, differences  among the complex units were revealed; polynomials did poorly, whereas  rationals and flexible Fourier series were comparable to sigmoids.
This paper is concerned with the problem of learning in networks where some  or all of the functions involved are not smooth. Examples of such networks are  those whose neural transfer functions are piecewise-linear and those whose error  function is defined in terms of the  norm.  Up to now, networks whose neural transfer functions are piecewise-linear have  received very little consideration in the literature, but the possibility of using an  earor function defined in terms of the  norm has received some attention. In  this latter work, however, the problems that can occur when gradient methods are  used for nonsmooth error functions have not been addressed.  In this paper we draw upon some recent results from the field of nonsmooth  optimi?ofion (NSO) to present an algorithm for the nonsmooth case. Our motivation for this work arose out of the fact that we have been able to show that,  in backpropagation, an error function based upon the  norm overcomes the  difficulties which can occur when using the 2 norm.
We present an iterative algorithm for nonlinear regression based on construction of sparse polynomials. Polynomials are built sequentially from  lower to higher order. Selection of new terms is accomplished using a novel  look-ahead approach that predicts whether a variable contributes to the  remaining error. The algorithm is based on the tree-growing heuristic in  LMS Trees which we have extended to approximation of arbitrary polynonrials of the input features. In addition, we provide a new theoretical  justification for this heuristic approach. The algorithm is shown to discover a known polynomial from samples, and to make accurate estimates  of pixel values in an image-processing task.
A constructive algorithm is proposed for feed-forward neural networks,  which uses node-splitting in the hidden layers to build large networks from  smaller ones. The small network forms an approximate model of a set of  training data, and the split creates a larger more powerful network which is  initialised with the approximate solution already found. The insufficiency  of the smaller network in modelling the system which generated the data  leads to oscillation in those hidden nodes whose weight vectors cover regions in the input space where more detail is required in the model. These  nodes are identified and split in two using principal component analysis,  allowing the new nodes to cover the two main modes of each oscillating  vector. Nodes are selected for splitting using principal component analysis  on the oscillating weight vectors, or by examining the Hessian matrix of  second derivatives of the network error with respect to the weights. The  second derivative method can also be applied to the input layer, where it  provides a useful indication of the relative importances of parameters for  the classification task. Node splitting in a standard Multi Layer Perceptton is equivalent to introducing a hinge in the decision boundary to allow  more detail to be learned. Initial results were promising, but further evaluation indicates that the long range effects of decision boundaries cause  the new nodes to slip back to the old node position, and nothing is gained.  This problem does not occur in networks of localised receptive fields such  as radial basis functions or ganssian mixtures, where the technique appears  to work well.  1072  Node Splitting: A Contructive Algorithm for Feed-Forward Neural Networks 1073
Automatic determination of proper neural network topology by trimming  over-sized networks is an important area of study, which has previously  been addressed using a variety of techniques. In this paper, we present  Information Measure Based Skeletonisation (IMBS), a new approach to  this problem where superfluous hidden units are removed based on their  information measure (IM). This measure, borrowed from decision tree induction techniques, reflects the degree to which the hyperplane formed  by a hidden unit discriminates between training data classes. We show  the results of applying IMBS to three classification tasks and demonstrate  that it removes a substantial number of hidden units without significantly  affecting network performance.
G/SPLINES is an algorithm for building functional models of data. It  uses genetic search to discover combinations of basis functions which  are then used to build a least-squares regression model. Because it  produces a population of models which evolve over time rather than a  single model, it allows analysis not possible with other regression-based  approaches.
David J.C. MacKay  California Institute of Technology 139-74  Pasadena CA 91125 U.S.A  We derive criteria for training adaptive classifier networks to perform unsupervised data analysis. The first criterion turns a simple Gaussian classifier  into a simple Gaussian mixture analyser. The second criterion, which is  much more generally applicable, is based on mutual information. It simplifies to an intuitively reasonable difference between two entropy functions,  one encouraging 'decisiveness,' the other 'fairness' to the alternative interpretations of the input. This 'firm but fair' criterion can be applied  to any network that produces probability-type outputs, but it does not  necessarily lead to useful behavior.
The localized linear discriminant network (LLDN) has been designed to address  classification problems containing relatively closely spaced data from different  classes (encounter zones [1], the accuracy problem [2]). Locally trained hyperplane segments are an effective way to define the decision boundaries for these  regions [3]. The LLD uses a modified perceptron training algorithm for effective  discovery of separating hyperplane/sigmoid units within narrow boundaries. The  basic unit of the network is the discriminant receptive field (DRF) which combines  the LLD function with Gaussians representing the dispersion of the local training  data with respect to the hyperplane. The DRF implements a local distance measure [4], and obtains the benefits of networks of localized units [5]. A constructive  algorithm for the two-class case is described which incorporates DRF's into the  hidden layer to solve local discrimination problems. The output unit produces a  smoothed, piecewise linear decision boundary. Preliminary results indicate the  ability of the LLDN to efficiently achieve separation when boundaries are narrow  and complex, in cases where both the "standard" multilayer perceptron (MLP)  and k-nearest neighbor (KNN) yield high error rates on training data.
The Probabilistic Neural Network (PNN) algorithm represents the likelihood function of a given class as the sum of identical, isotropic Gaussians.  In practice, PNN is often an excellent pattern classifier, outperforming  other classifiers including backpropagation. However, it is not robust with  respect to affine transformations of feature space, and this can lead to  poor performance on certain data. We have derived an extension of PNN  called Weighted PNN (WPNN) which compensates for this flaw by allowing anisotropic Gaussians, i.e. Gaussians whose covariance is not a multiple of the identity matrix. The covariance is optimized using a genetic  algorithm, some interesting features of which are its redundant, logarithmic encoding and large population size. Experimental results validate our  claims.
We designed and trained a connectionist network to generate  letterforms in a new font given just a few exemplars from  that font. During learning, our network constructed a  distributed internal representation of fonts as well as letters,  despite the fact that each training instance exemplified both a  font and a letter. It was necessary to have separate but  interconnected hidden units for "letter" and "font"  representations m several alternative architectures were not  successful.
We compare two strategies for training connectionist (as well as nonconnectionist) models for statistical pattern recognition. The probabilistic strategy is based on the notion that Bayesian discrimination (i.e., optimal classification) is achieved when the classifier learns the a posteriori class distributions of  the random feature vector. The differential strategy is based on the notion that  the identity of the largest class a posteriori probability of the feature vector is  all that is needed to achieve Bayesian discrimination. Each strategy is directly  linked to a family of objective functions that can be used in the supervised training  procedure. We prove that the probabilistic strategy -linked with error measure  objective functions such as mean-squared-error and cross-entropy -typically  used to train classifiers necessarily requires larger training sets and more complex  classifier architectures than those needed to approximate the Bayesian discriminant function. In contrast, we prove that the differential strategy  linked  with classificationfigure-of-merit objective functions (CFMo) [3]  requires  the minimum classifier functional complexity and the fewest training examples  necessary to approximate the Bayesian discriminant function with specified precision (measured in probability of error). We present our proofs in the context of  a game of chance in which an unfair C-sided die is tossed repeatedly. We show  that this rigged game of dice is a paradigm at the root of all statistical pattern  recognition tasks, and demonstrate how a simple extension of the concept leads  us to a general information-theoretic model of sample complexity for statistical  pattern recognition.  1125  1126 Hampshire and Kumar
Three methods for improving the performance of (gaussian) radial basis  function (RBF) networks were tested on the NETtalk task. In RBF, a  new example is classified by computing its Euclidean distance to a set of  centers chosen by unsupervised methods. The application of supervised  learning to learn a non-Euclidean distance metric was found to reduce the  error rate of RBF networks, while supervised learning of each center's variance resulted in inferior performance. The best improvement in accuracy  was achieved by networks called generalized radial basis function (GRBF)  networks. In GRBF, the center locations are determined by supervised  learning. After training on 1000 words, RBF classifies 56.5% of letters  correct, while GRBF scores 73.4% letters correct (on a separate test set).  From these and other experiments, we conclude that supervised learning  of center locations can be very important for radial basis function learning.
Optimizing the performance of self-organizing feature maps like the Kohonen map involves the choice of the output space topology. We present  a topographic product which measures the preservation of neighborhood  relations as a criterion to optimize the output space topology of the map  with regard to the global dimensionality D A as well as to the dimensions in the individual directions. We test the topographic product method  not only on synthetic mapping examples, but also on speech data. In the  latter application our method suggests an output space dimensionality of  D A = 3, in coincidence with recent recognition results on the same data  set.
We present here an interesting experiment in 'quick modeling' by humans,  performed independently on small samples, in several languages and two  continents, over the last three years. Comparisons to decision tree procedures and neural net processing are given. From these, we conjecture that  human reasoning is better represented by the latter, but substantially different from both. Implications for the 'strong convergence hypothesis' between neural networks and machine learning are discussed, now expanded  to include human reasoning comparisons.
Two projection based feedforward network learning methods for modelfree regression problems are studied and compared in this paper: one is  the popular back-propagation learning (BPL); the other is the projection  pursuit learning (PPL). Unlike the totally parametric BPL method, the  PPL non-parametrically estimates unknown nonlinear functions sequentially (neuron-by-neuron and layer-by-layer) at each iteration while jointly  estimating the interconnection weights. In terms of learning efficiency,  both methods have comparable training speed when based on a GaussNewton optimization algorithm while the PPL is more parsimonious. In  terms of learning robustness toward noise outliers, the BPL is more sensitive to the outliers.
Existing metrics for the learning performance of feed-forward neural networks do  not provide a satisfactory basis for comparison because the choice of the training  epoch limit can determine the results of the comparison. I propose new metrics  which have the desirable property of being independent of the training epoch  limit. The efficiency measures the yield of correct networks in proportion to the  training effort expended. The optimal epoch limit provides the greatest efficiency.  The learning performance is modelled statistically, and asymptotic performance  is estimated. Implementation details may be found in (Hamey, 1992).
XVe present a novel classification and regression method tha. t coinbines exploratory projection pursuit (unSUl)ervised training) with projection pursuit regression (supervised training), to yield a new family of  cost/complexity penalty terms. Some improved generalization properties  are demonstrated on real world problems.
This paper describes a technique for learning both the number of states and the  topology of Hidden Markov Models from examples. The induction process starts  with the most specific model consistent with the training data and generalizes  by successively merging states. Both the choice of states to merge and the  stopping criterion are guided by the Bayesian posterior probability. We compare  our algorithm with the Baum-Welch method of estimating fixed-size models, and  find that it can induce minimal HMMs from data in cases where fixed estimation  does not converge or requires redundant parameters to converge.
Artificial neural networks are comprised of an interconnected collection  of certain nonlinear devices; examples of commonly used devices include  linear threshold elements, sigmoidal elements and radial-basis elements.  We employ results from harmonic analysis and the theory of rational approximation to obtain almost tight lower bounds on the size (i.e. number  of elements) of neural networks. The class of neural networks to which  our techniques can be applied is quite general; it includes any feedforward  network in which each element can be piecewise approximated by a low  degree rational function. For example, we prove that any depth-(d ql)  network of sigmoidal units or linear threshold elements computing the parity function of n variables must have f2(dn 1/d-) size, for any fixed  > 0.  In addition, we prove that this lower bound is almost tight by showing  that the parity function can be computed with O(dn l/d) sigmoidal units  or linear threshold elements in a depth-(d + 1) network. These almost  tight bounds are the first known complexity results on the size of neural  networks with depth more than two. Our lower bound techniques yield  a unified approach to the complexity analysis of various models of neural  networks with feedforward structures. Moreover, our results indicate that  in the context of computing highly oscillating symmetric Boolean func19  20 Siu, Roychowdhury, and Kailath  tions, networks of continuous-output units such as sigmoidal elements do  not offer significant reduction in size compared with networks of linear  threshold elements of binary outputs.
Hidden units in multi-layer networks form a representation space in which each  region can be identified with a class of equivalent outputs (Elman, 1989) or a  logical state in a finite state machine (Cleeremans, Servan-Schreiber &  McClelland, 1989; Giles, Sun, Chen, Lee, & Chen, 1990). We extend the  analysis of the spatial structure of hidden unit space to a combinatorial task,  based on binding features together in a visual scene. The logical structure  requires a combinatorial number of states to represent all valid scenes. On  analysing our networks, we find that the high dimensionality of hidden unit  space is exploited by using the intersection of neighboring regions to represent  conjunctions of features. These results show how combinatorial structure can  be based on the spatial nature of networks, and not just on their emulation of  logical structure.
Holographic Recurrent Networks (HRNs) are recurrent networks  which incorporate associative memory techniques for storing sequential structure. HRNs can be easily and quickly trained using  gradient descent techniques to generate sequences of discrete outputs and trajectories through continuous space. The performance  of HRNs is found to be superior to that of ordinary recurrent networks on these sequence generation tasks.
A boosting algorithm converts a learning machine with error rate less  than 50% to one with an arbitrarily low error rate. However, the  algorithm discussed here depends on having a large supply of  independent training samples. We show how to circumvent this  problem and generate an ensemble of learning machines whose  performance in optical character recognition problems is dramatically  improved over that of a single network. We report the effect of  boosting on four databases (all handwritten) consisting of 12,000 digits  from segmented ZIP codes from the United State Postal Service  (USPS) and the following from the National Institute of Standards and  Testing (NIST): 220,000 digits, 45,000 upper case alphas, and 45,000  lower case alphas. We use two performance measures: the raw error  rate (no rejects) and the reject rate required to achieve a 1% error rate  on the patterns not rejected. Boosting improved performance in some  cases by a factor of three.
Memory-based classification algorithms such as radial basis functions or K-nearest neighbors typically rely on simple distances (Euclidean, dot product...), which are not particularly meaningful on  pattern vectors. More complex, better suited distance measures are  often expensive and rather ad-hoc (elastic matching, deformable  templates). We propose a new distance measure which (a) can be  made locally invariant to any set of transformations of the input  and (b) can be computed efficiently. We tested the method on  large handwritten character databases provided by the Post Office  and the NIST. Using invariances with respect to translation, rotation, scaling, shearing and line thickness, the method consistently  outperformed all other systems tested on the same databases.
An artificial neural network (ANN) is commonly modeled by a threshold  circuit, a network of interconnected processing units called linear threshold  gates. The depth of a network represents the number of unit delays or the  time for parallel computation. The size of a circuit is the number of gates  and measures the amount of hardware. It was known that traditional logic  circuits consisting of only unbounded fan-in AND, OR., NOT gates would  require at least f(logn/loglog n) depth to compute common arithmetic  functions such as the product or the quotient of two n-bit numbers, unless  we allow the size (and fan-in) to increase exponentially (in n). We show in  this paper that ANNs can be much more powerful than traditional logic  circuits. In particular, we prove that that iterated addition can be computed by depth-2 ANN, and multiplication and division can be computed  by depth-3 ANNs with polynomial size and polynomially bounded integer  weights, respectively. Moreover, it follows from known lower bound results that these ANNs are optimal in depth. We also indicate that these  techniques can be applied to construct polynomial-size depth-3 ANN for  powering, and depth-4 ANN for multiple product.
Although considerable interest has been shown in language inference and  automata induction using recurrent neural networks, success of these  models has mostly been limited to regular languages. We have previously demonstrated that Neural Network Pushdown Automaton (NNPDA)  model is capable of learning deterministic context-free languages (e.g.,  anb n and parenthesis languages) from examples. However, the learning  task is computationally intensive. In this paper we discus some ways in  which a priori knowledge about the task and data could be used for efficient  learning. We also observe that such knowledge is often an experimental  prerequisite for learning nontrivial languages (eg. a n b ncb mam).
We address the problem of learning an unknown function by  putting together several pieces of information (hints) that we know  about the function. We introduce a method that generalizes learning from examples to learning from hints. A canonical representation of hints is defined and illustrated for new types of hints. All  the hints are represented to the learning process by examples, and  examples of the function are treated on equal footing with the rest  of the hints. During learning, examples from different hints are  selected for processing according to a given schedule. We present  two types of schedules; fixed schedules that specify the relative emphasis of each hint, and adaptive schedules that are based on how  well each hint has been learned so fr. Our learning method is  compatible with any descent technique that we may choose to use.
PlatCs resource-allocation network (RAN) (Platt, 1991a, 1991b)  is modified for a reinforcement-learning paradigm and to "restart"  existing hidden units rather than adding new units. After restarting, units continue to learn via back-propagation. The resulting  restart algorithm is tested in a Q-learning network that learns to  solve an inverted pendulum problem. Solutions are found faster on  average with the restart algorithm than without it.
In a multi-layered neural network, any one of the hidden layers can be  viewed as computing a distributed representation of the input. Several  "encoder" experiments have shown that when the representation space is  small it can be fully used. But computing with such a representation  requires completely dependable nodes. In the case where the hidden  nodes are noisy and unreliable, we find that error correcting schemes  emerge simply by using noisy units during training; random errors injected during backpropagation result in spreading representations apart.  Average and minimum distances increase with misfire probability, as  predicted by coding-theoretic considerations. Furthermore, the effect of  this noise is to protect the machine against permanent node failure,  thereby potentially extending the useful lifetime of the machine.
The relationships between learning, development and evolution in  Nature is taken seriously, to suggest a model of the developmental  process whereby the genotypes manipulated by the Genetic Algorithm (GA) might be expressed to form phenotypic neural networks  (NNet) that then go on to learn. ONTOL is a grammar for generating polynomial NNets for time-series prediction. Genomes correspond to an ordered sequence of ONTOL productions and define a  grammar that is expressed to generate a NNet. The NNet's weights  are then modified by learning, and the individual's prediction error  is used to determine GA fitness. A new gene doubling operator  appears critical to the formation of new genetic alternatives in the  preliminary but encouraging results presented.
This paper describes R,PTURE -a system for revising probabilistic knowledge bases that combines neural and symbolic learning  methods. RAPTU}tE uses a modified version of backpropagation  to refine the certainty factors of a MYClN-style rule base and uses  ID3's information gain heuristic to add new rules. Results on refining two actual expert knowledge bases demonstrate that this  combined approach performs better than previous methods.
An incremental, higher-order, non-recurrent network combines two  properties found to be useful for learning sequential tasks: higher-
A performance comparison of two self-organizing networks, the Kohonen Feature Map and the recently proposed Growing Cell Structures is made. For this purpose several performance criteria for  self-organizing networks are proposed and motivated. The models  are tested with three example problems of increasing difficulty. The  Kohonen Feature Map demonstrates slightly superior results only  for the simplest problem. For the other more difficult and also more  realistic problems the Growing Cell Structures exhibit significantly  better performance by every criterion. Additional advantages of  the new model are that all parameters are constant over time and  that size as well as structure of the network are determined automatically.
Given a set of training examples, determining the appropriate number of free parameters is a challenging problem. Constructive  learning algorithms attempt to solve this problem automatically by  adding hidden units, and therefore free parameters, during learning. We explore an alternative class of algorithms--called metamorphosis algorithms--in which the number of units is fixed, but  the number of free parameters gradually increases during learning.  The architecture we investigate is composed of RBF units on a lattice, which imposes flexible constraints on the parameters of the  network. Virtues of this approach include variable subset selection, robust parameter selection, multiresolution processing, and  interpolation of sparse training data.
A new boundary hunting radial basis function (BH-RBF) classifier  which allocates RBF centers constructively near class boundaries is  described. This classifier creates complex decision boundaries only in  regions where confusions occur and corresponding RBF outputs are  similar. A predicted square error measure is used to determine how  many centers to add and to determine when to stop adding centers. Two  experiments are presented which demonstrate the advantages of the BHRBF classifier. One uses artificial data with two classes and two input  features where each class contains four clusters but only one cluster is  near a decision region boundary. The other uses a large seismic database  with seven classes and 14 input features. In both experiments the BHRBF classifier provides a lower error rate with fewer centers than are  required by more conventional RBF, Gaussian mixture, or MLP  classifiers.
Large VC-dimension classifiers can learn difficult tasks, but are usually impractical because they generalize well only if they are trained with huge quantities of data. In this paper we show that even high-order polynomial classifiers in high dimensional spaces can be trained with a small amount of training data and yet generalize better than classifiers with a smaller VC-dimension. This is achieved with a maximum margin algorithm (the Generalized Portrait). The technique is applicable to a wide variety of classifiers, including Percepttons, polynomial classifiers (sigma-pi unit networks) and Radial Basis Functions. The effective number of parameters is adjusted automatically by the training algorithm to match the complexity of the problem. It is shown to equal the number of those training patterns which are closest patterns to the decision boundary (supporting patterns). Bounds on the generalization error and the speed of convergence of the algorithm are given. Experimental results on handwritten digit recognition demonstrate good generalization compared to other algorithms. 
We propose a very simple, and well principled way of computing  the .optimal step size in gradient descent algorithms. The on-line  vermon is very efficient computationally, and is applicable to large  backpropagation networks trained on large data sets. The main  ingredient is a technique for estimating the principal eigenvalue(s)  and eigenvector(s) of the objective function's second derivative matrix (Hessian), which does not require to even calculate the Hessian. Several other applications of this technique are proposed for  speeding up learning, or for eliminating useless parameters.
We investigate the use of information from all second order derivatives of the error  function to perform network pruning (i.e., removing unimportant weights from a trained  network) in order to improve generalization, simplify networks, reduce hardware or  storage requirements, increase the speed of further training, and in some cases enable rule  extraction. Our method, Optimal Brain Surgeon (OBS), is significantly better than  magnitude-based methods and Optimal Brain Damage [Le Cun, Denker and Solla, 1990],  which often remove the wrong weights. OBS permits the pruning of more weights than  other methods (for the same error on the training set), and thus yields better  generalization on test data. Crucial to OBS is a recursion relation for calculating the  inverse Hessian matrix H -l from training data and structural information of the net. OBS  permits a 90%, a 76%, and a 62% reduction in weights over backpropagation with weight  decay on three benchmark MONK's problems [Thrun et al., 1991]. Of OBS, Optimal  Brain Damage, and magnitude-based methods, only OBS deletes the correct weights from  a trained XOR network in every case. Finally, whereas Sejnowski and Rosenberg [1987]  used 18,000 weights in their NETtalk network, we used OBS to prune a network to just  1560 weights, yielding better generalization.
We present a general formulation for a network of stochastic directional units. This formulation is an extension of the Boltzmann  machine in which the units are not binary, but take on values in a  cyclic range, between 0 and 27r radians. The state of each unit in  a Directional-Unit Boltzmann Machine (DUBM) is described by a  complex variable, where the phase component specifies a direction;  the weights are also complex variables. We associate a quadratic  energy function, and corresponding probability, with each DUBM  configuration. The conditional distribution of a unit's stochastic  state is a circular version of the Gaussian probability distribution,  known as the von Mises distribution. In a mean-field approximation to a stochastic DUBM, the phase component of a unit's state  represents its mean direction, and the magnitude component specifies the degree of certainty associated with this direction. This  combination of a value and a certainty provides additional representational power in a unit. We describe a learning algorithm and  simulations that demonstrate a mean-field DUBM'S ability to learn  interesting mappings.  Many kinds of information can naturally be represented in terms of angular, or  directional, variables. A circular range forms a suitable representation for explicitly  directional information, such as wind direction, as well as for information where  the underlying range is periodic, such as days of the week or months of the year.  In computer vision, tangent fields and optic flow fields are represented as fields of  oriented line segments, each of which can be described by a magnitude and direction.  Directions can also be used to represent a set of symbolic labels, e.g., object label  A at 0, and object label B at 7r/2 radians. We discuss below some advantages of  representing symbolic labels with directional units.  172  Directional-Unit Boltzmann Machines 173  These and many other phenomena can be usefully encoded using a directional  representation--a polar coordinate representation of complex values in which the  phase parameter indicates a direction between 0 and 27r radians. We have devised a  general formulation of networks of stochastic directional units. This paper describes  a directional-unit Boltzmann machine (DUBM), which is a novel generalization of a  Boltzmann machine (Ackley, Hinton and Sejnowski, 1985) in which the units are  not binary, but instead take on directional values between 0 and 27r.
We proposed a model of Time Warping Invariant Neural Networks (TWINN)  to handle the time warped continuous signals. Although TWINN is a simple modification of well known recurrent neural network, analysis has shown that TWINN completely removes time warping and is able to handle difficult classification problem. It  is also shown that TWINN has certain advantages over the current available sequential  processing schemes: Dynamic Programming(DP)[1], Hidden Markov Model(HMM)[2], Time Delayed Neural Networks(TDNN) [3] and Neural Network Finite  Automata(NNFA)[4].  We also analyzed the time continuity employed in TWINN and pointed out that  this kind of structure can memorize longer input history compared with Neural Network Finite Automata (NNFA). This may help to understand the well accepted fact  that for learning grammatical reference with NNFA one had to start with very short  strings in training set.  The numerical example we used is a trajectory classification problem. This  problem, making a feature of variable sampling rates, having internal states, continuous dynamics, heavily time-warped data and deformed phase space trajectories, is  shown to be difficult to other schemes. With TWINN this problem has been learned in  100 iterations. For benchmark we also trained the exact same problem with TDNN and  completely failed as expected.
In [5], a new incremental cascade network architecture has been  presented. This paper discusses the properties of such cascade  networks and investigates their generalization abilities under the  particular constraint of small data sets. The evaluation is done for  cascade networks consisting of local linear maps using the MackeyGlass time series prediction task as a benchmark. Our results indicate that to bring the potential of large networks to bear on the  problem of extracting information from small data sets without running the risk of overfitting, deeply cascaded network architectures  are more favorable than shallow broad architectures that contain  the same number of nodes.
The bootstrap algorithm is a computational intensive procedure to  derive nonparametric confidence intervals of statistical estimators  in situations where an analytic solution is intractable. It is applied to neural networks to estimate the predictive distribution for  unseen inputs. The consistency of different bootstrap procedures  and their convergence speed is discussed. A small scale simulation  experiment shows the applicability of the bootstrap to practical  problems and its potential use.
Previously, ve have introduced the idea of neural network transfer,  where learning on a target problem is sped up by using the weights  obtained from a network trained for a related source task. Here,  we present a new algorithm. called Discriminability-Based Transfer  (DBT), which uses an information measure to estimate the utility  of hyperplanes defined by source weights in the target network,  and rescales transferred weight magnitudes accordingly. Several  experiments demonstrate that target networks initialized via DBT  learn significantly faster than networks initialized randomly.
The algorithm presented performs gradient descent on the weight space  of an Artificial Neural Network (ANN), using a finite difference to  approximate the gradient. The method is novel in that it achieves a computational complexity similar to that of Node Perturbation, O(N3), but  does not require access to the activity of hidden or intemal neurons.  This is possible due to a stochastic relation between perturbations at the  weights and the neurons of an ANN. The algorithm is also similar to  Weight Perturbation in that it is optimal in terms of hardware requirements when used for the training of VLSI implementafiom of ANN's.
Vector Quantization is useful for data compression. Competitive Learning which minimizes reconstruction error is an appropriate algorithm for  vector quantization of unlabelled data. Vector quantization of labelled  data for classification has a different objective, to minimize the number  of misclassificafions, and a different algorithm is appropriate. We show  that a variant of Kohonen's LVQ2.1 algorithm can be seen as a multiclass extension of an algorithm which in a restricted 2 class case can  be proven to converge to the Bayes optimal classification boundary. We  compare the performance of the LVQ2.1 algorithm to that of a modified  version having a decreasing window and normalized step size, on a ten  class vowel classification problem.
Many techniques for model selection in the field of neural networks  correspond to well established statistical methods. The method  of 'stopped training', on the other hand, in which an oversized  network is trained until the error on a further validation set of examples deteriorates, then training is stopped, is a true innovation,  since model selection doesn't require convergence of the training  process.  In this paper we show that this performance can be significantly  enhanced by extending the 'nonconvergent model selection method'  of stopped training to include dynamic topology modifications  (dynamic weight pruning) and modified complexity penalty term  methods in which the weighting of the penalty term is adjusted  during the training process.
We have designed an architecture to span the gap between biophysics and cognitive science to address and explore issues of how  a discrete symbol processing system can arise from the continuum,  and how complex dynamics like oscillation and synchronization can  then be employed in its operation and affect its learning. We show  how a discrete-time recurrent "Elman" network architecture can  be constructed from recurrently connected oscillatory associative  memory modules described by continuous nonlinear ordinary differential equations. The modules can learn connection weights between themselves which will cause the system to evolve under a  clocked "machine cycle" by a sequence of transitions of attractors  within the modules, much as a digital computer evolves by transitions of its binary flip-flop attractors. The architecture thus employs the principle of "computing with attractors" used by macroscopic systems for reliable computation in the presence of noise. We  have specifically constructed a system which functions as a finite  state automaton that recognizes or generates the infinite set of six  symbol strings that are defined by a Reber grammar. It is a symbol  processing system, but with analog input and oscillatory subsymbolic representations. The time steps (machine cycles) of the system are implemented by rhythmic variation (clocking) of a bifurcation parameter. This holds input and "context" modules clamped  at their attractors while 'hidden and output modules change state,  then clamps hidden and output states while context modules are  released to load those states as the new context for the next cycle of  input. Superior noise immunity has been demonstrated for systems  with dynamic attractors over systems with static attractors, and  synchronization ("binding") between coupled oscillatory attractors  in different modules has been shown to be important for effecting  reliable transitions.  236  Synchronization and Grammatical Inference in an Oscillating Elman Net 237
A parallel stochastic algorithm is investigated for error-descent  learning and optimization in deterministic networks of arbitrary  topology. No explicit information about internal network structure is needed. The method is based on the model-free distributed  learning mechanism of Dembo and Kailath. A modified parameter  update rule is proposed by which each individual parameter vector  perturbation contributes a decrease in error. A substantially faster  learning speed is hence allowed. Furthermore, the modified algorithm supports learning time-varying features in dynamical networks. We analyze the convergence and scaling properties of the  algorithm, and present simulation results for dynamic trajectory  learning in recurrent networks.
The inverse kinematics problem for redundant manipulators is ill-posed and  nonlinear. There are two fundamentally different issues which result in the need  for some form of regularization; the existence of multiple solution branches  (global ill-posedness) and the existence of excess degrees of freedom (local illposedness). For certain classes of manipulators, learning methods applied to  input-output data generated from the forward function can be used to globally  regularize the problem by partitioning the domain of the forward mapping into  a finite set of regions over which the inverse problem is well-posed. Local  regularization can be accomplished by an appropriate parameterization of the  redundancy consistently over each region. As a result, the ill-posed problem can  be transformed into a finite set of well-posed problems. Each can then be solved  separately to construct approximate direct inverse functions.
We present a new algorithm, Prioritized Sweeping, for efficient prediction  and control of stochastic Markov systems. Incremental learning methods  such as Temporal Differencing and Q-learning have fast real time performance. Classical methods are slower, but more accurate, because they  make full use of the observations. Prioritized Sweeping aims for the best  of both worlds. It uses all previous experiences both to prioritize important dynamic programming sweeps and to guide the exploration of statespace. We compare Prioritized Sweeping with other reinforcement learning  schemes for a number of different stochastic optimal control problems. It  successfully solves large state-space real time problems with which other  methods have difficulty.
One way to speed up reinforcement learning is to enable learning to  happen simultaneously at multiple resolutions in space and time.  This paper shows how to create a Q-learning managerial hierarchy  in which high level managers learn how to set tasks to their submanagers who, in turn, learn how to satisfy them. Sub-managers  need not initially understand their managers' commands. They  simply learn to maximise their reinforcement in the context of the  current command.  We illustrate the system using a simple maze task.. As the system  learns how to get around, satisfying commands at the multiple  levels, it explores more efficiently than standard, flat, Q-learning  and builds a more comprehensive map.
This paper describes a technique called Input Reconstruction Reliability Estimation  (IRRE) for determining the response reliability of a restricted class of multi-layer  percepttons (MLPs). The technique uses a network's ability to accurately encode  the input pattern in its internal representation as a measure of its reliability. The  more accurately a network is able to reconstruct the input pattern from its internal  representation, the more reliable the network is considered to be. IRRE is provides  a good estimate of the reliability of MLPs trained for autonomous driving. Results  are presented in which the reliability estimates provided by IRRE are used to select  between networks trained for different driving situations.
How can artificial neural nets generalize better from fewer examples? In order  to generalize successfully, neural network learning methods typically require  large training data sets. We introduce a neural network learning method that  generalizes rationally from many fewer data points, relying instead on prior  knowledge encoded in previously learned neural networks. For example, in robot  control learning tasks reported here, previously learned networks that model the  effects of robot actions are used to guide subsequent learning of robot control  functions. For each observed training example of the target function (e.g. the  robot control policy), the learner explains the observed example in terms of its  prior knowledge, then analyzes this explanation to infer additional information  about the shape, or slope, of the target function. This shape knowledge is used  to bias generalization when learning the target function. Results are presented  applying this approach to a simulated robot task based on reinforcement learning.
Recent research on reinforcement learning has focused on algorithms based on the principles of Dynamic Programming (DP).  One of the most promising areas of application for these algorithms is the control of dynamical systems, and some impressive  results have been achieved. However, there are significant gaps  between practice and theory. In particular, there are no convergence proofs for problems with continuous state and action spaces,  or for systems involving non-linear function approximators (such  as multilayer percepttons). This paper presents research applying  DP-based reinforcement learning theory to Linear Quadratic Regulation (LQR), an important class of control problems involving  continuous state and action spaces and requiring a simple type of  non-linear function approximator. We describe an algorithm based  on Q-learning that is proven to converge to the optimal controller  for a large class of LQR problems. We also describe a slightly  different algorithm that is only locally convergent to the optimal  Q-function, demonstrating one of the possible pitfalls of using a  non-linear function approximator with DP-based learning.
The overall goal is to reduce spacecraft weight, volume, and cost by online adaptive non-linear control of flexible structural components. The  objective of this effort is to develop an adaptive Neural Network (NN)  controller for the Ball C-Side lm x 3m antenna with embedded actuators  and the RAMS sensor system. A traditional optimal controller for the  major modes is provided perturbations by the NN to compensate for  unknown residual modes. On-line training of recurrent and feed-forward  NN architectures have achieved adaptive vibration control with  unknown modal variations and noisy measurements. On-line training  feedback to each actuator NN output is computed via Newton's method  to reduce the difference between desired and achieved antenna positions.
The primate brain must solve two important problems in grasping movements. The first problem concerns the recognition of grasped objects:  specifically, how does the brain integrate visual and motor information  on a grasped object? The second problem concerns hand shape planning:  specifically, how does the brain design the hand configuration suited to the  shape of the object and the manipulation task? A neural network model  that solves these problems has been developed. The operations of the network are divided into a learning phase and an optimization phase. In the  learning phase, internal representations, which depend on the grasped objects and the task, are acquired by integrating visual and somatosensory  information. In the optimization phase, the most suitable hand shape for  grasping an object is determined by using a relaxation computation of the  network.  *Present Address: Parallel Distributed Processing Research Dept., Sony Corporation,  6-7-35 Kitashinagawa, Shinagawa-ku, Tokyo 141, Japan  311  312 Uno, Fukumura, Suzuki, and Kawato
In this paper, we discuss on-line estimation strategies that model  the optimal value function of a typical optimal control problem.  We present a general strategy that uses local corridor solutions  obtained via dynamic programming to provide local optimal control sequence training data for a neural architecture model of the  optimal value function.
A peg-in-hole insertion task is used as an example to illustrate  the utility of direct associative reinforcement learning methods for  learning control under real-world conditions of uncertainty and  noise. Task complexity due to the use of an unchainfeted hole  and a clearance of less than 0.2ram is compounded by the presence  of positional uncertainty of magnitude exceeding 10 to 50 times the  clearance. Despite this extreme degree of uncertainty, our results  indicate that direct reinforcement learning can be used to learn a  robust reactive control strategy that results in skillful peg-in-hole  insertions.
"Trajectory Extension Learning" is a new technique for Learning  Control in Robots which assumes that there exists some parameter  of the desired trajectory that can be smoothly varied from a region  of easy solvability of the dynamics to a region of desired behavior  which may have more difficult dynamics. By gradually varying the  parameter, practice movements remain near the desired path while  a Neural Network learns to approximate the inverse dynamics. For  example, the average speed of motion might be varied, and the inverse dynamics can be "bootstrapped" from slow movements with  simpler dynamics to fast movements. This provides an example of  the more general concept of a "Practice Strategy" in which a sequence of intermediate tasks is used to simplify learning a complex  task. I show an example of the application of this idea to a real  2-joint direct drive robot arm.
Within a simple test-bed, application of feed-forward neurocontrol  for short-term planning of robot trajectories in a dynamic environment is studied. The action network is embedded in a sensorymotoric system architecture that contains a separate world model.  It is continuously fed with short-term predicted spatio-temporal  obstacle trajectories, and receives robot state feedback. The action net allows for external switching between alternative planning tasks. It generates goal-directed motor actions -subject to  the robot's kinematic and dynamic constraints such that collisions with moving obstacles are avoided. Using supervised learning, we distribute examples of the optimal planner mapping over  a structure-level adapted parsimonious higher order network. The  training database is generated by a Dynamic Programming algorithm. Extensive simulations reveal, that the local planner mapping is highly nonlinear, but can be effectively and sparsely represented by the chosen powerful net model. Excellent generalization  occurs for unseen obstacle configurations. We also discuss the limitations of feed-forward neurocontrol for growing planning horizons.  *Tel.: (228)-550-364  FAX: (228)-550-425 e-mMl: gerald@nero.uni-bonn.de  342  Learning Spario-Temporal Planning from a Dynamic Programming Teacher 343
A three-step method for function approximation with a fuzzy system is proposed. First, the membership functions and an initial  rule representation are learned; second, the rules are compressed  as much as possible using information theory; and finally, a computational network is constructed to compute the function value.  This system is applied to two control examples: learning the truck  and trailer backer-upper control system, and learning a cruise control system for a radio-controlled model car.
The invariance of an objects' identity as it transformed over time  provides a powerful cue for perceptual learning. We present an unsupervised learning procedure which maximizes the mutual information between the representations adopted by a feed-forward network at consecutive time steps. We demonstrate that the network  can learn, entirely unsupervised, to classify an ensemble of several  patterns by observing pattern trajectories, even though there are  abrupt transitions from one object to another between trajectories. The same learning procedure should be widely applicable to  a variety of perceptual learning tasks.
Neurons in area MT of primate visual cortex encode the velocity  of moving objects. We present a model of how MT cells aggregate  responses from V1 to form such a velocity representation. Two  different sets of units, with local receptive fields, receive inputs  from motion energy filters. One set of units forms estimates of local  motion, while the second set computes the utility of these estimates.  Outputs from this second set of units "gate" the outputs from the  first set through a gain control mechanism. This active process  for selecting only a subset of local motion responses to integrate  into more global responses distinguishes our model from previous  models of velocity estimation. The model yields accurate velocity  estimates in synthetic images containing multiple moving targets  of varying size, luminance, and spatial frequency profile and deals  well with a number of transparency phenomena.
Multiple single neuron responses were recorded  from a single electrode in V1 of alert, behaving  monkeys. Drifting sinusoidal gratings were  presented in the cells' overlapping receptive  fields, and the stimulus was varied along several  visual dimensions. The degree of dimensional  separability was calculated for a large population  of neurons, and found to be a continuum. Several  cells showed different temporal response  dependencies to variation of different stimulus  dimensions, i.e. the tuning of the modulated  firing was not necessarily the same as that of the  mean firing rate. We describe a multidimensional  receptive field, and use simultaneously recorded  responses to compute a multi-neuron receptive  field, describing the information processing  capabilities of a group of cells. Using dynamic  correlation analysis, we propose several  computational schemes for multidimensional  spatiotemporal tuning for groups of cells. The  implications for neuronal coding of stimuli are  discussed.  377  378 Stern, Aertsen, Vaadia, and Hochstein
The classical computational model for stereo vision incorporates  a uniqueness inhibition constraint to enforce a one-to-one feature  match, thereby sacrificing the ability to handle transparency. Critics of the model disregard the uniqueness constraint and argue  that the smoothness constraint can provide the excitation support  required for transparency computation. However, this modification fails in neighborhoods with sparse features. We propose a  Bayesian approach to stereo vision with priors favoring cohesive  over transparent surfaces. The disparity and its segmentation into a  multi-layer "depth planes" representation are simultaneously computed. The smoothness constraint propagates support within each  layer, providing mutual excitation for non-neighboring transparent  or partially occluded regions. Test results for various random-dot  and other stereograms are presented.
In visual processing the ability to deal with missing and noisy information is crucial. Occlusions and unreliable feature detectors often lead to  situations where little or no direct information about features is available. However the available information is usually sufficient to highly  constrain the outputs. We discuss Bayesian techniques for extracting  class probabilities given partial data. The optimal solution involves integrating over the missing dimensions weighted by the local probability  densities. We show how to obtain closed-form approximations to the  Bayesian solution using Gaussian basis function networks. The framework extends naturally to the case of noisy features. Simulations on a  complex task (3D hand gesture recognition) validate the theory. When  both integration and weighting by input densities are used, performance  decreases gracefully with the number of missing or noisy features. Performance is substantially degraded if either step is omitted.
We are interested in the use of analog neural networks for recognizing visual objects. Objects are described by the set of parts  they are composed of and their structural relationship. Structural models are stored in a database and the recognition problem reduces to matching data to models in a structurally consistent way. The object recognition problem is in general very difficult in that it involves coupled problems of grouping, segmentation  and matching. We limit the problem here to the simultaneous labelling of the parts of a single object and the determination of  analog parameters. This coupled problem reduces to a weighted  match problem in which an optimizing neural network must minimize E(M,p) = Y'ai M, iW, i(p), where the {M,i} are binary  match variables for data parts i to model parts c and {W,i(p)}  are weights dependent on parameters p. In this work we show that  by first solving for estimates  without solving for Mi, we may  obtain good initial parameter estimates that yield better solutions  for M and p.  *Current address: International Computer Science Institute, 1947 Center Street,  Suite 600, Berkeley, CA 94704, utans@icsi.berkeley.edu  t Current address: SUNY Stony Brook, Department of Electrical Engineering, Stony  Brook, NY 11784  401  402 Utans and Gindi  Figure 1: Stored Model for a 3-Level Compositional Hierarchy (compare Figure 3).
Simplified models of the lateral geniculate nucles (LGN) and striate cortex illustrate the possibility that feedback to the LGN may  be used for robust, low-level pattern analysis. The information  fed back to the LGN is rebroadcast to cortex using the LGN's full  fan-out, so the cortexLGNcortex pathway mediates extensive  cortico-cortical communication while keeping the number of necessary connections small.
Human vision systems integrate information nonlocally, across long  spatial ranges. For example, a moving stimulus appears smeared  when viewed briefly (30 ms), yet sharp when viewed for a longer  exposure (100 ms) (Burr, 1980). This suggests that visual systems  combine information along a trajectory that matches the motion of  the stimulus. Our self-organizing neural network model shows how  developmental exposure to moving stimuli can direct the formation of  horizontal trajectory-specific motion integration pathways that unsmear  representations of moving stimuli. These results account for Burr's data  and can potentially also model other phenomena, such as visual inertia.
In this work we apply a texture classification network to remote sensing image analysis. The goal is to extract the characteristics of the area depicted  in the input image, thus achieving a segmented map of the region. We have  recently proposed a combined neural network and rule-based framework  for texture recognition. The framework uses unsupervised and supervised  learning, and provides probability estimates for the output classes. We  describe the texture classification network and extend it to demonstrate  its application to the Landsat and Aerial image analysis domain.
We have designed a neural network which detects the direction of egomotion from optic flow in the presence of eye movements (Lappe and  Rauschecker, 1993). The performance of the network is consistent with  human psychophysical c!t_a and its output neurons show great similarity  to "triple component" cells in area MSTd of monkey visual cortex. We  now show that by using assumptions about the kind of eye movements  that the observer is likely to perform, our model can generate various  other cell types found in MSTd as well.
This paper describes an approach to integrated segmentation and  rof,ognition of hand-printed characters. The approach, called Saccade,  integrates ballistic and corrective saccarles (eye movements) with  character recognition. A single backpropagation net is trained to make  a classification decision on a character centered in its input window, as  well as to estimate the distance of the current and next character from the  center of the input window. The net learns to accurately estimate these  distances regardless of variations in character width, spacing between  characters, writing style and other factors. During testing, the system  uses the net-extracted classification and distance information, along  with a set of jumping rules, to jump from character to character.  The ability to read rests on multiple foundation skills. In learning how to read, people learn  how to recognize individual characters centered in the visual field. They also learn how  to move their eyes along a line of text, sequentially centering the visual field on successive  characters. We believe that the key to developing optical character recognition (OCR) systems that can mimic human reading capabilities, is to develop systems that can learn these  and other skills in an integrated fashion. In this paper, we demonstrate that a backpropagation net can learn to navigate along a line of handwritten characters, as well as to recognize  the characters centered in its visual field. The system, called Saccade, extends the current  state of the art in OCR technology by using a single classifier to accurately and efficiently  locate and recognize characters, regardless of whether they touch each other or are separate. The Saccade system was described briefly at the last NIPS conference (Martin & Rashid, 1992). In this paper, we describe it more fully and report on results demonstrating  its accuracy and efficiency in recognizing handwritten digits.  The Saccade system takes a cue from the ballistic and corrective saccades (eye movements)  of natural vision systems. Natural saccades make it possible to efficiently move from one  informative area to another by jumping. The eye typically initiates a ballistic saccade to  441  442 Martin, Rashid, Chapman, and Pittman  move the center of focus to the general area of interest, followed, if necessary, by one or  more corrective saccades for fine-grained position corrections. Recognition processes are  applied only at these multiple fixation points.  We have copied some of these aspects in the artificial $accade system by training a neural  network to know about the locations of characters in its input window, as well as to know  about the identity of the character centered in its input window. During run-time, the Saccade system accesses this information computed by the net for successive input windows,  along with a set of simple jumping rules, to yield an OCR system that jumps from character  to character, classifying each character in a sequence.
The ensemble dynamics of stochastic learning algorithms can be studied using theoretical techniques from statistical physics. We develop the equations of motion for the weight space probability densities for stochastic learning algorithms. We discuss equilibria in the diffusion approximation and provide expressions for special cases of the LMS algorithm. The equilibrium densities are not in general thermal (Gibbs) distributions in the objective function being minimized, but rather depend upon an effective potential that includes diffusion effects. Finally we present an exact analytical expression for the time evolution of the density for a learning algorithm with weight updates proportional to the sign of the gradient.
In this paper we discuss the asymptotic properties of the most commonly used variant of the backpropagation algorithm in which network weights are trained by means of a local gradient descent on examples drawn randomly from a fixed training set, and the learning  rate  of the gradient updates is held constant (simple backpropagation). Using stochastic approximation results, we show that for   -+ 0 this training process approaches a batch training and provide results on the rate of convergence. Further, we show that for  small  one can approximate simple back propagation by the sum  of a batch training process and a Gaussian diffusion which is the  unique solution to a linear stochastic differential equation. Using  this approximation we indicate the reasons why simple backpropagation is less likely to get stuck in local minima than the batch  training process and demonstrate this empirically on a number of  examples.
In the presence of outliers, the existing self-organizing rules for Principal Component Analysis (PCA) perform poorly. Using statistical physics techniques including the Gibbs distribution, binary decision fields and effective energies, we propose self-organizing PCA rules which are capable of resisting outliers while fulfilling various PCA-related tasks such as obtaining the first principal component vector, the first k principal component vectors, and directly finding the subspace spanned by the first k vector principal component vectors without solving for each vector individually. Comparative experiments have shown that the proposed robust rules improve the performances of the existing PCA algorithms significantly when outliers are present. 
The attempt to find a single "optimal" weight vector in conventional network training can lead to overfitting and poor generalization. Bayesian methods avoid this, without the need for a validation set, by averaging the outputs of many networks with weights  sampled from the posterior distribution given the training data.  This sample can be obtained by simulating a stochastic dynamical  system that has the posterior as its stationary distribution.
We analyze the "query by committee" algorithm, a method for filtering informative queries from a random stream of inputs. We  show that if the two-member committee algorithm achieves information gain with positive lower bound, then the prediction error  decreases exponentially with the number of queries. We show that,  in particular, this exponential decrease holds for query learning of  thresholded smooth functions.
We analyse the effects of analog noise on the synaptic arithmetic  during MultiLayer Perceptron training, by expanding the cost function to include noise-mediated penalty terms. Predictions are made  in the light of these calculations which suggest that fault tolerance,  generalisation ability and learning trajectory should be improved  by such noise-injection. Extensive simulation experiments on two  distinct classification problems substantiate the claims. The results appear to be perfectly general for all training schemes where  weights are adjusted incrementally, and have wide-ranging implications for all applications, particularly those involving "inaccurate"  analog neural VLSI.
We present the information-theoretic derivation of a learning algorithm  that clusters unlabelled data with linear discriminants. In contrast to  methods that try to preserve information about the input patterns, we  maximize the information gained from observing the output of robust  binary discriminators implemented with sigmoid nodes. We derive a local  weight adaptation rule via gradient ascent in this objective, demonstrate  its dynamics on some simple data sets, relate our approach to previous  work and suggest directions in which it may be extended.
In stochastic learning, weights are random variables whose time  evolution is governed by a Markov process. At each time-step,  n, the weights can be described by a probability density function  P(w, n). We summarize the theory of the time evolution of P, and  give graphical examples of the time evolution that contrast the  behavior of stochastic learning with true gradient descent (batch  learning). Finally, we use the formalism to obtain predictions of the  time required for noise-induced hopping between basins of different  optima. We compare the theoretical predictions with simulations  of large ensembles of networks for simple problems in supervised  and unsupcrviscd learning.
We have attempted to use information theoretic quantities for aalyzing neuronal connection structure from spike trains. Two point  mutual information and its maximum value, channel capacity, between a pir of neurons were found to be useful for sensitive detection of crosscorrelation and for estimation of synaptic strength,  respectively. Three point mutual information among three neurons  could give their interconnection structure. Therefore, our information theoretic analysis was shown to be a very powerful technique  for deducing neuronal connection structure. Some concrete examples of its application to simulated spike trMns are presented.
We use statistical mechanics to study generalization in large committee machines. For an architecture with nonoverlapping recepfive fields a replica calculation yields the generalization error in the  limit of a large number of hidden units. For continuous weights the  generalization error falls off asymptotically inversely proportional  to c, the number of training examples per weight. For binary  weights we find a discontinuous transition from poor to perfect  generalization followed by a wide region of metastability. Broken  replica symmetry is found within this region at low temperatures.  For a fully connected architecture the generalization error is calculated within the annealed approximation. For both binary and  continuous weights we find transitions from a symmetric state to  one with specialized hidden units, accompanied by discontinuous  drops in the generalization error.
We present an algorithm for creating a neural network which produces accurate probability estimates as outputs. The network implements a Gibbs probability distribution model of the training  database. This model is created by a new transformation relating  the joint probabilities of attributes in the database to the weights  (Gibbs potentials) of the distributed network model. The theory  of this transformation is presented together with experimental results. One advantage of this approach is the network weights are  prescribed without iterative gradient descent. Used as a classifier  the network tied or outperformed published results on a variety of  databases.
The Bayesian "evidence" approximation has recently been employed to  determine the noise and weight-penalty terms used in back-propagation.  This paper shows that for neural nets it is far easier to use the exact result  than it is to use the evidence approximation. Moreover, unlike the evidence approximation, the exact result neither has to be re-calculated for  every new data set, nor requires the running of computer code (the exact  result is closed form). In addition, it tums out that the evidence procedure's MAP estimate for neural nets is, in toto, approximation error. Another advantage of the exact analysis is that it does not lead one to incorrect intuition, like the claim that using evidence one can "evaluate different priors in light of the data". This paper also discusses sufficiency  conditions for the evidence approximation to hold, why it can sometimes  give "reasonable" results, etc.
The occurence of chaos in recurrent neural networks is supposed to  depend on the architecture and on the synaptic coupling strength. It is  studied here for a randomly diluted architecture. By normalizing the  variance of synaptic weights, we produce a bifurcation parameter,  dependent on this variance and on the slope of the transfer function but  independent of the connectivity, that allows a sustained activity and the  occurence of chaos when reaching a critical value. Even for weak  connectivity and small size, we find numerical results in accordance  with the theoretical ones previously established for fully connected  infinite sized networks. Moreover the route towards chaos is  numerically checked to be a quasi-periodic one, whatever the type of the  first bifurcation is (Hopf bifurcation, pitchfork or flip).  549  550 Doyon, Cessac, Quoy, and Samuelides
Recurrent networks of threshold elements have been studied intensively as associative memories and pattern-recognition devices. While  most research has concentrated on fully-connected symmetric networks, which relax to stable fixed points, asymmetric networks show  richer dynamical behavior, and can be used as sequence generators or  flexible pattern-recognition devices. In this paper, we approach the  problem of predicting the complex global behavior of a class of random asymmetric networks in terms of network parameters. These networks can show fixed-point, cyclical or effectively aperiodic behavior,  depending on parameter values, and our approach can be used to set  parameters, as necessary, to obtain a desired complexity of dynamics.  The approach also provides qualitative insight into why the system  behaves as it does and suggests possible applications.
We analyze in detail the performance of a Hamming network classifying inputs that are distorted versions of one of its m stored  memory patterns. The activation function of the memory neurons  in the original Hamming network is replaced by a simple threshold  function. The resulting Threshold Hamming Network (THN) correctly classifies the input pattern, with probability approaching 1,  using only O(m In m) connections, in a single iteration. The THN  drastically reduces the time and space complexity of Hamming Network classifiers.
We present a methodological framework enabling a detailed description of the performance of Hopfield-like attractor neural networks (ANN) in the first two iterations. Using the Bayesian approach, we find that performance is improved when a history-based  term is included in the neuron's dynamics. A further enhancement  of the network's performance is achieved by judiciously choosing  the censored neurons (those which become active in a given iteration) on the basis of the magnitude of their post-synaptic potentials. The contribution of biologically plausible, censored, historydependent dynamics is especially marked in conditions of low firing  activity and sparse connectivity, two important characteristics of  the mammalian cortex. In such networks, the performance attained is higher than the performance of two 'independent' iterations, which represents an upper bound on the performance of  history-independent networks.
A method for creating a non-linear encoder-decoder for multidimensional data  with compact representations is presented. The commonly used technique of  autoassociation is extended to allow non-linear representations, and an objective function which penalizes activations of individual hidden units is shown  to result in minimum dimensional encodings with respect to allowable error in  reconstruction.
Neural networks with binary weights are very important from both  the theoretical and practical points of view. In this paper, we investigate the learnability of single binary percepttons and unions of  p-binary-perceptron networks,/. e. an "OR" of binary percepttons  where each input unit is connected to one and only one perceptron. We give a polynomial time algorithm that PAC learns these  networks under the uniform distribution. The algorithm is able  to identify both the network connectivity and the weight values  necessary to represent the target function. These results suggest  that, under reasonable distributions, p-perceptron networks may  be easier to learn than fully connected networks.
Two theorems and a lemma are presented about the use of jackknife estimator and the cross-validation method for model selection. Theorem 1  gives the asymptotic form for the jackknife estimator. Combined with the  model selection criterion, this asymptotic form can be used to obtain the  fit of a model. The model selection criterion we used is the negative of the  average predictive likehood, the choice of which is based on the idea of the  cross-validation method. Lemma 1 provides a formula for further exploration of the asymptotics of the model selection criterion. Theorem 2 gives  an asymptotic form of the model selection criterion for the regression case,  when the parameters optimization criterion has a penalty term. Theorem  2 also proves the asymptotic equivalence of Moody's model selection criterion (Moody, 1992) and the cross-validation method, when the distance  measure between response y and regression function takes the form of a  squared difference.
Learning curves show hoxv a neural network is improved as the  number of training examples increases and how it is related to  the network complexity. The present paper clarifies asymptotic  properties and their relation of two learning curves, one concerning  the predictive loss or generalization loss and the other the training  loss. The result gives a natural definition of the complexity of a  neural network. Moreover, it provides a new criterion of model  selection.
We compare activation functions in terms of the approximation  power of their feedforward nets. We consider the case of analog as  well as boolean input.
A connection is drawn between rational functions, the realization  theory of dynamical systems, and feedforward neural networks.  This allows us to parametrize single hidden layer scalar neural  networks with (almost) arbitrary analytic activation functions in  terms of strictly proper rational functions. Hence, we can solve the  uniqueness of parametrization problem for such networks.
We have trained networks of E-II units with short-range connections to simulate simple cellular automata that exhibit complex or  chaotic behaviour. Three levels of learning are possible (in decreasing order of difficulty): learning the underlying automaton rule,  learning asymptotic dynamical behaviour, and learning to extrapolate the training history. The levels of learning achieved with and  without weight sharing for different automata provide new insight  into their dynamics.
The feed-forward networks with fixed hidden units (FHU-networks)  are compared against the category of remaining feed-forward networks with variable hidden units (VttU-networks). Two broad  classes of tasks on a finite domain X C R n are considered: approximation of every function from an open subset of functions on  X and representation of every dichotomy of X. For the first task  it is found that both network categories require the same minimal  number of synaptic weights. For the second task and X in general position it is shown that VHU-networks with threshold logic  hidden units can have approximately 1In times fewer hidden units  than any FHU-network must have.
A number f hybrid multilayer percepgon (MI.P)fniddon Markov  model (HMM) speech recognition systems have been developed in  recent years (Morgan and Bourlard, 1990). In this paper, we present  a new MI.P architecture and training algorith which allows the  modeling of context-dependent phonetic classes in a hybrid  gained at different degrees  context dependence in order to obtain  a robust estimate of the c(mtext.dependent probabilities. Tests with  the DARPA Resource Management database have shown substantial  advantages of the context-dependent MLPs over earlier contextindependent MLPs, and have shown substantial advantages of thig  hybrid approach over a pure  approach.
This study demonstrates a paradigm for modeling speech production based on neural networks. Using physiological data from  speech utterances, a neural network learns the forward dynamics  relating motor commands to muscles and the ensuing articulator  behavior that allows articulator trajectories to be generated from  motor commands constrained by phoneme input strings and global  performance parameters. From these movement trajectories, a second neural network generates PARCOR parameters that are then  used to synthesize the speech acoustics.
This paper discusses the parameterization of speech by an analog cochlear  model. The tradeoff between time and frequency resolution is viewed as  the fundamental difference between conventional spectrographic analysis  and cochlear signal processing for broadband, rapid-changing signals. The  models response exhibits a wavelet-like analysis in the scale domain that  preserves good temporal resolution; the frequency of each spectral component in a broadband signal can be accurately determined from the interpeak intervals in the instantaneous firing rates of auditory fibers. Such  properties of the cochlear model are demonstrated with natural speech  and synthetic complex signals.
Channel equalization problem is an important problem in high-speed  communications. The sequences of symbols transmitted are distorted by  neighboring symbols. Traditionally, the channel equalization problem is  considered as a channel-inversion operation. One problem of this  approach is that there is no direct correspondence between error probability and residual error produced by the channel inversion operation. In  this paper, the optimal equalizer design is formulated as a classification  problem. The optimal classifier can be constructed by Bayes decision  rule. In general it is nonlinear. An efficient hybrid linear/nonlinear  equalizer approach has been proposed to train the equalizer. The error  probability of new linear/nonlinear equalizer has been shown to be better than a linear equalizer in an experimental channel.
We would like to incorporate speaker-dependent consistencies, such as  gender, in an otherwise speaker-independent speech recognition system.  In this paper we discuss a Gender Dependent Neural Network (GDNN)  which can be tuned for each gender, while sharing most of the speaker  independent parameters. We use a classification network to help generate  gender-dependent phonetic probabilities for a statistical (HMM) recognition system. The gender classification net predicts the gender with high  accuracy, 98.3% on a Resource Management test set. However, the integration of the GDNN into our hybrid HMM-neural network recognizer  provided an improvement in the recognition score that is not statistically  significant on a Resource Management test set.
Matched filtering has been one of the most powerful techniques  employed for transient detection. Here we will show that a dynamic  neural network outperforms the conventional approach. When the  artificial neural network (ANN) is trained with supervised learning  schemes there is a need to supply the desired signal for all time,  although we are only interested in detecting the transient. In this  paper we also show the effects on the detection agreement of  different strategies to construct the desired signal. The extension of  the Bayes decision rule (0/1 desired signal), optimal in static  classification, performs worse than desired signals constructed by  random noise or prediction during the background.
Connectionist speech recognition systems are often handicapped by  an inconsistency between training and testing criteria. This problem is addressed by the Multi-State Time Delay Neural Network  (MS-TDNN), a hierarchical phoneme and word classifier which uses  DTW to modulate its connectivity pattern, and which is directly  trained on word-level targets. The consistent use of word accuracy as a criterion during both training and testing leads to very  high system performance, even wilh limited training data. Until  now, the MS-TDNN has been applied primarily to small vocabulary recognition and word spotting tasks. In this paper we apply  the architecture to large vocabulary continuous speech recognition,  and demonstrate that our MS-TDNN outperforms all other systems that have been tested on the CMU Conference Registration  database.
Untill recently, state-of-the-art, large-vocabulary, continuous speech  recognition (CSR) has employed Hidden Markov Modeling (HMM)  to model speech sounds. In an attempt to improve over HMM we  developed a hybrid system that integrates HMM technology with neural networks. We present the concept of a "Segmental Neural Net"  (SNN) for phonetic modeling in CSR. By taking into account all the  frames of a phonetic segment simultaneously, the SNN overcomes the  well-known conditional-independence limitation of HIVIMs. In several  speaker-independent experiments with the DARPA Resource Management corpus, the hybrid system showed a consistent improvement in  performance over the baseline HIVIM system.
The Multi-State Time Delay Neural Network (MS-TDNN) integrates a nonlinear time alignment procedure (DTW) and the highaccuracy phoneme spotting capabilities of a TDNN into a connectionist speech recognition system with word-level classification and  error backpropagation. We present an MS-TDNN for recognizing  continuously spelled letters, a task characterized by a small but  highly confusable vocabulary. Our MS-TDNN achieves 98.5/92.0%  word accuracy on speaker dependent/independent tasks, outperforming previously reported results on the same databases. We propose training techniques aimed at improving sentence level performance, including free alignment across word boundaries, word duration modeling and error backpropagation on the sentence rather  than the word level. Architectures integrating submodules specialized on a subset of speakers achieved further improvements.
This paper reports on the performance of two methods for  recognition-based segmentation of strings of on-line hand-printed  capital Latin characters. The input strings consist of a timeordered sequence of X-Y coordinates, punctuated by pen-lifts. The  methods were designed to work in "run-on mode" where there is no  constraint on the spacing between characters. While both methods  use a neural network recognition engine and a graph-algorithmic  post-processor, their approaches to segmentation are quite different. The first method, which we call INSEG (for input segmentation), uses a combination of heuristics to identify particular penlifts as tentative segmentation points. The second method, which  we call OUTSEG (for output segmentation), relies on the empirically trained recognition engine for both recognizing characters and  identifying relevant segmentation points.
We propose in this paper a statistical model (planar hidden Markov model PHMM) describing statistical properties of images. The model generalizes  the single-dimensional HMM, used for speech processing, to the planar case.  For this model to be useful an efficient segmentation algorithm, similar to the  Viterbi algorithm for HMM, must exist. We present conditions in terms of  the PHMM parameters that are sufficient to guarantee that the planar  segmentation problem can be solved in polynomial time, and describe an  algorithm for that. This algorithm aligns optimally the image with the model,  and therefore is insensitive to elastic distortions of images. Using this  algorithm a joint optimal segmentation and recognition of the image can be  performed, thus overcoming the wealmess of traditional OCR systems where  segmentation is performed independently before the recognition leading to  unrecoverable recognition errors.  The PHMM approach was evaluated using a set of isolated hand-written  digits. An overall digit recognition accuracy of 95% was achieved. An  analysis of the results showed that even in the simple case of recognition of  isolated characters, the elimination of elastic distortions enhances the  performance significantly. We expect that the advantage of this approach will  be even more significant for tasks such as connected writing  recognition/spotting, for which there is no known high accuracy method of  recognition.
We are developing a forecaster for daily extremes of demand for  electric power encountered in the service area of a large midwestern utility and using this application as a testbed for approaches  to input dimension reduction and decomposition of network training. Projection pursuit regression representations and the ability  of algorithms like SIR to quickly find reasonable weighting vectors  enable us to confront the vexing architecture selection problem by  reducing high-dimensional gradient searchs to fitting single-input  single-output (SISO) subnets. We introduce dimension reduction  algorithms, to select features or relevant subsets of a set of many  variables, based on minimizing an index of level-set dispersions  (closely related to a projection index and to SIR), and combine  them with backfitting to implement a neural network version of  projection pursuit. The performance achieved by our approach,  when trained on 1989, 1990 data and tested on 1991 data, is comparable to that achieved in our earlier study of backpropagation  trained networks.
Hidden Markov Models (HMMs) can be applied to several important problems in molecular biology. We introduce a new convergent  learning algorithm for HMMs that, unlike the classical Baum-Welch  algorithm is smooth and can be applied on-line or in batch mode,  with or without the usual Viterbi most likely path approximation.  Left-right HMMs with insertion and deletion states are then trained  to represent several protein families including immunoglobulins and  kinases. In all cases, the models derived capture all the important  statistical properties of the families and can be used efficiently in  a number of important tasks such as multiple alignment, motif detection, and classification.  *and Division of Biology, California Institute of Technology.  t and Department of Psychology, Stanford University.  747  748 Baldi, Chauvin, Hunkapiller, and McClure
The planar thallium-201 myocardial perfusion scintigram is a widely used  diagnostic technique for detecting and estimating the risk of coronary  artery disease. Neural networks learned to interpret 100 thallium scintigrams as determined by individual expert ratings. Standard error backpropagation was compared to standard LMS, and LMS combined with  one layer of RBF units. Using the "leave-one-out" method, generalization was tested on all 100 cases. Training time was determined automatically from cross-validation performance. Best performance was attained  by the RBF/LMS network with three hidden units per view and compares  favorably with human experts.
We have designed, fabricated, and tested an analog VLSI chip  which computes radial basis functions in parallel. We have developed a synapse circuit that approximates a quadratic function.  We aggregate these circuits to form radial basis functions. These  radial basis functions are then averaged together using a follower  aggregator.
An analog CMOS VLSI neural processing chip has been designed and fabricated. The device employs "pulse-stream" neural state siLmalling, and is capable of computing some 360 million symaptic connections per second. In addition to basic characterisation results. the performance of the chip in solving  "real-world" problems is also demonstrated.
The real time computation of motion from real images  using a single chip with integrated sensors is a hard problen. We present two analog VLSI schemes that use pulse  domain neuromorphic circuits to compute motion. Pulses  of variable width, rather than graded potentials, represent  a natural medimn for evaluating temporal relationships.  Both algorithms measure speed by timing a moving edge  in the image. Our first model is inspired by Reichardt's  algorithm in the fly and yields a non-monotonic response  rs. velocity curve. We present data from a chip that  implements this model. Our second algorithm yields a  nonotonic response rs. velocity curve and is currently  being translated into silicon.
We describe an analog VLSI implementation of a multi-dimensional  gradient estimation and descent technique for minimizing an onchip scalar function f(). The implementation uses noise injection and multiplicative correlation to estimate derivatives, as in  [Anderson, Kerns 92]. One intended application of this technique  is setting circuit parameters on-chip automatically, rather than  manually [Kirk 91]. Gradient descent optimization may be used  to adjust synapse weights for a backpropagation or other on-chip  learning implementation. The approach combines the features of  continuous multi-dimensional gradient descent and the potential  for an annealing style of optimization. We present data measured  from our analog VLSI implementation.
The field of software simulators for neural networks has been expanding very rapidly in the last years but their importance is still  being underestimated. They must provide increasing levels of assistance for the design, simulation and analysis of neural networks.  With our object-oriented framework (SESAME) we intend to show  that very high degrees of transparency, manageability and flexibility for complex experiments can be obtained. SESAME's basic design philosophy is inspired by the natural way in which researchers  explain their computational models. Experiments are performed  with networks of building blocks, which can be extended very easily. Mechanisms have been integrated to facilitate the construction  and analysis of very complex architectures. Among these mechanisms are the automatic configuration of building blocks for an  experiment and multiple inheritance at run-time.
Networks with local inhibition are shown to have enhanced computational performance with respect to the classical Hopfield-like networks. In particular the critical capacity of the network is increased  as well as its capability to store correlated patterns. Chaotic dynamic behaviour (exponentially long transients) of the devices indicates the overloading of the associative memory. An implementation based on a programmable logic device is here presented. A 16  neurons circuit is implemented whir a XILINK 4020 device. The  peculiarity of this solution is the possibility to change parts of the  project (weights, transfer function or the whole architecture) with  a simple software download of the configuration into the XILINK  chip.
We demonstrate the use of a digital signal processing board to construct  hybrid networks consisting of computer model neurons connected to a  biological neural network. This system operates in real time, and the  synaptic connections are realistic effective conductances. Therefore,  the synapses made from the computer model neuron are integrated  correctly by the postsynaptic biological neuron. This method provides  us with the ability to add additional, completely known elements to a  biological network and study their effect on network activity.  Moreover, by changing the parameters of the model neuron, it is  possible to assess the role of individual conductances in the activity of  the neuron, and in the network in which it participates.  'Present address, 1XL, Universit6 de Bordeaux 1-Enserb,  CNRSURA 846, 351 crs de la Liberation, 33405 Talence Cedex,  France.  Present address, LNPC, CNRS, Universit6 de Bordeaux 1, Place  de Dr. Peyneau, 33120 Arcachon, France  813  814 Renaud-LeMasson, LeMasson, Marder, and Abbott
Several research group are inl)hmcnl. ing alalog integrated circuit  models of biological auditory processing. The outl)uts of these  circuit nodels have taken several k)nns, including vicico format  for monitor display, simple scanned out. put for oscilloscope display  and parallel analog outl3uts suitable for da. ta-acquisition systems.  In this paper, we describe an alternative output method for silicon  auditory models, suitable for direct interfa. ce to digital computers.  * Present address: hi. Mallowaid, MI{.(-', Anatomical Neurol)hamacology  Unit, Mansfield Rd, Oxford OX 1 3TII England. mamvax. oxford. ac .uk  } Present. address: N!ass Sivilol.ti, 'l'ancr 1/,esca.rch, 180 North Vinedo  Avenue, Pasadena, CA 911()7, masstanner.com  + Present address: Dave Gilh,spic, Sval)l.ics, 2698 ()rcla. rd Parkway, San  Jose CA, 95134. davegsynaptics. corn  820  Silicon Auditory Processors as Computer Peripherals 821
We describe two successfully working, analog VLSI vision circuits  that move beyond pixel-based early vision algorithms. One circuit,  implementing the dynamic wires model, provides for dedicated lines  of communication among groups of pixels that share a common  property. The chip uses the dynamic wires model to compute the  arclength of visual contours. Another circuit labels all points inside  a given contour with one voltage and all other with another voltage. Its behavior is very robust, since small breaks in contours are  automatically sealed, providing for FigureGround segregation in  a noisy environment. Both chips are implemented using networks  of resistors and switches and represent a step towards object level  processing since a single voltage value encodes the property of an  ensemble of pixels.
Typical methods for gradient descent in neural network learning involve  calculation of derivatives based on a detailed knowledge of the network  model. This requires extensive, time consuming calculations for each pattern presentation and high precision that makes it difficult to implement  in VLSI. We present here a perturbation technique that measures, not  calculates, the gradient. Since the technique uses the actual network as  a measuring device, errors in modeling neuron activation and synaptic  weights do not cause errors in gradient descent. The method is parallel  in nature and easy to implement in VLSI. We describe the theory of such  an algorithm, an analysis of its domain of applicability, some simulations  using it and an outline of a hardware implementation.
Basic connectionist principles imply that gramxnars should take the  form of systems of parallel soft constraints defining an optimization  problem the solutions to which are the well-formed structures in  the language. Such Harmonic Grammars have been successfully  applied to a number of problems in the theory of natural languages.  IIere it is shown that formal languages too can be specified by  Harmonic Grammars, rather than by conventional serial re-write  rule systems.
Neural network models have been criticized for their inability to make  use of compositional representations. In this paper, we describe a series  of psychological phenomena that demonstrate the role of structured  representations in cognition. These findings suggest that people  compare relational representations via a process of structural alignment.  This process will have to be captured by any model of cognition,  symbolic or subsymbolic.
We present a neural net architecture that can discover hierarchical and recursire structure in symbol strings. To detect structure at multiple levels,  the architecture has the capability of reducing symbols substrings to single  symbols, and makes use of an external stack memory. In terms of formal  languages, the architecture can learn to parse strings in an LR(0) contextfree grammar. Given training sets of positive and negative exemplars,  the architecture has been trained to recognize many different grammars.  The architecture has only one layer of modifiable weights, allowing for a  straightforward interpretation of its behavior.  Many cognitive domains involve complex sequences that contain hierarchical or  recursire structure, e.g., music, natural language parsing, event perception. To illustrate, "the spider that ate the hairy fly" is a noun phrase containing the embedded noun phrase "the hairy fly." Understanding such multilevel structures requires  forming reduced descriptions (Hinton, 1988) in which a string of symbols or states  ("the hairy fly") is reduced to a single symbolic entity (a noun phrase). We present  a neural net architecture that learns to encode the structure of symbol strings via  such reduction transformations.  The difficult problem of extracting multilevel structure from complex, extended  sequences has been studied by Mozer (1992), Ring (1993), Rohwer (1990), and  Schmidhuber (1992), among others. While these previous efforts have made some  863  864 Mozer and Das  input  queue  default  unit demon units  symbol 1 symbol 2  stack units  Figure 1: The demon model.  progress, no one has claimed victory over the problem. Our approach is based on a  new perspective one of symbolic reduction transformations which affords a fresh  attack on the problem,
We demonstrate in this paper how certain forms of rule-based  knowledge can be used to prestructure a neural network of normalized basis functions and give a probabilistic interpretation of  the network architecture. We describe several ways to assure that  rule-based knowledge is preserved during training and present a  method for complexity reduction that tries to minimize the number of rules and the number of conjuncts. After training the refined  rules are extracted and analyzed.
We describe a model of visual word recognition that accounts for  several aspects of the temporal processing of sequences of briefly  presented words. The model utilizes a new representation for written words, based on dynamic time warping and multidimensional  scaling. The visual input passes through cascaded perceptual, comparison, and detection stages. We describe how these dynamical  processes can account for several aspects of word recognition, including repetition priming and repetition blindness.
We propose a model of the development of geometric reasoning in children that  explicitly involves learning. The model uses a neural network that is initialized  with an understanding of geometry similar to that of second-grade children.  Through the presentation of a series of examples, the model is shown to develop  an understanding of geometry similar to that of fifth-grade children who were  trained using similar materials.
Representations for semantic information about words are necessary for many applications of neural networks in natural language  processing. This paper describes an efficient, corpus-based method  for inducing distributed semantic representations for a large number of words (50,000) from lexical coccurrence statistics by means  of a large-scale linear regression. The representations are successfully applied to word sense disambiguation using a nearest neighbor  method.
Which processes underly our ability to quickly recognize familiar  objects within a complex visual input scene? In this paper an implemented neural network model is described that attempts to specify  how selective visual attention, perceptual organisation, and invariance transformations might work together in order to segment, select,  and recognize objects out of complex input scenes containing multiple, possibly overlapping objects. Retinotopically organized feature  maps serve as input for two main processing routes: the 'wherepathway' dealing with location information and the 'what-pathway'  computing the shape and attributes of objects. A location-based attention mechanism operates on an early stage of visual processing  selecting a contigous region of the visual field for preferential processing. Additionally, location-based attention plays an important role  for invariant object recognition controling appropriate normalization  processes within the what-pathway. Object recognition is supported  through the segmentation of the visual field into distinct entities. In  order to represent different segmented entities at the same time, the  model uses an oscillatory binding mechanism. Connections between  the where-pathway and the what-pathway lead to a flexible cooperation between different functional subsystems producing an overall  behavior which is consistent with a variety of psychophysical data.  903  904 Goebel
A computer model of the musculoskeletal system of the lobster  gastric mill was constructed in order to provide a behavioral interpretation of the rhythmic patterns obtained from isolated stomatogastric ganglion. The model was based on Hill's muscle model  and quasi-static approximation of the skeletal dynamics and could  simulate the change of chewing patterns by the effect of neuromodulators.
In the electrosensory system of weakly electric fish, descending  pathways to a first-order sensory nucleus have been shown to influence the gain of its output neurons. The underlying neural mechanisms that subserve this descending gain control capability are not  yet fully understood. We suggest that one possible gain control  mechanism could involve the regulation of total membrane conductance of the output neurons. In this paper, a neural model based  on this idea is used to demonstrate how activity levels on descending pathways could control both the gain and baseline excitation  of a target neuron.
A model of the hippocampus as a central element in rat navigation is presented. Simulations show both the behaviour of single  cells and the resultant navigation of the rat. These are compared  with single unit recordings and behavioural data. The firing of  CA1 place cells is simulated as the (artificial) rat moves in an environment. This is the input for a neuronal network whose output,  at each theta (0) cycle, is the next direction of travel for the rat.  Cells are characterised by the number of spikes fired and the time  of firing with respect to hippocampal 0 rhythm. 'Learning' occurs  in 'on-off' synapses that are switched on by simultaneous preand  post-synaptic activity. The simulated rat navigates successfully to  goals encountered one or more times during exploration in open  fields. One minute of random exploration of a lrn 2 environment  allows navigation to a newly-presented goal from novel starting positions. A limited number of obstacles can be successfully avoided.
We present a theory of cortico-hippocmnpal interaction in discrinination learning. The  hippocmnpal region is presumed to form new stinulus representations which facilitate  learning by enhancing the discrininability of predictive stimuli and conpressing  stimulus-stimulus redundancies. The cortical and cerebellar regions, which are the sites  of long-term metnory, nay acquire these new representations but m'e not asstuned to be  capable of forming new representations themselves. Instantiated as a connectionist  model, this theory accounts for a wide range of trial-level classical conditioning  phenmnena in normal (intact) and hippocampal-lesioned animals. It also nakes several  novel predictions which renain to be investigated empirically. The theory implies that  the hippocmnpal region is involved in even the simplest learning tasks; although  hippocampal-lesioned animals may be able to use other strategies to learn these tasks, the  theory predicts that they will show consistently different patterns of transfer and  generalization when the task demands change.
So far there has been no general method for relating extracellular  electrophysiological measured activity of neurons in the associative  cortex to underlying network or "cognitive" states. We propose  to model such data using a multivariate Poisson Hidden Markov  Model. We demonstrate the application of this approach for temporal segmentation of the firing patterns, and for characterization  of the cortical responses to external stimuli. Using such a statistical model we can significantly discriminate two behavioral modes  of the monkey, and characterize them by the different firing patterns, as well as by the level of coherency of their multi-unit firing  activity.  Our study utilized measurements carried out on behaving Rhesus  monkeys by M. Abeles, E. Vaadia, and H. Bergman, of the Hadassa  Medical School of the Hebrew University.
An information-theoretic optimization principle ('infomax') has  previously been used for unsupervised learning of statistical regularities in an input ensemble. The principle states that the inputoutput mapping implemented by a processing stage should be chosen so as to maximize the average mutual information between  input and output patterns, subject to constraints and in the presence of processing noise. In the present work I show how infomax,  when applied to a class of nonlinear input-output mappings, can  under certain conditions generate optimal filters that have additional useful properties: (1) Output activity (for each input pattern) tends to be concentrated among a relatively small number  of nodes. (2) The filters are sensitive to higher-order statistical  structure (beyond pairwise correlations). If the input features are  localized, the filters' receptive fields tend to be localized as well.  (3) Multiresolution sets of filters with subsampling at low spatial  frequencies related to pyramid coding and wavelet representations  emerge as favored solutions for certain types of input ensembles.
The vestibulo-ocular reflex (VOR) is a compensatory eye movement that  stabilizes images on the retina during head turns. Its magnitude, or gain,  can be modified by visual experience during head movements. Possible  learning mechanisms for this adaptation have been explored in a model  of the oculomotor system based on anatomical and physiological constraints. The local correlational learning rules in our model reproduce the  adaptation and behavior of the VOR under certain parameter conditions.  From these conditions, predictions for the time course of adaptation at  the learning sites are made.
We present a local learning rule in which Hebbian learning is  conditional on an incorrect prediction of a reinforcement signal.  We propose a biological interpretation of such a framework and  display its utility through examples in which the reinforcement  signal is cast as the delivery of a neuromodulator to its target.  Three examples are presented which illustrate how this framework  can be applied to the development of the oculomotor system.
A switching between apparently coherent (oscillatory) and stochastic  episodes of activity has been observed in responses from cat and monkey  visual cortex. We describe the dynamics of these phenomena in two parallel approaches, a phenomenological and a rather microscopic one. On the  one hand we analyze neuronal responses in terms of a hidden state model  (HSM). The parameters of this model are extracted directly from experimental spike trains. They characterize the underlying dynamics as well  as the coupling of individual neurons to the network. This phenomenological model thus provides a new framework for the experimental analysis  of network dynamics. The application of this method to multi unit activities from the visual cortex of the cat substantiates the existence of  oscillatory and stochastic states and quantifies the switching behaviour  in the assembly dynamics. On the other hand we start from the single  spiking neuron and derive a master equation for the time evolution of the  assembly state which we represent by a phase density. This phase density  dynamics (PDD) exhibits costability of two attractors, a limit cycle, and  a fixed point when synaptic interaction is nonlinear. External fluctuations  can switch the bistable system from one state to the other. Finally we  show, that the two approaches are mutually consistent and therefore both  explain the detailed time structure in the data.  977  978 Pawelzik, Bauer, Deppisch, and Geisel
A new computational model that addresses the formation of both topography and ocular dominance is presented. This is motivated by experimental evidence that these phenomena may be subserved by the same  mechanisms. An important aspect of this model is that ocular dominance segregation can occur when input activity is both distributed, and  positively correlated between the eyes. This allows investigation of the  dependence of the pattern of ocular dominance stripes on the degree of  correlation between the eyes: it is found that increasing correlation leads  to narrower stripes. Experiments are suggested to test whether such behaviour occurs in the natural system.
We interpret the time interval data obtained from periodically stimulated  sensory neurons in terms of two simple dynamical systems driven by noise  with an embedded weak periodic function called the signal: 1) a bistable  system defined by two potential wells separated by a barrier, and 2) a FitzHugh-Nagnmo system. The implementation is by analog simulation: elcotronic circuits which mimic the dynamics. For a given signal frequency, our  simulators have only two adjustable parameters, the signal and noise intensities. We show that experimental data obtained from the periodically stimulated mechanoreceptor in the crayfish tailfan can be accurately approximated  by these simulations. Finally, we discuss stochastic resonance in the two  models.
The formation of propagating spiral waves is studied in a randomly  connected neural network composed of integrate-and-fire neurons  with recovery period and cxcitatory connections using computer  simulations. Network activity is initiated by periodic stimulation  at a single point. The results suggest that spiral waves can arise in  such a network via a sub-critical Hopf bifurcation.
This paper examines and extends the work of Linsker (1986) on  self organising feature detectors. Linsker concentrates on the visual processing system, but infers that the weak assumptions made  will allow the model to be used in the processing of other sensory  information. This claim is examined here, with special attention  paid to the auditory system, where there is much lower connectivity and therefore more statistical variability. On-line training is  utilised, to obtain an idea of training times. These are then compared to the time available to pre-natal mammals for the formation  of feature sensitive cells.
This paper presents a neural network able to control saccadic  movements. The input to the network is a specification of a  stimulation site on the collicular motor map. The output is the time  course of the eye position in the orbit (horizontal and vertical angles).  The units in the network exhibit a one-to-one correspondance with  neurons in the intermediate layer of the superior colliculus (collicular  motor map), in the brainstem and with oculomotor neurons.  Simulations carried out with this network demonstrate its ability to  reproduce in a straightforward fashion many experimental observations.
It is known from biological data that the response patterns of  interneurons in the olfactory macroglomerulus (MGC) of insects are of  central importance for the coding of the olfactory signal. We propose an  analytically tractable model of the MGC which allows us to relate the  distribution of response patterns to the architecture of the network.
Information theory is used to derive a simple formula for the  amount of information conveyed by the firing rate of a neuron about  any experimentally measured variable or combination of variables  (e.g. running speed, head direction, location of the animal, etc.).  The derivation treats the cell as a communication channel whose  input is the measured variable and whose output is the cell's spike  train. Applying the formula, we find systematic differences in the  information content of hippocampal "place cells" in different experimental conditions.
An autoencoder network uses a set of recognition weights to convert an  input vector into a code vector. It then uses a set of generative weights to  convert the code vector into an approximate reconstruction of the input  vector. We derive an objective function for training autoencoders based  on the Minimum Description Length (MDL) principle. The aim is to  minimize the information required to describe both the code vector and  the reconstruction error. We show that this information is minimized  by choosing code vectors stochastically according to a Boltzmann distribution, where the generafive weights define the energy of each possible  code vector given the input vector. Unfortunately, if the code vectors  use distributed representations, it is exponentially expensive to compute  this Boltzmann distribution because it involves all possible code vectors.  We show that the recognition weights of an autoencoder can be used to  compute an approximation to the Boltzmann distribution and that this approximation gives an upper bound on the description length. Even when  this bound is poor, it can be used as a Lyapunov function for learning  both the generafive and the recognition weights. We demonstrate that  this approach can be used to learn factorial codes.
The Minimum Description Length principle (MDL) can be used to  train the hidden units of a neural network to extract a representation that is cheap to describe but nonetheless allows the input to  be reconstructed accurately. We show how MDL can be used to  develop highly redundant population codes. Each hidden unit has  a location in a low-dimensional implicit space. If the hidden unit  activities form a bump of a standard shape in this space, they can  be cheaply encoded by the center of this bump. So the weights from  the input units to the hidden units in an autoencoder are trained  to make the activities form a standard bump. The coordinates of  the hidden units in the implicit space are also learned, thus allowing flexibility, as the network develops a discontinuous topography  when presented with different input classes. Population-coding in  a space other than the input enables a network to extract nonlinear  higher-order properties of the inputs.  Most existing unsupervised learning algorithms can be understood using the Minimum Description Length (MDL) principle (Rissanen, 1989). Given an ensemble  of input vectors, the aim of the learning algorithm is to find a method of coding  each input vector that minimizes the total cost, in bits, of communicating the input  vectors to a receiver. There are three terms in the total description length:  ß The code-cost is the number of bits required to communicate the code  that the algorithm assigns to each input vector.  ll  12 Zemel and Hinton  ß The model-cost is the number of bits required to specify how to reconstruct input vectors from codes (e.g., the hidden-to-output weights).  ß The reconstruction-error is the number of bits required to fix up any  errors that occur when the input vector is reconstructed from its code.  Formulating the problem in terms of a communication model allows us to derive an  objective function for a network (note that we are not actually sending the bits).  For example, in competitive learning (vector quantization), the code is the identity  of the winning hidden unit, so by limiting the system to 7/ units we limit the  average code-cost to at most log 2 7/bits. The reconstruction-error is proportional  to the squared difference between the input vector and the weight-vector of the  winner, and this is what competitive learning algorithms minimize. The model-cost  is usually ignored.  The representations produced by vector quantization contain very little information  about the input (at most log s 7/bits). To get richer representations we must allow  many hidden units to be active at once and to have varying activity levels. Principal  components analysis (PCA) achieves this for linear mappings from inputs to codes.  It can be viewed as a version of MDL in which we limit the code-cost by only  having a few hidden units, and ignoring the model-cost and the accuracy with which  the hidden activities must be coded. An autoencoder (see Figure 2) that tries to  reconstruct the input vector on its output units will perform a version of PCA if the  output units are linear. We can obtain novel and interesting unsupervised learning  algorithms using this MDL approach by considering various alternative methods of  communicating the hidden activities. The algorithms can all be implemented by  backpropagating the derivative of the code-cost for the hidden units in addition to  the derivative of the reconstruction-error backpropagated from the output units.  Any method that communicates each hidden activity separately and independently  will tend to lead to factorial codes because any mutual information between hidden  units will cause redundancy in the communicated message, so the pressure to keep  the message short will squeeze out the redundancy. In (Zemel, 1993) and (Hinton  and Zemel, 1994), we present algorithms derived from this MDL approach aimed  at developing factoriM codes. Although factoriM codes are interesting, they are not  robust against hardware failure nor do they resemble the population codes found in  some parts of the brain. Our aim in this paper is to show how the MDL approach  can be used to develop population codes in which the activities of hidden units are  highly correlated. For a more complete discussion of the details of this algorithm,  see (Zemel, 1993).  Unsupervised algorithms contain an implicit assumption about the nature of the  structure or constraints underlying the input set. For example, competitive learning  algorithms are suited to datasets in which each input can be attributed to one of  a set of possible causes. In the algorithm we present here, we assume that each  input can be described as a point in a low-dimensional continuous constraint space.  For instance, a complex shape may require a detailed representation, but a set of  images of that shape from multiple viewpoints can be concisely represented by first  describing the shape, and then encoding each instance as a point in the constraint  space spanned by the viewing parameters. Our goal is to find and represent the  constraint space underlying high-dimensional data samples.  Developing Population Codes by Minimizing Description Length 13  size   ß 0 ø  ß  ß  0X0 *  orientatior  Figure 1: The population code for an instance in a two-dimensional implicit space.  The position of each blob corresponds to the position of a unit within the population,  and the blob size corresponds to the unit's activity. Here one dimension describes  the size and the other the orientation of a shape. We can determine the instantiation  parameters of this particular shape by computing the center of gravity of the blob  activities, marked here by an "X".
Although recurrent neural nets have been moderately successful  in learning to emulate finite-state machines (FSMs), the continuous internal state dynamics of a neural net are not well matched  to the discrete behavior of an FSM. We describe an architecture,  called )oLc, that allows discrete states to evolve in a net as learning progresses. OOLCr, consists of a standard recurrent neural net  trained by gradient descent and an adaptive clustering technique  that quantizes the state space. DOLCE is based on the assumption  that a finite set of discrete internal states is required for the task,  and that the actual network state belongs to this set but has been  corrupted by noise due to inaccuracy in the weights. DOLCe, learns  to recover the discrete state with maximum a posterJori probability from the noisy state. Simulations show that oo,c, leads to a  significant improvement in generalization performance over earlier  neural net approaches to FSM induction.
This paper presents a formulation for unsupervised learning of clusters reflecting multiple causal structure in binary data. Unlike the  standard mixture model, a multiple cause model accounts for observed data by combining assertions from many hidden causes, each  of which can pertain to varying degree to any subset of the observable dimensions. A crucial issue is the mixing-function for combining beliefs from different cluster-centers in order to generate data  reconstructions whose errors are minimized both during recognition  and learning. We demonstrate a weakness inherent to the popular  weighted sum followed by sigmoid squashing, and offer an alternative form of the nonlinearity. Results are presented demonstrating  the algorithm's ability successfully to discover coherent multiple  causal representations of noisy test data and in images of printed  characters.
We present a new algorithm for eliminating excess parameters and  improving network generalization after supervised training. The  method, "Principal Cmnponents Pruning (PCP)", is based on principal component analysis of the node activations of successive layers  of the network. It is simple, cheap to implement, and effective. It  requires no network retraining, and does not involve calculating  the full Hessian of the cost function. Only the weight and the node  activity correlation matrices for each layer of nodes are required.  We demonstrate the efficacy of the method on a regression problem  using polynomial basis functions, and on an economic time series  prediction problem using a two-layer, feedforward network.
Most connectionist research has focused on learning mappings from  one space to another (eg. classification and regression). This paper  introduces the more general task of learning constraint surfaces.  It describes a simple but powerful architecture for learning and  manipulating nonlinear surfaces from data. We demonstrate the  technique on low dimensional synthetic surfaces and compare it to  nearest neighbor approaches. We then show its utility in learning  the space of lip images in a system for improving speech recognition  by lip reading. This learned surface is used to improve the visual  tracking performance during recognition.
We analyze a simple hill-climbing algorithm (IMHC) that was previously shown to outperform a genetic algorithm (GA) on a simple  "Royal load" function. We then analyze an "idealized" genetic  algorithm (IGA) that is significantly faster than IMHC and that  gives a lower bound for GA speed. We identify the features of the  IGA that give rise to this speedup, and discuss how these features  can be incorporated into a real GA.
Selecting a good model of a set of input points by cross validation  is a computationally intensive process, especially if the number of  possible models or the number of training points is high. Techniques such as gradient descent are helpful in searching through  the space of models, but problems such as local minima, and more  importantly, lack of a distance metric between various models reduce the applicability of these search methods. Hoeffding Races is  a technique for finding a good model for the data by quickly discarding bad models, and concentrating the computational effort at  differentiating between the better ones. This paper focuses on the  special case of leave-one-out cross validation applied to memorybased learning algorithms, but we also argue that it is applicable  to any class of model selection problems.
We show how an "Ehnan" network architecture, constructed from  recurrently connected oscillatory associative memory network modules, can employ selective "attentional" control of synchronization  to direct the flow of communication and computation within the  architecture to solve a grammatical inference problem.  Previously we have shown how the discrete time "Ehnan" network  algorithm can be implemented in a network completely described  by continuous ordinary differential equations. The time steps (machine cycles) of the system are implemented by rhythmic variation  (clocking) of a bifurcation parameter. In this architecture, oscillation amplitude codes the information content or activity of a module (unit), whereas phase and frequency are used to "softwire" the  network. Only synchronized modules communicate by exchanging amplitude information; the activity of non-resonating modules  contributes incoherent crosstalk noise.  Attentional control is modeled as a special subset of the hidden  modules with ouputs which affect the resonant frequencies of other  hidden modules. They control synchrony among the other modules and direct the flow of computation (attention) to effect transitions between two subgraphs of a thirteen state automaton which  the system emulates to generate a Reber grammar. The internal  crosstalk noise is used to drive the required random transitions of  the automaton.  67  68 Baird, Troyer, and Eeckman
Learning to recognize or predict sequences using long-term context has many applications. However, practical and theoretical  problems are found in training recurrent neural networks to perform tasks in which input/output dependencies span long intervals.  Starting from a mathematical analysis of the problem, we consider  and compare alternative algorithms and architectures on tasks for  which the span of the input/output dependencies can be controlled.  Results on the new algorithms show performance qualitatively superior to that obtained with backpropagation.
This paper presents a simple algorithm to learn trajectories with a  continuous time, continuous activation version of the Boltzmann  machine. The algorithm takes advantage of intrinsic Brownian  noise in the network to easily compute gradients using entirely local  computations. The algorithm may be ideal for parallel hardware  implementations.  This paper presents a learning algorithm to train continuous stochastic networks  to respond with desired trajectories in the output units to environmental input  trajectories. This is a task, with potential applications to a variety of problems such  as stochastic modeling of neural processes, artificial motor control, and continuous  speech recognition. For example, in a continuous speech recognition problem, the  input trajectory may be a sequence of fast Fourier transform coefficients, and the  output a likely trajectory of phonemic patterns corresponding to the input. This  paper was based on recent work on diffusion networks by Movellan and McClelland  (in press) and by recent papers by Apolloni and de Falco (1991) and Neal (1992)  on asymmetric Boltzmann machines. The learning algorithm can be seen as a  generalization of their work to the stochastic diffusion case and to the problem of  learning continuous stochastic trajectories.  Diffusion networks are governed by the standard connectionist differential equations  plus an independent additive noise component. The resulting process is governed  * Part of this work was done while at Carnegie Mellon University.  83  84 Movellan  by a set of Langevin stochastic differential equations  dai(t) = hi drifti(t) dt +adBi(t) ; i  {1,...,n} (1)  where hi is the processing rate of the ita unit, a is the diffusion constant, which controls the flow of entropy throughout the network, and dBi(t) is a Brownian motion  differential (Soon, 1973). The drift function is the deterministic part of the process.  For consistency I use the same drift function as in Movellan and McClelland, 1992  but many other options are possible: drifti(t) = -?=l wiiaJ(t) f-lai(t), where  wij is the weight from the jth to the i th unit, and f- is the inverse of a logistic  function scaled in the (rnin max) interval:f-(a) = log a-,i  mtsot$ '  In practice DNs are simulated in digital computers with a system of stochastic  difference equations  ai(t + At) = ai(t) + hi drifti(t) At +  zi(t) ¾At ; i  {1, ...,n} (2)  where zi(t) is a standard Gaussian random variable. I start the derivations of  the learning algorithm for the trajectory learning task using the discrete time process (equation 2) and then I take limits to obtain the continuous diffusion expression. To simplify the derivations I adopt the following notation: a trajectory  of states -input, hidden and output unitsis represented as a = [a(1)...a(tm)] =  The trajectory vector can be partitioned into 3  consecutive row vectors representing the trajectories of the input, hidden and output units a = [xhy].  The key to the learning algorithm is obtaining the gradient of the probability of  specific trajectories. Once we know this gradient we have all the information needed  to increase the probability of desired trajectories and decrease the probability of  unwanted trajectories. To obtain this gradient we first need to do some derivations  on the transition probability densities. Using the discrete time approximation to  the diffusion process, it follows that the conditional transition probability density  functions are multivariate Gaussian  p(a(t + At)la(t)) =  From equation 2 and 3 it follows that  Since the  computed from the product of the transition probabilities  era--!  r(a) = r(a(t0)) 17I p((t +  =o  The derivative of the probability of a specific trajectory follows  Or() ½  =  =to  0  Owi-log p(a(t + At)l a(t)) = hizi(t) ¾aj(t) (4)  network is Markovian, the probability of an entire trajectory can be  (5)  (6)  A Local Algorithm to Learn Trajectories with Stochastic Neural Networks 85  In practice, the above rule is all is needed for discrete time computer simulations.  We can obtain the continuous time form by taking limits as At -. O, in which case  the sum becomes Ito's stochastic integral of aj(t) with respect to the Brownian  motion differential over a {to, T} interval.  A similar equation may be obtained for the )q parameters  For notational convenience I define the following random variables and refer to them  as the delia signals  Svii(a) c31og p(a) hl T  = = -a(i)dBi(t) (9)  and  5x,(a) = Olog p(a) = 1_. a' drifti(i)dBi(t) (10)  A 1 B  1  I I  0 100 200 900 0 100 200 300  Time Steps Time Steps  Figure 1: A) A sample Trajectory. B) The Average Trajectory. As Time Progresses  Sample Trajectories Become Statistically Independent Dampening the Average.  86 Movellan  The approach taken in this paper is to minimize the expected value of the error  assigned to spontaneously generated trajectories 0 = E(p(a)) where p(a) is a signal  indicating the overall error of a particular trajectory and usually depends only on  the output unit trajectory. The necessary gradients follow  0o  = E(6,,jp) (11)  Owij  o  =  Since the above learning rule does not require calculating derivatives of the p function, it provides great flexibility making it applicable to a wide variety of situations.  For example p(a) can be the TSS between the desired and obtained output unit  trajectories or it could be a reinforcement signal indicating whether the trajectory is  or is not desirable. Figure 1.a shows a typical output of a network trained with TSS  as the p signal to follow a sinusoidal trajectory. The network consisted of 1 input  unit, 3 hidden units, and 1 output unit. The input was constant through time and  the network was trained only with the first period of the sinusoid. The expected  values in equations 11 and 12 were estimated using 400 spontaneously generated  trajectories at each learning epoch. It is interesting to note that although the network was trained for a single period, it continued oscillating without dampening.  However, the expected value of the activations dampened, as Figure 1.b shows.  The dampening of the average activation is due to the fact that as time progresses,  the effects of noise accumulate and the initially phase locked trajectories become  independent oscillators.  2O  p transition: 0.2  Hidden state: 0  Hidden state = 1  p(response 1): 0.1 p(response 1): 0.8  18140  0 640  .0  best possible performance
This paper introduces GNARL, an evolutionary program which induces  recurrent neural networks that are structurally unconstrained. In contrast  to constructive and destructive algorithms, GNARL employs a population of networks and uses a fitness function's unsupervised feedback to  guide search through network space. Annealing is used in generating  both gaussian weight changes and structural modifications. Applying  GNARL to a complex search and collection task demonstrates that the  system is capable of inducing networks with complex internal dynamics.
With a point matching distance measure which is invariant under  translation, rotation and permutation, we learn 2-D point-set objects, by clustering noisy point-set images. Unlike traditional clustering methods which use distance measures that operate on feature  vectors a representation common to most problem domains this  object-based clustering technique employs a distance measure specific to a type of object within a problem domain. Formulating  the clustering problem as two nested objective functions, we derive  optimization dynamics similar to the Expectation-Maximization  algorithm used in mixture models.
Data clustering amounts to a combinatorial optimization problem to reduce the complexity of a data representation and to increase its precision.  Central and pairwise data clustering are studied in the maximum entropy framework. For central clustering we derive a set of reestimation  equations and a minimization procedure which yields an optimal number of clusters, their centers and their cluster probabilities. A meanfield  approximation for pairwise clustering is used to estimate assignment  probabilities. A selfconsistent solution to multidimensional scaling and  pairwise clustering is derived which yields an optimal embedding and  clustering of data points in a d-dimensional Euclidian space.
One of the advantages of supervised learning is that the final error metric is available during training. For classifiers, the algorithm can directly  reduce the number of misclassifications on the training set. Unfortunately, when modeling human learning or constructing classifiers for autonomous robots, supervisory labels are often not available or too expensive. In this paper we show that we can substitute for the labels by  making use of structure between the pattern distributions to different sensory modalities. We show that minimizing the disagreement between the  outputs of networks processing patterns from these different modalities is  a sensible approximation to minimizing the number of misclassifications  in each modality, and leads to similar results. Using the Peterson-Barney  vowel dataset we show that the algorithm performs well in finding appropriate placement for the codebook vectors particularly when the confuseable classes are different for the two modalities.
Real-world learning tasks may involve high-dimensional data sets  with arbitrary patterns of missing data. In this paper we present  a framework based on maximum likelihood density estimation for  learning from such data. sets. We use mixture models for the density estimates and make two distinct appeals to the ExpectationMaximization (EM) principle (Dempster et al., 1977) in deriving  a learning algorithm--EM is used both for the estimation of mixture components and for coping with missing data. The resulting algorithm is applicable to a wide range of supervised as well  as unsupervised learning problems. Results kom a classification  benchmark--the iris data set--are presented.
We analyze how data with uncertain or missing input features can  be incorporated into the training of a neural network. The general solution requires a weighted integration over the unknown or  uncertain input although computationally cheaper closed-form solutions can be found for certain Gaussian Basis Function (GBF)  networks. We also discuss cases in which heuristical solutions such  as substituting the mean of an unknown input can be harmful.
We describe a number of learning rules that can be used to train  supervised parallel feature extraction systems. The learning rules  are derived using gradient ascent of a quality function. We consider a number of quality functions that are rational functions of  higher order moments of the extracted feature values. We show  that one system learns the principle components of the correlation matrix. Principal component analysis systems are usually not  optimal feature extractors for classification. Therefore we design  quality functions which produce feature vectors that support unsupervised classification. The properties of the different systems are  compared with the help of different artificially designed datasets  and a database consisting of all Munsell color spectra.
The Singular Value Decomposition (SVD) is an important tool for  linear algebra and can be used to invert or approximate matrices.  Although many authors use "SVD" synonymously with "Eigenvector Decomposition" or "Principal Components Transform", it  is important to realize that these other methods apply only to  symmetric matrices, while the SVD can be applied to arbitrary  nonsquare matrices. This property is important for applications to  signal transmission and control.  I propose two new algorithms for iterative computation of the SVD  given only sample inputs and outputs from a matrix. Although  there currently exist many algorithms for Eigenvector Decomposition (Sanger 1989, for example), these are the first true samplebased SVD algorithms.
We present a fast algorithm for non-linear dimension reduction.  The algorithm builds a local linear model of the data by merging  PCA with clustering based on a new distortion measure. Experiments with speech and image data indicate that the local linear  algorithm produces encodings with lower distortion than those built  by five layer auto-associative networks. The local linear algorithm  is also more than an order of magnitude faster to train.
An approach is presented to learning high dimensional functions in the case  where the learning algorithm can affect the generation of new data. A local  modeling algorithm, locally weighted regression, is used to represent the learned  function. Architectural parameters of the approach, such as distance metrics, are  also localized and become a function of the query point instead of being global.  Statistical tests are given for when a local model is good enough and sampling  should be moved to a new area. Our methods explicitly deal with the case where  prediction accuracy requirements exist during exploration: By gradually shifting  a "center of exploration" and controlling the speed of the shift with local prediction accuracy, a goal-directed exploration of state space takes place along the  fringes of the current data support until the task goal is achieved. We illustrate  this approach with simulation results and results from a real robot learning a  complex juggling task.  1
By their very nature, memory based algorithms such as KNN or  Parzen windows require a computationally expensive search of a  large database of prototypes. In this paper we optimize the searching process for tangent distance (Simard, LeCun and Denker, 1993)  to improve speed performance. The closest prototypes are found  by recursively searching included subsets of the database using distances of increasing complexity. This is done by using a hierarchy  of tangent distances (increasing the number of tangent vectors from  0 to its maximum) and multiresolution (using wavelets). At each  stage, a confidence level of the classification is computed. If the  confidence is high enough, the computation of more complex distances is avoided. The resulting algorithm applied to character  recognition is close to three orders of magnitude faster than computing the full tangent distance on every prototypes.
We propose a learning algorithm for a variable memory length  Markov process. Human communication, whether given as text,  handwriting, or speech, has multi characteristic time scales. On  short scales it is characterized mostly by the dynamics that generate the process, whereas on large scales, more syntactic and semantic information is carried. For that reason the conventionally  used fixed memory Markov models cannot capture effectively the  complexity of such structures. On the other hand using long memory models uniformly is not practical even for as short memory as  four. The algorithm we propose is based on minimizing the statistical prediction error by extending the memory, or state length,  adaptively, until the total prediction error is sufficiently small. We  demonstrate the algorithm by learning the structure of natural English text and applying the learned model to the correction of corrupted text. Using less than 3000 states the model's performance  is far superior to that of fixed memory models with similar number of states. We also show how the algorithm can be applied to  intergenic E. coli DNA base prediction with results comparable to  HMM based methods.
Four versions of a k-nearest neighbor algorithm with locally adaptive k are introduced and compared to the basic k-nearest neighbor algorithm (kNN). Locally adaptive kNN algorithms choose the  value of k that should be used to classify a query by consulting the  results of cross-validation computations in the local neighborhood  of the query. Local kNN methods are shown to perform similar to  kNN in experiments with twelve commonly used data sets. Encouraging results in three constructed tasks show that local methods  can significantly outperform kNN in specific applications. Local  methods can be recommended for on-line learning and for applications where different regions of the input space are covered by  patterns solving different sub-tasks.
In this paper, it is shown that the conventional back-propagation  (BPP) algorithm for neural network regression is robust to leverages (data with = corrupted), but not to outliers (data with y  corrupted). A robust model is to model the error as a mixture of  normal distribution. The influence function for this mixture model  is calculated and the condition for the model to be robust to outliers  is given. EM algorithm [5] is used to estimate the parameter. The  usefulness of model selection criteria is also discussed. Illustrative  simulations are performed.
The conventional Bayesian justification of backprop is that it finds the  MAP weight vector. As this paper shows, to find the MAP i-o function  instead one must add a correction term to backprop. That term biases one  towards i-o functions with small description lengths, and in particular favors (some kinds of) feature-selection, pruning, and weight-sharing.
MacKay's Bayesian framework for backpropagation is conceptually  appealing as well as practical. It automatically adjusts the weight  decay parameters during training, and computes the evidence for  each trained network. The evidence is proportional to our belief  in the model. The networks with highest evidence turn out to  generalise well. In this paper, the framework is extended to pruned  nets, leading to an Ockham Factor for "tuning the architecture  to the data". A committee of networks, selected by their high  evidence, is a natural Bayesian construction. The evidence of a  committee is computed. The framework is illustrated on real-world  data from a near infrared spectrometer used to determine the fat  content in minced meat. Error bars are computed, including the  contribution from the dissent of the committee members.
In drug activity prediction (as in handwritten character recognition), the features extracted to describe a training example depend  on the pose (location, orientation, etc.) of the example. In handwritten character recognition, one of the best techniques for addressing this problem is the tangent distance method of Simard,  LeCun and Denker (1993). Jain, et al. (1993a; 1993b) introduce a  new technique--dynamic reposing--that also addresses this problem. Dynamic reposing iteratively learns a neural network and then  reposes the examples in an effort to maximize the predicted output values. New models are trained and new poses computed until  models and poses converge. This paper compares dynamic reposing  to the tangent distance method on the task of predicting the biological activity of musk compounds. In a 20-fold cross-validation,  216  A Comparison of Dynamic Reposing and Tangent Distance for Drug Activity Prediction 217  dynamic reposing attains 91% correct compared to 79% for the  tangent distance method, 75% for a neural network with standard  poses, and 75% for the nearest neighbor method.
We propose a method for improving the performance of any network designed to predict the next value of a time series. We advocate analyzing the deviations of the network's predictions from the  data in the training set. This can be carried out by a secondary network trained on the time series of these residuals. The combined  system of the two networks is viewed as the new predictor. We  demonstrate the simplicity and success of this method, by applying it to the sunspots data. The small corrections of the secondary  network can be regarded as resulting from a Taylor expansion of  a complex network which includes the combined system. We find  that the complex network is more difficult to train and performs  worse than the two-step procedure of the combined system.
The back propagation algorithm has been modified to work without any multiplications and to tolerate computations with a low  resolution, which makes it more attractive for a hardware implementation. Numbers are represented in floating point format with  i bit mantissa and 3 bits in the exponent for the states, and i bit  mantissa and 5 bit exponent for the gradients, while the xveights are  16 bit fixed-point numbers. In this way, all the computations can  be executed with shift and add operations. Large netxvorks with  over 100,000 weights were trained and demonstrated the same performance as networks computed with full precision. An estimate of  a circuit implementation shows that a large network can be placed  on a single chip, reaching more than 1 billion weight updates per  second. A speedup is also obtained on any machine where a multiplication is slower than a shift operation.
Bumptrees are geometric data structures introduced by Omohundro  (1991) to provide efficient access to a collection of functions on a  Euclidean space of interest. We describe a modified bumptree structure  that has been employed as a neural network classifier, and compare its  performance on several classification tasks against that of radial basis  function networks and the standard mutli-layer perceptron.
Performance of many nonparametric methods critically depends  on the strategy for positioning knots along the regression surface.  Constrained Topological Mapping algorithm is a novel method that  achieves adaptive knot placement by using a neural network based  on Kohonen's self-organizing maps. We present a modification to  the original algorithm that provides knot placement according to  the estimated second derivative of the regression surface.
We present a new incremental radial basis function network suitable for classification and regression problems. Center positions  are continuously updated through soft competitive learning. The  width of the radial basis functions is derived from the distance  to topological neighbors. During the training the observed error  is accumulated locally and used to determine where to insert the  next unit. This leads (in case of classification problems) to the  placement of units near class borders rather than near frequency  peaks as is done by most existing methods. The resulting networks  need few training epochs and seem to generalize very well. This is  demonstrated by examples.
We extend Optimal Brain Surgeon (OBS) -a second-order  method for pruning networks -to allow for general error measures, and explore a reduced computational and storage implementation via a dominant eigenspace decomposition. Simulations on  nonlinear, noisy pattern classification problems reveal that OB$  does lead to improved generalization, and performs favorably in  comparison with Optimal Brain Damage (OBD). We find that the  required retraining steps in OBD may lead to inferior generalization, a result that can be interpreted as due .to injecting noise back  into the system. A common technique is to stop training of a large  network at the minimum validation error. We found that the test  error could be reduced even further by means of OB$ (but not  OBD) pruning. Our results justify the t - o approximation used  in OB$ and indicate why retraining in a highly pruned network  may lead to inferior performance.  263  264 Hassibi, Stork, Wolff, and Watanabe
In the present paper, we propose an entropy method to transform  the internal representation. The entropy function is defined with  respect to the state of hidden unit, that is, internal representation.  The internal representation can be transformed by changing the  parameter c for the entropy function. Thus, the transformation is  referred to as -transformation. The internal representation can  be transformed according to given problems. By transforming the  internal representation into the minimum entropy representation,  we can obtain kernel networks, smaller networks with explicit interpretation. On the other hand, by changing appropriately the  parameter a, we can obtain intermediate internal representations  for the improved generalization. We applied the entropy method  to an autoencoder and we succeeded in obtaining kernel networks  with small internal entropy. In addition, we applied the method  to the frequency identification problem and we could obtain derived networks whose generalization performance was significantly  superior to the performance by standard back-propagation.
We present an algorithm for the training of feedforward and recurrent neural networks. It detects internal representation conflicts  and uses these conflicts in a constructive manner to add new neurons to the network. The advantages are twofold: (1) starting with  a small network neurons are only allocated when required; (2) by  detecting and resolving internal conflicts at an early stage learning  time is reduced. Empirical results on two real-world problems substantiate the faster learning speed; when applied to the training  of a recurrent network on a well researched sequence recognition  task (the Reber grammar), training times are significantly less than  previously reported.
I propose a learning algorithm for learning hierarchical models for object recognition. The model architecture is a compositional hierarchy  that represents part-whole relationships: parts are described in the local context of substructures of the object. The focus of this report is  learning hierarchical models from data, i.e. inducing the structure of  model prototypes from observed exemplars of an object. At each node  in the hierarchy, a probability distribution governing its parameters must  be learned. The connections between nodes reflects the structure of the  object. The formulation of substructures is encouraged such that their  parts become conditionally independent. The resulting model can be  interpreted as a Bayesian Belief Network and also is in many respects  similar to the stochastic visual grammar described by Mjolsness.
This paper proposes a practical optimization method for layered  neural networks, by which the optimal model and parameter can  be found simultaneously. We modify the conventional information  criterion into a differentiable function of parameters, and then, minimize it, while controlling it back to the ordinary form. Effectivehess of this inethod is discussed theoretically and experimentally.
We study the problexn of when to stop learning a class of feedforward networks  networks with linear outputs neuron and fixed input weights when they are  trained with a gradient descent a.lgorithm on a finite number of examples. Under  general regularity conditions, it is shown that there are in general three distinct  phases in the generalization performance in the learning process, and in particular,  the network has better generalization performance when learning is stopped at a  certain time before the global minimum of the empirical error is reached. A notion  of effective size of a machine is defined and used to explain the trade-off between  the complexity of the machine and the training error in the learning process.  The study leads naturally to a network size selection criterion, which turns out to  be a generalization of Akaike's Infornmtion Criterion for the learning process. It is  shown tha. t stopping learning before the global minimum of the empirical error has  the effect of network size selection.
There exist a number of negative results ([J], [BR], [KV]) about  learning on neural nets in Valiant's model IV] for probably approximately correct learning ("PAC-learning"). These negative results  are based on an asymptotic analysis where one lets the number of  nodes in the neural net go to infinity. Hence this analysis is less adequate for the investigation of learning on a small fixed neural net  with relatively few analog inputs (e.g. the principal components of  some sensory data). The latter type of learning problem gives rise  to a different kind of asymptotic question: Can the true error of the  neural net be brought arbitrarily close to that of a neural net with  "optimal" weights through sufficiently long training? In this paper  we employ some new arguments in order to give a positive answer  to this question in Haussler's rather realistic refinement of Valiant's  model for PAC-learning ([H], [KSS]). In this more realistic model  no a-priori assumptions are required about the "learning target",  noise is permitted in the training data, and the inputs and outputs  are not restricted to boolean values. As a special case our result  implies one of the first positive results about learning on multi-layer  neural nets in Valiant's original PAC-learning model. At the end  of this paper we will describe an efficient parallel implementation  of this new learning algorithm.
We study the complexity problem in artificial feedforward neural networks  designed to approximate real valued functions of several real variables; i.e.,  we estimate the number of neurons in a network required to ensure a given  degree of approximation to every function in a given function class. We  indicate how to construct networks with the indicated number of neurons  evaluating standard activation functions. Our general theorem shows that  the smoother the activation function, the better the rate of approximation.
Training classifiers on large databases is computationally demanding. It is desirable to develop efficient procedures for a reliable  prediction of a classifier's suitability for implementing a given task,  so that resources can be assigned to the most promising candidates  or freed for exploring new classifier candidates. We propose such  a practical and principled predictive method. Practical because it  avoids the costly procedure of training poor classifiers on the whole  training set, and principled because of its theoretical foundation.  The effectiveness of the proposed procedure is demonstrated for  both singleand multi-layer networks.
We study feed-forward nets with arbitrarily many layers, using the standard sigmoid, tanh x. Aside from technicalities, our theorems are:
We show how randomly scrambling the output classes of various  fractions of the training data may be used to improve predictive  accuracy of a classification algorithm. We present a method for  calculating the "noise sensitivity signature" of a learning algorithm  which is based on scrambling the output classes. This signature can  be used to indicate a good match between the complexity of the  classifier and the complexity of the data. Use of noise sensitivity  signatures is distinctly different from other schemes to avoid overtraining, such as cross-validation, which uses only part of the training data, or various penalty functions, which are not data-adaptive.  Noise sensitivity signature methods use all of the training data and  are manifestly data-adaptive and non-parametric. They are well  suited for situations with limited training data.
We have recently shown that the widely known LMS algorithm is  an H a optimal estimator. The H a criterion has been introduced,  initially in the control theory literature, as a means to ensure robust performance in the face of model uncertainties and lack of  statistical information on the exogenous signals. We extend here  our analysis to the nonlinear setting often encountered in neural  networks, and show that the backpropagation algorithm is locally  H a optimal. This fact provides a theoretical justification of the  widely observed excellent robustness properties of the LMS and  backpropagation algorithms. We further discuss some implications  of these results.
In this paper the efficiency of recurrent neural network implementations of m-state finite state machines will be explored. Specifically,  it will be shown that the node complexity for the unrestricted case  can be bounded above by O (x/) ß It will also be shown that the  node complexity is O (x/m log m) when the weights and thresholds  are restricted to the set {1, 1}, and O (m) when the fan-in is restricted to two. Matching lower bounds will be provided for each  of these upper bounds assuming that the state of the FSM can be  encoded in a subset of the nodes of size [log mi.
For two layer networks with n sigmoidal hidden units, the generalization error is  shown to be bounded by  0(: ) + O( (:C)d  N  where d and N are the input dimension and the number of training samples, respectively. E represents the expectation on random number I( of hidden units  (1 _< X _< n). The proba,bility Pr(I( = k) (1 <_ k <_ n) is dctermined by a prior  distribution of weights, which corresponds to a Gibbs distribtttion of a regularizer.  This relationship makes it possible to characterize explicitly how a regularization  term affects bias/variance of networks. The bound can be obta.ined analytically  for a large c. lass of commonly used priors. It can also be applied to estimate the  expected network complexity E.r in practice. The result provides a quantitative  explanation on how large networks can generalize well.
We show that a randomly selected N-tuple  of points of R ' with  probability > 0 is such that any multi-layer perceptron with the  first hidden layer composed of hi threshold logic units can impleof. >  ment exactly 2 z_,i:0 then such a perceptron must have all units of the first hidden layer  fully connected to inputs. This implies the maximal capacities (in  the sense of Cover) of 2n input patterns per hidden unit and 2 input  patterns per synaptic weight of such networks (both capacities are  achieved by networks with single hidden layer and are the same as  for a single neuron). Comparing these results with recent estimates  of VC-dimension we find that in contrast to the single neuron case,  for sufficiently large n and hi, the VC-dimension exceeds Cover's  capacity.
The fundamental backpropagation (BP) algorithm for training artificial neural networks is cast as a deterministic nonmonotone perturbed gradient method. Under certain natural assumptions, such  as the series of learning rates diverging while the series of their  squares converging, it is established that every accumulation point  of the online BP iterates is a stationary point of the BP error function. The results presented cover serial and parallel online BP,  modified BP with a momentum term, and BP with weight decay.
Integrated Mean Squared Error (IMSE) is a version of the usual  mean squared error criterion, averaged over all possible training  sets of a given size. If it could be observed, it could be used  to determine optimal network complexity or optimal data subsets for efficient training. We show that two common methods of  cross-validating average squared error deliver unbiased estimates  of IMSE, converging to IMSE with probability one. These estimates thus make possible approximate IMSE-based choice of network complexity. We also show that two variants of cross validation  measure provide unbiased IMSE-based estimates potentially useful  for selecting optimal data subsets.
The problem of learning from examples in multilayer networks is  studied within the framework of statistical mechanics. Using the  replica formalism we calculate the average generalization error of a  fully connected committee machine in the limit of a large number  of hidden units. If the number of training examples is proportional  to the number of inputs in the network, the generalization error  as a function of the training set size approaches a finite value. If  the number of training examples is proportional to the number of  weights in the network we find first-order phase transitions with a  discontinuous drop in the generalization error for both binary and  continuous weights.
Neurons learning under an unsupervised Hebbian learning rule can  perform a nonlinear generalization of principal component analysis.  This relationship between nonlinear PCA and nonlinear neurons is  reviewed. The stable fixed points of the neuron learning dynamics  correspond to the maxima of the statist, ic optimized under nonlinear PCA. However, in order to predict, what the neuron learns,  knowledge of the basins of attractions of the neuron dynamics is  required. Here the correspondence between nonlinear PCA and  neural networks breaks down. This is shown for a simple model.  Methods of statistical mechanics can be used to find the optima  of the objective function of non-linear PCA. This determines what  the neurons can learn. In order to find how the solutions are partitioned amoung the neurons, however, one must solve the dynamics.
We describe the use of smoothing spline analysis of variance (SSANOVA) in the penalized log likelihood context, for learning  (estimating) the probability p of a '1' outcome, given a training set with attribute vectors and outcomes. p is of the form  p(t) el(t)/(1 + el(t)), where, if t is a vector of attributes, f  is learned as a sum of smooth functions of one attribute plus a  sum of smooth functions of two attributes, etc. The smoothing  parameters governing f are obtained by an iterative unbiased risk  or iterative GCV method. Confidence intervals for these estimates  are available.
Solvable models of nonlinear lem'ning machines m'e proposed, and  learning in artificial neural networks is studied based on the theory  of ordinary differential equations. A learning algorithm is constructed, by which the optimal parameter can be found without  any recursive procedure. The solvable models enable us to analyze  the reason why experimental results by the error backpropagation  often contradict the statistical learning theory.
We prove that the so called "loading problem" for (recurrent) neural networks is unsolvable. This extends several results which already demonstrated that training and related design problems for neural networks are  (at least) NP-complete. Our result also implies that it is impossible to  find or to formulate a universal training algorithm, which for any neural network architecture could determine a correct set of weights. For  the simple proof of this, we will just show that the loading problem is  equivalent to "Hilbert's tenth problem" which is known to be unsolvable.
The satisfiability of random CNF formulae with precisely k variables per clause ("k-SAT") is a popular testbed for the performance  of search algorithms. Formulae have M clauses from N variables,  randomly negated, keeping the ratio a M/N fixed. For k 2,  this model has been proven to have a sharp threshold at a 1  between formulae which are almost aways satisfiable and formulae  which are almost never satisfiable as N -- oc. Computer experiments for k 2, 3, 4, 5 and 6, (carried out in collaboration with  B. Selman of ATT Bell Labs.). show similar threshold behavior for  each value of k. Finite-size scaling, a theory of the critical point  phenomena used in statistical physics, is shown to characterize the  size dependence near the threshold. Annealed and replica-based  mean field theories give a good account of the results.  *Permanent address: IBM TJ Watson Research Center, Yorktown Heights, NY 10598  USA. (kirk@watson.ibm.com) Portions of this work were done while visiting the Salk  Institute, with support from the McDonnell-Pew Foundation.  439  440 Kirkpatrick, GyOrgyi, Tishby, and Troyansky
A simple model of coupled dynamics of fast neurons and slow interactions, modelling self-organization in recurrent neural networks,  leads naturally to an effective statistical mechanics characterized  by a partition function which is an average over a replicated system.  This is reminiscent of the replica trick used to study spin-glasses,  but with the difference that the number of replicas has a physical meaning as the ratio of two temperatures and can be varied  throughout the whole range of real values. The model has interesting phase consequences as a function of varying this ratio and  external stilnuli, and can be extended to a range of other models.
We prove that except possibly for small exceptional sets, discretetime analog neural nets are globally observable, i.e. all their corrupted pseudo-orbits on computer simulations actually reflect the  true dynamical behavior of the network. Locally finite discrete  (boolean) neural networks are observable without exception.
What is the 'correct' theoretical description of neuronal activity?  The analysis of the dynamics of a globally connected network of  spiking neurons (the Spike Response Model) shows that a description by mean firing rates is possible only if active neurons fire incoherently. If firing occurs coherently or with spatio-temporal correlations, the spike structure of the neural code becomes relevant.  Alternatively, neurons can be gathered into local or distributed ensembles or 'assemblies'. A description based on the mean ensemble  activity is, in principle, possible but the interaction between different assemblies becomes highly nonlinear. A description with spikes  should therefore be preferred.
Most theoretical investigations of large recurrent networks focus on  the properties of the macroscopic order parameters such as population averaged activities or average overlaps with memories. However, the statistics of the fluctuations in the local activities may  be an important testing ground for comparison between models  and observed cortical dynamics. We evaluated the neuronal correlation functions in a stochastic network comprising of excitatory  and inhibitory populations. We show that when the network is in  a stationary state, the cross-correlations are relatively weak, i.e.,  their amplitude relative to that of the auto-correlations are of order of l/N, N being the size of the interacting population. This  holds except in the neighborhoods of bifurcations to nonstationary  states. As a bifurcation point is approached the amplitude of the  cross-correlations grows and becomes of order 1 and the decay timeconstant diverges. This behavior is analogous to the phenomenon  of critical slowing down in systems at thermal equilibrium near a  critical point. Near a Hopf bifurcation the cross-correlations exhibit damped oscillations.  471  472 Ginzburg and Sompolinsky
Stochastic optimization algorithms typically use learning rate  schedules that behave asymptotically as (t) = o/t. The ensemble dynamics (Leen and Moody, 1993) for such algorithms provides  an easy path to results on mean squared weight error and asymptotic normality. We apply this approach to stochastic gradient  algorithms with momentum. We show that at late times, learning  is governed by an effective learning rate e# o/(1 -/) where  / is the momentum parameter. We describe the behavior of the  asymptotic weight error and give conditions on e# that insure  optimal convergence speed. Finally, we use the results to develop  an adaptive form of momentum that achieves optimal convergence  speed independent of o.
In [Meilijson and Ruppin, 1993] we presented a methodological  framework describing the two-iteration performance of Hopfieldlike attractor neural networks with history-dependent, Bayesian  dynamics. We now extend this analysis in a number of directions:  input patterns applied to small subsets of neurons, general connectivity architectures and more efficient use of history. We show  that the optimal signal (activation) function has a slanted sigmoidal  shape, and provide an intuitive account of activation functions with  a non-monotone shape. This function endows the model with some  properties characteristic of cortical neurons' firing.
Motivated by mathematical modeling, analog implementation and  distributed simulation of neural networks, we present a definition of  asynchronous dynamics of general CT dynamical systems defined  by ordinary differential equations, based on notions of local times  and communication times. We provide some preliminary results  on globally asymptotical convergence of asynchronous dynamics  for contractive and monotone CT dynamical systems. When applying the results to neural networks, we obtain some conditions  that ensure additive-type neural networks to be asynchronizable.
Several recurrent networks have been proposed as representations for the  task of formal language learning. After training a recurrent network recognize a formal language or predict the next symbol of a sequence, the  next logical step is to understand the information processing carried out  by the network. Some researchers have begun to extracting finite state  machines from the internal state trajectories of their recurrent networks.  This paper describes how sensitivity to initial conditions and discrete  measurements can trick these extraction methods to return illusory finite  state descriptions.
Biological neurons have a variety of intrinsic properties because of the  large number of voltage dependent currents that control their activity.  Neuromodulatory substances modify both the balance of conductances  that determine intrinsic properties and the strength of synapses. These  mechanisms alter circuit dynamics, and suggest that functional circuits  exist only in the modulatory environment in which they operate.
Intradendritic electrophysiological recordings reveal a bewildering  repertoire of complex electrical spikes and plateaus that are difficult to reconcile with conventional notions of neuronal function.  In this paper we argue that such dendritic events are just an exuberant expression of a more important mechanism a proportional  current amplifier whose primary task is to offset electrotonic losses.  Using the example of functionally important synaptic inputs to the  superficial layers of an anatomically and electrophysiologically reconstructed layer 5 pyramidal neuron, we derive and simulate the  properties of conductances that linearize and amplify distal synaptic input current in a graded manner. The amplification depends  on a potassium conductance in the apical tuft and calcium conductances in the apical trunk.  *To whom all correspondence should be addressed.  519  520 Bernander, Koch, and Douglas
Based on precise anatomical data of the bee's olfactory system, we  propose an investigation of the possible mechanisms of modulation and  control between the two levels of olfactory information processing: the  antennal lobe glomeruli and the mushroom bodies. We use simplified  neurons, but realistic architecture. As a first conclusion, we postulate  that the feature extraction performed by the antennal lobe (glomeruli and  interneurons) necessitates central input from the mushroom bodies for  fine tuning. The central input thus facilitates the evolution from fuzzy  olfactory images in the glomerular layer towards more focussed images  upon odor presentation.
Using a quasi-realistic model of the feedback inhibition of motoneurons  (MNs) by Renshaw cells, we show that weak inhibition is sufficient to  maximally desynchronize MNs, with negligible effects on total MN  activity. MN synchrony can produce a 20 30 Hz peak in the force  power spectrum, which may cause instability in feedback loops.  1
Maps of orientation preference and ocular dominance were recorded  optically from the cortices of 5 infant macaque monkeys, ranging in  age from 3.5 to 14 weeks. In agreement with previous observations,  we found that basic features of orientation and ocular dominance  maps, as well as correlations between them, are present and robust  by 3.5 weeks of age. We did observe changes in the strength of  ocular dominance signals, as well as in the spacing of ocular dominance bands, both of which increased steadily between 3.5 and 14  weeks of age. The latter finding suggests that the adult spacing  of ocular dominance bands depends on cortical growth in neonatal  animals. Since we found no corresponding increase in the spacing  of orientation preferences, however, there is a possibility that the  orientation preferences of some cells change as the cort;.cal surface  expands. Since correlations between the patterns of orientation  selectivity and ocular dominance are present at an age, when the  visual system is still immature, it seems more likely that their development may be an innate process and may not require extensive  visual experience.  543  544 Obermayer, Kiorpes, and Blasdel
In order to best understand a visual system one should attempt  to characterize the natural images it processes. We gather images  from the woods and find that these scenes possess an ensemble scale  invariance. Further, they are highly non-Gaussian, and this nonGaussian character cannot be removed through local linear filtering. We find that including a simple "gain control" nonlinearity in  the filtering process makes the filter output quite Gaussian, meaning information is maximized at fixed channel variance. Finally, we  use the measured power spectrum to place an upper bound on the  information conveyed about natural scenes by an array of receptors.
The fovea of a mammal retina was simulated with its detailed biological properties to study the local preprocessing of images. The  direct visual pathway (photoreceptors, bipolar and ganglion cells)  and the horizontal units, as well as the D-amacrine cells were simulated. The computer program simulated the analog non-spiking  transmission between photoreceptor and bipolar cells, and between  bipolar and ganglion cells, as well as the gap-junctions between horizontal cells, and the release of dopamine by D-amacrine cells and  its diffusion in the extra-cellular space. A 64x64 photoreceptors  retina, containing 16,448 units, was carried out. This retina displayed contour extraction with a Mach effect, and adaptation to  brightness. The simulation showed that the dopaminergic amacrine  cells were necessary to ensure adaptation to local brightness.
A gradient descent algorithm for parameter estimation which is  similar to those used for continuous-time recurrent neural networks  was derived for Hodgkin-Huxley type neuron models. Using membrane potential trajectories as targets, the parameters (maximal  conductances, thresholds and slopes of activation curves, time constants) were successfully estimated. The algorithm was applied to  modeling slow non-spike oscillation of an identified neuron in the  lobster stomatogastric ganglion. A model with three ionic currents  was trained with experimental data. It revealed a novel role of  A-current for slow oscillation below -50 mV.
We provide a computational description of the function of the Mauthner system. This is the bralnstem circuit which initiates faststart escapes in telcost fish in response to sounds. Our simulations, using backpropagation in a realistically constrained feedforward network, have generated hypotheses which are directly interpretable in terms of the activity of the auditory nerve fibers, the  principle cells of the system and their associated inhibitory neurons.
In an effort to understand saccadic eye movements and their relation to visual attention and other forms of eye movements, we -in collaboration with a number of other laboratories -are carrying out a large-scale effort to design and build a complete primate  oculomotor system using analog CMOS VLSI technology. Using  this technology, a low power, compact, multi-chip system has been  built which works in real-time using real-world visual inputs. We  describe in this paper the performance of an early version of such  a system including a 1-D array of photoreceptors mimicking the  retina, a circuit computing the mean location of activity representing the superior colliculus, a saccadic burst generator, and a one  degree-of-freedom rotational platform which models the dynamic  properties of the primate oculomotor plant.
Signal processing and classification algorithms often have limited  applicability resulting from an inaccurate model of the signal's underlying structure. We present here an efficient, Bayesian algorithm for modeling a signal composed of the superposition of brief,  Poisson-distributed functions. This methodology is applied to the  specific problem of modeling and classifying extracellular neural  waveforms which are composed of a superposition of an unknown  number of action potentials (APs). Previous approaches have had  limited success due largely to the problems of determining the spike  shapes, deciding how many are shapes distinct, and decomposing  overlapping APs. A Bayesian solution to each of these problems is  obtained by inferring a probabilistic model of the waveform. This  approach quantifies the uncertainty of the form and number of the  inferred AP shapes and is used to obtain an efficient method for  decomposing complex overlaps. This algorithm can extract many  times more information than previous methods and facilitates the  extracellular investigation of neuronal classes and of interactions  within neuronal circuits.  590  Bayesian Modeling and Classification of Neural Signals 591
Survival is enhanced by an ability to predict the availability of food,  the likelihood of predators, and the presence of mates. We present a  concrete model that uses diffuse neurotransmitter systems to implement  a predictive version of a Hebb learning rule embedded in a neural architecture based on anatomical and physiological studies on bees. The  model captured the strategies seen in the behavior of bees and a number of  other animals when foraging in an uncertain environment. The predictive  model suggests a unified way in which neuromodulatory influences can  be used to bias actions and control synaptic plasticity.  Successful predictions enhance adaptive behavior by allowing organisms to prepare for future actions, rewards, or punishments. Moreover, it is possible to improve upon behavioral  choices if the consequences of executing different actions can be reliably predicted.
We do not have a good understanding of how theoretical principles  of learning are realized in neural systems. To address this problem  we built a computational model of development in the owl's sound  localization system. The structure of the model is drawn from  known experimental data while the learning principles come from  recent work in the field of brain style computation. The model  accounts for numerous properties of the owl's sound localization  system, makes specific and testable predictions for future experiments, and provides a theory of the developmental process.
(Masino and Knudsen 1990) showed some remarkable results which  suggest that head motion in the barn owl is controlled by distinct  circuits coding for the horizontal and vertical components of movement. This implies the existence of a set of orthogonal internal coordinates that are related to meaningful coordinates of the external  world. No coherent computational theory has yet been proposed  to explain this finding. I have proposed a simple model which provides a framework for a theory of low-level motor learning. I show  that the theory predicts the observed microstimulation results in  the barn owl. The model rests on the concept of "Optimal Unsupervised Motor Learning", which provides a set of criteria that  predict optimal internal representations. I describe two iterative  Neural Network algorithms which find the optimal solution and  demonstrate possible mechanisms for the development of internal  representations in animals.
I detail the design and construction of an analog VLSI model of the  neural system responsible for swimming behaviors of the leech. Why  the leech? The biological network is small and relatively well  understood, and the silicon model can therefore span three levels of  organization in the leech nervous system (neuron, ganglion, system); it  represents one of the first comprehensive models of leech swimming  operating in real-time. The circuit employs biophysically motivated  analog neurons networked to form multiple biologically inspired silicon  ganglia. These ganglia are coupled using known interganglionic  connections. Thus the model retains the flavor of its biological  counterpart, and though simplified, the output of the silicon circuit is  similar to the output of the leech swim central pattern generator. The  model operates on the same timeand spatial-scale as the leech nervous  system and will provide an excellent platform with which to explore  real-time adaptive locomotion in the leech and other "simple"  invertebrate nervous systems.
We investigate a model for neural activity that generates long range  temporal correlations, 1If noise, and oscillations in global activity.  The model consists of a two-dimensional sheet of leaky integrateand-fire neurons with feedback connectivity consisting of local excitation and surround inhibition. Each neuron is independently  driven by homogeneous external noise. Spontaneous symmetry  breaking occurs, resulting in the formation of "hotspots" of activity in the network. These localized patterns of excitation appear  as clusters that coalesce, disintegrate, or fluctuate in size while simultaneously moving in a random walk constrained by the interaction with other clusters. The emergent cross-correlation functions  have a dual structure, with a sharp peak around zero on top of  a much broader hill. The power spectrum associated with single  units shows a 1If decay for small frequencies and is flat at higher  frequencies, while the power spectrum of the spiking activity averaged over many cells--equivalent to the local field potential--shows  no 1If decay but a prominent peak around 40 Hz.  629  630 Stemmler, Usher, Koch, and Olami
Transition point dynamic programming (TPDP) is a memorybased, reinforcement learning, direct dynamic programming approach to adaptive optimal control that can reduce the learning  time and memory usage required for the control of continuous  stochastic dynamic systems. TPDP does so by determining an  ideal set of transition points (TPs) which specify only the control  action changes necessary for optimal control. TPDP converges to  an ideal TP set by using a variation of Q-learning to assess the merits of adding, swapping and removing TPs from states throughout  the state space. When applied to a race track problem, TPDP  learned the optimal control policy much sooner than conventional  Q-learning, and was able to do so using less memory.
Recently, Ott, Grebogi and Yorke (OGY) [6] found an effective  method to control chaotic systems to unstable fixed points by using only small control forces; however, OGY's method is based on  and limited to a linear theory and requires considerable knowledge  of the dynamics of the system to be controlled. In this paper we use  two radial basis function networks: one as a model of an unknown  plant and the other as the controller. The controller is trained  with a recurrent learning algorithm to minimize a novel objective  function such that the controller can locate an unstable fixed point  and drive the system into the fixed point with no a priori knowledge of the system dynamics. Our results indicate that the neural  controller offers many advantages over OGY's technique.
While exploring to find better solutions, an agent performing online reinforcement learning (RL) can perform worse than is acceptable. In some cases, exploration might have unsafe, or even catastrophic, results, often modeled in terms of reaching 'failure' states  of the agent's environment. This paper presents a method that uses  domain knowledge to reduce the number of failures during exploration. This method formulates the set of actions from which the  RL agent composes a control policy to ensure that exploration is  conducted in a policy space that excludes most of the unacceptable  policies. The resulting action set has a more abstract relationship  to the task being solved than is common in many applications of  RL. Although the cost of this added safety is that learning may  result in a suboptimal solution, we argue that this is an appropriate tradeoff in many problems. We illustrate this method in the  domain of motion planning.  *This work was done while the first author was finishing his Ph.D in computer science  at the University of Massachusetts, Amherst.  655  656 Singh, Barto, Grupen, and Connolly  An agent using reinforcement learning (Sutton et al., 1991; Barto et al., to appear)  (RL) to approximate solutions to optimal control problems has to search, or explore,  to improve its policy for selecting actions. Although exploration does not directly  affect performance (Moore & Atkeson, 1993) in off-line learning with a model of  the environment, exploration in on-line learning can lead the agent to perform  worse than is acceptable. In some cases, exploration might have unsafe, or even  catastrophic, results, often modeled in terms of reaching 'failure' states of the agent's  environment. To make on-line RL more practical, especially if it involves expensive  hardware, task-specific minimal levels of performance should be ensured during  learning, a topic not addressed by prior RL research.  Although the need for exploration cannot be entirely removed, domain knowledge  can sometimes be used to define the set of actions from which the RL agent composes  a control policy so that exploration is conducted in a space that excludes most of  the unacceptable policies. We illustrate this approach using a simulated dynamic  mobile robot in two different environments.
Dynamic programming provides a methodology to develop planners  and controllers for nonlinear systems. However, general dynamic  programming is computationally intractable. We have developed  procedures that allow more complex planning and control problems  to be solved. We use second order local trajectory optimization  to generate locally optimal plans and local models of the value  function and its derivatives. We maintain global consistency of the  local models of the value function, guaranteeing that our locally  optimal plans are actually globally optimal, up to the resolution of  our search procedures.  Learning to do the right thing at each instant in situations that evolve over time is  difficult, as the future cost of actions chosen now may not be obvious immediately,  and may only become clear with time. Value functions are a representational tool  that makes the consequences of actions explicit. Value functions are difficult to  learn directly, but they can be built up from learned models of the dynamics of the  world and the cost function. This paper focuses on how fast optimizers that only  produce locally optimal answers can play a useful role in speeding up the process  of computing or learning a globally optimal value function.  Consider a system with dynamics Xkq-1 -f(xk, uk) and a cost function L(xk, uk),  663  664 Atkeson  where x is the state of the system and u is a vector of actions or controls. The subscript k serves as a time index, but will be dropped in the equations that follow. A  goal of reinforcement learning and optimal control is to find a policy that minimizes  the total cost, which is the sum of the costs for each time step. One approach to  doing this is to construct an optimal value function, V(x). The value of this value  function at a state x is the sum of all future costs, given that the system started in  state x and followed the optimal policy P(x) (chose optimal actions at each time  step as a function of the state). A local planner or controller can choose globally  optimal actions if it knew the future cost of each action. This cost is simply the  sum of the cost of taking the action right now and the future cost of the state that  the action leads to, which is given by the value function.  u* -arg nn (L(x, u) + V(f(x, u))) (1)  Value functions are difficult to learn. The environment does not provide training  examples that pair states with their optimal cost (x, V(x)). In fact, it seems that the  optimal policy depends on the optimal value function, which in turn depends on the  optimal policy. Algorithms to compute value functions typically iteratively refine  a candidate value function and/or a corresponding policy (dynamic programming).  These algorithms are usually expensive. We use local optimization to generate  locally optimal plans and local models of the value function and its derivatives. We  maintain global consistency of the local models of the value function, guaranteeing  that our locally optimal plans are actually globally optimal, up to the resolution of  our search procedures.
This paper describes the Q-routing algorithm for packet routing,  in which a reinforcement learning module is embedded into each  node of a switching network. Only local communication is used  by each node to keep accurate statistics on which routing decisions  lead to minimal delivery times. In simple experiments involving  a 36-node, irregularly connected network, Q-routing proves superior to a nonadaptive algorithm based on precomputed shortest  paths and is able to route efficiently even when critical aspects of  the simulation, such as the network load, are allowed to vary dynamically. The paper concludes with a discussion of the tradeoff  between discovering shortcuts and maintaining stable policies.
Consider the problem of learning input/output mappings through  exploration, e.g. learning the kinematics or dynamics of a robotic  manipulator. If actions are expensive and computation is cheap,  then we should explore by selecting a trajectory through the input space which gives us the most amount of information in the  fewest number of steps. I discuss how results from the field of optimal experiment design may be used to guide such exploration, and  demonstrate its use on a simple kinematics problem.
We describe the relationship between certain reinforcement learning (RL)methods based on dynamic programming (DP)and a class  of unorthodox Monte Carlo methods for solving systems of linear  equations proposed in the 1950's. These methods recast the solution of the linear system as the expected vlue of a statistic suitably  defined over sample paths of a Markov chain. The significance of  our observations lies in arguments (Curriss, 1954) that these Monte  Carlo methods scale better with respect to state-space size than do  standard, iterative techniques for solving systems of linear equations. This analysis also establishes convergence rate estimates.  Because methods used in RL systems for approximating the evaluation function of a fixed control policy also approximate solutions  to systems of linear equations, the connection to these Monte Carlo  methods establishes that algorithms very similar to TD algorithms  (Sutton, 1988) are asymptotically more efficient in a precise sense  than other methods for ewluating policies. Further, all DP-based  RL methods have some of the properties of these Monte Carlo algorithms, which suggests that although RL is often perceived to  be slow, for sufficiently large problems, it may in fact be more efficient than other known classes of methods capable of producing  the same results.  687  688 Barto and Duff
Reinforcement Learning methods based on approximating dynamic  programming (DP) are receiving increased attention due to their  utility in forming reactive control policies for systems embedded  in dynamic environments. Environments are usually modeled as  controlled Markov processes, but when the environment model is  not known a priori, adaptive methods are necessary. Adaptive control methods are often classified as being direct or indirect. Direct  methods directly adapt the control policy from experience, whereas  indirect methods adapt a model of the controlled process and compute control policies based on the latest model. Our focus is on  indirect adaptive DP-based methods in this paper. We present a  convergence result for indirect adaptive asynchronous value iteration algorithms for the case in which a look-up table is used to store  the value function. Our result implies convergence of several existing reinforcement learning algorithms such as adaptive real-time  dynamic programming (ARTDP) (Barto, Bradtke, & Singh, 1993)  and prioritized sweeping (Moore & Atkeson, 1993). Although the  emphasis of researchers studying DP-bascd reinforcement learning  has been on direct adaptive methods such as Q-Learning (Watkins,  1989) and methods using TD algorithms (Sutton, 1988), it is not  clear that these direct methods are preferable in practice to indirect  methods such as those analyzed in this paper.  695  696 Gullapalli and Barto
Increasing attention has recently been paid to algorithms based on  dynamic programming (DP) due to the suitability of DP for learning problems involving control. In stochastic environments where  the system being controlled is only incompletely known, however,  a unifying theoretical account of these methods has been missing.  In this paper we relate DP-based learning algorithms to the powerful techniques of stochastic approximation via a new convergence  theorem, enabling us to establish a class of convergent algorithms  to which both TD(A) and Q-learning belong.
Parti-game is a new algorithm for learning from delayed rewards  in high dimensional real-valued state-spaces. In high dimensions  it is essential that learning does not explore or plan over state  space uniformly. Parti-game maintains a decision-tree partitioning  of state-space and applies game-theory and computational geometry techniques to efficiently and reactively concentrate high resolution only on critical areas. Many simulated problems have been  tested, ranging from 2-dimensional to 9-dimensional state-spaces,  including mazes, path planning, non-linear dynamics, and uncurling snake robots in restricted spaces. In all cases, a good solution  is found in less than twenty trials and a few minutes.
We describe an extension to the Mixture of Experts architecture for  modelling and controlling dynamical systems which exhibit nultiple modes of behavior. This extension is based on a Markov process  model, and suggests a recurrent network for gating a set of linear  or non-linear controllers. The new architecture is demonstrated to  be capable of learning effective control strategies for jump linear  and non-linear plants with multiple modes of behavior.
We propose a trajectory planning and control theory for continuous  movements such as connected cursive handwriting and continuous  natural speech. Its hardware is based on our previously proposed  forward-inverse-relaxation neural network (Wada & Kawato, 1993).  Computationally, its optimization principle is the minimum torquechange criterion. Regarding the representation level, hard constraints  satisfied by a trajectory are represented as a set of via-points extracted  from a handwritten character. Accordingly, we propose a via-point  estimation algorithm that estimates via-points by repeating the  trajectory formation of a character and the via-point extraction from the  character. In experiments, good quantitative agreement is found  between human handwriting data and the trajectories generated by the  theory. Finally, we propose a recognition schema based on the  movement generation. We show a result in which the recognition  schema is applied to the handwritten character recognition and can be  extended to the phoneme timing estimation of natural speech.
This paper describes an algorithm for verification of signatures  written on a pen-input tablet. The algorithm is based on a novel,  artificial neural network, called a "Siamese" neural network. This  network consists of two identical sub-networks joined at their outputs. During training the two sub-networks extract features from  two signatures, while the joining neuron measures the distance between the two feature vectors. Verification consists of comparing an  extracted feature vector with a stored feature vector for the signer.  Signatures closer to this Stored representation than a chosen threshold are accepted, all other signatures are rejected as forgeries.
This paper describes the use of a convolutional neural network  to perform address block location on machine-printed mail pieces.  Locating the address block is a difficult object recognition problem  because there is often a large amount of extraneous printing on a  mail piece and because address blocks vary dramatically in size and  shape.  We used a convolutional locator network with four outputs, each  trained to find a different corner of the address block. A simple  set of rules was used to generate ABL candidates from the network  output. The system performs very well: when allowed five guesses,  the network will tightly bound the address delivery information in  98.2% of the cases.
We have developed an artificial neural network based gaze tracking system  which can be customized to individual users. Unlike other gaze trackers,  which normally require the user to wear cumbersome headgear, or to use a  chin rest to ensure head immobility, our system is entirely non-intrusive.  Currently, the best intrusive gaze tracking systems are accurate to approximately 0.75 degrees. In our experiments, we have been able to achieve an  accuracy of 1.5 degrees, while allowing head mobility. In this paper we  present an empirical analysis of the performance of a large number of artificial neural network architectures for this task.
Human genes are not continuous but rather consist of short coding regions (exons) interspersed with highly variable non-coding  regions (introns). We apply HMMs to the problem of modeling exons, introns and detecting splice sites in the human genome. Our  most interesting result so far is the detection of particular oscillatory patterns, with a minimal period of roughly 10 nucleotides, that  seem to be characteristic of exon regions and may have significant  biological implications.  *and Division of Biology, California Institute of Technology.  rand Department of Psychology, Stanford University.  761  762 Baldi, Brunak, Chauvin, Engelbrecht, and Krogh  oxon intron  EXON  3' splice site  acceptor site  5' splice site  donor site  CONSENSUS SEQUENCES
Changes in lighting conditions strongly effect the performance and reliability of computer vision systems. We report face recognition results  under drastically changing lighting conditions for a computer vision system which concurrently uses a contrast sensitive silicon retina and a conventional, gain controlled CCD camera. For both input devices the face  recognition system employs an elastic matching algorithm with wavelet  based features to classify unknown faces. To assess the effect of analog  on-chip preprocessing by the silicon retina the CCD images have been  "digitally preprocessed" with a bandpass filter to adjust the power spectrum. The silicon retina with its ability to adjust sensitivity increases  the recognition rate up to 50 percent. These comparative experiments  demonstrate that preprocessing with an analog VLSI silicon retina generates image data enriched with object-constant features.
This paper introduces a new recognition-based segmentation approach to recognizing on-line cursive handwriting from a database  of 10,000 English words. The original input stream of a:, y pen coordinates is encoded as a sequence of uniform stroke descriptions that  are processed by six feed-forward neural-networks, each designed  to recognize letters of different sizes. Words are then recognized by  performing best-first search over the space of all possible segmentations. Results demonstrate that the method is effective at both  writer dependent recognition (1.7% to 115.15% error rate) and writer  independent recognition (15.2% to 31.1% error rate).
We developed a system for finding address blocks on mail pieces that can  process four images per second. Besides locating the address block, our  system also determines the writing style, handwritten or machine printed, and  moreover, it measures the skew angle of the text lines and cleans noisy  images. A layout analysis of all the elements present in the image is  performed in order to distinguish drawings and dirt from text and to separate  text of advertisement from that of the destination address.  A speed of more than four images per second is obtained on a modular  hardware platform, containing a board with two of the NET32K neural net  chips, a SPARC2 processor board, and a board with 2 digital signal  processors. The system has been tested with more than 100,000 images. Its  performance depends on the quality of the images, and lies between 85%  correct location in vej noisy images to over 98% in cleaner images.
Functional complexity of a software module can be measured in  terms of static complexity metrics of the program text. Classifying software modules, based on their static complexity measures,  into different fault-prone categories is a difficult problem in software engineering. This research investigates the applicability of  neural network classifiers for identifying fault-prone software modules using a data set from a commercial software system. A preliminary empirical comparison is performed between a minimum  distance based Gaussian classifier, a perceptton classifier and a  multilayer layer feed-forward network classifier constructed using  a modified Cascade-Correlation algorithm. The modified version  of the Cascade-Correlation algorithm constrains the growth of the  network size by incorporating a cross-validation check during the  output layer training phase. Our preliminary results suggest that  a multilayer feed-forward network can be used as a tool for identifying fault-prone software modules early during the development  cycle. Other issues such as representation of software metrics and  selection of a proper training samples are also discussed.  793  794 Karunanithi
Airline companies usually schedule their flights and crews well in  advance to optimize their crew pools activities. Many events such  as flight delays or the absence of a member require the crew pool  rescheduling team to change the initial schedule (rescheduling). In  this paper, we show that the neural network comparison paradigm  applied to the backgammon game by Tesauro (Tesatlro and Sejnowski, 1989) can also be applied to the rescheduling problem of  an aircrew pool. Indeed both problems correspond to choosing  the best solution from a set of possible ones without ranking them  (called here best choice problem). The paper explains from a mathematical point of view the architecture and the learning strategy of  the backpropagation neural network used for the best choice problem. We also show how the learning phase of the network can be  accelerated. Finally we apply the neural network model to some  real rescheduling problems for the Belgian Airline (Sabena).
We use two co-evolving neural networks to determine new classes  of protein secondary structure which are significantly more predictable from local amino sequence than the conventional secondary  structure classification. Accurate prediction of the conventional  secondary structure classes: alpha helix, beta strand, and coil, from  primary sequence has long been an important problem in computational molecular biology. Neural networks have been a popular  method to attempt to predict these conventional secondary structure classes. Accuracy has been disappointingly low. The algorithm presented here uses neural networks to similtaneously examine both sequence and structure data, and to evolve new classes  of secondary structure that can be predicted from sequence with  significantly higher accuracy than the conventional classes. These  new classes have both similarities to, and differences with the conventional alpha helix, beta strand and coil. 
The game of Go has a high branching factor that defeats the tree  search approach used in computer chess, and long-range spatiotemporal interactions that make position evaluation extremely  difficult. Development of conventional Go programs is hampered  by their knowledge-intensive nature. We demonstrate a viable  alternative by training networks to evaluate Go positions via temporal difference (TD) learning.  Our approach is based on network architectures that reflect the  spatial organization of both input and reinforcement signals on  the Go board, and training protocols that provide exposure to  competent (though unlabelled) play. These techniques yield far  better performance than undifferentiated networks trained by selfplay alone. A network with less than 500 weights learned within  3,000 games of 9x9 Go a position evaluation function that enables  a primitive one-ply search to defeat a commercial Go program at  a low playing level.
This paper describes probabilistic methods for novelty detection  when using pattern recognition methods for fault monitoring of  dynamic systems. The problem of novelty detection is particularly acute when prior knowledge and training data only allow one  to construct an incomplete classification model. Allowance must  be made in model design so that the classifier will be robust to  data generated by classes not included in the training phase. For  diagnosis applications one practical approach is to construct both  an input density model and a discriminative class model. Using  Bayes' rule and prior estimates of the relative likelihood of data  of known and unknown origin the resulting classification equations  are straightforward. The paper describes the application of this  method in the context of hidden Markov models for online fault  monitoring of large ground antennas for spacecraft tracking, with  particular application to the detection of transient behaviour of  unknown origin.
Online cursive handwriting recognition is currently one of the most  intriguing challenges in pattern recognition. This study presents a  novel approach to this problem which is composed of two complementary phases. The first is dynamic encoding of the writing trajectory into a compact sequence of discrete motor control symbols.  In this compact representation we largely remove the redundancy of  the script, while preserving most of its intelligible components. In  the second phase these control sequences are used to train adaptive  probabilistic acyclic automata (PAA) for the important ingredients  of the writing trajectories, e.g. letters. We present a new and efficient learning algorithm for such stochastic automata, and demonstrate its utility for spotting and segmentation of cursive scripts.  Our experiments show that over 90% of the letters are correctly  spotted and identified, prior to any higher level language model.  Moreover, both the training and recognition algorithms are very  efficient compared to other modeling methods, and the models are  'on-line' adaptable to other writers and styles.
This paper describes the MM32k, a massively-parallel SIMD computer which is easy to program, high in performance, low in cost  and effective for implementing highly parallel neural network architectures. The MM32k has 32768 bit serial processing elements,  each of which has 512 bits of memory, and all of which are interconnected by a switching network. The entire system resides on  a single PC-AT compatible card. It is programmed from the host  computer using a C++ language class library which abstracts the  parallel processor in terms of fast arithmetic operators for vectors  of variable precision integers.
A neurocomputer was implemented using radial basis functions and a  combination of analog and digital VLSI cimuits. The hybrid system  uses custom analog circuits for the input layer and a digital signal  processiag board for the hidden and output layers. The system combines  the advantages of both analog and digital cimuits, featuring low power  consumption while minimizing overall system error. The analog circuits  have been fabricated and tested, the system has been built, and several  applications have been executed on the system. One application  provides significantly better results for a remote sensing problem than  have been previously obtained using ½onvelltional methods.
We present experimental results on supervised learning of dynamical features in an analog VLSI neural network chip. The recurrent network, containing six continuous-time analog neurons and 42  free parameters (connection strengths and thresholds), is trained to  generate time-varying outputs approximating given periodic signals  presented to the network. The chip implements a stochastic perturbative algorithm, which observes the error gradient along random  directions in the parameter space for error-descent learning. In addition to the integrated learning functions and the generation of  pseudo-random perturbations, the chip provides for teacher forcing and long-term storage of the volatile parameters. The network  learns a I kHz circular trajectory in 100 sec. The chip occupies  2mm x 2mm in a 2pm CMOS process, and dissipates 1.2 mW.
Recent physiological research has shown that synchronization of  oscillatory responses in striate cortex may code for relationships  between visual features of objects. A VLSI circuit has been designed to provide rapid phase-locking synchronization of multiple  oscillators to allow for further exploration of this neural mechanism.  By exploiting the intrinsic random transistor mismatch of devices  operated in subthreshold, large groups of phase-locked oscillators  can be readily partitioned into smaller phase-locked groups. A  multiple target tracker for binary images is described utilizing this  phase-locking architecture. A VLSI chip has been fabricated and  tested to verify the architecture. The chip employs Pulse Amplitude Modulation (PAM) to encode the output at the periphery of  the system.
This paper describes a low power analogue VLSI neural network  called Wattle. Wattle is a 10:6:4 three layer perceptron with multiplying DAC synapses and on chip switched capacitor neurons fabricated in 1.2um CMOS. The on chip neurons facillitate variable gain  per neuron and lower energy/connection than for previous designs.  The intended application of this chip is Intra Cardiac Electrogram  classification as part of an implantable pacemaker/defibrillator system. Measurements of the chip indicate that 10pJ per connection  is achievable as part of an integrated system. Wattle has been successfully trained in loop on parity 4 and ICEG morphology classification problems.
The "Softmax" Nonlinearity:  Derivation Using Statistical Mechanics  and Useful Properties  as a Multiterminal Analog Circuit  Element
The performance requirements in experimental research on artificial neural nets often exceed the capability of workstations and  PCs by a great amount. But speed is not the only requirement.  Flexibility and implementation time for new algorithms are usually  of equal importance. This paper describes the simulation of neural  nets on the MUSIC parallel supercomputer, a system that shows a  good balance between the three issues and therefore made many  research projects possible that were unthinkable before. (MUSIC  stands for Multiprocessor _ystem with Intelligent Communication)
We built a high-speed, digital mean-field Boltzmann chip and SBus  board for general problems in constraint satisfaction and learning.  Each chip has 32 neural processors and 4 weight update processors,  supporting an arbitrary topology of up to 160 functional neurons.  On-chip learning is at a theoretical maximum rate of 3.5 x 10 s connection updates/sec; recall is 12000 patterns/sec for typical conditions. The chip's high speed is due to parallel computation of inner  products, limited (but adequate) precision for weights and activations (5 bits), fast clock (125 MHz), and several design insights.  896  Digital Boltzmann VLSI for Constraint Satisfaction and Learning 897
We present a neural network simulation which we implemented  on the massively parallel Connection Machine 2. In contrast to  previous work, this simulator is based on biologically realistic neurons with nontrivial single-cell dynamics, high connectivity with a  structure modelled in agreement with biological data, and preservation of the temporal dynamics of spike interactions. We simulate  neural networks of 16,384 neurons coupled by about 1000 synapses  per neuron, and estimate the performance for much larger systems.  Communication between neurons is identified as the computationally most demanding task and we present a novel method to overcome this bottleneck. The simulator has already been used to study  the primary visual system of the cat.
The most commonly used neural network models are not well suited  to direct digital implementations because each node needs to perform a large number of operations between floating point values.  Fortunately, the ability to learn from examples and to generalize is  not restricted to networks of this type. Indeed, networks where each  node implements a simple Boolean function (Boolean networks) can  be designed in such a way as to exhibit similar properties. Two  algorithms that generate Boolean networks from examples are presented. The results show that these algorithms generalize very  well in a class of problems that accept compact Boolean network  descriptions. The techniques described are general and can be applied to tasks that are not known to have that characteristic. Two  examples of applications are presented: image reconstruction and  hand-written character recognition.
We will present the implementation of intelligent electronic circuits  realized for the first time using a new functional device called Neuron  MOS Transistor (neuMOS or vMOS in short) simulating the behavior  of biological neurons at a single transistor level. Search for the most  resembling data in the memory cell array, for instance, can be  automatically carried out on hardware without any software  manipulation. Soft Hardware, which we named, can arbitrarily change  its logic function in real time by external control signals without any  hardware modification. Implementation of a neural network equipped  with an on-chip self-learning capability is also described. Through the  studies of vMOS intelligent circuit implementation, we noticed an  interesting similarity in the architectures of vMOS logic circuitry and  biological systems.
A fast event-driven software simulator has been developed for simulating large networks of spiking neurons and synapses. The primitive network elements are designed to exhibit biologically realistic behaviors, such as spiking, refractoriness, adaptation, axonal  delays, summation of post-synaptic current pulses, and tonic current inputs. The efficient event-driven representation allows large  networks to be simulated in a fraction of the time that would be  required for a full compartmental-model simulation. Corresponding analog CMOS VLSI circuit primitives have been designed and  characterized, so that large-scale circuits may be simulated prior  to fabrication.
We introduce a new approach for on-line recognition of handwritten words written in unconstrained mixed style. The preprocessor  performs a word-level normalization by fitting a model of the word  structure using the EM algorithm. Words are then coded into low  resolution "annotated images" where each pixel contains information about trajectory direction and curvature. The recognizer is a  convolution network which can be spatially replicated. From the  network output, a hidden Markov model produces word scores. The  entire system is globally trained to minimize word-level errors.
We present a method for learning, tracking, and recognizing human hand  gestures recorded by a conventional CCD camera without any special  gloves or other sensors. A view-based representation is used to model  aspects of the hand relevant to the trained gestures, and is found using an  unsupervised clustering technique. We use normalized correlation networks, with dynamic time warping in the temporal domain, as a distance  function for unsupervised clustering. Views are computed separably for  space and time dimensions; the distributed response of the combination  of these units characterizes the input data with a low dimensional representation. A supervised classification stage uses labeled outputs of the  spatio-temporal units as training data. Our system can correctly classify  gestures in real time with a low-cost image processing accelerator.
We propose a computational model for how the cortex discriminates  shape and depth from texture. The model consists of four stages: (1)  extraction of local spatial frequency, (2) frequency characterization, (3)  detection of texture compression by normalization, and (4) integration  of the normalized frequency over space. The model accounts for a  number of psychophysical observations including experiments based on  novel random textures. These textures are generated from white noise  and manipulated in Fourier domain in order to produce specific  frequency spectra. Simulations with a range of stimuli, including real  images, show qualitative and quantitative agreement with human  perception.
The feature correspondence problem is a classic hurdle in visual  object-recognition concerned with determining the correct mapping  between the features measured from the image and the features expected by the model. In this paper we show that determining good  correspondences requires information about the joint probability  density over the image features. We propose "likelihood based  correspondence matching" as a general principle for selecting optimal correspondences. The approach is applicable to non-rigid  models, allows nonlinear perspective transformations, and can optimally deal with occlusions and missing features. Experiments  with rigid and non-rigid 3D hand gesture recognition support the  theory. The likelihood based techniques show almost no decrease  in classification performance when compared to performance with  perfect correspondence knowledge.
The goal of this work was to investigate the role of primate  MT neurons in solving the structure from motion (SFM)  problem. Three types of receptive field (RF) surrounds  found in area MT neurons (K. Tanaka et a/.,1986; Allman et  a/.,1985) correspond, as our analysis suggests, to the 0 th, I st  and 2 nd order fuzzy space-differential operators. The large  surround/center radius ratio (> 7) allows both  differentiation of smooth velocity fields and discontinuity  detection at boundaries of objects. The model is in  agreement with recent psychophysical data on surface  interpolation involvement in SFM. We suggest that area  MT partially segregates information about object shape  from information about spatial relations necessary for  navigation and manipulation.
We address the problem of optical flow reconstruction and in particular the problem of resolving ambiguities near edges. They occur due to (i) the aperture problem and (ii) the occlusion problem,  where pixels on both sides of an intensity edge are assigned the same  velocity estimates (and confidence). However, these measurements  are correct for just one side of the edge (the non occluded one).  Our approach is to introduce an uncertmnty field with respect to  the estimates and confidence measures. We note that the confidence measures are large at intensity edges and larger at the convex sides of the edges, i.e. inside corners, than at the concave side.  We resolve the ambiguities through local interactions via coupled  Markov random fields (MRF) The result is the detection of motion  for regions of images with large global convexity
We present a Mean Field Theory method for locating twodimensional objects that have undergone rigid transformations.  The resulting algorithm is a form of coarse-to-fine correlation  matching. We first consider problems of matching synthetic point  data, and derive a point matching objective function. A tractable  line segment matching objective function is derived by considering  each line segment as a dense collection of points, and approximating it by a sum of Gaussians. The algorithm is tested on real images  from which line segments are extracted and matched.
We propose that the binding and segmentation of visual features  is mediated by two complementary mechanisms; a low resolution, spatial-based, resource-free process and a high resolution,  temporal-based, resource-limited process. In the visual cortex, the  former depends upon the orderly topographic organization in striate and extrastriate areas while the latter may be related to observed temporal relationships between neuronal activities. Computer simulations illustrate the role the two mechanisms play in  figure/ground discrimination, depth-from-occlusion, and the vividness of perceptual completion.
Recent work by Becker and Hinton (Becker and Hinton, 1992)  shows a promising mechanism, based on maximizing mutual information assuming spatial coherence, by which a system can selforganize itself to learn visual abilities such as binocular stereo. We  introduce a more general criterion, based on Bayesian probability  theory, and thereby demonstrate a connection to Bayesian theories of visual perception and to other organization principles for  early vision (Atick and Redlich, 1990). Methods for implementation using variants of stochastic learning are described and, for the  special case of linear filtering, we derive an analytic expression for  the output.
Short term memory is indispensable for the processing of time  varying information with artificial neural networks. In this paper a  model for linear memories is presented, and ways to include  memories in connectionist topologies are discussed. A comparison  is drawn among different memory types, with indication of what is  the salient characteristic of each memory model.
Spotting tasks require detection of target patterns from a background of  richly varied non-target inputs. The performance measure of interest for  these tasks, called the figure of merit (FOM), is the detection rate for  target patterns when the false alarm rate is in an acceptable range. A  new approach to training spotters is presented which computes the FOM  gradient for each input pattern and then directly maximizes the FOM  using backpropagation. This eliminates the need for thresholds during  training. It also uses network resources to model Bayesian a posteriori  probability functions accurately only for patterns which have a  significant effect on the detection accuracy over the false alarm rate of  interest. FOM training increased detection accuracy by 5 percentage  points for a hybrid radial basis function (RBF) hidden Markov model  (HMM) wordspotter on the credit-card speech corpus.
We have developed visual preprocessing algorithms for extracting  phonologically relevant features from the grayscale video image of  a speaker, to provide speaker-independent inputs for an automatic lipreading ("speechreading") system. Visual features such as  mouth open/closed, tongue visible/not-visible, teeth visible/notvisible, and several shape descriptors of the mouth and its motion  are all rapidly computable in a manner quite insensitive to lighting  conditions. We formed a hybrid speechreading system consisting  of two time delay neural networks (video and acoustic) and integrated their responses by means of independent opinion pooling  -the Bayesian optimal method given conditional independence,  which seems to hold for our data. This hybrid system had an error rate 25% lower than that of the acoustic subsystem alone on a  five-utterance speaker-independent task, indicating that video can  be used to improve speech recognition.  1027  1028 Wolff, Prasad, Stork, and Hennecke
A new classifier is presented for text-independent speaker recognition. The  new classifier is called the modified neural tree network (MNTN). The  NTN is a hierarchical classifier that combines the properties of decision  trees and feed-forward neural networks. The MNTN differs from the standard NTN in that a new learning rule based on discriminant learning  is used, which minimizes the classification error as opposed to a norm  of the approximation error. The MNTN also uses leaf probability measures in addition to the class labels. The MNTN is evaluated for several  speaker identification experiments and is compared to multilayer percepttons (MLPs) decision trees, and vector quantization (VQ) classifiers. The  VQ classifier and MNTN demonstrate comparable performance and perform significantly better than the other classifiers for this task. Additionally the MNTN provides a logarithmic saving in retrieval time over that  of the VQ classifier. The MNTN and VQ classifiers are also compared  for several speaker verification experiments where the MNTN is found to  outperform the VQ classifier.
Progress has been made in COml)utational implementation of speech  production based on physiological data. An inverse dynamics  model of the speech articulator's musculo-skeletal system. which  is tile maI)ping from articulator trajectories to electromyographic  (EMG) signals, was modeled using tile acquired forward dynamics  model and temporal (smoothness of EMG activation) and range  constraints. This inverse dynamics model allows the use of a faster  speech motor control scheme, which can be applied to phoneme-tospeech synthesis via musclo-skeletal system dynamics, or to future  use in speech recognition. Tile forward acoustic model, which is the  mapping from articulator trajectories to tile acoustic parameters,  was improved by adding velocity and voicing information inputs  to distinguish acoustic parameter differences caused by cha%es in  source characteristics.
Hybrid connectionist/HMM systems model time both using a Markov  chain and through properties of a connectionist network. In this paper,  we discuss the nature of the time dependence currently employed in our  systems using recurrent networks (RNs) and feed-forward multi-layer  perceptrons (MLPs). In particular, we introduce local recurrences into a  MLP to produce an enhanced input representation. This is in the form  of an adaptive gamma filter and incorporates an automatic approach for  learning temporal dependencies. We have experimented on a speakerindependent phone recognition task using the TIMIT database. Results  using the gamma filtered input representation have shown improvement  over the baseline MLP system. Improvements have also been obtained  through merging the baseline and gamma filter models.
Previously, we had developed the concept of a Segmental Neural Net (SNN) for  phonetic modeling in continuous speech recognition (CSR). This kind of neural network technology advanced the state-of-the-art of large-vocabulary CSR,  which employs Hidden Markov Models (HMM), for the ARPA 1000-word Resource Management corpus. More Recently, we started porting the neural net  system to a larger, more challenging corpus the ARPA 20,000-word Wall Street  Journal (WSJ) corpus. During the porting, we explored the following research  directions to refine the system: i) training context-dependent models with a regularization method; ii) training SNN with projection pursuit; and ii) combining  different models into a hybrid system. When tested on both a development set  and an independent test set, the resulting neural net system alone yielded a performance at the level of the HMM system, and the hybrid SNN/HMM system  achieved a consistent 10-15% word error reduction over the HMM system. This  paper describes our hybrid system, with emphasis on the optimization methods  employed.
Although the visual and auditory systems share the same basic  tasks of informing an organism about its environment, most connectionist work on hearing to date has been devoted to the very  different problem of speech recognition. We believe that the most  fundamental task of the auditory system is the analysis of acoustic  signals into components corresponding to individual sound sources,  which Bregman has called auditory scene analysis. Computational  and connectionist work on auditory scene analysis is reviewed, and  the outline of a general model that includes these approaches is  described.
We consider the problem of how the CNS learns to control dynamics of a mechanical system. By using a paradigm where a subject's  hand interacts with a virtual mechanical environment, we show  that learning control is via composition of a model of the imposed  dynamics. Some properties of the computational elements with  which the CNS composes this model are inferred through the generalization capabilities of the subject outside the training data.
This study explores the extent to which a network that learns the  temporal relationships within and between the component features of  Western tonal music can account for music theoretic and psychological  phenomena such as the tonal hierarchy and rhythmic expectancies.  Predicted and generated sequences were recorded as the representation of  a 153-note waltz melody was learnt by a predictive, recurrent network.  The network learned transitions and relations between and within pitch  and timing components: accent and duration values interacted in the  development of rhythmic and metric structures and, with training, the  network developed chordal expectancies in response to the activation of  individual tones. Analysis of the hidden unit representation revealed  that musical sequences are represented as transitions between states in  hidden unit space.
Imagine you have designed a neural network that successfully learns  a complex classification task. What are the relevant input features  the classifier relies on and how are these features combined to produce the classification decisions? There are applications where a  deeper insight into the structure of an adaptive system and thus  into the underlying classification problem may well be as important  as the system's performance characteristics, e.g. in economics or  medicine. GDS  is a backpropagation-based training scheme that  produces networks transformable into an equivalent and concise  set of IF-THEN rules. This is achieved by imposing penalty terms  on the network parameters that adapt the network to the expressive  power of this class of rules. Thus during training we simultaneously  minimize classification and transformation error. Some real-world  tasks demonstrate the viability of our approach.
A variant of the encoder architecture, where units at the input and output layers represent nodes on a graph, is applied to the task of mapping  locations to sets of neighboring locations. The degree to which the resuiting internal (i.e. hidden unit) representations reflect global properties of the environment depends upon several parameters of the learning  procedure. Architectural bottlenecks, noise, and incremental learning of  landmarks are shown to be important factors in maintaining topographic relationships at a global scale.
Models of analog retrieval require a computationally cheap method of  estimating similarity between a probe and the candidates in a large pool  of memory items. The vector dot-product operation would be ideal for  this purpose if it were possible to encode complex structures as vector  representations in such a way that the superficial similarity of vector  representations reflected underlying structural similarity. This paper describes how such an encoding is provided by Holographic Reduced Representations (HRRs), which are a method for encoding nested relational  structures as fixed-width distributed representations. The conditions under which structural similarity is reflected in the dot-product rankings of  HRRs are discussed.
The non-linear complexities of neural networks make network solutions  difficult to understand. Sanger's contribution analysis is here extended to  the analysis of networks automatically generated by the cascadecorrelation learning algorithm. Because such networks have cross  connections that supersede hidden layers, standard analyses of hidden  unit activation patterns are insufficient. A contribution is defined as the  product of an output weight and the associated activation on the sending  unit, whether that sending unit is an input or a hidden unit, multiplied  by the sign of the output target for the current input pattern.  Intercorrelations among contributions, as gleaned from the matrix of  contributions x input patterns, can be subjected to principal  components analysis (PCA) to extract the main features of variation in  the contributions. Such an analysis is applied to three problems,  continuous XOR, arithmetic comparison, and distinguishing between  two interlocking spirals. In all three cases, this technique yields useful  insights into network solutions that are consistent across several  networks.
In this paper we propose an extension to the RAAM by Pollack.  This extension, the Labeling RAAM (LRAAM), can encode labeled graphs with cycles by representing pointers explicitly. Data  encoded in an LRAAM can be accessed by pointer as well as by  content. Direct access by content can be achieved by transforming the encoder network of the LRAAM into an analog Hopfield  network with hidden units. Different access procedures can be  defined depending on the access key. Sufficient conditions on the  asymptotical stability of the associated Hopfield network are briefly  introduced.
We apply active exemplar selection (Plutowski & White, 1991; 1993) to predicting a chaotic time series. Given a fixed set of examples, the method chooses a concise subset for training. Fitting these exemplars results in the entire set being fit as well as desired. The algorithm incorporates a method for regulating network complexity, automatically adding exemplars and hidden units as needed. Fitting examples generated from the Mackey-Glass equation with fractal dimension 2.1 to an rmse of 0.01 required about 25 exemplars and 3 to 6 hidden units. The method requires an order of magnitude fewer floating point operations than training on the entire set of examples, is significantly cheaper than two contending exemplar selection techniques, and suggests a simpler active selection technique that performs comparably. 
A new neural network, the Binary Diamond, is presented and its use  as a classifier is demonstrated and evaluated. The network is of the  feed-forward type. It learns from examples in the 'one shot' mode,  and recruits new neurons as needed. It was tested on the problem of  pixel classification, and performed well. Possible applications of the  network in associative memories are outlined.
In this paper, we will consider the problem of classifying electroencephalogram (EEG) signals of normal subjects, and subjects suffering from psychiatric disorder, e.g., obsessive compulsive disorder, schizophrenia, using a  class of artificial neural networks, viz., multi-layer perceptton. It is shown  that the multilayer perceptton is capable of classifying unseen test EEG  signals to a high degree of accuracy.
Almost all models of orientation and direction selectivity in visual  cortex are based on feedforward connection schemes, where geniculate input provides all excitation to both pyramidal and inhibitory  neurons. The latter neurons then suppress the response of the former for non-optimal stimuli. However, anatomical studies show  that up to 90 % of the excitatory synaptic input onto any cortical cell is provided by other cortical cells. The massive excitatory  feedback nature of cortical circuits is embedded in the canonical  microcircuit of Douglas & Martin (1991). We here investigate analytically and through biologically realistic simulations the functioning of a detailed model of this circuitry, operating in a hysterelic  mode. In the model, weak geniculate input is dramatically amplified by intracortical excitation, while inhibition has a dual role: (i)  to prevent the early geniculate-induced excitation in the null direction and (ii) to restrain excitation and ensure that the neurons  fire only when the stimulus is in their receptive-field. Among the  4 Humbert Suarez, Christof Koch, Rodney Douglas  insights gained are the possibility that hysteresis underlies visual  cortical function, paralleling proposals for short-term memory, and  strong limitations on linearity tests that use gratings. Properties  of visual cortical neurons are compared in detail to this model and  to a classical model of direction selectivity that does not include  excitatory cortico-cortical connections. The model explain a number of puzzling features of direction-selective simple cells, including the small somatic input conductance changes that have been  measured experimentally during stimulation in the null direction.  The model also allows us to understand why the velocity-response  curve of area 17 neurons is different from that of their LGN afferents, and the origin of expansive and compressive nonlinearities in  the contrast-response curve of striate cortical neurons.
We propose a computational framework for understanding and  modeling human consciousness. This framework integrates many  existing theoretical perspectives, yet is sufficiently concrete to allow  simulation experiments. We do not attempt to explain qualia (subjective experience), but instead ask what differences exist within  the cognitive information processing system when a person is conscious of mentally-represented information versus when that information is unconscious. The central idea we explore is that the contents of consciousness correspond to temporally persistent states  in a network of computational modules. Three simulations are described illustrating that the behavior of persistent states in the  models corresponds roughly to the behavior of conscious states  people experience when performing similar tasks. Our simulations  show that periodic settling to persistent (i.e., conscious) states improves performance by cleaning up inaccuracies and noise, forcing  decisions, and helping keep the system on track toward a solution.
Biological sensorimotor systems are not static maps that transform  input (sensory information) into output (motor behavior). Evidence from many lines of research suggests that their representations are plastic, experience-dependent entities. While this plasticity is essential for flexible behavior, it presents the nervous system  with dimcult organizational challenges. If the sensorimotor system  adapts itself to perform well under one set of circumstances, will it  then perform poorly when placed in an environment with different  demands (negative transfer)? Will a later experience-dependent  change undo the benefits of previous learning (catastrophic interference)? We explore the first question in a separate paper in this  volume (Shadmehr et al. 1995). Here we present psychophysical  and computational results that explore the question of catastrophic  interference in the context of a dynamic motor learning task. Under some conditions, subjects show evidence of catastrophic interference. Under other conditions, however, subjects appear to be  immune to its effects. These results suggest that motor learning  can undergo a process of consolidation. Modular neural networks  are well suited for the demands of learning multiple input/output  mappings. By incorporating the notion of fastand slow-changing  connections into a modular architecture, we were able to account  for the psychophysical results.  20 Tom Brashers-Krug, Reza Shadmehr, Emanuel Todorov
This paper presents the design and simulation results of a selforganizing neural network which induces a grammar from example sentences. Input sentences are generated from a simple phrase  structure grammar including number agreement, verb transitivity, and recursive noun phrase construction rules. The network  induces a grammar explicitly in the form of symbol categorization  rules and phrase structure rules.
Current understanding of the effects of damage on neural networks  is rudimentary, even though such understanding could lead to important insights concerning neurological and psychiatric disorders.  Motivated by this consideration, we present a simple analytical  framework for estimating the functional damage resulting from focal structural lesions to a neural network. The effects of focal lesions of varying area, shape and number on the retrieval capacities  of a spatially-organized associative memory. Although our analytical results are based on some approximations, they correspond well  with simulation results. This study sheds light on some important  features characterizing the clinical manifestations of multi-infarct  dementia, including the strong association between the number of  infarcts and the prevalence of dementia after stroke, and the 'multiplicative' interaction that has been postulated to occur between  Alzheimer's disease and multi-infarct dementia.  *Dr. Reggia is also with the Department of Neurology and the Institute of Advanced  Computer Studies at the University of Maryland.  36 Eytan Ruppin, James A. Reggia
Based on computational principles, with as yet no direct experimental validation, it has been proposed that the central nervous  system (CNS) uses an internal model to simulate the dynamic behavior of the motor system in planning, control and learning (Sutton and Barto, 1981; Ito, 1984; Kawato et al., 1987; Jordan and  Rumelhart, 1992; Miall et al., 1993). We present experimental results and simulations based on a novel approach that investigates  the temporal propagation of errors in the sensorimotor integration  process. Our results provide direct support for the existence of an  internal model.
A model of short-term memory for serially ordered lists of verbal  stimuli is proposed as an implementation of the 'articulatory loop'  thought to mediate this type of memory (Baddeley, 1986). The  model predicts the presence of a repeatable time-varying 'context'  signal coding the timing of items' presentation in addition to a  store of phonological information and a process of serial rehearsal.  Items are associated with context nodes and phonemes by Hebbian  connections showing both short and long term plasticity. Items are  activated by phonemic input during presentation and reactivated  by context and phonemic feedback during output. Serial selection  of items occurs via a winner-take-all interaction amongst items,  with the winner subsequently receiving decaying inhibition. An  approximate analysis of error probabilities due to Gaussian noise  during output is presented. The model provides an explanatory  account of the probability of error as a function of serial position,  list length, word length, phonemic similarity, temporal grouping,  item and list familiarity, and is proposed as the starting point for  a model of rehearsal and vocabulary acquisition.
A new model for chemosensory reception is presented. It models reactions between odor molecules and receptor proteins and the activation of  second messenger by receptor proteins. The mathematical formulation  of the reaction kinetics is transformed into an artificial neural network  (ANN). The resulting feed-forward network provides a powerful means  for parameter fitting by applying learning algorithms. The weights of the  network corresponding to chemical parameters can be trained by presenting experimental data. We demonstrate the simulation capabilities of the  model with experimental data from honey bee chemosensory neurons. It  can be shown that our model is sufficient to rebuild the observed data and  that simpler models are not able to do this task.
The spatial distribution and time course of electrical signals in neurons  have important theoretical and practical consequences. Because it is  difficult to infer how neuronal form affects electrical signaling, we  have developed a quantitative yet intuitive approach to the analysis of  electrotonus. This approach transforms the architecture of the cell  from anatomical to electrotonic space, using the logarithm of voltage  attenuation as the distance metric. We describe the theory behind this  approach and illustrate its use.
A model of the hippocampus is presented which forms rapid self-organized representations of input arriving via the perforant path, performs  recall of previous associations in region CA3, and performs comparison  of this recall with afferent input in region CA1. This comparison drives  feedback regulation of cholinergic modulation to set appropriate  dynamics for learning of new representations in region CA3 and CA1.  The network responds to novel patterns with increased cholinergic modulation, allowing storage of new self-organized representations, but  responds to familiar patterns with a decrease in acetylcholine, allowing  recall based on previous representations. This requires selectivity of the  cholinergic suppression of synaptic transmission in stratum radiatum of  regions CA3 and CA1, which has been demonstrated experimentally.
A biological neuron can be viewed as a device that maps a multidimensional temporal event signal (dendritic postsynaptic activations) into a  unidimensional temporal event signal (action potentials). We have  designed a network, the Spatio-Temporal Event Mapping (STEM)  architecture, which can learn to perform this mapping for arbitrary biophysical models of neurons. Such a network appropriately trained,  called a STEM cell, can be used in place of a conventional compartmental model in simulations where only the transfer function is important,  such as network simulations. The STEM cell offers advantages over  compartmental models in terms of computational efficiency, analytical  tractabililty, and as a framework for VLSI implementations of biological neurons.
More than ten of the most prominent models for the structure  and for the activity dependent formation of orientation and ocular donfinance columns in the striate cortex have been evaluated.  We implemented those models on parallel machines, we extensively  explored parameter space, and we quantitatively compared model  predictions with experimental data which were recorded optically  from macaque striate cortex.  In our contribution we present a summary of our results to date.  Briefly, we find that (i) despite apparent differences, many models  are based on similar principles and, consequently, make similar predictions, (ii) certain "pattern models" as well as the developmental  "correlation-based learning" models disagree with the experimental data, and (iii) of the models we have investigated, "competitive  Hebbian" models and the recent model of Swindale provide the  best match with experimental data.
Songbirds learn to imitate a tutor song through auditory and motor learning. We have developed a theoretical framework for song learning that  accounts for response properties of neurons that have been observed in  many of the nuclei that are involved in song learning. Specifically, we  suggest that the anteriorforebrain pathway, which is not needed for song  production in the adult but is essential for song acquisition, provides  synaptic perturbations and adaptive evaluations for syllable vocalization  learning. A computer model based on reinforcement learning was constructed that could replicate a real zebra finch song with 90% accuracy  based on a spectrographic measure. The second generation of the birdsong model replicated the tutor song with 96% accuracy.
A neural network model for the self-organization of ocular dominance and  lateral connections from binocular input is presented. The self-organizing  process results in a network where (1) afferent weights of each neuron organize into smooth hill-shaped receptive fields primarily on one of the retinas, (2) neurons with common eye preference form connected, intertwined  patches, and (3) lateral connections primarily link regions of the same eye  preference. Similar self-organization of cortical structures has been observed experimentally in strabismic kittens. The model shows how patterned lateral connections in the cortex may develop based on correlated  activity and explains why lateral connection patterns follow receptive field  properties such as ocular dominance.
The maximization of diversity of neuronal response properties has been  recently suggested as an organizing principle for the formation of such  prominent features of the functional architecture of the brain as the cortical columns and the associated patchy projection patterns (Malach, 1994).  We show that (1) maximal diversity is attained when the ratio of dendritic  and axonal arbor sizes is equal to one, as found in many cortical areas  and across species (Lund et al., 1993; Malach, 1994), and (2) that maximization of diversity leads to better performance in systems of receptive  fields implementing steerable/shiftable filters, and in matching spatially  distributed signals, a problem that arises in many high-level visual tasks.
The auditory system of the barn owl contains several spatial maps.  In young barn owls raised with optical prisms over their eyes, these  auditory maps are shifted to stay in register with the visual map,  suggesting that the visual input imposes a frame of reference on  the auditory maps. However, the optic tectum, the first site of  convergence of visual with auditory information, is not the site of  plasticity for the shift of the auditory maps; the plasticity occurs  instead in the inferior colliculus, which contains an auditory map  and projects into the optic tectum. We explored a model of the owl  remapping in which a global reinforcement signal whose delivery is  controlled by visual foveation. A hebb learning rule gated by reinforcement learned to appropriately adjust auditory maps. In addition, reinforcement learning preferentially adjusted the weights in  the inferior colliculus, as in the owl brain, even though the weights  were allowed to change throughout the auditory system. This observation raises the possibility that the site of learning does not  have to be genetically specified, but could be determined by how  the learning procedure interacts with the network architecture.  126 Alexandre Pouget, Cedric Deffayet, Terrence J. Sejnowski  Optic Tectum    Alhistrlatum  Inferior Colllculus  External nucleus Forebrain Field L  (ICx) (FBr)  Infeor Co!!tculus  nl ucleus  (ICc)  Cochlea  Visual System  Figure 1: Schematic view of the auditory pathways in the barn owl.
The macaque lateral geniculate nucleus (LGN) exhibits an intricate  lamination pattern, which changes midway through the nucleus at a  point coincident with small gaps due to the blind spot in the retina.  We present a three-dimensional model of morphogenesis in which  local cell interactions cause a wave of development of neuronal receptive fields to propagate through the nucleus and establish two  distinct lamination patterns. We examine the interactions between  the wave and the localized singularities due to the gaps, and find  that the gaps induce the change in lamination pattern. We explore  critical factors which determine general LGN organization.
Accumulating data from neurophysiology and neuropsychology  have suggested two information processing roles for prefrontal cortex (PFC): 1) short-term active memory; and 2) inhibition. We  present a new behavioral task and a computational model which  were developed in parallel. The task was developed to probe both  of these prefrontal functions simultaneously, and produces a rich  set of behavioral data that act as constraints on the model. The  model is implemented in continuous-time, thus providing a natural  framework in which to study the temporal dynamics of processing  in the task. We show how the model can be used to examine the behavioral consequences of neuromodulation in PFC. Specifically, we  use the model to make novel and testable predictions regarding the  behavioral performance of schizophrenics, who are hypothesized to  suffer from reduced dopaminergic tone in this brain area.
We implement and study a computational model of Stevens' [1992]  theory of the pathogenesis of schizophrenia. This theory hypothesizes that the onset of schizophrenia is associated with reactive  synaptic regeneration occurring in brain regions receiving degenerating temporal lobe projections. Concentrating on one such area,  the frontal cortex, we model a frontal module as an associative  memory neural network whose input synapses represent incoming  temporal projections. We analyze how, in the face of weakened  external input projections, compensatory strengthening of internal  synaptic connections and increased noise levels can maintain memory capacities (which are generally preserved in schizophrenia).  However, These compensatory changes adversely lead to spontaneous, biased retrieval of stored memories, which corresponds to  the occurrence of schizophrenic delusions and hallucinations without any apparent external trigger, and for their tendency to concentrate on just few central themes. Our results explain why these  symptoms tend to wane as schizophrenia progresses, and why delayed therapeutical intervention leads to a much slower response.  150 Eytan Ruppin, James A. Reggia, David Horn
The parietal cortex is thought to represent the egocentric positions of objects in particular coordinate systems. We propose an  alternative approach to spatial perception of objects in the parietal cortex from the perspective of sensorimotor transformations.  The responses of single parietal neurons can be modeled as a gaussian function of retinal position multiplied by a sigmoid function  of eye position, which form a set of basis functions. We show here  how these basis functions can be used to generate receptive fields  in either retinotopic or head-centered coordinates by simple linear  transformations. This raises the possibility that the parietal cortex  does not attempt to compute the positions of objects in a particular frame of reference but instead computes a general purpose  representation of the retinal location and eye position from which  any transformation can be synthesized by direct projection. This  representation predicts that hemineglect, a neurological syndrome  produced by parietal lesions, should not be confined to egocentric  coordinates, but should be observed in multiple frames of reference  in single patients, a prediction supported by several experiments.  158 Alexandre Pouget, Terrence J. Sejnowski
Many cells in the dorsal part of the medial superior temporal  (MST) area of visual cortex respond selectively to spiral flow  patterns--specific combinations of expansion/contraction and rotation motions. Previous investigators have suggested that these  cells may represent self-motion. Spiral patterns can also be generated by the relative motion of the observer and a particular object.  An MST cell may then account for some portion of the complex  flow field, and the set of active cells could encode the entire flow;  in this manner, MST effectively segments moving objects. Such  a grouping operation is essential in interpreting scenes containing  several independent moving objects and observer motion. We describe a model based on the hypothesis that the selective tuning  of MST cells reflects the grouping of object components undergoing coherent motion. Inputs to the model were generated from  sequences of ray-traced images that simulated realistic motion situations, combining observer motion, eye movements, and independent object motion. The input representation was modeled after  response properties of neurons in area MT, which provides the primary input to area MST. After applying an unsupervised learning  algorithm, the units became tuned to patterns signaling coherent  motion. The results match many of the known properties of MST  cells and are consistent with recent studies indicating that these  cells process 3-D object motion information.  166 Richard $. Zemel, Terrence J. Sejnowski
In the last decade the outlines of the neural structures subserving  the sense of direction have begun to emerge. Several investigations  have shed light on the effects of vestibular input and visual input  on the head direction representation. In this paper, a model is  formulated of the neural mechanisms underlying the head direction  system. The model is built out of simple ingredients, depending on  nothing more complicated than connectional specificity, attractor  dynamics, Hebbian learning, and sigmoidal nonlinearities, but it  behaves in a sophisticated way and is consistent with most of the  observed properties of real head direction cells. In addition it makes  a number of predictions that ought to be testable by reasonably  straightforward experiments.
We investigate the computational power of a formal model for networks of spiking neurons, both for the assumption of an unlimited  timing precision, and for the case of a limited timing precision. We  also prove upper and lower bounds for the number of examples that  are needed to train such networks.
We derive global H a optimal training algorithms for neural networks. These algorithms guarantee the smallest possible prediction  error energy over all possible disturbances of fixed energy, and are  therefore robust with respect to model uncertainties and lack of  statistical information on the exogenous signals. The ensuing estimators are infinite-dimensional, in the sense that updating the  weight vector estimate requires knowledge of all previous weight  esimates. A certain finite-dimensional approximation to these estimators is the backpropagation algorithm. This explains the local H a optimality of backpropagation that has been previously  demonstrated.
An novel class of locally excitatory, globally inhibitory oscillator  networks is proposed. The model of each oscillator corresponds to a  standard relaxation oscillator with two time scales. The network  exhibits a mechanism of selective gating, whereby an oscillator  jumping up to its active phase rapidly recruits the oscillators stimulated  by the same pattern, while preventing others from jumping up. We  show analytically that with the selective gating mechanism the network  rapidly achieves both synchronization within blocks of oscillators that  are stimulated by connected regions and desynchronization between  different blocks. Computer simulations demonstrate the network's  promising ability for segmenting multiple input patterns in real time.  This model lays a physical foundation for the oscillatory correlation  theory of feature binding, and may provide an effective computational  framework for scene segmentation and figure/ground segregation.
We present a new method for obtaining the response function 6  and its average G from which most of the properties of learning  and generalization in linear perceptrons can be derived. We first  rederive the known results for the 'thermodynamic limit' of infinite  perceptron size N and show explicitly that 6 is self-averaging in  this limit. We then discuss extensions of our method to more general learning scenarios with anisotropic teacher space priors, input  distributions, and weight decay terms. Finally, we use our method  to calculate the finite N corrections of order 1IN to G and discuss  the corresponding finite size effects on generalization and learning  dynamics. An important spin-off is the observation that results  obtained in the thermodynamic limit are often directly relevant to  systems of fairly modest, 'real-world' sizes.
We discuss a model of consistent learning with an additional restriction on the probability distribution of training samples, the  target concept and hypothesis class. We show that the model provides a significant improvement on the upper bounds of sample  complexity, i.e. the minimal number of random training samples  allowing a selection of the hypothesis with a predefined accuracy  and confidence. Further, we show that the model has the potential for providing a finite sample complexity even in the case of  infinite VC-dimension as well as for a sample complexity below  VC-dimension. This is achieved by linking sample complexity to  an "average" number of implementable dichotomies of a training  sample rather than the maximal size of a shattered sample, i.e.  VC-dimension.
Ideally pattern recognition machines provide constant output when  the inputs are transformed under a group 6 of desired invariances.  These invariances can be achieved by enhancing the training data  to include examples of inputs transformed by elements of 6, while  leaving the corresponding targets unchanged. Alternatively the  cost function for training can include a regularization term that  penalizes changes in the output when the input is transformed under the group.  This paper relates the two approaches, showing precisely the sense  in which the regularized cost function approximates the result of  adding transformed (or distorted) examples to the training data.  The cost function for the enhanced training set is equivalent to the  sum of the original cost function plus a regularizer. For unbiased  models, the regularizer reduces to the intuitively obvious choice a term that penalizes changes in the output when the inputs are  transformed under the group. For infinitesimal transformations,  the coecient of the regularization term reduces to the variance of  the distortions introduced into the training data. This correspondence provides a simple bridge between the two approaches.  2 2 4 Todd Leen
Learning of continuous valued functions using neural network ensembles (committees) can give improved accuracy, reliable estimation of the generalization error, and active learning. The ambiguity  is defined as the variation of the output of ensemble members averaged over unlabeled data, so it quantifies the disagreement among  the networks. It is discussed how to use the ambiguity in combination with cross-validation to give a reliable estimate of the ensemble  generalization error, and how this type of ensemble cross-validation  can sometimes improve performance. It is shown how to estimate  the optimal weights of the ensemble members using unlabeled data.  By a generalization of query by committee, it is finally shown how  the ambiguity can be used to select new training data to be labeled  in an active learning scheme.
Random errors and insufficiencies in databases limit the performance of any classifier trained from and applied to the database.  In this paper we propose a method to estimate the limiting performance of classifiers imposed by the database. We demonstrate this  technique on the task of predicting failure in telecommunication  paths.
A neural network learning paradigm based on information theory is proposed as a way to perform in an unsupervisd fashion, rodundancy  _reduction among the elements of the output layer without loss of information from the sensory input. The model developed performs nonlinear decorrelation up to higher orders of the cumulant tensors and results  in probabilistically independent components of the output layer. This  means that we don't need to assme Gaussian distribution neither at the  input nor at the output. The theory presented is related to the unsupervised-leaming theory of Barlow, which proposes redundancy reduction  as the goal of cognition. When nonlinear units are used nonlinear principal component analysis is obtained. In this case nonlinear manifolds can  be reduced to minimum dimension manifolds. If such units are used the  network performs a generalized principal component analysis in the  sense that non-Gaussian distributions can be linearly decorrelated and  higher orders of the correlation tensors are also taken into account. The  basic structure of the architecture involves a general transformation that  is volume conserving and therefore the entropy, yielding a map without  loss of information. Minimization of the mutual information among the  output neurons eliminates the redundancy between the outputs and  results in statistical decorrelation of the extracted features. This is  known as factorial learning.  248 Gustavo Deco, Wilfried Brauer
Using a statistical mechanical formalism we calculate the evidence,  generalisation error and consistency measure for a linear perceptton trained and tested on a set of examples generated by a non  linear teacher. The teacher is said to be unrealisable because the  student can never model it without error. Our model allows us to  interpolate between the known case of a linear teacher, and an unrealisable, nonlinear teacher. A comparison of the hyperparameters  which maximise the evidence with those that optimise the performance measures reveals that, in the non-linear case, the evidence  procedure is a misleading guide to optimising performance. Finally,  we explore the extent to which the evidence procedure is unreliable  and find that, despite being sub-optimal, in some circumstances it  might be a useful method for fixing the hyperparameters.
This paper presents a rigorous characterization of how a general  nonlinear learning machine generalizes during the training process  when it is trained on a random sample using a gradient descent  algorithm based on reduction of training error. It is shown, in  particular, that best generalization performance occurs, in general,  before the global minimum of the training error is achieved. The  different roles played by the complexity of the machine class and  the complexity of the specific machine in the class during learning  are also precisely demarcated.
We present here an analysis of the stochastic neurodynamics of  a neural network composed of three-state neurons described by  a master equation. An outer-product representation of the master equation is employed. In this representation, an extension of  the analysis from two to three-state neurons is easily performed.  We apply this formalism with approximation schemes to a simple three-state network and compare the results with Monte Carlo  simulations.
We present a statistical method that PAC learns the class of  stochastic perceptrons with arbitrary monotonic activation function and weights wi  (-1, 0, +1} when the probability distribution  that generates the input examples is member of a family that we  call k-blocking distributions. Such distributions represent an important step beyond the case where each input variable is statistically  independent since the 2k-blocking family contains all the Markov  distributions of order k. By stochastic perceptron we mean a perceptron which, upon presentation of input vector x, outputs i with  probability f(i WiXi -)' Because the same algorithm works for  any monotonic (nondecreasing or nonincreasing) activation function f on Boolean domain, it handles the well studied cases of  sigmods and the "usual" radial basis functions.
In supervised learning, learning from queries rather than from  random examples can improve generalization performance significantly. We study the performance of query learning for problems  where the student cannot learn the teacher perfectly, which occur  frequently in practice. As a prototypical scenario of this kind, we  consider a linear perceptron student learning a binary perceptron  teacher. Two kinds of queries for maximum information gain, i.e.,  minimum entropy, are investigated: Minimum student space entropy (MSSE) queries, which are appropriate if the teacher space  is unknown, and minimum teacher space entropy (MTSE) queries,  which can be used if the teacher space is assumed to be known, but  a student of a simpler form has deliberately been chosen. We find  that for MSSE queries, the structure of the student space determines the efficacy of query learning, whereas MTSE queries lead  to a higher generalization error than random examples, due to a  lack of feedback about the progress of the student in the way queries  are selected.
We consider the effect of combining several least squares estimators  on the expected performance of a regression problem. Computing  the exact bias and variance curves as a function of the sample size  we are able to quantitatively compare the effect of the combination  on the bias and variance separately, and thus on the expected error  which is the sum of the two. Our exact calculations, demonstrate  that the combination of estimators is particularly useful in the case  where the data set is small and noisy and the function to be learned  is unrealizable. For large data sets the single estimator produces  superior results. Finally, we show that by splitting the data set  into several independent parts and training each estimator on a  different subset, the performance can in some cases be significantly  improved.  Key words: Bias, Variance, Least Squares, Combination.
The performance of on-line algorithms for learning dichotomies is studied. In on-line learning, the number of examples P is equivalent to the learning time, since each example is  presented only once. The learning curve, or generalization error as a function of P, depends  on the schedule at which the learning rate is lowered. For a target that is a perceptton rule,  the learning curve of the perceptton algorithm can decrease as fast as p-i, if the schedule is optimized. If the target is not realizable by a perceptton, the perceptton algorithm  does not generally converge to the solution with lowest generalization error. For the case  of unrealizability due to a simple output noise, we propose a new on-line algorithm for a  perceptron yielding a learning curve that can approach the optimal generalization error as  fast as p-l/2. We then generalize the perceptron algorithm to any class of thresholded  smooth functions learning a target from that class. For "well-behaved" input distributions,  if this algorithm converges to the optimal solution, its learning curve can decrease as fast
This paper discusses the use of artificial neural networks for dynamic  modelling of time series. We argue that multistep prediction is more  appropriate to capture the dynamics of the underlying dynamical system,  because it constrains the iterated model. We show how this method can be  implemented by a recurrent ANN trained with trajectory learning. We also  show how to select the trajectory length to train the iterated predictor for the  case of chaotic time series. Experimental results corroborate the proposed  method.
We propose a novel rigorous approach for the analysis of Linsker's  unsupervised Hebbian learning network. The behavior of this  model is determined by the underlying nonlinear dynamics which  are parameterized by a set of parameters originating from the Hebbian rule and the arbor density of the synapses. These parameters  determine the presence or absence of a specific receptive field (also  referred to as a 'connection pattern') as a saturated fixed point  attractor of the model. In this paper, we perform a qualitative  analysis of the underlying nonlinear dynamics over the parameter  space, determine the effects of the system parameters on the emergence of various receptive fields, and predict precisely within which  parameter regime the network will have the potential to develop  a specially designated connection pattern. In particular, this approach exposes, for the first time, the crucial role played by the  synaptic density functions, and provides a complete precise picture  of the parameter space that defines the relationships among the  different receptive fields. Our theoretical predictions are confirmed  by numerical simulations.  320 Jianfeng Feng, H. Pan, V. P. Roychowdhury
We estimate the number of training samples required to ensure that  the performance of a neural network on its training data matches  that obtained when fresh data is applied to the network. Existing  estimates are higher by orders of magnitude than practice indicates.  This work seeks to narrow the gap between theory and practice by  transforming the problem into determining the distribution of the  supremum of a random field in the space of weight vectors, which  in turn is attacked by application of a recent technique called the  Poisson clumping heuristic.
We study the asymptotic properties of the sequence of iterates of  weight-vector estimates obtained by training a multilayer feedforward neural network with a basic gradient-descent method using  a fixed learning constant and no batch-processing. In the onedimensional case, an exact analysis establishes the existence of a  limiting distribution that is not Gaussian in general. For the general case and small learning constant, a linearization approximation  permits the application of results from the theory of random matrices to again establish the existence of a limiting distribution.  We study the first few moments of this distribution to compare  and contrast the results of our analysis with those of techniques of  stochastic approximation.
Increasing attention has been paid to reinforcement learning algorithms in recent years, partly due to successes in the theoretical  analysis of their behavior in Markov environments. If the Markov  assumption is removed, however, neither generally the algorithms  nor the analyses continue to be usable. We propose and analyze  a new learning algorithm to solve a certain class of non-Markov  decision problems. Our algorithm applies to problems in which  the environment is Markov, but the learner has restricted access  to state information. The algorithm involves a Monte-Carlo policy evaluation combined with a policy improvement method that is  similar to that of Markov decision problems and is guaranteed to  converge to a local maximum. The algorithm operates in the space  of stochastic policies, a space which can yield a policy that performs considerably better than any deterministic policy. Although  the space of stochastic policies is continuous--even for a discrete  action space our algorithm is computationally tractable.  346 Tommi Jaakkola, Satinder P. Singh, Michael I. Jordan
An application of reinforcement learning to a linear-quadratic, differential  game is presented. The reinforcement learning system uses a recently  developed algorithm, the residual gradient form of advantage updating.  The game is a Markov Decision Process (MDP) with continuous time,  states, and actions, linear dynamics, and a quadratic cost function. The  game consists of two players, a missile and a plane; the missile pursues  the plane and the plane evades the missile. The reinforcement learning  algorithm for optimal control is modified for differential games in order to  find the minimax point, rather than the maximum. Simulation results are  compared to the optimal solution, demonstrating that the simulated  reinforcement learning system converges to the optimal answer. The  performance of both the residual gradient and non-residual gradient forms  of advantage updating and Q-learning are compared. The results show that  advantage updating converges faster than Q-learning in all simulations.  The results also show advantage updating converges regardless of the time  step duration; Q-learning is unable to converge as the time step duration  [rows small.  U.S.A.F. Academy, 2354 Fairchild Dr. Suite 6K41, USAFA, CO 80840-6234  354 Mance E. Harmon, Leemon C. Baird III, A. Harry Klopf
It is widely accepted that the use of more compact representations  than lookup tables is crucial to scaling reinforcement learning (RL)  algorithms to real-world problems. Unfortunately almost all of the  theory of reinforcement learning assumes lookup table representations. In this paper we address the pressing issue of combining  function approximation and RL, and present 1) a function approximator based on a simple extension to state aggregation (a commonly used form of compact representation), namely soft state  aggregation, 2) a theory of convergence for RL with arbitrary, but  fixed, soft state aggregation, 3) a novel intuitive understanding of  the effect of state aggregation on online RL, and 4) a new heuristic  adaptive state aggregation algorithm that finds improved compact  representations by exploiting the non-discrete nature of soft state  aggregation. Preliminary empirical results are also presented.
A straightforward approach to the curse of dimensionality in reinforcement learning and dynamic programming is to replace the  lookup table with a generalizing function approximator such as a neural net. Although this has been successful in the domain of backgammon, there is no guarantee of convergence. In this paper, we show  that the combination of dynamic programming and function approximation is not robust, and in even very benign cases, may produce  an entirely wrong policy. We then introduce Grow-Support, a new  algorithm which is safe from divergence yet can still reap the benefits  of successful generalization.
This paper presents instance-based state identification, an approach  to reinforcement learning and hidden state that builds disambiguating amounts of short-term memory on-line, and also learns with an  order of magnitude fewer training steps than several previous approaches. Inspired by a key similarity between learning with hidden  state and learning in continuous geometrical spaces, this approach  uses instance-based (or "memory-based") learning, a method that  has worked well in continuous spaces.
Reinforcement learning addresses the problem of learning to select actions in order to  maximize one's performance in unknown environments. To scale reinforcement learning  to complex real-world tasks, such as typically studied in AI, one must ultimately be able  to discover the structure in the world, in order to abstract away the myriad of details and  to operate in more tractable problem spaces.  This paper presents the SKILLS algorithm. SKILLS discovers skills, which are partially  defined action policies that arise in the context of multiple, related tasks. Skills collapse  whole action sequences into single operators. They are learned by minimizing the compactness of action policies, using a description length argument on their representation.  Empirical results in simple grid navigation tasks illustrate the successful discovery of  structure in reinforcement learning.
Semi-Maxkov Decision Problems axe continuous time generalizations of discrete time Markov Decision Problems. A number of  reinforcement leaxning lgorithms have been developed recently  for the solution of Markov Decision Problems, based on the ideas  of asynchronous dynamic programming and stochastic approximation. Among these are TD(,), Q-leaxning, and Real-time Dynamic  Programming. After reviewing semi-Maxkov Decision Problems  and Bellman's optimality equation in that context, we propose lgorithms similax to those named above, adapted to the solution of  semi-Markov Decision Problems. We demonstrate these algorithms  by applying them to the problem of determining the optimal control for a simple queueing system. We conclude with a discussion  of circumstances under which these algorithms may be usefully applied.
We prove the convergence of an actor/critic algorithm that is equivalent to Q-learning by construction. Its equivalence is achieved by  encoding Q-values within the policy and value function of the actor and critic. The resultant actor/critic algorithm is novel in two  ways: it updates the critic only when the most probable action is  executed from any given state, and it rewards the actor using criteria that depend on the relative probability of the action that was  executed.
The basic paradigm for learning in neural networks is 'learning from  examples' where a training set of input-output examples is used to  teach the network the target function. Learning from hints is a generalization of learning from examples where additional information  about the target function can be incorporated in the same learning  process. Such information can come from common sense rules or  special expertise. In financial market applications where the training data is very noisy, the use of such hints can have a decisive  advantage. We demonstrate the use of hints in foreign-exchange  trading of the U.S. Dollar versus the British Pound, the German  Mark, the Japanese Yen, and the Swiss Franc, over a period of 32  months. We explain the general method of learning from hints and  how it can be applied to other markets. The learning model for  this method is not restricted to neural networks.
This paper discusses the linearly weighted combination of estimators in which the weighting functions are dependent on the input.  We show that the weighting functions can be derived either by  evaluating the input dependent variance of each estimator or by  estimating how likely it is that a given estimator has seen data in  the region of the input space close to the input pattern. The latter solution is closely related to the mixture of experts approach  and we show how learning rules for the mixture of experts can be  derived from the theory about learning with missing features. The  presented approaches are modular since the weighting functions  can easily be modified (no retraining) if more estimators are added. Furthermore, it is easy to incorporate estimators which were  not derived from data such as expert systems or algorithms.
We introduce a recurrent architecture having a modular structure  and we formulate a training procedure based on the EM algorithm.  The resulting model has similarities to hidden Markov models, but  supports recurrent networks processing style and allows to exploit  the supervised learning paradigm while using maximum likelihood  estimation.
We propose a statistical mechanical framework for the modeling  of discrete time series. Maximum likelihood estimation is done via  Boltzmann learning in one-dimensional networks with tied weights.  We call these networks Boltzmann chains and show that they  contain hidden Markov models (HMMs) as a special case. Our  framework also motivates new architectures that address particular shortcomings of HMMs. We look at two such architectures:  parallel chains that model feature sets with disparate time scales,  and looped networks that model long-term dependencies between  hidden states. For these networks, we show how to implement  the Boltzmann learning rule exactly, in polynomial time, without  resort to simulated or mean-field annealing. The necessary computations are done by exact decimation procedures from statistical  mechanics.
If data collection is costly, there is much to be gained by actively selecting particularly informative data points in a sequential way. In  a Bayesian decision-theoretic framework we develop a query selection criterion which explicitly takes into account the intended use  of the model predictions. By Markov Chain Monte Carlo methods  the necessary quantities can be approximated to a desired precision. As the number of data points grows, the model complexity  is modified by a Bayesian model selection strategy. The properties of two versions of the criterion are demonstrated in numerical  experiments.
In many vision based tasks, the ability to focus attention on the important  portions of a scene is crucial for good performance on the tasks. In this paper  we present a simple method of achieving spatial selective attention through  the use of a saliency map. The saliency map indicates which regions of the  input retina are important for performing the task. The saliency map is created through predictive auto-encoding. The performance of this method is  demonstrated on two simple tasks which have multiple very strong distracting features in the input retina. Architectural extensions and application  directions for this model are presented.
Visualizing and structuring pairwise dissimilarity data are difficult combinatorial optimization problems known as multidimensional scaling or pairwise data clustering.  Algorithms for embedding dissimilarity data set in a EuclidJan space, for clustering  these data and for actively selecting data to support the clustering process are discussed  in the maximum entropy framework. Active data selection provides a strategy to discover  structure in a data set efficiently with partially unknown data.
A new learning algorithm is derived which performs online stochastic gradient ascent in the mutual information between outputs and  inputs of a network. In the absence of a priori knowledge about  the 'signal' and 'noise' components of the input, propagation of  information depends on calibrating network non-linearities to the  detailed higher-order moments of the input density functions. By  incidentally minimising mutual information between outputs, as  well as maximising their individual entropies, the network 'factorises' the input into independent components. As an example  application, we have achieved near-perfect separation of ten digitally mixed speech signals. Our simulations lead us to believe that  our network performs better at blind separation than the HeraultJutten network, reflecting the fact that it is derived rigorously from  the mutual information objective.  468 Anthony J. Bell, Terrence J. Sejnowski
Differentiation between the nodes of a competitive learning network is conventionally achieved through competition on the basis of neural activity. Simple inhibitory mechanisms are limited  to sparse representations, while decorrelation and factorization  schemes that support distributed representations are computationally unattractive. By letting neural plasticity mediate the competitive interaction instead, we obtain diffuse, nonadaptive alternatives for fully distributed representations. We use this technique  to simplify and improve our binary information gain optimization algorithm for feature extraction (Schraudolph and Sejnowski,  1993); the same approach could be used to improve other learning  algorithms.
Existing recurrent net learning algorithms are inadequate. We introduce the conceptual framework of viewing recurrent training as  matching vector fields of dynamical systems in phase space. Phasespace reconstruction techniques make the hidden states explicit,  reducing temporal learning to a feed-forward problem. In short,  we propose viewing iterated prediction [LF88] as the best way of  training recurrent networks on deterministic signals. Using this  framework, we can train multiple trajectories, insure their stability, and design arbitrary dynamical systems.
We present a new method for obtaining local error bars for nonlinear  regression, i.e., estimates of the confidence in predicted values that depend on the input. We approach this problem by applying a maximumlikelihood framework to an assumed distribution of errors. We demonstrate our method first on computer-generated data with locally varying,  normally distributed target noise. We then apply it to laser data from the  Santa Fe lme Series Competition where the underlying system noise is  known quantization error and the error bars give local estimates of model  misspecificafion. In both cases, the method also provides a weightedregression effect that improves generalization performance.  Learning Local Error Bars Using a Maximum Likelihood  Framework: Motivation, Concept, and Mechanics  Feed-forward artificial neural networks used for nonlinear regression can be interpreted as  predicting the mean of the target distribution as a function of (conditioned on) the input  pattern (e.g., Buntine & Weigend, 1991; Bishop, 1994), typically using one linear output unit  per output variable. If parameterized, this conditional target distribution (CTD) may also be  *http://www'cs'cøløradø'edu/andreas/Høme'html'  This paper is avlable with figures in cobrs  ftp://ftp.cs.colorado.edu/pub/  Time-Series/MyPapers/nix.weigend_nips7.ps.Z  490 David A. Nix, Andreas S. Weigend  viewed as an error model (Rumelhart et al., 1995). Here, we present a simple method that  provides higher-order information about the CTD than simply the mean. Such additional  information could come from attempting to estimate the entire CTD with connectionist  methods (e.g., "Mixture Density Networks," Bishop, 1994; "fractional binning, "Srivastava  & Weigend, 1994) or with non-connectionist methods such as a Monte Carlo on a hidden  Markov model (Fraser & Dimitriadis, 1994). While non-parametric estimates of the shape  of a CTD require large quantities of data, our less data-hungry method (Weigend & Nix,  1994) assumes a specific parameterized form of the CTD (e.g., Gaussian) and gives us the  value of the error bar (e.g., the width of the Gaussian) by finding those parameters which  maximize the likelihood that the target data was generated by a particular network model.  In this paper we derive the specific update rules for the Gaussian case. We would like to  emphasize, however, that any parameterized unimodal distribution can be used for the CTD  in the method presented here.   !  !  hj  O. O0  Figure 1: Architecture of the network for estimating error bars using an auxiliary output unit. All  weight layers have full connectivity. This architecture allows the conditional variance 2-unit access  to both information in the input pattern itself and in the hidden unit representation formed while  learning the conditional mean, ,0(x).  We model the desired observed target value d as d(x) = y(x) + n(x), where y(x) is the  underlying function we wish to approximate and n(x) is noise drawn from the assumed  CTD. Just as the conditional mean of this CTD, V(x), is a function of the input, the  variance rr 2 of the CTD, the noise level, may also vary as a function of the input x  (noise heterogeneity). Therefore, not only do we want the network to learn a function  .0(x) that estimates the conditional mean V(x) of the CTD, but we also want it to learn a  function 82 (x) that estimates the conditional variance rr 2 (x). We simply add an auxiliary  output unit, the b2-unit, to compute our estimate of rr 2 (x). Since rr 2 (x) must be positive,  we choose an exponential activation function to naturally impose this bound: 82 (x) =  exp [k wa2kh (x) +/3], where/3 is the offset (or"bias"), and wa2 is the weight between  hidden unit k and the 2-unit. The particular connectivity of our architecture (Figure 1),  in which the b2-unit has a hidden layer of its own that receives connections from both the  .0-unit's hidden layer and the input pattern itself, allows great flexibility in learning 82 (x).  In contrast, if the 2-unit has no hidden layer of its own, the 2-unit is constrained to  approximate rr 2 (x) using only the exponential of a linear combination of basis functions  (hidden units) already tailored to represent .0(x) (since learning the conditional variance  b2(x) before learning the conditional mean .0(x) is troublesome at best). Such limited  connectivity can be too constraining on the functional forms for ?r2 (x) and, in our experience,   The case of a single Gaussian to represent a unimodal distribution can also been generalized to a  mixture of several Gaussians that allows the modeling of multimodal distributions (Bishop, 1994).  Learning Local Error Bars for Nonlinear Regression 491  produce inferior results. This is a significant difference compared to Bishop's (1994)  Gaussian mixture approach in which all output units are directly connected to one set of  hidden units. The other extreme would be not to share any hidden units at all, i.e., to  employ two completely separate sets of hidden units, one to the 0(x)-unit, the other one to  the 8 '2 (x)-unit This is the right thing to do ff there is indeed no overlap in the mapping  from the inputs to y and from the inputs to 2. The two examples discussed in this paper are  between these two extremes; this justifies the mixed architecture we use. Further discussion  on shared vs. separate hidden units for the second example of the laser data is given by  Kazlas & Weigend (1995, this volume).  For one of our network outputs, the 0-unit, the target is easily available--it is simply given  by d. But what is the target for the 32-unit? By maximizing the likelihood of our network model iV given the data, P (iVI x, d), a target is "invented" as follows. Applying Bayes' mle  and assuming statistical independence of the errors, we equivalently do gradient descent in  the negative log likelihood of the targets d given the inputs and the network model, summed  over all patterns i (see Rumelhart et al., 1995): C i in P(di Ixi, iV). Traditionally,  the resulting form of this cost function involves only the estimate ,0(xi) of the conditional  mean; the variance of the CrD is assumed to be constant for all xi, and the constant terms  drop out after differentiation. In contrast, we allow the conditional variance to depend on  x and explicitly keep these terms in C, approximating the conditional variance for x4 by  .2 x  (-). Given any network architecture and any parametric form for the CTD (i.e., any  error model), the appropriate weight-update equations for gradient decent learning can be  straighfforwardly derived.  Assuming normally distributed errors around y(x) corresponds to a CTD density function  [a,_y(x,)] 1 ^  of P(dilxi) = [27rrr2(xi)] -1/2 exp 2,2(x,) j. Using the network output y(xi) m  a 2 x, 2(xi)  y(x4) to estimate the conditional mean and using the auxiliary output (.)   to estimate the conditional variance, we ob!ain the monotonically related negative log  [d-(x0] 2  likelihood, In P (di [xi, iV) = « In 2r3 '2 (xi) + 252(x,) . Summation over all patterns  gives the total cost:  . .2 x  C- . a2(xi) +in ( .)+ln27r (1)  To write explicit weight-update equations, we must specify the network unit transfer functions. Here we choose a linear activation function for the -unit, tanh functions for the  hidden units, and an exponential function for the 3'2-unit. We can then take derivatives of  the cost C with respect to the network weights. To update weights connected to the .0 and  '2-units we have:  1  Awj = a2(x)[a hj(x) (2)  1  y( hk(xi) (3)  Awa2 k = r/232(xi ){[di^ X 2  where r/is the learning rate. For weights not connected to the output, the weight-update  equations are derived using the chain rule in the same way as in standard backpropagation.  Note that Eq. (3) is equivalent to training a separate function-approximation network for  '2(x) where the targets are the squared errors [di -y(Xi)]2]. Note also that if 3'2(xi) is  492 David A. Nix, Andreas S. Weigend  constant, Eqs. (1)-(2) reduce to their familiar forms for standard backpropagation with a  sum-squared error cost function.  The 1/32(x) term in Eqs. (2)-(3) can be interpreted as a form of "weighted regression,"  increasing the effective learning rate in low-noise regions and reducing it in high-noise  regions. As a result, the network emphasizes obtaining small errors on those patterns where  it can (low 32); it discounts learning patterns for which the expected error is going to be large  anyway (large 32). This weighted-regression term can itself be highly beneficial where  outliers (i.e., samples from high-noise regions) would ordinarily pull network resources  away from fitting low-noise regions which would otherwise be well approximated.  For simplicity, we use simple gradient descent learning for training. Other nonlinear minimization techniques could be applied, however, but only if the following problem is avoided.  If the weighted-regression term described above is allowed a significant influence early in  learning, local minima frequently result. This is because input patterns for which low errors  are initially obtained are interpreted as "low noise" in Eqs. (2)-(3) and overemphasized  in learning. Conversely, patterns for which large errors are initially obtained (because  significant learning of .0 has not yet taken place) are erroneously discounted as being in  "high-noise" regions and little subsequent learning takes place for these patterns, leading  to highly-suboptimal solutions. This problem can be avoided if we separate training into  the following three phases:  Phase I (Initial estimate of the conditional mean): Randomly split the available data  into equal halves, sets ,4 and/3. Assuming r2(x) is constant, learn the estimate of the  conditional mean .0(x) using set ,4 as the training set. This corresponds to "traditional"  training using gradient descent on a simple squared-error cost function, i.e., Eqs. (1)-(2)  without the 1/32(x) terms. To reduce overfitting, training is considered complete at the  minimum of the squared error on the cross-validation set/3, monitored at the end of each  complete pass through the training data.  Phase II (Initial estimate of the conditional variance): Attach a layer of hidden units  connected to both the inputs and the hidden units of the network from Phase I (see Figure 1).  Freeze the weights trained in Phase I, and train the 32-unit to predict the squared errors  (see Eq. (3)), again using simple gradient descent as in Phase I. The training set for this  phase is set/3, with set ,4 used for cross-validation. If set ,4 were used as the training set  in this phase as well, any overfitting in Phase I could result in seriously underestimating  r2(x). To avoid this risk, we interchange the data sets. The initial value for the offset/3  of the b2-unit is the natural logarithm of the mean squared error (from Phase I) of set/3.  Phase II stops when the squared error on set ,4 levels off or starts to increase.  Phase III (Weighted regression): Re-split the available data into two new halves, ,4' and  /3'. Unfreeze all weights and train all network parameters to minimize the full cost function  C on set ,4'. Training is considered complete when C has reached its minimum on set/3'.  2 Examples  Example #1: To demonstrate this method, we construct a one-dimensional example problem where y(z) and r2(z) are known. We take the equation y(z) = sin(w,z) sin(w/z)  with w, = 3 and w/ = 5. We then generate (z, d) pairs by picking z uniformly from the interval [0, r/2] and obtaining the corresponding target d by adding normally distributed noise  n(z) = N[0, r2(z)] to the underlying y(z), where r2(z) = 0.02 + 0.25 x [1 sin(w/z)] 2.  Learning Local Error Bars for Nonlinear Regression 493  Table 1: Results for Example #1. ENM$ denotes the mean squared error divided by the overall  variance of the target; "Mean cost" represents the cost function (Eq. (1)) averaged over all patterns.  Row 4 lists these values for the ideal model (true /(x) and rr2(a:)) given the data generated. Row 5  gives the correlation coefficient between the network's predictions for the standard error (i.e., the  square root of the &2-unit's activation) and the actually occurring L1 residual errors, [d(xi) Row 6 gives the correlation between the true rr(x) and these residual errors. Rows 7-9 give the  percentage of residuals smaller than one and two standard deviations for the obtained and ideal  models as well as for an exact Gaussian.  I ow I I Training (/hi' = 10 3) I Evaluation (/¾ = 10 5) ]  E N M, Mean cost  Phase I 0.576 0.853  Phase II 0.576 0.542  Phase III 0.552 0.440  ,(  ) (ex,t ,tiw nois) 0.545 0.430  E) N M' S Mean cost  0.593 0.882  0.593 0.566  0.570 0.462  0.563 0.441  p(&(x), residual errors)  o of errors < (); 2()  go ofrro, < ,(); 2,()  ( cact Gaussian)  p p  0.564  0.602  1 std 2 std  64.8 95.4  66.6 96.0  68.3 95.4  0.548  0.584  1 std 2 std  67.0 94.6  68.4 95.4  68.3 95.4  We generate 1000 patterns for training and an additional 105 patterns for post-training  evaluation.  Training follows exactly the three phases described above with the following details: 2 Phase  I uses a network with one hidden layer of 10 tanh units and r/= 10 -2. For Phase II we add  an auxiliary layer of 10 tanh hidden units connected to the &2-unit (see Figure 1) and use  the same r/. Finally, in Phase III the composite network is trained with r/-10 -4.  At the end of Phase I (Figure 2a), the only available estimate of a2(a:) is the global  root-mean-squared error on the available data, and the model misspecification is roughly  uniform over a:--a typical solution were we training with only the traditional squared-error  cost function. The corresponding error measures are listed in Table 1. At the end of Phase  II, however, we have obtained an initial estimate of r2(a:) (since the weights to the .O-unit  are frozen during this phase, no modification of 0 is made). Finally, at the end of Phase  III, we have better estimates of both /(:) and a2(x). First we note that the correlations  between the predicted errors and actual errors listed in Table 1 underscore the near-optimal  prediction of local errors. We also see that these errors correspond, as expected, to the  assumed Gaussian error model. Second, we note that not only has the value of the cost  function dropped from Phase II to Phase III, but the generalization error has also dropped,  indicating an improved estimate of /(x). By comparing Phases I and III we see that the  quality of () has improved significantly in the low-noise regions (roughly a: < 0.6) at a  minor sacrifice of accuracy in the high-noise region.  Example #2: We now apply our method to a set of observed data, the 1000-point laser  2Further details: all inputs are scaled to zero mean and unit variance. All initial weights feeding  into hidden units are drawn from a uniform distribution between 1/i and 1/i where i is the number of  incoming connections. All initial weights feeding into  or &2 are drawn from a uniform distribution  between -s/i and s/i where s is the standard deviation of the (overall) target distribution. No  momentum is used, and all weight updates are averaged over the forward passes of 20 patterns.  494 David A. Nix, Andreas S. Weigend  -1  '1  x  0.6  0.6  0.4  0.2  x  .n  'o 1  Phmm II  Phase III  Phase III  Figure 2: (a) Example #1: Results after each phase of training. The top row gives the true l/(z)  (solid line) and network estimate 0(z) (dotted line); the bottom row gives the true a2(z) (solid line)  and network estimate 82(z) (dotted line). (b) Example #2: state-space embedding of laser data  (evaluation set) using linear grey-scaling of 0.50 (lightest) < 8(xt) < 6.92 (darkest). See text for  details.  intensity series from the Santa Fe competition) Since our method is based on the network's  observed errors, the predicted error b2 (x) actually represents the sum of the underlying  system noise, characterized by tr 2 (x), and the model adsspecification. Here, since we know  the system noise is roughly uniform 8-bit sampling resolution quantization error, we can  apply our method to evaluate the local quality of the manifold approximation. 4  The prediction task is easier if we have more points that lie on the manifold, thus better  constraining its shape. In the competition, Sauer (1994) upsampled the 1000 available data  points with an FFT method by a factor of 32. This does not change the effective sampling  rate, but it "fills in" more points, .more pi'ecisely defining the manifold. We use the same  upsampling trick (without filtered embedding), and obtain 31200 full (x, d) patterns for  learning. We apply the three-phase approach described above for the simple network of  Figure 1 with 25 inputs (corresponding to 25 past values), 12 hidden units feeding the .O-unit,  and a liberal 30 hidden units feeding the b2_unit (since we are uncertain as to the complexity  of rr 2 (x) for this dataset). We use r/10 -7 for Phase I and r/= 10l0 for Phases II and III.  Since we know the quantization error is +0.5, error estimates less than this are meaningless.  Therefore, we enforce a minimum value of r 2 (x) = 0.25 (the quantization error squared)  on the squared errors in Phases II and III.  sThe data set and several predictions and characterizations are described in the volume edited by Weigend & Gershenfeld (1994). The data is available by anonymous ftp  at ftp.½s.½olorado.edu in /pub/Tñme-Seres/SantaFe as A.dat. See also  http://www. cs. colorado. edu/Time-Sertes/TSWelcome. html for further analyses  of this and other time series data sets.  4When we make a single-step prediction where the manifold approximation is poor, we have little  confidence making iterated predictions based on that predicted value. However, if we know we are in  a low-error region, we can have increased confidence in iterated predictions that involve our current  prediction.  Learning Local Error Bars for Nonlinear Regression 495  Table 2: Results for Example #2 (See Table 1 caption for definitions).  I row I I II'aining (/'V m 975) Evaluation (/'V m 23, 950) I  ENM S Mean cost EiVMS Mean cost
Dynamic Cell Structures (DCS) represent a family of artificial neural  architectures suited both for unsupervised and supervised learning.  They belong to the recently [Martinetz94] introduced class of Topology  Representing Networks (TRN) which build perfectly topology preserving feature maps. DCS employ a modified K0honen learning rule  in conjunction with competitive Hebbian learning. The Kohonen type  learning rule serves to adjust the synaptic weight vectors while Hebbian  learning establishes a dynamic lateral connection structure between  the units reflecting the topology of the feature manifold. In case of supervised learning, i.e. function approximation, each neural unit implements  a Radial Basis Function, and an additional layer of linear output units  adjusts according to a delta-rule. DCS is the first RBF-based approximation scheme attempting to concurrently learn and utilize a perfectly topology preserving map for improved performance.  Simulations on a selection of CMU-Benchmarks indicate that the DCS  idea applied to the Growing Cell Structure algorithm [Fritzke93] leads  to an efficient and elegant algorithm that can beat conventional models  on similar tasks.
Although artificial neural networks have been applied in a variety of real-world scenarios  with remarkable success, they have often been criticized for exhibiting a low degree of  human comprehensibility. Techniques that compile compact sets of symbolic rules out  of artificial neural networks offer a promising perspective to overcome this obvious  deficiency of neural network representations.  This paper presents an approach to the extraction of if-then rules from artificial neural networks. Its key mechanism is validity interval analysis, which is a generic  tool for extracting symbolic knowledge by propagating rule-like knowledge through  Backpropagation-style neural networks. Empirical studies in a robot arm domain illustrate the appropriateness of the proposed method for extracting rules from networks with  real-valued and distributed representations.
We have determined the capacity and information efficiency of an  associative net configured in a brain-like way with partial connectivity and noisy input cues. Recall theory was used to calculate  the capacity when pattern recall is achieved using a winners-takeall strategy. Transforming the dendritic sum according to input  activity and unit usage can greatly increase the capacity of the  associative net under these conditions. For moderately sparse patterns, maximum information efficiency is achieved with very low  connectivity levels (<_ 10%). This corresponds to the level of connectivity commonly seen in the brain and invites speculation that  the brain is connected in the most information efficient way.
Radial Basis Function (RBF) Networks, also known as networks  of locally-tuned processing units (see [6]) are well known for their  ease of use. Most algorithms used to train these types of networks, however, require a fixed architecture, in which the number  of units in the hidden layer must be determined before training  starts. The RCE training algorithm, introduced by Reilly, Cooper  and Elbaurn (see [8]), and its probabilistic extension, the P-RCE  algorithm, take advantage of a growing structure in which hidden  units are only introduced when necessary. The nature of these algorithms allows training to reach stability much faster than is the  case for gradient-descent based methods. Unfortunately P-RCE  networks do not adjust the standard deviation of their prototypes  individually, using only one global value for this parameter.  This paper introduces the Dynamic Decay Adjustment (DDA) algorithm which utilizes the constructive nature of the P-RCE algorithm together with independent adaptation of each prototype's  decay factor. In addition, this radial adjustment is class dependent  and distinguishes between different neighbours. It is shown that  networks trained with the presented algorithm perform substantially better than common RBF networks.  522 Michael R. Berthold, Jay Diamond
We present a new algorithm for finding low complexity networks  with high generalization capability. The algorithm searches for  large connected regions of so-called "fiat" minima of the error function. In the weight-space environment of a "fiat" minimum, the  error remains approximately constant. Using an MDL-based argument, fiat minima can be shown to correspond to low expected  overfitting. Although our algorithm requires the computation of  second order derivatives, it has backprop's order of complexity.  Experiments with feedforward and recurrent nets are described. In  an application to stock market prediction, the method outperforms  conventional backprop, weight decay, and "optimal brain surgeon".
Product units provide a method of automatically learning the  higher-order input combinations required for efficient learning in  neural networks. However, we show that problems are encountered when using backpropagation to train networks containing  these units. This paper examines these problems, and proposes  some atypical heuristics to improve learning. Using these heuristics  a constructive method is introduced which solves well-researched  problems with significantly less neurons than previously reported.  Secondly, product units are implemented as candidate units in the  Cascade Correlation (Fahlman & Lebiere, 1990) system. This resulted in smaller networks which trained faster than when using  sigmoidal or Gaussian units.
We present a deterministic annealing variant of the EM algorithm  for maximum likelihood parameter estimation problems. In our  approach, the EM process is reformulated as the problem of minimizing the thermodynamic free energy by using the principle of  macimum entropy and statistical mechanics analogy. Unlike simulated annealing approaches, this minimization is deterministically  performed. Moreover, the derived algorithm, unlike the conventional EM algorithm, can obtain better estimates free of the initial  parameter values.
This paper studies the problem of diffusion in Markovian models,  such as hidden Markov models (HMMs) and how it makes very  difficult the task of learning of long-term dependencies in sequences.  Using results from Markov chain theory, we show that the problem  of diffusion is reduced if the transition probabilities approach 0 or 1.  Under this condition, standard HMMs have very limited modeling  capabilities, but input/output HMMs can still perform interesting  computations.
We introduce a novel algorithm for actorial learning, motivated  by segmentation problems in computational vision, in which the  underlying factors correspond to clusters of highly correlated input  features. The algorithm derives from a new kind of competitive  clustering model, in which the cluster generators compete to explain each feature of the data set and cooperate to explain each  input example, rather than competing for examples and cooperating on features, as in traditional clustering algorithms. A natural extension of the algorithm recovers hierarchical models of data  generated from multiple unknown categories, each with a different, multiple causal structure. Several simulations demonstrate  the power of this approach.
This paper presents an alternating minimization (AM) algorithm  used in the training of radial basis function and linear regressor  networks. The algorithm is a modification of a small-step interior  point method used in solving primal linear programs. The algorithm has a convergence rate of O(v/-dL) iterations where n is a  measure of the network size and L is a measure of the resulting  solution's accuracy. Two results are presented that specify how  aggressively the two steps of the AM may be pursued to ensure  convergence of each step of the alternating minimization.
A self-organizing neural network for sequence classification called  SARDNET is described and analyzed experimentally. SARDNET  extends the Kohonen Feature Map architecture with activation retention and decay in order to create unique distributed response  patterns for different sequences. SARDNET yields extremely dense  yet descriptive representations of sequential input in very few training iterations. The network has proven successful on mapping arbitrary sequences of binary and real numbers, as well as phonemic  representations of English words. Potential applications include  isolated spoken word recognition and cognitive science models of  sequence processing.
This paper studies the convergence properties of the well known  K-Means clustering algorithm. The K-Means algorithm can be described either as a gradient descent algorithm or by slightly extending the mathematics of the EM algorithm to this hard threshold  case. We show that the K-Means algorithm actually minimizes the  quantization error using the very fast Newton algorithm.
We develop a principled strategy to sample a function optimally for  function approximation tasks within a Bayesian framework. Using  ideas from optimal experiment design, we introduce an objective  function (incorporating both bias and variance) to measure the degree of approximation, and the potential utility of the data points  towards optimizing this objective. We show how the general strategy can be used to derive precise algorithms to select data for two  cases: learning unit step functions and polynomial functions. In  particular, we investigate whether such active algorithms can learn  the target with fewer examples. We obtain theoretical and empirical results to suggest that this is the case.
Understanding knowledge representations in neural nets has been a  difficult problem. Principal components analysis (PCA) of  contributions (products of sending activations and connection weights)  has yielded valuable insights into knowledge representations, but much  of this work has focused on the correlation matrix of contributions. The  present work shows that analyzing the variance-covariance matrix of  contributions yields more valid insights by taking account of weights.
Casting neural network weights in symbolic terms is crucial for  interpreting and explaining the behavior of a network. Additionally, in  some domains, a symbolic description may lead to more robust  generalization. We present a principled approach to symbolic rule  extraction based on the notion of weight templates, parameterized  regions of weight space corresponding to specific symbolic expressions.  With an appropriate choice of representation, we show how template  parameters may be efficiently identified and instantiated to yield the  optimal match to a unit's actual weights. Depending on the requirements  of the application domain, our method can accommodate arbitrary  disjunctions and copjunctions with O(k) complexity, simple n-of-m  expressions with O(k 2) compl_exity, or a more general class of recursive  n-of-m expressions with O(k a) complexity, where k is the number of  inputs to a unit. Our method of rule extraction offers several benefits  over alternative approaches in the literature, and simulation results on a  variety of problems demonstrate its effectiveness.
Many real world learning problems are best characterized by an  interaction of multiple independent causes or factors. Discovering such causal structure from the data is the focus of this paper.  Based on Zemel and I-Iinton's cooperative vector quantizer (CVQ)  architecture, an unsupervised learning algorithm is derived from  the Expectation-Maximization (EM) framework. Due to the combinatorial nature of the data generation process, the exact E-step  is computationally intractable. Two alternative methods for computing the E-step are proposed: Gibbs sampling and mean-field  approximation, and some promising empirical results are presented.
An incremental network model is introduced which is able to learn  the important topological relations in a given set of input vectors by  means of a simple Hebb-like learning rule. In contrast to previous  approaches like the "neural gas" method of Martinetz and Schulten  (1991, 1994), this model has no parameters which change over time  and is able to continue learning, adding units and connections, until  a performance criterion has been met. Applications of the model  include vector quantization, clustering, and interpolation.
We propose an alternative model for mixtures of experts which uses  a different parametric form for the gating network. The modified  model is trained by the EM algorithm. In comparison with earlier  models--trained by either EM or gradient ascent--there is no need  to select a learning stepsize. We report simulation experiments  which show that the new architecture yields faster convergence.  We also apply the new model to two problem domains: piecewise  nonlinear function approximation and the combination of multiple  previously trained classifiers.
Most of the common techniques for estimating conditional probability densities are inappropriate for applications involving periodic variables. In this paper we introduce three novel techniques  for tackling such problems, and investigate their performance using synthetic data. We then apply these techniques to the problem  of extracting the distribution of wind vector directions from radar  scatterometer data gathered by a remote-sensing satellite.
We introduce and study methods of inserting synaptic noise into  dynamically-driven recurrent neural networks and show that applying a controlled amount of noise during training may improve  convergence and generalization. In addition, we analyze the effects  of each noise parameter (additive vs. multiplicative, cumulative vs.  non-cumulative, per time step vs. per string) and predict that best  overall performance can be achieved by injecting additive noise at  each time step. Extensive simulations on learning the dual parity  grammar from temporal strings substantiate these predictions.
Hinton [6] proposed that generalization in artificial neural nets  should improve if nets learn to represent the domain's underlying  regularities. Abu-Mustafa's hints work [1] shows that the outputs  of a backprop net can be used as inputs through which domainspecific information can be given to the net. We extend these ideas  by showing that a backprop net learning many related tasks at the  same time can use these tasks as inductive bias for each other and  thus learn better. We identify five mechanisms by which multitask  backprop improves generalization and give empirical evidence that  multitask backprop generalizes better in real domains.
We present a graph-based method for rapid, accurate search  through prototypes for transformation-invariant pattern classification. Our method has in theory the same recognition accuracy as  other recent methods based on 'tangent distance" [Simard et al.,  1994], since it uses the same categorization rule. Nevertheless ours  is significantly faster during classification because far fewer tangent distances need be computed. Crucial to the success of our  system are 1) a novel graph architecture in which transformation  constraints and geometric relationships among prototypes are encoded during learning, and 2) an improved graph search criterion,  used during classification. These architectural insights are applicable to a wide range of problem domains. Here we demonstrate that  on a handwriting recognition task, a basic implementation of our  system requires less than half the computation of the Euclidean  sorting method.
Second order properties of cost functions for recurrent networks  are investigated. We analyze a layered fully recurrent architecture,  the virtue of this architecture is that it features the conventional  feedforward architecture as a special case. A detailed description of  recursive computation of the full Hessian of the network cost function is provided. We discuss the possibility of invoking simplifying  approximations of the Hessian and show how weight decays iron the  cost function and thereby greatly assist training. We present tentative pruning results, using Hassibi et al.'s Optimal Brain Surgeon,  demonstrating that recurrent networks can construct an efficient  internal memory.
In this paper, we derive classifiers which are winner-take-all (WTA)  approximations to a Bayes classifier with Gaussian mixtures for  class conditional densities. The derived classifiers include clustering  based algorithms like LVQ and k-Means. We propose a constrained  rank Gaussian mixtures model and derive a WTA algorithm for it.  Our experiments with two speech classification tasks indicate that  the constrained rank model and the WTA approximations improve  the performance over the unconstrained models.
We present efficient algorithms for dealing with the problem of missing inputs (incomplete feature vectors) during training and recall.  Our approach is based on the approximation of the input data distribution using Parzen windows. For recall, we obtain closed form  solutions for arbitrary feedforward networks. For training, we show  how the backpropagation step for an incomplete pattern can be  approximated by a weighted averaged backpropagation step. The  complexity of the solutions for training and recall is independent  of the number of missing features. We verify our theoretical results  using one classification and one regression problem.
Many different discrete-time recurrent neural network architectures have been proposed. However, there has been virtually no  effort to compare these arch:_tectures experimentally. In this paper  we review and categorize many of these architectures and compare  how they perform on various classes of simple problems including  grammatical inference and nonlinear system identification.
For many types of learners one can compute the statistically "optimal" way to select data. We review how these techniques have  been used with feedforward neural networks [MacKay, 1992; Cohn,  1994]. We then show how the same principles may be used to select  data for two alternative, statistically-based learning architectures:  mixtures of Gaussians and locally weighted regression. While the  techniques for neural networks are expensive and approximate, the  techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate.
Prior constraints are imposed upon a learning problem in the form  of distance measures. Prototypical 2-D point sets and graphs are  learned by clustering with point matching and graph matching distance measures. The point matching distance measure is approx.  invariant under affine transformationstranslation, rotation, scale  and shear and permutations. It operates between noisy images  with missing and spurious points. The graph matching distance  measure operates on weighted graphs and is invariant under permutations. Learning is formulated as an optimization problem.  Large objectives so formulated (-- million variables) are efficiently  minimized using a combination of optimization techniques algebraic transformations, iterative projective scaling, clocked objectives, and deterministic annealing.
This paper explores the application of Temporal Difference (TD) learning  (Sutton, 1988) to forecasting the behavior of dynamical systems with realvalued outputs (as opposed to game-like situations). The performance  of TD learning in comparison to standard supervised learning depends  on the amount of noise present in the data. In this paper, we use a  deterministic chaotic time series from a low-noise laser. For the task of  direct five-step ahead predictions, our experiments show that standard  supervised learning is better than TD learning. The TD algorithm can be  viewed as linking adjacent predictions. A similar effect can be obtained  by sharing the internal representation in the network. We thus compare  two architectures for both paradigms: the first architecture ("separate  hidden units") consists of individual networks for each of the five direct  multi-step prediction tasks; the second ("shared hidden units") has a  single (larger) hidden layer that finds a representation from which all five  predictions for the next five steps are generated. For this data set we do  not find any significant difference between the two architectures.  *http://www. cs.colorado.edu/~andreas/Home.htm1.  This paper is avlab wi figus in colors as ftp://ftp.cs.colorado.edu/pu/  Time-Series/MyPapers/kazlas.weigend_nips7.ps.Z .  722 Peter Kazlas, Andreas S. Weigend
An analogue VLSI neural network has been designed and tested  to perform cardiac morphology classification tasks. Analogue techniques were chosen to meet the strict power and area requirements  of an Implantable Cardioverter Defibrillator (ICD) system. The robustness of the neural network architecture reduces the impact of  noise, drift and offsets inherent in analogue approaches. The network is a 10:6:3 multi-layer perceptron with on chip digital weight  storage, a bucket brigade input to feed the Intracardiac Electrogram (ICEG) to the network and has a winner take all circuit  at the output. The network was trained in loop and included a  commercial ICD in the signal processing path. The system has successfully distinguished arrhythmia for different patients with better  than 90% true positive and true negative detections for dangerous  rhythms which cannot be detected by present ICDs. The chip was  implemented in 1.2urn CMOS and consumes less than 200nW maximum average power in an area of 2.2 x 2.2ram 2.
We present a silicon model of an axon which shows promise as a  building block for pulse-based neural computations involving correlations of pulses across both space and time. The circuit shares  a number of features with its biological counterpart including an  excitation threshold, a brief refractory period after pulse completion, pulse amplitude restoration, and pulse width restoration. We  provide a simple explanation of circuit operation and present data  from a chip fabricated in a standard 2/rn CMOS process through  the MOS Implementation Service (MOSIS). We emphasize the necessity of the restoration of the width of the pulse in time for stable  propagation in axons.
In this paper we present a new version of the standard multilayer  perceptton (MLP) algorithm for the state-of-the-art in neural network VLSI implementations: the Intel Nil000. This new version of  the MLP uses a fundamental property of high dimensional spaces  which allows the /2-norm to be accurately approximated by the  /x-norm. This approach enables the standard MLP to utilize the  parallel architecture of the Nil000 to achieve on the order of 40000,  256-dimensional classifications per second.
We describe an analog VLSI implementation of the ART1 algorithm  (Carpenter, 1987). A prototype chip has been fabricated in a standard low  cost 1.5gm double-metal single-poly CMOS process. It has a die area of  lcrn 2 and is mounted in a 120-pins PGA package. The chip realizes a  modified version of the original ART1 architecture. Such modification  has been shown to preserve all computational properties of the original  algorithm (Serrano, 1994a), while being more appropriate for VLSI  realizations. The chip implements an ART1 network with 100 F1 nodes  and 18 F2 nodes. It can therefore cluster 100 binary pixels input patterns  into up to 18 different categories. Modular expansibility of the system is  possible by assembling an NxM array of chips without any extra  interfacing circuitry, resulting in an F1 layer with 100xN nodes, and an  F2 layer with 18xM nodes. Pattern classification is performed in less  than 1.8gs, which means an equivalent computing power of 2.2x109  connections and connection-updates per second. Although internally the  chip is analog in nature, it interfaces to the outside world through digital  signals, thus having a true asynchrounous digital behavior. Experimental  chip test results are available, which have been obtained through test  equipments for digital chips.
A novel two-terminal device, consisting of a thin 1000J layer ofp +  a-Si:H sandwiched between Vanadium and Chromium electrodes,  exhibits a non-volatile, analogue memory action. This device stores  synaptic weights in an ANN chip, replacing the capacitor previously  used for dynamic weight storage. Two different synapse designs are  discussed and results are presented.
A training method based on a form of continuous spatially distributed  optical error back-propagation is presented for an aH optical network  composed of nondiscrete neurons and weighted interconnections. The all  optical network is feed-forward and is composed of thin layers of a Kerrtype self focusing/defocusing nonlinear optical material. The training  method is derived from a Lagrangian formulation of the constrained  minimization of the network error at the output. This leads to a  formulation that describes training as a calculation of the distributed error  of the optical signal at the output which is then reflected back through the  device to assign a spatially distributed error to the internal layers. This  error is then used to modify the internal weighting values. Results from  several computer simulations of the training are presented, and a simple  optical table demonstration of the network is discussed.  772 Elizabeth C. Behrman
We present an analog VLSI chip for parallel analog vector quantization. The MOSIS 2.0 tzm double-poly CMOS Tiny chip contains an  array of 16 x 16 charge-based distance estimation cells, implementing a  mean absolute difference (MAD) metric operating on a 16-input analog  vector field and 16 analog template vectors. The distance cell including dynamic template storage measures 60 x 78 /xm 2. Additionally,  the chip features a winner-take-all (WTA) output circuit of linear complexity, with global positive feedback for fast and decisive settling of a  single winner output. Experimental results on the complete 16 x 16 VQ  system demonstrate correct operation with 34 dB analog input dynamic  range and 3 tzsec cycle time at 0.7 mW power dissipation.
The localization and orientation to various novel or interesting  events in the environment is a critical sensorimotor ability in all  animals, predator or prey. In mammals, the superior colliculus  (SC) plays a major role in this behavior, the deeper layers exhibiting topographically mapped responses to visual, auditory, and  somatosensory stimuli. Sensory information arriving from different modalities should then be represented in the same coordinate  frame. Auditory cues, in particular, are thought to be computed  in head-based coordinates which must then be transformed to retinal coordinates. In this paper, an analog VLSI implementation for  auditory localization in the azimuthal plane is described which extends the architecture proposed for the barn owl to a primate eye  movement system where further transformation is required. This  transformation is intended to model the projection in primates from  auditory cortical areas to the deeper layers of the primate superior  colliculus. This system is interfaced with an analog VLSI-based  saccadic eye movement system also being constructed in our laboratory.
We consider the problem of decoding block coded data, using a physical  dynamical system. We sketch out a decompression algorithm for fractal  block codes and then show how to implement a recurrent neural  network using physically simple but highly-nonlinear, analog circuit  models of neurons and synapses. The nonlinear system has many fixed  points, but we have at our disposal a procedure to choose the parameters  in such a way that only one solution, the desired solution, is stable. As  a partial proof of the concept, we present experimental data from a  small system a 16-neuron analog CMOS chip fabricated in a 2m analog  p-well process. This chip operates in the subthreshold regime and, for  each choice of parameters, converges to a unique stable state. Each state  exhibits a qualitatively fractal shape.
We have continued our study of a parallel perturbative learning  method [Alspector et al., 1993] and implications for its implementation in analog VLSI. Our new results indicate that, in most cases,  a single parallel perturbation (per pattern presentation) of the function parameters (weights in a neural network) is theoretically the  best course. This is not true, however, for certain problems and  may not generally be true when faced with issues of implementation such as limited precision. In these cases, multiple parallel  perturbations may be best as indicated in our previous results.
This paper describes a way of neural hardware  implementation with the analog-digital mixed mode neural  chip. The full custom neural VLSI of Universally  Reconstructible Artificial Neural network(URAN) is used  to implement Korean speech recognition system. A  multi-layer perceptron with linear neurons is trained  successfully under the limited accuracy in computations.  The network with a large frame input layer is tested to  recognize spoken korean words at a forward retrieval.  Multichip hardware module is suggested with eight chips  or more for the extended performance and capacity.  812 II-Song Han, Hwang-Soo Lee, Ki-Chul Kim
We describe single-transistor silicon synapses that compute, learn,  and provide non-volatile memory retention. The single transistor  synapses simultaneously perform long term weight storage, compute the product of the input and the weight value, and update the  weight value according to a Hebbian or a backpropagation learning  rule. Memory is accomplished via charge storage on polysilicon  floating gates, providing long-term retention xvithout refresh. The  synapses efficiently use the physics of silicon to perform weight updates; the weight value is increased using tunneling and the weight  value decreases using hot electron injection. The small size and  low power operation of single transistor synapses allows the development of dense synaptic arrays. We describe the design, fabrication, characterization, and modeling of an array of single transistor synapses. When the steady state source current is used as  the representation of the weight value, both the incrementing and  decrementing functions are proportional to a power of the source  current. The synaptic array was fabricated in the standard 2pro  double poly, analog process available from MOSIS.
Deciding the appropriate representation to use for modeling human  auditory processing is a critical issue in auditory science. While engineers have successfully performed many single-speaker tasks with LPC  and spectrogram methods, more difficult problems will need a richer  representation. This paper describes a powerful auditory representation  known as the correlogram and shows how this non-linear representation  can be converted back into sound, with no loss of perceptually important information. The correlogram is interesting because it is a neurophysiologically plausible representation of sound. This paper shows  improved methods for spectrogram inversion (conventional pattern  playback), inversion of a cochlear model, and inversion of the correlogram representation.
In this paper we consider speech coding as a problem of speech  modelling. In particular, prediction of parameterised speech over  short time segments is performed using the Hierarchical Mixture of  Experts (HME) (Jordan & Jacobs 1994). The HME gives two advantages over traditional non-linear function approximators such  as the Multi-Layer Perceptton (MLP); a statistical understanding of the operation of the predictor and provision of information  about the performance of the predictor in the form of likelihood  information and local error bars. These two issues are examined  on both toy and real world problems of regression and time series  prediction. In the speech coding context, we extend the principle  of combining local predictions via the HME to a Vector Quantization scheme in which fixed local codebooks are combined on-line  for each observation.
Glove-TalklI is a system which translates hand gestures to speech  through an adaptive interface. Hand gestures are mapped continuously to 10 control parameters of a parallel formant speech synthesizer. The mapping allows the hand to act as an artificial vocal  tract that produces speech in real time. This gives an unlimited  vocabulary in addition to direct control of fundamental frequency  and volume. Currently, the best version of Glove-TalklI uses several input devices (including a CyberGlove, a ContactGlove, a 3space tracker, and a foot-pedal), a parallel formant speech synthesizer and 3 neural networks. The gesture-to-speech task is divided  into vowel and consonant production by using a gating network  to weight the outputs of a vowel and a consonant neural network.  The gating network and the consonant network are trained with  examples from the user. The vowel network implements a fixed,  user-defined relationship between hand-position and vowel sound  and does not require any training examples from the user. Volume,  fundamental frequency and stop consonants are produced with a  fixed mapping from the input devices. One subject has trained to  speak intelligibly with Glove-TalklI. He speaks slowly with speech  quality similar to a text-to-speech synthesizer but with far more  natural-sounding pitch variations.  844 S. Sidney Fels, Geoffrey Hinton
This paper presents ongoing work on a speaker independent visual  speech recognition system. The work presented here builds on previous  research efforts in this area and explores the potential use of simple  hidden Markov models for limited vocabulary, speaker independent  visual speech recognition. The task at hand is recognition of the first  four English digits, a task with possible applications in car-phone  dialing. The images were modeled as mixtures of independent  Gaussian distributions, and the temporal dependencies were captured  with standard left-to-right hidden Markov models. The results indicate  that simple hidden Markov models may be used to successfully  recognize relatively unprocessed image sequences. The system achieved  performance levels equivalent to untrained humans when asked to  recognize the first four English digits.
In this paper, we incorporate the Hierarchical Mixtures of Experts (HME)  method of probability estimation, developed by Jordan [1], into an HMMbased continuous speech recognition system. The resulting system can be  thought of as a continuous-density HMM system, but instead of using gaussian  mixtures, the HME system employs a large set of hierarchically organized but  relatively small neural networks to perform the probability density estimation.  The hierarchical structure is reminiscent of a decision tree except for two  important differences: each "expert" or neural net performs a "soft" decision  rather than a hard decision, and, unlike ordinary decision trees, the parameters  of all the neural nets in the HME are automatically trainable using the EM  algorithm. We report results on the ARPA 5,000-word and 40,000-word Wall  Street Journal corpus using HME models.
The paper presents a rapid speaker-normalization technique based  on neural network spectral mapping. The neural network is used  as a front-end of a continuous speech recognition system (speakerdependent, HMM-based) to normalize the input acoustic data from  a new speaker. The spectral difference between speakers can be  reduced using a limited amount of new acoustic data (40 phonetically rich sentences). Recognition error of phone units from the  acoustic-phonetic continuous speech corpus APASCI is decreased  with an adaptability ratio of 25%. We used local basis networks of  elliptical Gaussian kernels, with recursive allocation of units and  on-line optimization of parameters (GRAN model). For this application, the model included a linear term. The results compare  favorably with multivariate linear mapping based on constrained  orthonormal transformations.
Speech recognizers provide good performance for most users but the  error rate often increases dramatically for a small percentage of talkers  who are "different" from those talkers used for training. One expensive  solution to this problem is to gather more training data in an attempt to  sample these outlier users. A second solution, explored in this paper, is  to artificially enlarge the number of training talkers by transforming the  speech of existing training talkers. This approach is similar to enlarging  the training set for OCR digit recognition by warping the training digit  images, but is more difficult because continuous speech has a much  larger number of dimensions (e.g. linguistic, phonetic, style, temporal,  spectral) that differ across talkers. We explored the use of simple linear  spectral warping to enlarge a 48-talker training data base used for word  spotting. The average detection rate overall was increased by 2.9  percentage points (from 68.3% to 71.2%) for male speakers and 2.5  percentage points (from 64.8% to 67.3%) for female speakers. This  increase is small but similar to that obtained by doubling the amount of  training data.
We present a unifying view of discrete-time operator models used in the  context of finite word length linear signal processing. Comparisons are  made between the recently presented gamma operator model, and the delta  and rho operator models for performing nonlinear system identification  and prediction using neural networks. A new model based on an adaptive  bilinear transformation which generalizes all of the above models is  presented.
We describe a framework for learning saccadic eye movements using a  photometric representation of target points in natural scenes. The representation takes the form of a high-dimensional vector comprised of the  responses of spatial filters at different orientations and scales. We first  demonstrate the use of this response vector in the task of locating previously foveated points in a scene and subsequently use this property in  a multisaccade strategy to derive an adaptive motor map for delivering  accurate saccades.
We describe a system that can track a hand in a sequence of video  frames and recognize hand gestures in a user-independent manner.  The system locates the hand in each video frame and determines  if the hand is open or closed. The tracking system is able to track  the hand to within -t-10 pixels of its correct location in 99.7% of  the flames from a test set containing video sequences from 18 different individuals captured in 18 different room environments. The  gesture recognition network correctly determines if the hand being  tracked is open or closed in 99.1% of the frames in this test set.  The system has been designed to operate in real time with existing  hardware.
We describe a framework for real-time tracking of facial expressions  that uses neurally-inspired correlation and interpolation methods. A  distributed view-based representation is used to characterize facial state,  and is computed using a replicated correlation network. The ensemble  response of the set of view correlation scores is input to a network based  interpolation method, which maps perceptual state to motor control states  for a simulated 3-D face model. Activation levels of the motor state  correspond to muscle activations in an anatomically derived model. By  integrating fast and robust 2-D processing with 3-D models, we obtain a  system that is able to quickly track and interpret complex facial motions  in real-time.
Perceptual learning is defined as fast improvement in performance and  retention of the learned ability over a period of time. In a set of psychophysical experiments we demonstrated that perceptual learning occurs for the discrimination of direction in stochastic motion stimuli. Here  we model this learning using two approaches: a clustering model that  learns to accommodate the motion noise, and an averaging model that  learns to ignore the noise. Simulations of the models show performance  similar to the psychophysical results.
This paper outlines a dynamic theory of development and adaptation in neural networks with feedback connections. Given input ensemble, the connections change in strength according to an  associative learning rule and approach a stable state where the  neuronal outputs are decorrelated. We apply this theory to primary visual cortex and examine the implications of the dynamical  decorrelation of the activities of orientation selective cells by the  intracortical connections. The theory gives a unified and quantitative explanation of the psychophysical experiments on orientation  contrast and orientation adaptation. Using only one parameter, we  achieve good agreements between the theoretical predictions and  the experimental data.
Unsupervised learning procedures have been successful at low-level  feature extraction and preprocessing of raw sensor data. So far,  however, they have had limited success in learning higher-order  representations, e.g., of objects in visual images. A promising approach is to maximize some measure of agreement between the  outputs of two groups of units which receive inputs physically separated in space, time or modality, as in (Becker and Hinton, 1992;  Becker, 1993; de Sa, 1993). Using the same approach, a much simpler learning procedure is proposed here which discovers features  in a single-layer network consisting of several populations of units,  and can be applied to multi-layer networks trained one layer at  a time. When trained with this algorithm on image sequences of  moving geometric objects a two-layer network can learn to perform  accurate position-invariant object classification.
This paper presents a new method for image compression by neural  networks. First, we show that we can use neural networks in a pyramidal framework, yielding the so-called PCA pyramids. Then we  present an image compression method based on the PCA pyramid,  which is similar to the Laplace pyramid and wavelet transform.  Some experimental results with real images are reported. Finally,  we present a method to combine the quantization step with the  learning of the PCA pyramid.
This paper presents an unsupervised learning scheme for categorizing  3D objects from their 2D projected images. The scheme exploits an  auto-associative network's ability to encode each view of a single object  into a representation that indicates its view direction. We propose two  models that employ different classification mechanisms; the first model  selects an auto-associative network whose recovered view best matches  the input view, and the second model is based on a modular architecture  whose additional network classifies the views by splitting the input  space nonlinearly. We demonstrate the effectiveness of the proposed  classification models through simulations using 3D wire-frame objects.
A fundamental open problem in computer vision--determining  pose and correspondence between two sets of points in space-is solved with a novel, robust and easily implementable algorithm.  The technique works on noisy point sets that may be of unequal  sizes and may differ by non-rigid transformations. A 2D variation calculates the pose between point sets related by an affine  transformation--translation, rotation, scale and shear. A 3D to 3D  variation calculates translation and rotation. An objective describing the problem is derived from Mean field theory. The objective  is minimized with clocked (EM-like) dynamics. Experiments with  both handwritten and synthetic data provide empirical evidence  for the method.
Deformable models are an attractive approach to recognizing nonrigid objects which have considerable within class variability. However, there are severe search problems associated with fitting the  models to data. We show that by using neural networks to provide  better starting points, the search time can be significantly reduced.  The method is demonstrated on a character recognition task.  In previous work we have developed an approach to handwritten character recognition based on the use of deformable models (Hinton, Williams and Revow, 1992a;  Revow, Williams and Hinton, 1993). We have obtained good performance with this  method, but a major problem is that the search procedure for fitting each model to  an image is very computationally intensive, because there is no efficient algorithm  (like dynamic programming) for this task. In this paper we demonstrate that it is  possible to "compile down" some of the knowledge gained while fitting models to  data to obtain better starting points that significantly reduce the search time.
The problem of interpolating between specified images in an image  sequence is a simple, but important task in model-based vision.  We describe an approach based on the abstract task of "manifold  learning" and present results on both synthetic and real image sequences. This problem arose in the development of a combined  lip-reading and speech recognition system.
The efficiency of image search can be greatly improved by using a  coarse-to-fine search strategy with a multi-resolution image representation. However, if the resolution is so low that the objects have few distinguishing features, search becomes difficult. We show that the  performance of search at such low resolutions can be improved by using  context information, i.e., objects visible at low-resolution which are not  the objects of interest but are associated with them. The networks can be  given explicit context information as inputs, or they can learn to detect  the context objects, in which case the user does not have to be aware of  their existence. We also use Integrated Feature Pyramids, which represent high-frequency information at low resolutions. The use of multiresolution search techniques allows us to combine information about the  appearance of the objects on many scales in an efficient way. A natural  fom of exemplar selection also arises from these techniques. We illustrate these ideas by training hierarchical systems of neural networks to  find clusters of buildings in aerial photographs of farmland.
When training neural networks by the classical backpropagation algorithm the whole problem to learn must be expressed by a set of inputs and  desired outputs. However, we often have high-level knowledge about  the learning problem. In optical character recognition (OCR), for instance, we know that the classification should be invariant under a set of  transformations like rotation or translation. We propose a new modular  classification system based on several autoassociative multilayer perceptrons which allows the efficient incorporation of such knowledge. Results  are reported on the NIST database of upper case handwritten letters and  compared to other approaches to the invariance problem.
Simard, LeCun & Denker (1993) showed that the performance of  nearest-neighbor classification schemes for handwritten character  recognition can be improved by incorporating invariance to specific transformations in the underlying distance metric -the so  called tangent distance. The resulting classifier, however, can be  prohibitively slow and memory intensive due to the large amount of  prototypes that need to be stored and used in the distance comparisons. In this paper we develop rich models for representing large  subsets of the prototypes. These models are either used singly per  class, or as basic building blocks in conjunction with the K-means  clustering algorithm.  *This work was performed while Trevor Hastie was a member of the Statistics and Data  Analysis Research Group, AT&T Bell Laboratories, Murray Hill, NJ 07974.  1000 Trevor Hastie, Patrice Simard, Eduard Siickinger
This paper presents results from the first use of neural networks  for the real-time feedback control of high temperature plasmas in  a tokamak fusion experiment. The tokamak is currently the principal experimental device for research into the magnetic confinement approach to controlled fusion. In the tokamak, hydrogen  plasmas, at temperatures of up to 100 Million K, are confined  by strong magnetic fields. Accurate control of the position and  shape of the plasma boundary requires real-time feedback control  of the magnetic field structure on a time-scale of a few tens of microseconds. Software simulations have demonstrated that a neural  network approach can give significantly better performance than  the linear technique currently used on most tokamak experiments.  The practical application of the neural network approach requires  high-speed hardware, for which a fully parallel implementation of  the multilayer perceptron, using a hybrid of digital and analogue  technology, has been developed.  1008 C. Bishop, P. Haynes, M. Smith, T. Todd, D. Trotman, C. Windsor
We construct a mixture of locally linear generative models of a collection of pixel-based images of digits, and use them for recognition. Different models of a given digit are used to capture different  styles of writing, and new images are classified by evaluating their  log-likelihoods under each model. We use an EM-based algorithm  in which the M-step is computationally straightforward principal  components analysis (PCA). Incorporating tangent-plane information [12] about expected local deformations only requires adding  tangent vectors into the sample covariance matrices for the PCA,  and it demonstrably improves performance.
The theory of Optimal Unsupervised Motor Learning shows how  a network can discover a reduced-order controller for an unknown  nonlinear system by representing only the most significant modes.  Here, I extend the theory to apply to command sequences, so that  the most significant components discovered by the network correspond to motion "primitives". Combinations of these primitives  can be used to produce a wide variety of different movements.  I demonstrate applications to human handwriting decomposition  and synthesis, as well as to the analysis of electrophysiological  experiments on movements resulting from stimulation of the frog  spinal cord.
In this study, an integrated neural network control architecture for nonlinear dynamic systems is  presented. Most of the recent emphasis in the neural network control field has no error feedback as the  control input, which rises the lack of adaptation problem. The integrated architecture in this paper  combines feed forward control and error feedback adaptive control using neural networks. The paper  reveals the different internal functionality of these two kinds of neural network controllers for certain  input styles, e.g., state feedback and error feedback. With error feedback, neural network controllers  learn the slopes or the gains with respect to the error feedback, producing an error driven adaptive  contrbl systems. The results demonstrate that the two kinds of control scheme can be combined to  realize their individual advantages. Testing with disturbances added to the plant shows good tracking  and adaptation with the integrated neural control architecture.
Each year people spend a huge amount of time typing. The text people type  typically contains a tremendous amount of redundancy due to predictable  word usage patterns and the text's structure. This paper describes a  neural network system call AutoTypist that monitors a person's typing and  predicts what will be entered next. AutoTypist displays the most likely  subsequent word to the typist, who can accept it with a single keystroke,  instead of typing it in its entirety. The multi-layer perceptron at the heart  of AutoTypist adapts its predictions of likely subsequent text to the user's  word usage pattern, and to the characteristics of the text currently being  typed. Increases in typing speed of 2-3% when typing English prose and  10-20% when typing C code have been demonstrated using the system,  suggesting a potential time savings of more than 20 hours per user per year.  In addition to increasing typing speed, AutoTypist reduces the number of  keystrokes a user must type by a similar amount (2-3% for English, 1020% for computer programs). This keystroke savings has the potential to  significantly reduce the frequency and severity of repeated stress injuries  caused by typing, which are the most common injury suffered in today's  office environment.
To compress text files, a neural predictor network P is used to approximate the conditional probability distribution of possible "next  characters", given n previous characters. P's outputs are fed into  standard coding algorithms that generate short codes for characters  with high predicted probability and long codes for highly unpredictable characters. Tested on short German newspaper articles,  our method outperforms widely used Lempel-Ziv algorithms (used  in UNIX functions such as "compress" and "gzip").  1048 Jiirgen Schmidhuber, Stefan Heil
Experiments demonstrated that sigmoid multilayer perceptron (MLP)  networks provide slightly better risk prediction than conventional  logistic regression when used to predict the risk of death, stroke, and  renal failure on 1257 patients who underwent coronary artery bypass  operations at the Lahey Clinic. MLP networks with no hidden layer and  networks with one hidden layer were trained using stochastic gradient  descent with early stopping. MLP networks and logistic regression used  the same input features and were evaluated using bootstrap sampling  with 50 replications. ROC areas for predicting mortality using  preoperative input features were 70.5% for logistic regression and  76.0% for MLP networks. Regularization provided by early stopping  was an important component of improved performance. A simplified  approach to generating confidence intervals for MLP risk predictions  using an auxiliary "confidence MLP" was developed. The confidence  MLP is trained to reproduce confidence intervals that were generated  during training using the outputs of 50 MLP networks trained with  different bootstrap samples.
The TNM staging system has been used since the early 1960's  to predict breast cancer patient outcome. In an attempt to increase prognostic accuracy, many putative prognostic factors have  been identified. Because the TNM stage model can not accommodate these new factors, the proliferation of factors in breast  cancer has lead to clinical confusion. What is required is a new  computerized prognostic system that can test putative prognostic  factors and integrate the predictive factors with the TNM variables in order to increase prognostic accuracy. Using the area under the curve of the receiver operating characteristic, we compare  the accuracy of the following predictive models in terms of five  year breast cancer-specific survival: pTNM staging system, principal component analysis, classification and regression trees, logistic  regression, cascade correlation neural network, conjugate gradient  descent neural, probabilistic neural network, and backpropagation  neural network. Several statistical models are significantly more ac1064 Harry B. Burke, David B. Rosen, Philip H. Goodman  curate than the TNM staging system. Logistic regression and the  backpropagation neural network are the most accurate prediction  models for predicting five year breast cancer-specific survival
This paper presents NeuroChess, a program which learns to play chess from the final  outcome of games. NeuroChess learns chess board evaluation functions, represented  by artificial neural networks. It integrates inductive neural network learning, temporal  differencing, and a variant of explanation-based learning. Performance results illustrate  some of the strengths and weaknesses of this approach.
Diagnosis of human disease or machine fault is a missing data problem  since many variables are initially unknown. Additional information needs  to be obtained. The joint probability distribution of the data can be used to  solve this problem. We model this with mixture models whose parameters  are estimated by the EM algorithm. This gives the benefit that missing  data in the database itself can also be handled correctly. The request for  new information to refine the diagnosis is performed using the maximum  utility principle. Since the system is based on learning it is domain  independent and less labor intensive than expert systems or probabilistic  networks. An example using a heart disease database is presented.
In remote sensing applications "ground-truth" data is often used  as the basis for training pattern recognition algorithms to generate thematic maps or to detect objects of interest. In practical  situations, experts may visually examine the images and provide a  subjective noisy estimate of the truth. Calibrating the reliability  and bias of expert labellers is a non-trivial problem. In this paper  we discuss some of our recent work on this topic in the context  of detecting small volcanoes in Magellan SAR images of Venus.  Empirical results (using the Expectation-Maximization procedure)  suggest that accounting for subjective noise can be quite significant in terms of quantifying both human and algorithm detection  performance.
In this paper we present NPen ++, a connectionist system for  writer independent, large vocabulary on-line cursive handwriting  recognition. This system combines a robust input representation,  which preserves the dynamic writing information, with a neural  network architecture, a so called Multi-State Time Delay Neural  Network (MS-TDNN), which integrates recognition and segmentation in a single framework. Our preprocessing transforms the  original coordinate sequence into a (still temporal) sequence of feature vectors, which combine strictly local features, like curvature  or writing direction, with a bitmap-like representation of the coordinate's proximity. The MS-TDNN architecture is well suited  for handling temporal sequences as provided by this input representation. Our system is tested both on writer dependent and  writer independent tasks with vocabulary sizes ranging from 400  up to 20,000 words. For example, on a 20,000 word vocabulary we  achieve word recognition rates up to 88.9% (writer dependent) and  84.1% (writer independent) without using any language models.  1094 Stefan Manke, Michael Finke, Alex Waibel
For machines to perform classification tasks, such as speech and  character recognition, appropriately handling deformed patterns  is a key to achieving high performance. The authors presents a  new type of classification system, an Adaptive Input Field Neural Network (AIFNN), which includes a simple pre-trained neural  network and an elastic input field attached to an input layer. By  using an iterative method, AIFNN can determine an optimal afIine  translation for an elastic input field to compensate for the original  deformations. The convergence of the AIFNN algorithm is shown.  AIFNN is applied for handwritten numerals recognition. Consequently, 10.83% of originally misclassified patterns are correctly  categorized and total performance is improved, without modifying  the neural network.
Multi-class classification problems can be efficiently solved by  partitioning the original problem into sub-problems involving only two  classes: for each pair of classes, a (potentially small) neural network is  trained using only the data of these two classes. We show how to  combine the outputs of the two-class neural networks in order to obtain  posterior probabilities for the class decisions. The resulting probabilistic  pairwise classifier is part of a handwriting recognition system which is  currently applied to check reading. We present results on real world data  bases and show that, from a practical point of view, these results compare  favorably to other neural network approaches.
Experiments were performed to reveal some of the computational  properties of the human motor memory system. We show that  as humans practice reaching movements while interacting with a  novel mechanical environment, they learn an internal model of the  inverse dynamics of that environment. Subjects show recall of this  model at testing sessions 24 hours after the initial practice. The  representation of the internal model in memory is such that there  is interference when there is an attempt to learn a new inverse  dynamics map immediately after an anticorrelated mapping was  learned. We suggest that this interference is an indication that  the same computational elements used to encode the first inverse  dynamics map are being used to learn the second mapping. We  predict that this leads to a forgetting of the initially learned skill.
One of the fundamental properties that both neural networks and  the central nervous system share is the ability to learn and generalize from examples. While this property has been studied extensively in the neural network literature it has not been thoroughly  explored in human perceptual and motor learning. We have chosen  a coordinate transformation system--the visuomotor map which  transforms visual coordinates into motor coordinates--to study the  generalization effects of learning new input-output pairs. Using a  paradigm of computer controlled altered visual feedback, we have  studied the generalization of the visuomotor map subsequent to  both local and context-dependent remappings. A local remapping  of one or two input-output pairs induced a significant global, yet  decaying, change in the visuomotor map, suggesting a representation for the map composed of units with large functional receptive  fields. Our study of context-dependent remappings indicated that  a single point in visual space can be mapped to two different finger locations depending on a context variable--the starting point  of the movement. Furthermore, as the context is varied there is  a gradual shift between the two remappings, consistent with two  visuomotor modules being learned and gated smoothly with the  context.
The additive clustering (ADCL US)model (Shepard & Arabie, 1979)  treats the similarity of two stimuli as a weighted additive measure  of their common features. Inspired by recent work in unsupervised  learning with multiple cause models, we propose a new, statistically  well-motivated algorithm for discovering the structure of natural  stimulus classes using the ADCLUS model, which promises substantial gains in conceptual simplicity, practical efficiency, and solution  quality over earlier efforts. We also present preliminary results with  artificial data and two classic similarity data sets.
We have recently developed a theory of spatial representations in  which the position of an object is not encoded in a particular frame  of reference but, instead, involves neurons computing basis functions of their sensory inputs. This type of representation is able  to perform nonlinear sensorimotor transformations and is consistent with the response properties of parietal neurons. We now ask  whether the same theory could account for the behavior of human  patients with parietal lesions. These lesions induce a deficit known  as hemineglect that is characterized by a lack of reaction to stimuli  located in the hemispace contralateral to the lesion. A simulated  lesion in a basis function representation was found to replicate three  of the most important aspects of hemineglect: i) The models failed  to cross the leftmost lines in line cancellation experiments, ii) the  deficit affected multiple frames of reference and, iii) it could be  object centered. These results strongly support the basis function  hypothesis for spatial representations and provide a computational  theory of hemineglect at the single cell level.
Whereas optical character recognition (OCR) systems learn to classify single characters; people learn to classify long character strings  in parallel, within a single fixation. This difference is surprising  because high dimensionality is associated with poor classification  learning. This paper suggests that the human reading system  avoids these problems because the number of to-be-classified images is reduced by consistent and optimal eye fixation positions,  and by character sequence regularities.  An interesting difference exists between human reading and optical character recognition (OCR) systems. The input/output dimensionality of character classification  in human reading is much greater than that for OCR systems (see Figure 1). OCR  systems classify one character at time; while the human reading system classifies  as many as 8-13 characters per eye fixation (Rayner, 1979) and within a fixation,  character category and sequence information is extracted in parallel (Blanchard,  McConkie, Zola, and Wolverton, 1984; Reicher, 1969).  OCR (Low Dimensionality)  [Dorothy lived in the .... ]  Human Reading (High Dimensionality)  [ Dorothy lived in the raidst of the ..... ]  Dot[ oyl ................................................................. ."DOROTHY LI"  [livecl in the ] ................................ l"LIVED IN THE"  [midst of the ] . "MIDST OF THE"  Figure 1: Character classification versus character sequence classification.  This is an interesting difference because high dimensionality is associated with poor  classification learning-the so-called curse of dimensionality (Denker, et al; 1987;  Geman, Bienenstock, & Doursat, 1992). OCR systems are designed to classify  single characters to minimize such problems. The fact that most people learn to read  quite well even with the high dimensional inputs and outputs, implies that variance  18 G.L. MARTIN  is somehow lowered in this domain, thereby making accurate classification learning  possible. The present paper reports on simulations of parallel character classification  which suggest that variance is lowered through regularities in eye fixation positions  and in character sequences making up valid words.
A significant limitation of neural networks is that the representations they learn are usually incomprehensible to humans. We  present a novel algorithm, TREPAN, for extracting comprehensible,  symbolic representations from trained neural networks. Our algorithm uses queries to induce a decision tree that approximates the  concept represented by a given network. Our experiments demonstrate that TREPAN is able to produce decision trees that maintain  a high level of fidelity to their respective networks while being comprehensible and accurate. Unlike previous work in this area, our  algorithm is general in its applicability and scales well to large networks and problems with high-dimensional input spaces.
Harmony networks have been proposed as a means by which connectionist models can perform symbolic computation. Indeed, proponents claim that a harmony network can be built that constructs  parse trees for strings in a context free language. This paper shows  that harmony networks do not work in the following sense: they  construct many outputs that are not valid parse trees.  In order to show that the notion of systematicity is compatible with connectionism,  Paul Smolensky, Geraldine Legendre and Yoshiro Miyata (Smolensky, Legendre,  and Miyata 1992; Smolensky 1993; Smolensky, Legendre, and Miyata 1994) proposed a mechanism, "Harmony Theory," by which connectionist models purportedly  perform structure sensitive operations without implementing classical algorithms.  Harmony theory describes a "harmony network" which, in the course of reaching a  stable equilibrium, apparently computes parse trees that are valid according to the  rules of a particular context-free grammar.  Harmony networks consist of four major components which will be explained in  detail in Section 1. The four components are,  Tensor Representation: A means to interpret the activation vector of a connectionist system as a parse tree for a string in a context-free language.  Harmony: A function that maps all possible parse trees to the non-positive integers so that a parse tree is valid if and only if its harmony is zero.  Energy: A function that maps the set of activation vectors to the real numbers  and which is minimized by certain connectionist networks x.  Recurslye Construction: A system for determining the weight matrix of a connectionist network so that if its activation vector is interpreted as a parse   Smolensky, Legendre and Miyata use the term "harmony" to refer to both energy and  harmony. To distinguish between them, we will use the term that is often used to describe  the Lyapunov function of dynamic systems, "energy" (see for example Golden 1986).  32 R. GOURLEY  tree, then the network's energy is the negation of the harmony of that parse  tree.  Smolensky et al. contend that, in the process of minimizing their energy values,  harmony networks implicitly maximize the harmony of the parse tree represented by  their activation vector. Thus, if the harmony network reaches a stable equilibrium  where the energy is equal to zero, the parse tree that is represented by the activation  vector must be a valid parse tree:  When the lower-level description of the activation-spreading process satisfies certain mathematical properties, this process can be  analyzed on a higher level as the construction of that structure  including the given input structure which maximizes Harmony.  (Smolensky 1993, p848, emphasis is original)  Unfortunately, harmony networks do not work -they do not always construct  maximum-harmony parse trees. The problem is that the energy function is defined  on the values of the activation vector. By contrast, the harmony function is defined  on possible parse trees. Section 2 of this paper shows that these two domains are  not equal, that is, there are some activation vectors that do not represent any parse  tree.  The recursive construction merely guarantees that the energy function passes  through zero at the appropriate points; its minima are unrestricted. So, while  it may be the case that the energy and harmony functions are negations of one  another, it is not always the case that a local minimum of one is a local maximum  of the other. More succinctly, the harmony network will find minima that are not  even trees, let alone valid parse trees.  The reason why harmony networks do not work is straightforward. Section 3 shows  that the weight matrix must have only negative eigenvalues, for otherwise the network constructs structures which are not valid trees. Section 4 shows that if the  weight matrix has only negative eigenvalues, then the energy function admits only  a single zero -the origin. Furthermore, we show that the origin cannot be interpreted as a valid parse tree. Thus, the stable points of a harmony network are not  valid parse trees.
In consideration of attention as a means for goal-directed behavior in non-stationary environments, we argue that the dynamics of  attention should satisfy two opposing demands: long-term maintenance and quick transition. These two characteristics are contradictory within the linear domain. We propose the near saddlenode bifurcation behavior of a sigmoidal unit with self-connection  as a candidate of dynamical mechanism that satisfies both of these  demands. We further show in simulations of the 'bug-eat-food'  tasks that the near saddle-node bifurcation behavior of recurrent  networks can emerge as a functional property for survival in nonstationary environments.
The choice of an input representation for a neural network can have  a profound impact on its accuracy in classifying novel instances.  However, neural networks are typically computationally expensive  to train, making it difficult to test large numbers of alternative  representations. This paper introduces fast quality measures for  neural network representations, allowing one to quickly and accurately estimate which of a collection of possible representations  for a problem is the best. We show that our measures for ranking  representations are more accurate than a previously published measure, based on experiments with three difficult, real-world pattern  recognition problems.
An essential feature of intelligent sensory processing is the ability to  focus on the part of the signal of interest against a background of  distracting signals, and to be able to direct this focus at will. In this  paper the problem of auditory scene segmentation is considered and a  model of the early stages of the process is proposed. The behaviour of  the model is shown to be in agreement with a number of well known  psychophysical results. The principal contribution of this model lies in  demonstrating how streaming might result from interactions between  the tonotopic patterns of activity of input signals and traces of previous  activity which feedback and influence the way in which subsequent  signals are processed.
We have developed a computational theory of rodent navigation that  includes analogs of the place cell system, the head direction system, and  path integration. In this paper we present simulation results showing how  interactions between the place and head direction systems can account for  recent observations about hippocampal place cell responses to doubling  and/or rotation of cue cards in a cylindrical arena (Sharp et al., 1990).  Rodents have multiple internal representations of their relationship to their environment.  They have, for example, a representation of their location (place cells in the hippocampal  formation, see Muller et al., 1991), and a location-independent representation of their  heading (head direction cells in the postsubiculum and the anterior thalamic nuclei, see  Taube et al., 1990; Taube, 1995).  If these representations are to be used for navigation, they must be aligned consistently  whenever the animal reenters a familiar environment. This process was examined in a set  of experiments by Sharp et al. (1990).
We have analyzed the relationship between correlated spike count  and the peak in the cross-correlation of spike trains for pairs of simultaneously recorded neurons from a previous study of area MT  in the macaque monkey (Zohary et al., 1994). We conclude that  common input, responsible for creating peaks on the order of ten  milliseconds wide in the spike train cross-correlograms (CCGs),  is also responsible for creating the correlation in spike count observed at the two second time scale of the trial. We argue that  both common excitation and inhibition may play significant roles  in establishing this correlation.
While it is generally agreed that neurons transmit information  about their synaptic inputs through spike trains, the code by which  this information is transmitted is not well understood. An upper  bound on the information encoded is obtained by hypothesizing  that the precise timing of each spike conveys information. Here we  develop a general approach to quantifying the information carried  by spike trains under this hypothesis, and apply it to the leaky  integrate-and-fire (IF) model of neuronal dynamics. We formulate the problem in terms of the probability distribution p(T) of  interspike intervals (ISis), assuming that spikes are detected with  arbitrary but finite temporal resolution. In the absence of added  noise, all the variability in the ISis could encode information, and  the information rate is simply the entropy of the ISI distribution,  H(T) = (-p(T)log2p(T)) , times the spike rate. H(T) thus provides an exact expression for the information rate. The methods  developed here can be used to determine experimentally the information carried by spike trains, even when the lower bound of the  information rate provided by the stimulus reconstruction method  is not tight. In a preliminary series of experiments, we have used  these methods to estimate information rates of hippocampal neurons in slice in response to somatic current injection. These pilot  experiments suggest information rates as high as 6.3 bits/spike.
Topographic maps in primary areas of mammalian cerebral cortex reorganise as a result of behavioural training. The nature of this reorganisation seems consistent with the behaviour of competitive neural networks, as has been demonstrated in the past by computer simulation.  We model tactile training on the hand representation in primate somatosensory cortex, using the Neural Field Theory of Amari and his colleagues. Expressions for changes in both receptive field size and magnification factor are derived, which are consistent with owl monkey experiments and make a prediction which goes beyond them.
The vestibulo-ocular reflex (VOR) stabilizes images on the retina during rapid  head motions. The gain of the VOR (the ratio of eye to head rotation velocity)  is typically around -1 when the eyes are focused on a distant target. However, to  stabilize images accurately, the VOR gain must vary with context (eye position,  eye vergerice and head translation). We first describe a kinematic model of the  VOR which relies solely on sensory information available from the semicircular  canals (head rotation), the otoliths (head translation), and neural correlates of eye  position and vergerice angle. We then propose a dynamical model and compare it  to the eye velocity responses measured in monkeys. The dynamical model reproduces the observed amplitude and time course of the modulation of the VOR and  suggests one way to combine the required neural signals within the cerebellum and  the brain stem. It also makes predictions for the responses of neurons to multiple  inputs (head rotation and translation, eye position, etc.) in the oculomotor system.
An extended version of the dual constraint model of motor endplate morphogenesis is presented that includes activity dependent  and independent competition. It is supported by a wide range of  recent neurophysiological evidence that indicates a strong relationship between synaptic efficacy and survival. The computational  model is justified at the molecular level and its predictions match  the developmental and regenerative behaviour of real synapses.
In the Poisson neuron model, the output is a rate-modulated Poisson process (Snyder and Miller, 1991); the time varying rate parameter r(t) is an instantaneous function G[.] of the stimulus,  r(t) G[s(t)]. In a Poisson neuron, then, r(t) gives the instantaneous firing rate--the instantaneous probability of firing at any  instant t--and the output is a stochastic function of the input. In  part because of its great simplicity, this model is widely used (usually with the addition of a refractory period), especially in in vivo  single unit electrophysiological studies, where s(t) is usually taken  to be the value of some sensory stimulus. In the integrate-and-fire  neuron model, by contrast, the output is a filtered and thresholded  function of the input: the input is passed through a low-pass filter  (determined by the membrane time constant v) and integrated until the membrane potential v(t) reaches threshold 0, at which point  v(t) is reset to its initial value. By contrast with the Poisson model,  in the integrate-and-fire model the ouput is a deterministic function  of the input. Although the integrate-and-fire model is a caricature  of real neural dynamics, it captures many of the qualitative features, and is often used as a starting point for conceptualizing the  biophysical behavior of single neurons. Here we show how a slightly  modified Poisson model can be derived from the integrate-and-fire  model with noisy inputs y(t) = s(t) + n(t). In the modified model,  the transfer function G[.] is a sigmoid (err) whose shape is determined by the noise variance a. Understanding the equivalence  between the dominant in vivo and in vitro simple neuron models  may help forge links between the two levels.  104 C.F. STEVENS, A. ZADOR
A .computational model of song learning in the song sparrow  (Melospiza melodia) learns to categorize the different syllables of  a song sparrow song and uses this categorization to train itself to  reproduce song. The model fills a crucial gap in the computational  explanation of birdsong learning by exploring the organization of  perception in songbirds. It shows how competitive learning may  lead to the organization of a specific nucleus in the bird brain,  replicates the song production results of a previous model (Doya  and Sejnowski, 1995), and demonstrates how perceptual learning  can guide production through reinforcement learning.
We analyse the geometry of eye rotations, and in particular  saccarles, using basic Lie group theory and differential geometry. Various parameterizations of rotations are related through  a unifying mathematical treatment, and transformations between  co-ordinate systems are computed using the Campbell-BakerHausdorff formula. Next, we describe Listing's law by means of  the Lie algebra so(3). This enables us to demonstrate a direct  connection to Dontiers' law, by showing that eye orientations are  restricted to the quotient space S0(3)/S0(2). The latter is equivalent to the sphere $2, which is exactly the space of gaze directions.  Our analysis provides a mathematical framework for studying the  oculomotor system and could also be extended to investigate the  geometry of multi-joint arm movements.
Binaural coincidence detection is essential for the localization of  external sounds and requires auditory signal processing with high  temporal precision. We present an integrate-and-fire model of spike  processing in the auditory pathway of the barn owl. It is shown that  a temporal precision in the microsecond range can be achieved with  neuronal time constants which are at least one magnitude longer.  An important feature of our model is an unsupervised Hebbian  learning rule which leads to a temporal fine tuning of the neuronal  connections.  *email: kempter,wgerst,lvh @ physik.tu-muenchen.de  Temporal Coding in the Submillisecond Range: Model of Barn Owl Auditory Pathway 125
Selective suppression of transmission at feedback synapses during  learning is proposed as a mechanism for combining associative feedback with self-organization of feedforward synapses. Experimental  data demonstrates cholinergic suppression of synaptic transmission in  layer I (feedback synapses), and a lack of suppression in layer IV (feedforward synapses). A network with this feature uses local rules to learn  mappings which are not linearly separable. During learning, sensory  stimuli and desired response are simultaneously presented as input.  Feedforward connections form self-organized representations of input,  while suppressed feedback connections leam the transpose of feedforward connectivity. During recall, suppression is removed, sensory input  activates the self-organized representation, and activity generates the  learned response.
We present a hypothesis about how the cerebellum could participate in regulating movement in the presence of significant feedback  delays without resorting to a forward model of the motor plant. We  show how a simplified cerebellar model can learn to control endpoint positioning of a nonlinear spring-mass system with realistic  delays in both afferent and efferent pathways. The model's operation involves prediction, but instead of predicting sensory input, it  directly regulates movement by reacting in an anticipatory fashion  to input patterns that include delayed sensory feedback.
Because of the distance between the skull and brain and their different resistivities, electroencephalographic (EEG) data collected from  any point on the human scalp includes activity generated within  a large brain area. This spatial smearing of EEG data by volume  conduction does not involve significant time delays, however, suggesting that the Independent Component Analysis (ICA) algorithm  of Bell and Sejnowski [1] is suitable for performing blind source separation on EEG data. The ICA algorithm separates the problem of  source identification from that of source localization. First results  of applying the ICA algorithm to EEG and event-related potential  (ERP) data collected during a sustained auditory detection task  show: (1) ICA training is insensitive to different random seeds. (2)  ICA may be used to segregate obvious artifactual EEG components  (line and muscle noise, eye movements) from other sources. (3) ICA  is capable of isolating overlapping EEG phenomena, including alpha and theta bursts and spatially-separable ERP components, to  separate ICA channels. (4) Nonstationarities in EEG and behavioral state can be tracked using ICA via changes in the amount of  residual correlation between ICA-filtered output channels.  146 S. MAKEIG, A. J. BELL, T.-P. JUNG, T. J. SEJNOWSKI
Several regions of the rat brain contain neurons known as head-direction cells, which encode the animal's directional heading during spatial  navigation. This paper presents a biophysical model of head-direction  cell activity, which suggests that a thalamocortical circuit might compute the rat's head direction by integrating the angular velocity of the  head over time. The model was implemented using the neural simulator  NEURON, and makes testable predictions about the structure and function of the rat head-direction circuit.
Despite the phylogenic and structural differences, the visual systems of different species, whether vertebrate or invertebrate, share  certain functional properties. The center-surround opponent receptive field (CSRF) mechanism represents one such example. Here,  analogous CSRFs are shown to be formed in an artificial neural  network which learns to localize contours (edges) of the luminance  difference. Furthermore, when the input pattern is corrupted by  a background noise, the CSRFs of the hidden units becomes shallower and broader with decrease of the signal-to-noise ratio (SNR).  The same kind of SNR-dependent plasticity is present in the CSRF  of real visual neurons; in bipolar cells of the carp retina as is shown  here experimentally, as well as in large monopolar cells of the fly  compound eye as was described by others. Also, analogous SNRdependent plasticity is shown to be present in the biphasic flash  responses (BPFR) of these artificial and biological visual systems.  Thus, the spatial (CSRF) and temporal (BPFR) filtering properties with which a wide variety of creatures see the world appear to  be optimized for detectability of changes in space and time.
In this paper the problem of learning appropriate domain-specific  bias is addressed. It is shown that this can be achieved by learning  many related tasks from the same domain, and a theorem is given  bounding the number tasks that must be learnt. A corollary of the  theorem is that if the tasks are known to possess a common internal representation or preprocessing then the number of examples  required per task for good generahsation when learning n tasks simultaneously scales like O(a + ), where O(a) is a bound on the  minimum number of examples requred to learn a single task, and  O(a + b) is a bound on the number of examples required to learn  each task independently. An experiment providing strong qualitative support for the theoretical results is reported.
A statistical theory for overtraining is proposed. The analysis  treats realizable stochastic neural networks, trained with KullbackLeibler loss in the asymptotic case. It is shown that the asymptotic  gain in the generalization error is small if we perform early stopping, even if we have access to the optimal stopping time. Considering cross-validation stopping we answer the question: In what ratio  the examples should be divided into training and testing sets in order to obtain the optimum performance. In the non-asymptotic  region cross-validated early stopping always decreases the generalization error. Our large scale simulations done on a CM5 are in  nice agreement with our analytical findings.
We analyze the performance of cross validation  in the context of model selection and complexity regularization. We work in a setting in which we must choose the right number of parameters for a hypothesis function in response to a finite training sample, with the goal of minimizing the resulting generalization error. There is a large and interesting literature on cross validation methods, which often emphasizes asymptotic statistical properties, or the exact calculation of the generalization error for simple models. Our approach here is somewhat different, and is primarily inspired by two sources. The first is the work of Barron and Cover [2], who introduced the idea of bounding the error of a model selection method (in their case, the Minimum Description Length Principle) in terms of a quantity known as the index of resolvability. The second is the work of Vapnik [5], who provided extremely powerful and general tools for uniformly bounding the deviations between training and generalization errors. 
We study the characteristics of learning with ensembles. Solving  exactly the simple model of an ensemble of linear students, we  find surprisingly rich behaviour. For learning in large ensembles,  it is advantageous to use under-regularized students, which actually over-fit the training data. Globally optimal performance can  be obtained by choosing the training set sizes of the students appropriately. For smaller ensembles, optimization of the ensemble  weights can yield significant improvements in ensemble generalization performance, in paxticulax if the individual students are subject to noise in the training process. Choosing students with a wide  range of regularization parameters makes this improvement robust  against changes in the unknown level of noise in the training data.
This paper shows that neural networks which use continuous activation functions have VC dimension at least as large as the square  of the number of weights w. This result settles a long-standing  open question, namely whether the well-known O(w log w) bound,  known for hard-threshold nets, also held for more general sigmoidal  nets. Implications for the number of samples needed for valid generalization are discussed.
Recurrent perceptron classifiers generalize the classical perceptron  model. They take into account those correlations and dependences  among input coordinates which arise from linear digital filtering.  This paper provides tight bounds on sample complexity associated  to the fitting of such models to experimental data.
It has remained unknown whether one can in principle carry out  reliable digital computations with networks of biologically realistic  models for neurons. This article presents rigorous constructions  for simulating in real-time arbitrary given boolean circuits and finite automata with arbitrarily high reliability by networks of noisy  spiking neurons.  In addition we show that with the help of "shunting inhibition"  even networks of very unreliable spiking neurons can simulate in  real-time any McCulloch-Pitts neuron (or "threshold gate"), and  therefore any multilayer perceptron (or "threshold circuit") in a  reliable manner. These constructions provide a possible explanation for the fact that biological neural systems can carry out quite  complex computations witlfin 100 msec.  It turns out that the assumption that these constructions require  about the shape of the EPSP's and the behaviour of the noise are  surprisingly weak.
In this paper we examine a perceptron learning task. The task is  realizable since it is provided by another perceptron with identical architecture. Both perceptrons have nonlinear sigmoid output  functions. The gain of the output function determines the level of  nonlinearity of the learning task. It is observed that a high level  of nonlinearity leads to overfitting. We give an explanation for this  rather surprising observation and develop a method to avoid the  overfitting. This method has two possible interpretations, one is  learning with noise, the other cross-validated early stopping.
A stability criterion for dynamic parameter adaptation is given. In  the case of the learning rate of backpropagation, a class of stable  algorithms is presented and studied, including a convergence proof.
A new nearest-neighbor method is described for estimating the Bayes risk  of a multiclass pattern classification problem from sample data (e.g., a  classified training set). Although it is assumed that the classification problem can be accurately described by sufficiently smooth class-conditional  distributions, neither these distributions, nor the corresponding prior probabilities of the classes are required. Thus this method can be applied to  practical problems where the underlying probabilities are not known. This  method is illustrated using two different pattern recognition problems.
In this paper, recursive estimation algorithms for dynamic modular  networks are developed. The models are ba.sed on Gaussian RBF  networks and the gating network is considered in two stages: At  first, it is simply a time-varying scalar and in the second, it is  based on the state, as in the mixture of local experts scheme. The  resulting algorithm uses Kalman filter estimation for the model  estimation and the gating probability estimation. Both, 'hard' and  'soft' competition based estimation schemes are developed where in  the former, the most probable network is adapted and in the latter  all networks are adapted by appropriate weighting of the data.
Linear threshold elements are the basic building blocks of artificial  neural networks. A linear threshold element computes a function  that is a sign of a weighted sum of the input variables. The weights  are arbitrary integers; actually, they can be very big integers-exponential in the number of the input variables. However, in  practice, it is difficult to implement big weights. In the present  literature a distinction is made between the two extreme cases:  linear threshold functions with polynomial-size weights as opposed  to those with exponential-size weights. The main contribution of  this paper is to fill up the gap by further refining that separation.  Namely, we prove that the class of linear threshold functions with  polynomial-size weights can be divided into subclasses according  to the degree of the polynomial. In fact, we prove a more general  result--that there exists a minimal weight linear threshold function  for any arbitrary number of inputs and any weight size. To prove  those results we have developed a novel technique for constructing  linear threshold functions with minimal weights.
Modern Analytic Techniques to Solve the  Dynamics of Recurrent Neural Networks  A.C.C. Coolen  Dept. of Mathematics  King's College London  Strand, London WC2R 2LS, U.K.  S.N. Laughton  Dept. of Physics Theoretical Physics  University of Oxford
The Fourier transform of boolean functions has come to play an  important role in proving many important learnability results. We  aim to demonstrate that the Fourier transform techniques are also  a useful and practical algorithm in addition to being a powerful  theoretical tool. We describe the more prominent changes we have  introduced to the algorithm, ones that were crucial and without  which the performance of the algorithm would severely deteriorate. One of the benefits we present is the confidence level for each  prediction which measures the likelihood the prediction is correct.
We propose a way of using boolean circuits to perform real valued  computation in a way that naturally extends their boolean functionahty. The functionahty of multiple fan in threshold gates in  this model is shown to mimic that of a hardware implementation  of continuous Neural Networks. A Vapnik-Chervonenkis dimension  and sample size analysis for the systems is performed giving best  known sample sizes for a real valued Neural Network. Experimental results confirm the conclusion that the sample sizes required for  the networks are significantly smaller than for sigmoidal networks.
The process of machine learning can be considered in two stages: model  selection and parameter estimation. In this paper a technique is presented  for constructing dynamical systems with desired qualitative properties. The  approach is based on the fact that an rt-dimensional nonlinear dynamical  system can be decomposed into one gradient and (rt 1) Hamiltonian systems. Thus, the model selection stage consists of choosing the gradient and  Hamiltonian portions appropriately so that a certain behavior is obtainable.  To estimate the parameters, a stably convergent learning rule is presented.  This algorithm has been proven to converge to the desired system trajectory  for all initial conditions and system inputs. This technique can be used to  design neural network models which are guaranteed to solve the trajectory  learning problem.
Recent experiments show that the neural codes at work in a wide  range of creatures share some common features. At first sight, these  observations seem unrelated. However, we show that these features  arise naturally in a linear filtered threshold crossing (LFTC) model  when we set the threshold to maximize the transmitted information.  This maximization process requires neural adaptation to not only  the DC signal level, as in conventional light and dark adaptation,  but also to the statistical structure of the signal and noise distributions. We also present a new approach for calculating the mutual  information between a neuron's output spike train and any aspect  of its input signal which does not require reconstruction of the input signal. This formulation is valid provided the correlations in  the spike train are small, and we provide a procedure for checking  this assumption. This paper is based on joint work (DeWeese [1],  1995). Preliminary results from the LFTC model appeared in a  previous proceedings (DeWeese [2], 1995), and the conclusions we  reached at that time have been reaffirmed by further analysis of the  model.
We present a statistical method that exactly learns the class of  constant depth /-perceptron networks with weights taken from  f-l, 0 q1) and arbitrary thresholds when the distribution that  generates the input examples is member of the family of product  distributions. These networks (also known as nonoverlapping perceptron networks or read-once formulas over a weighted threshold  basis) are loop-free neural nets in which each node has only one  outgoing weighl{. With arbitrary high probability, the learner is  able to exactly identify the connectivity (or skeleton) of the target  /-perceptron network by using a new statistical test which exploits  the strong unimodality property of sums of independent random  variables.
We propose an active learning method with hidden-unit reduction,  which is devised specially for multilayer perceptrons (MLP). First,  we review our active learning method, and point out that many  Fisher-information-based methods applied to MLP have a critical  problem: the information matrix may be singular. To solve this  problem, we derive the singularity condition of an information mat fix, and propose an active learning technique that is applicable to  MLP. Its effectiveness is verified through experiments.
We consider the problem of on-line gradient descent learning for  general two-layer neural networks. An analytic solution is presented and used to investigate the role of the learning rate in controlling the evolution and convergence of the learning process.  Learning in layered neural networks refers to the modification of internal parameters  {J} which specify the strength of the interneuron couplings, so as to bring the map  fj implemented by the network as close as possible to a desired map f. The  degree of success is monitored_through the generalization error, a measure of the  dissimilarity between fj and f.  Consider maps from an N-dimensional input space  onto a scalar (, as arise in  the formulation of classification and regression tasks. Two-layer networks with an  arbitrary number of hidden units have been shown to be universal approximators  [1] for such N-to-one dimensional maps. Information about the desired map f is  provided through independent examples (,(), with ( = f() for all/. The  examples are used to train a student network with N input units, K hidden units,  and a single linear output unit; the target map f is defined through a teacher  network of similar architecture except for the number M of hidden units. We  investigate the emergence of generalization ability in an on-line learning scenario  [2], in which the couplings are modified after the presentation of each example so  as to minimize the corresponding error. The resulting changes in {J} are described  as a dynamical evolution; the number of examples plays the role of time.  In this paper we limit our discussion to the case of the soft-committee machine  [2], in which all the hidden units are connected to the output unit with positive  couplings of unit strength, and only the input-to-hidden couplings are adaptive.  * D.Saad@aston.ac.uk  /On leave from AT&T Bell Laboratories, Holmdel, NJ 07733, USA  Dynamics of On-line Gradient Descent Learning for Multilayer Neural Networks 303  Consider the student network: hidden unit i receives information from input unit  r through the weight Jir, and its activation under presentation of an input pattern   = ((,...,(N) is zi = Ji' , with Ji: (Jii,..., Jilv) defined as the vector of  incoming weights onto the i-th hidden unit. The output of the student network is  cr(J,) = -/K=l g (ji. ), where g is the activation function of the hidden units,  taken here to be the error function g(z) -erf(z/v), and J _= {Ji}i<i<K is the set  of input-to-hidden adaptive weights.  Training examples are of the form (, (). The components of the independently  drawn input vectors  are uncorrelated random variables with zero mean and  unit variance. The corresponding output ( is given by a deterministic teacher  whose internal structure is the same as for the student network but may differ in  the number of hidden units. Hidden unit n in the teacher network receives input  information through the weight vector B, = (B, 1,..., B,y), and its activation  under presentation of the input pattern  is y = B, ß . The corresponding  output is ( = -,M__l  (B,. ). We will use indices i,j,k,l... to refer to units  in the student network, and n, m,... for units in the teacher network.  The error made by a student with weights J on a given input  is given by the  quadratic deviation  1 ]2 1 [ K M] 2  e(a,)_-[cr(a,)-( =  yg(xi)-yg(y,) (1)  i=1 n=l  Performance on a typical input defines the generalization error ca(J ) -< e(J,) >{e) through an average over all possible input vectors , to be performed implicitly through averages over the activations x = (x,..., x:) and  Y = (Y,..., YM). Note that both < xi >=< y >= 0; second order correlations are  given by the overlaps among the weight vectors associated with the various hidden  units: < xi xk > = Ji ß Jk ---Qik, < xi Yn > = Ji ' Bn ---lrin, and < y, y, > =  B ß B. -T,. Averages over x and y are performed using the resulting multivariate Gaussian probability distribution, and yield an expression for the generalization  error in terms of the parameters Qi, Rir, and Tm [3]. For g(x) -_erf(x/v) the  result is:  eg(J) = 1 {/ arcsin Qi Trm  7 v/1 qQii x/1 + Q +  arcsin 41 + T x/1 +  nm  -2 y arcsin v/1 + Qii x/1 + T,, ' (2)  in  The parameters T, are characteristic of the task to be learned and remain fixed.  The overlaps Qit: and ]in, which characterize the correlations among the various  student units and their degree of specialization towards the implementation of the  desired task, are determined by the student weights J and evolve during training.  A gradient descent rule for the update of the student weights results in J'+ =  J' + ½ ' , where the learning rate r/has been scaled with the input size N, and  r--1  is defined in terms of both the activation function g and its derivative gr. The time  evolution of the overlaps ]in and Qit: can be explicitly written in terms of similar  304 D. SAAD, S. A. SOLLA  difference equations. In the large N limit the normalized number of examples   =/tin can be interpreted as a continuous time variable, leading to the equations  of motion  dRin  = r/<Si y >{} ,  da  dQi  = r/< 5i xk >{} +r/< 5k xi >{} +r/2 < 5 5 >{} , (4)  da  to be averaged over all possible ways in which an example can be chosen at a given  time step. The dependence on the current input  is only through the activations  x and y; the corresponding averages can be performed analytically for g(x) =  erf(x/v), resulting in a set of coupled first-order differential equations [3]. These  dynamical equations are exact, and provide a novel tool used here to analyze the  learning process for a general soft-committee machine with an arbitrary number K  of hidden units, trained to implement a task defined through a teacher of similar  architecture except for the number M of hidden units. In what follows we focus on  uncorrelated teacher vectors of unit length, T, =  The time evolution of the overlaps tiin and Qit follows from integrating the equations of motion (4) from initial conditions determined by a random initialization of  the student vectors {Ji}l<i<K. Random initial norms Qii for the student vectors  are taken here from a uniform distribution in the [0, 0.5] interval. Overlaps Qit  between independently chosen student vectors Ji and J, or tiin between Ji and  an unknown teacher vector B are small numbers, of order 1/v/-ff for N >> K, M,  and taken here from a uniform distribution in the [0, 10 -2] interval.  We show in Fig. la-c the evolution of the overlaps and generalization error for a  realizable case: K = M = 3 and r/ = 0.1. This example illustrates the successive regimes of the learning process. The system quickly evolves into a symmetric  subspace controlled by an unstable suboptimal solution which exhibits no differentiation among the various student hidden units. Trapping in the symmetric subspace  prevents the specialization needed to achieve the optimal solution, and the generalization error remains finite, as shown by the plateau in Fig. lc. The symmetric  solution is unstable, and the perturbation introduced through the random initialization of the overlaps tiin eventually takes over: the student units become specialized  and the matrix R of student-teacher overlaps tends towards the matrix T, except  for a permutational symmetry associated with the arbitrary labeling of the student  hidden units. The generalization error plateau is followed by a monotonic decrease  towards zero once the specialization begins and the system evolves towards the  optimal solution. The evolution of the overlaps and generalization error for the unrealizable case K < M is characterized by qualitatively similar stages, except that  the asymptotic behavior is controlled by a suboptimal solution which reflects the  differences between student and teacher architectures.  Curves for the time evolution of the generalization error for different values of  shown in Fig. ld for K = M -3 identify trapping in the symmetric subspace  as a small r/ phenomenon. We therefore consider the equations of motion (4) in  the small r/ regime. The term proportional to r/2 is neglected and the resulting  truncated equations of motion are used to investigate a phase characterized by  students of similar norms: Qii Q for all 1 _< i _< K, similar correlations among  themselves: Qik -C for all i - k, and similar correlations with the teacher vectors:  Rin / for all 1 < i < K, 1 _< n _< M. The resulting dynamical equations exhibit  a fixed point solution at  Q* = C* M M K 2 + x/K 4 K  = K 2 2M-1 and R*= (5)  Dynamics of On-line Gradient Descent Learning for Multilayer Neural Networks 305  (a)  0.8-- 0.60.4o.o/  I I  0 2000 4000  6000 8000  (b)  0.8'  0.60.40.20.0  0  I I  2000 4000 6000  8000  (c)  (d)  0.080.060.040.020.0  0
We analyze and compare the well-known Gradient Descent algorithm and a new algorithm, called the Exponentiated Gradient  algorithm, for training a single neuron with an arbitrary transfer  function. Both algorithms are easily generalized to larger neural  networks, and the generalization of Gradient Descent is the standard back-propagation algorithm. In this paper we prove worstcase loss bounds for both algorithms in the single neuron case.  Since local minima make it difficult to prove worst-case bounds  for gradient-based algorithms, we must use a loss function that  prevents the formation of spurious local minima. We define such  a matching loss function for any strictly increasing differentiable  transfer function and prove worst-case loss bound for any such  transfer function and its corresponding matching loss. For example, the matching loss for the identity function is the square loss  and the matching loss for the logistic sigmoid is the entropic loss.  The different structure of the bounds for the two algorithms indicates that the new algorithm out-performs Gradient Descent when  the inputs contain a large number of irrelevant components.  310 D.P. HELMBOLD, J. KIVINEN, M. K. WARMUTH
We show that for a single neuron with the logistic function as the transfer  function the number of local minima of the error function based on the  square loss can grow exponentially in the dimension.
An adaptive back-propagation algorithm is studied and compared  with gradient descent (standard back-propagation) for on-line  learning in two-layer neural networks with an arbitrary number  of hidden units. Within a statistical mechanics framework, both  numerical studies and a rigorous analysis show that the adaptive  back-propagation method results in faster training by breaking the  symmetry between hidden units more efficiently and by providing  faster convergence to optimal generalization than gradient descent.
"Topographic" mappings occur frequently in the brain. A popular approach to understanding the structure of such mappings  is to map points representing input features in a space of a few  dimensions to points in a 2 dimensional space using some selforganizing algorithm. We argue that a more general approach  may be useful where similarities between features are not constrained to be geometric distances, and the objective function for  topographic matching is chosen exphcitly rather than being specified implicitly by the self-organizing algorithm. We investigate  analytically an example of this more general approach applied to  the structure of interdigitated mappings, such as the pattern of  ocular dominance columns in primary visual cortex.
The dynamics of complex neural networks modelling the selforganization process in cortical maps must include the aspects of  long and short-term memory. The behaviour of the network is such  characterized by an equation of neural activity as a fast phenomenon and an equation of synaptic modification as a slow part of the  neural system. We present a quadratic-type Lyapunov function for  the flow of a competitive neural system with fast and slow dynamic  variables. We also show the consequences of the stability analysis  on the neural net parameters.
We examine the issue of evaluation of model specific parameters in a  modified VC-formalism. Two examples are analyzed: the 2-dimensional  homogeneous perceptron and the 1-dimensional higher order neuron.  Both models are solved theoretically, and their leaming curves are compared against true learning curves. It is shown that the formalism has  the potential to generate a variety of leaming curves, including ones  displaying "phase transitions."
We present a Bayesian framework for inferring the parameters of  a mixture of experts model based on ensemble learning by variational free energy minimisation. The Bayesian approach avoids the  over-fitting and noise level under-estimation problems of traditional  maximum likelihood inference. We demonstrate these methods on  artificial problems and sunspot time series prediction.
In this paper we consider probabilities of different asymptotics of  convergent unlearning algorithm for the Hopfield-type neural network (Plakhov & Semenov, 1994) treating the case of unbiased  random patterns. We show also that failed unlearning results in  total memory breakdown.
A theory of early stopping as applied to linear models is presented.  The backpropagation learning algorithm is modeled as gradient  descent in continuous time. Given a training set and a validation  set, all weight vectors found by early stopping must lie on a certain quadric surface, usually an ellipsoid. Given a training set and  a candidate early stopping weight vector, all validation sets have  least-squares weights lying on a certain plane. This latter fact can  be exploited to estimate the probability of stopping at any given  point along the trajectory from the initial weight vector to the leastsquares weights derived from the training set, and to estimate the  probability that training goes on indefinitely. The prospects for  extending this theory to nonlinear models are discussed.
For a given recurrent neural network, a discrete-time model may  have asymptotic dynamics different from the one of a related  continuous-time model. In this paper, we consider a discrete-time  model that discretizes the continuous-time leaky integrator model  and study its parallel and sequential dynamics for symmetric networks. We provide sufficient (and necessary in many cases) conditions for the discretized model to have the same cycle-free dynamics of the corresponding continuous-time model in symmetric  networks.
We introduce and analyze a mixture model for supervised learning of  probabilistic transducers. We devise an online learning algorithm that  efficiently infers the structure and estimates the parameters of each model  in the mixture. Theoretical analysis and comparative simulations indicate  that the learning algorithm tracks the best model from an arbitrarily large  (possibly infinite) pool of models. We also present an application of the  model for inducing a noun phrase recognizer.
In this paper, we introduce REMAP, an approach for the training  and estimation of posterior probabilities using a recursive algorithm  that is reminiscent of the EM-based Forward-Backward (Liporace  1982) algorithm for the estimation of sequence likelihoods. Although very general, the method is developed in the context of a  statistical model for transition-based speech recognition using Artificial Neural Networks (ANN) to generate probabilities for Hidden Markov Models (HMMs). In the new approach, we use local  conditional posterior probabilities of transitions to estimate global  posterior probabilities of word sequences. Although we still use  ANNs to estimate posterior probabilities, the network is trained  with targets that are themselves estimates of local posterior probabilities. An initial experimental result shows a significant decrease  in error-rate in comparison to a baseline system.
In this paper we propose recurrent neurM networks with feedback into the input  units for handling two types of data analysis problems. On the one hand, this  scheme can be used for static data when some of the input variables are missing.  On the other hand, it can also be used for sequential data, when some of the  input variables are missing or are available at different frequencies. Unlike in the  case of probabilistic models (e.g. Gaussian) of the missing variables, the network  does not attempt to model-the distribution of the missing variables given the  observed variables. Instead it is a more "discriminant" approach that fills in the  missing variables for the sole purpose of minimizing a learning criterion (e.g., to  minimize an output error).
"Family discovery" is the task of learning the dimension and structure of a parameterized family of stochastic models. It is especially appropriate when the training examples are partitioned into  "episodes" of samples drawn from a single parameter value. We  present three family discovery algorithms based on surface learning and show that they significantly improve performance over two  alternatives on a parameterized classification task.
Nearest neighbor classification expects the class conditional probabilities to be locally constant, and suffers from bias in high dimensions We propose a locally adaptive form of nearest neighbor  classification to try to finesse this curse of dimensionality. We use  a local linear discriminant analysis to estimate an effective metric for computing neighborhoods. We determine the local decision  boundaries from centroid information, and then shrink neighborhoods in directions orthogonal to these local decision boundaries,  and elongate them parallel to the boundaries. Thereafter, any  neighborhood-based classifier can be employed, using the modified  neighborhoods. We also propose a method for global dimension  reduction, that combines local dimension information. We indicate  how these techniques can be extended to the regression problem.
A new approach for clustering is proposed. This method is based  on an analogy to a physical model; the ferromagnetic Potts model  at thermal equilibrium is used as an analog computer for this hard  optimization problem. We do not assume any structure of the underlying distribution of the data. Phase space of the Potts model is  divided into three regions; ferromagnetic, super-paramagnetic and  paramagnetic phases. The region of interest is that corresponding  to the super-paramagnetic one, where domains of aligned spins appear. The range of temperatures where these structures are stable  is indicated by a non-vanishing magnetic susceptibility. We use a  very efficient Monte Carlo algorithm to measure the susceptibility and the spin spin correlation function. The values of the spin  spin correlation function, at the super-paramagnetic phase, serve  to identify the partition of the data points into clusters.  Many natural phenomena can be viewed as optimization processes, and the drive to  understand and analyze them yielded powerful mathematical methods. Thus when  wishing to solve a hard optimization problem, it may be advantageous to apply these  methods through a physical analogy. Indeed, recently techniques from statistical  physics have been adapted for solving hard optimization problems (see e.g. Yuille  and Kosowsky, 1994). In this work we formulate the problem of clustering in terms  of a ferromagnetic Potts spin model. Using the Monte Carlo method we estimate  physical quantities such as the spin spin correlation function and the susceptibility,  and deduce from them the number of clusters and cluster sizes.  Cluster analysis is an important technique in exploratory data analysis and is applied in a variety of engineering and scientific disciplines. The problem of partitional  clustering can be formally stated as follows. With every one of i = 1, 2,...N patterns represented as a point i in a d-dimensional metric space, determine the  partition of these N points into M groups, called clusters, such that points in a  cluster are more similar to each other than to points in different clusters. The value  of M also has to be determined.  Clustering Data through an Analogy to the Potts Model 417  The two main approaches to partitional clustering are called parametric and nonparametric. In parametric approaches some knowledge of the clusters' structure is  assumed (e.g. each cluster can be represented by a center and a spread around  it). This assumption is incorporated in a global criterion. The goal is to assign the  data points so that the criterion is minimized. A typical example is variance minimization (Rose, Gurewitz, and Fox, 1993). On the other hand, in non-parametric  approaches a local criterion is used to build clusters by utilizing local structure of  the data. For example, clusters can be formed by identifying high-density regions  in the data space or by assigning a point and its K-nearest neighbors to the same  cluster. In recent years many parametric partitional clustering algorithms rooted  in statistical physics were presented (see e.g. Buhmann and Kiihnel , 1993). In the  present work we use methods of statistical physics in non-parametric clustering.  Our aim is to use a physical problem as an analog to the clustering problem. The  notion of clusters comes very naturally in Potts spin models (Wang and Swendsen,  1990) where clusters are closely related to ordered regions of spins. We place a Potts  spin variable si at each point ai (that represents one of the patterns), and introduce  a short range ferromagnetic interaction Jij between pairs of spins, whose strength  decreases as the inter-spin distance [[aiaj [[ increases. The system is governed by  the Hamiltonian (energy function)  =  <i,j>  where the notation < i, j > stands for neighboring points i and j in a sense that is  defined later. Then we study the ordering properties of this inhomogeneous Potts  model.  As a concrete example, place a Potts spin at each of the data points of fig. 1.  3  2  1  0  -1  -2  Figure 1: This data set is made of three rectangles, each consisting of 800 points  uniformly distributed, and a uniform rectangular background of lower density, also  consisting of 800 points. Points classified (with Tcus = 0.08 and  = 0.5) as  belonging to the three largest clusters are marked by crosses, squares and x's. The  fourth cluster is of size 2 and all others are single point clusters marked by triangles.  At high temperatures the system is in a disordered (paramagnetic) phase. As  the temperature is lowered, larger and larger regions of high density of points (or  spins) exhibit local ordering, until a phase transition occurs and spins in the three  rectangular high density regions become completely aligned (i.e. within each region  all si take the same value super-paramagnetic phase).  The aligned regions define the clusters which we wish to identify. As the temperature  418 M. BLATT, S. WISEMAN, E. DOMANY  is further lowered, a pseudo-transition occurs and the system becomes completely  ordered (ferromagnetic).
We propose a new learning method, "Generalized Learning Vector Quantization (GLVQ)," in which reference vectors are updated  based on the steepest descent method in order to minimize the cost  function. The cost function is deternfined so that the obtained  learning rule satisfies the convergence condition. We prove that  Kohonen's rule as used in LVQ does not satisfy the convergence  condition and thus degrades recognition ability. Experimental results for printed Chinese character recognition reveal that GLVQ  is superior to LVQ in recognition ability.
We investigate the effectiveness of stochastic hillclimbing as a baseline for  evaluating the performance of genetic algorithms (GAs) as combinatorial function optimizers. In particular, we address two problems to which  GAs have been applied in the literature: Koza's 11-multiplexer problem  and the jobshop problem. We demonstrate that simple stochastic hillclimbing methods are able to achieve results comparable or superior to  those obtained by the GAs designed to address these two problems. We  further illustrate, in the case of the jobshop problem, how insights obtained in the formulation of a stochastic hillclimbing algorithm can lead  to improvements in the encoding used by a GA.
Statistically independent features can be extracted by finding a factorial representation of a signal distribution. Principal Component  Analysis (PCA) accomplishes this for linear correlated and Gaussian distributed signals. Independent Component Analysis (ICA),  formalized by Comon (1994), extracts features in the case of linear statistical dependent but not necessarily Gaussian distributed  signals. Nonlinear Component Analysis finally should find a factorial representation for nonlinear statistical dependent distributed  signals. This paper proposes for this task a novel feed-forward,  information conserving, nonlinear map the explicit symplectic  transformations. It also solves the problem of non-Gaussian output  distributions by considering single coordinate higher order statistics.
A Bayesian-Kullback learning scheme, called Ying-Yang Machine, is proposed based on the two complement but equivalent Bayesian representations for joint density and their Kullback divergence. Not only the scheme unifies existing major supervised and unsupervised learnings, including the classical maximum likelihood or least square learning, the maximum information preservation, the EM &em algorithm and information geometry, the recent popular Helmholtz machine, as well as other learning methods with new variants and new results; but also the scheme provides a number of new learning models. 
Natural and artificial neural circuits must be capable of traversing specific state space trajectories. A natural approach to this  problem is to learn the relevant trajectories from examples. Unfortunately, gradient descent learning of complex trajectories in  amorphous networks is unsuccessful. We suggest a possible approach where trajectories are realized by combining simple oscillators, in various modular ways. We contrast two regimes of fast  and slow oscillations. In all cases, we show that banks of oscillators  with bounded frequencies have universal approximation properties.  Open questions are also discussed briefly.
We derive a smoothing regularizer for recurrent network models by  requiring robustness in prediction performance to perturbations of  the training data. The regularizer can be viewed as a generalization of the first order Tikhonov stabilizer to dynamic models. The  closed-form expression of the regularizer covers both time-lagged  and simultaneous recurrent nets, with feedforward nets and onelayer linear nets as special cases. We have successfully tested this  regularizer in a number of case studies and found that it performs  better than standard quadratic weight decay.
There is currently considerable interest in developing general nonlinear density models based on latent, or hidden, variables. Such  models have the ability to discover the presence of a relatively small  number of underlying 'causes' which, acting in combination, give  rise to the apparent complexity of the observed data set. Unfortunately, to train such models generally requires large computational  effort. In this paper we introduce a novel latent variable algorithm  which retains the general non-linear capabilities of previous models  but which uses a training procedure based on the EM algorithm.  We demonstrate the performance of the model on a toy problem  and on data from flow diagnostics for a multi-phase oil pipeline.
We present a framework for learning in hidden Markov models with  distributed state representations. Within this framework, we derive a learning algorithm based on the Expectation-Maximization  (EM) procedure for maximum likelihood estimation. Analogous to  the standard Baum-Welch update rules, the M-step of our algorithm is exact and can be solved analytically. However, due to the  combinatorial nature of the hidden state representation, the exact  E-step is intractable. A simple and tractable mean field approximation is derived. Empirical results on a set of problems suggest that  both the mean field approximation and Gibbs sampling are viable  alternatives to the computationally expensive exact algorithm.
A new boosting algorithm of Freund and Schapire is used to improve  the performance of decision trees which are constructed using the  information ratio criterion of Quinlan's C4.5 algorithm. This boosting  algorithm iteratively constructs a series of decision trees, each decision  tree being trained and pruned on examples that have been filtered by  previously trained trees. Examples that have been incorrectly classified  by the previous trees in the ensemble are resampled with higher  probability to give a new probability distribution for the next tree in the  ensemble to train on. Results from optical character recognition  (OCR), and knowledge discovery and data mining problems show that  in comparison to single trees, or to trees trained independently, or to  trees trained on subsets of the feature space, the boosting ensemble is  much better.
We develop a refined mean field approximation for inference and  learning in probabilistic neural networks. Our mean field theory,  unlike most, does not assume that the units behave as independent  degrees of freedom; instead, it exploits in a principled way the  existence of large substructures that are computationally tractable.  To illustrate the advantages of this framework, we show how to  incorporate weak higher order interactions into a first-order hidden  Markov model, treating the corrections (but not the first order  structure) within mean field theory.
We have already shown that extracting long-term dependencies from sequential data is difficult, both for deterministic dynamical systems such  as recurrent networks, and probabilistic models such as hidden Markov  models (HMMs) or input/output hidden Markov models (IOHMMs). In  practice, to avoid this problem, researchers have used domain specific  a-priori knowledge to give meaning to the hidden or state variables representing past context. In this paper, we propose to use a more general  type of a-priori knowledge, namely that the temporal dependencies are  structured hierarchically. This implies that long-term dependencies are  represented by variables with a long time scale. This principle is applied  to a recurrent network which includes delays and multiple time scales. Experiments confirm the advantages of such structures. A similar approach  is proposed for HMMs and IOHMMs.
We study Bayesian networks for continuous variables using nonlinear conditional density estimators. We demonstrate that useful structures can be extracted from a data set in a self-organized  way and we present sampling techniques for belief update based on  Markov blanket conditional density models.
Conventional binary classification trees such as CART either split  the data using axis-aligned hyperplanes or they perform a computationally expensive search in the continuous space of hyperplanes  with unrestricted orientations. We show that the limitations of the  former can be overcome without resorting to the latter. For every  pair of training data-points, there is one hyperplane that is orthogonal to the line joining the data-points and bisects this line. Such  hyperplanes are plausible candidates for splits. In a comparison  on a suite of 12 datasets we found that this method of generating  candidate splits outperformed the standard methods, particularly  when the training sets were small.
The Bayesian analysis of neural networks is difficult because a simple prior over weights implies a complex prior distribution over  functions. In this paper we investigate the use of Gaussian process  priors over functions, which permit the predictive Bayesian analysis for fixed values of hyperparameters to be carried out exactly  using matrix operations. Two methods, using optimization and averaging (via Hybrid Monte Carlo) over hyperparameters have been  tested on a number of challenging problems and have produced  excellent results.
The purpose of most architecture optimization schemes is to improve generalization. In this presentation we suggest to estimate  the weight saliency as the associated change in generalization error  if the weight is pruned. We detail the implementation of both an  O(N)-storage scheme extending OBD, as well as an O(N 2) scheme  extending OBS. We illustrate the viability of the approach on prediction of a chaotic time series.
Sigmoid type belief networks, a class of probabilistic neural networks, provide a natural framework for compactly representing  probabilistic information in a variety of unsupervised and supervised learning problems. Often the parameters used in these networks need to be learned from examples. Unfortunately, estimating the parameters via exact probabilistic calculations (i.e, the  EM-algorithm) is intractable even for networks with fairly small  numbers of hidden units. We propose to avoid the infeasibility of  the E step by bounding likelihoods instead of computing them exactly. We introduce extended and complementary representations  for these networks and show that the estimation of the network  parameters can be made fast (reduced to quadratic optimization)  by performing the estimation in either of the alternative domains.  The complementary networks can be used for continuous density  estimation as well.
Neural-network ensembles have been shown to be very accurate  classification techniques. Previous work has shown that an effective ensemble should consist of networks that are not only highly  correct, but ones that make their errors on different parts of the  input space as well. Most existing techniques, however, only indirectly address the problem of creating such a set of networks.  In this paper we present a technique called ADDEMUP that uses  genetic algorithms to directly search for an accurate and diverse  set of trained networks. ADDEMUP works by first creating an initial population, then uses genetic operators to continually create  new networks, keeping the set of networks that are as accurate as  possible while disagreeing with each other as much as possible. Experiments on three DNA problems show that ADDEMUP is able to  generate a set of trained networks that is more accurate than several existing approaches. Experiments also show that ADDEMUP  is able to effectively incorporate prior knowledge, if available, to  improve the quality of its ensemble.
We compare two regularization methods which can be used to improve the generalization capabilities of Gaussian mixture density  estimates. The first method uses a Bayesian prior on the parameter space. We derive EM (Expectation Maximization) update rules  which maximize the a posterior parameter probability. In the second approach we apply ensemble averaging to density estimation.  This includes Breiman's "bagging", which recently has been found  to produce impressive results for classification networks.
Following Shrager and Johnson (1995) we study growth of logical function complexity in a network swept by two overlapping  waves: one of pruning, and the other of Hebbian reinforcement of  connections. Results indicate a significant spatial gradient in the  appearance of both linearly separable and non linearly separable  functions of the two inputs of the network; the n.l.s. cells are much  sparser and their slope of appearance is sensitive to parameters in  a highly non-linear way.
Recently, several researchers have reported encouraging experimental results when using Gaussian or bump-like activation functions in multilayer  percepttons. Networks of this type usually require fewer hidden layers  and units and often learn much faster than typical sigmoidal networks.  To explain these results we consider a hyper-ridge network, which is a  simple perceptron with no hidden units and a rid e activation function If  g ß  we are interested in partitioningp points in d dimensions into two classes  then in the limit as d approaches infinity the capacity of a hyper-ridge and  a perceptton is identical. However, we show that for p >> d, which is the  usual case in practice, the ratio of hyper-ridge to perceptron dichotomies  approaches p/2(d + 1).
Backpropagation learning algorithms typically collapse the network's  structure into a single vector of weight parameters to be optimized. We  suggest that their performance may be improved by utilizing the structural information instead of discarding it, and introduce a framework for  "tempering" each weight accordingly.  In the tempering model, activation and error signals are treated as approximately independent random variables. The characteristic scale of weight  changes is then matched to that of the residuals, allowing structural properties such as a node's fan-in and fan-out to affect the local learning rate  and backpropagated error. The model also permits calculation of an upper  bound on the global learning rate for batch updates, which in turn leads  to different update rules for bias rs. non-bias weights.  This approach yields hitherto unparalleled performance on the family relations benchmark, a deep multi-layer network: for both batch learning  with momentum and the delta-bar-delta algorithm, convergence at the  optimal learning rate is sped up by more than an order of magnitude.
We propose a hierarchical scheme for rapid learning of context dependent  "skills" that is based on the recently introduced "Parameterized SelfOrganizing Map" ("PSOM"). The underlying idea is to first invest some  learning effort to specialize the system into a rapid learner for a more  restricted range of contexts.  The specialization is carried out by a prior "investment learning stage",  during which the system acquires a set of basis mappings or "skills" for  a set of prototypical contexts. Adaptation of a "skill" to a new context  can then be achieved by interpolating in the space of the basis mappings  and thus can be extremely rapid.  We demonstrate the potential of this approach for the task of a 3D visuomotor map for a Puma robot and two cameras. This includes the forward and backward robot kinematics in 3D end effector coordinates, the  2D+2D retina coordinates and also the 6D joint angles. After the investment phase the transformation can be learned for a new camera set-up  with a single observation.
It has recently been shown that gradient descent learning algorithms for recurrent neural networks can perform poorly on tasks  that involve long-term dependencies. In this paper we explore  this problem for a class of architectures called NARX networks,  which have powerful representational capabilities. Previous work  reported that gradient descent learning is more effective in .NARX  networks than in recurrent networks with "hidden states". We  show that although NARX networks do not circumvent the problem of long-term dependencies, they can greatly improve performance on such problems. We present some experimental 'results  that show that NARX networks can often retain information for  two to three times as long as conventional recurrent networks.
We present two additions to the hierarchical mixture of experts  (HME) architecture. By applying a likelihood splitting criteria to  each expert in the HME we "grow" the tree adaptively during training. Secondly, by considering only the most probable path through  the tree we may "prune" branches away, either temporarily, or permanently if they become redundant. We demonstrate results for  the growing and path pruning algorithms which show significant  speed ups and more efficient use of parameters over the standard  fixed structure in discriminating between two interlocking spirals  and classifying 8-bit parity patterns.
A new learning algorithm is developed for the design of statistical  classifiers minimizing the rate of misclassification. The method,  which is based on ideas from information theory and analogies to  statistical physics, assigns data to classes in probability. The distributions are chosen to minimize the expected classification error  while simultaneously enforcing the classifier's structure and a level  of "randomness" measured by Shannon's entropy. Achievement of  the classifier structure is quantified by an associated cost. The constrained optimization problem is equivalent to the minimization of  a Helmholtz free energy, and the resulting optimization method  is a basic extension of the deterministic annealing algorithm that  explicitly enforces structural constraints on assignments while reducing the entropy and expected cost with temperature. In the  limit of low temperature, the error rate is minimized directly and a  hard classifier with the requisite structure is obtained. This learning algorithm can be used to design a variety of classifier structures.  The approach is compared with standard methods for radial basis  function design and is demonstrated to substantially outperform  other design methods on several benchmark examples, while often retaining design complexity comparable to, or only moderately  greater than that of strict descent-based methods.  592 D. MILLER, A. RAO, K. ROSE, A. GERSHO
A practical method for Bayesian training of feed-forward neural  networks using sophisticated Monte Carlo methods is presented  and evaluated. In reasonably small amounts of computer time this  approach outperforms other state-of-the-art methods on 5 datalimited tasks from real world domains.
We introduce a constructive, incremental learning system for regression  problems that models data by means of locally linear experts. In contrast  to other approaches, the experts are trained independently and do not  compete for data during learning. Only when a prediction for a query is  required do the experts cooperate by blending their individual predictions. Each expert is trained by minimizing a penalized local cross validation error using second order methods. In this way, an expert is able to  find a local distance metric by adjusting the size and shape of the receptive field in which its predictions are valid, and also to detect relevant input features by adjusting its bias on the importance of individual input  dimensions. We derive asymptotic results for our method. In a variety of  simulations the properties of the algorithm are demonstrated with respect  to interference, learning speed, prediction accuracy, feature detection,  and task oriented incremental learning.
This paper relates the computational power of Fahlman's Recurrent  Cascade Correlation (RCC) architecture to that of finite state automata  (FSA). While some recurrent networks are FSA equivalent, RCC is not.  The paper presents a theoretical analysis of the RCC architecture in the  form of a proof describing a large class of FSA which cannot be realized  by RCC.
We report on our development of a high-performance system for  neural network and other signal processing applications. We have  designed and implemented a vector microprocessor and packaged it as an attached processor for a conventional workstation.  We present performance comparisons with commercial workstations on neural network backpropagation training. The SPERT-II  system demonstrates significant speedups over extensively handoptimization code running on the workstations.
A new technique, termed softassign, is applied for the first time  to two classic combinatorial optimization problems, the traveling salesman problem and graph partitioning. Softassign, which  has emerged from the recurrent neural network/statistical physics  framework, enforces two-way (assignment) constraints without the  use of penalty terms in the energy functions. The softassign can  also be generalized from two-way winner-take-all constraints to  multiple membership constraints which are required for graph partitioning. The softassign technique is compared to the softmax  (Potts glass). Within the statistical physics framework, softmax  and a penalty term has been a widely used method for enforcing the  two-way constraints common within many combinatorial optimization problems. The benchmarks present evidence that softassign  has clear advantages in accuracy, speed, parallelizability and algorithmic simplicity over softmax and a penalty term in optimization  problems with two-way constraints.
We investigate the optimization of neural networks governed by  general objective functions. Practical formulations of such objectives are notoriously difficult to solve; a common problem is the  poor local extrema that result by any of the applied methods. In  this paper, a novel framework is introduced for the solution of largescale optimization problems. It assumes little about the objective  function and can be applied to general nonlinear, non-convex functions; objectives in thousand of variables are thus efficiently minimized by a combination of techniques deterministic annealing,  multiscale optimization, attention mechanisms and trust region optimization methods.
This paper investigates learning in a lifelong context. Lifelong learning  addresses situations in which a learner faces a whole stream of learning tasks. Such scenarios provide the opportunity to transfer knowledge  across multiple learning tasks, in order to generalize more accurately from  less training data. In this paper, several different approaches to lifelong  learning are described, and applied in an object recognition domain. It  is shown that across the board, lifelong learning approaches generalize  consistently more accurately from less training data, by their ability to  transfer knowledge across learning tasks.
Many classification problems have the property that the only costly  part of obtaining examples is the class label. This paper suggests  a simple method for using distribution information contained in  unlabeled examples to augment labeled examples in a supervised  training framework. Empirical tests show that the technique described in this paper can significantly improve the accuracy of a  supervised learner when the learner is well below its asymptotic  accuracy level.
We introduce a new algorithm designed to learn sparse percepttons over input representations which include high-order features.  Our algorithm, which is based on a hypothesis-boosting method,  is able to PAC-learn a relatively natural class of target concepts.  Moreover, the algorithm appears to work well in practice: on a set  of three problem domains, the algorithm produces classifiers that  utilize small numbers of features yet exhibit good generalization  performance. Perhaps most importantly, our algorithm generates  concept descriptions that are easy for humans to understand.
The wake-sleep algorithm (Hinton, Dayan, Frey and Neal 1995) is a relatively efficient method of fitting a multilayer stochastic generative  model to high-dimensional data. In addition to the top-down connections in the generafive model, it makes use of bottom-up connections for  approximating the probability distribution over the hidden units given  the data, and it trains these bottom-up connections using a simple delta  rule. We use a variety of synthetic and real data sets to compare the performance of the wake-sleep algorithm with Monte Carlo and mean field  methods for fitting the same generative model and also compare it with  other models that are less powerful but easier to fit.
Analog electronic cochlear models need exponentially scaled filters.  CMOS Compatible Lateral Bipolar Transistors (CLBTs) can create  exponentially scaled currents when biased using a resistive line with a  voltage difference between both ends of the line. Since these CLBTs  are independent of the CMOS threshold voltage, current sources  implemented with CLBTs are much better matched than current  sources created with MOS transistors operated in weak inversion.  Measurements from integrated test chips are shown to verify the  improved matching.
Both vertebrate and invertebrate retinas are highly eicient in extracting contrast independent of the background intensity over five  or more decades. This eiciency has been rendered possible by  the adaptation of the DC operating point to the background intensity while maintaining high gain transient responses. The centersurround properties of the retina allows the system to extract information at the edges in the image. This silicon retina models the  adaptation properties of the receptors and the antagonistic centersurround properties of the laminar cells of the invertebrate retina  and the outer-plexiform layer of the vertebrate retina. We also illustrate the spatio-temporal responses of the silicon retina on moving  bars. The chip has 59x64 pixels on a 6.9x6.8mm  die and it is  fabricated in 2/rn n-well technology.
A unique architecture of winner search hardware has been developed using a novel neuron-like high functionality device called  Neuron MOS transistor (or vMOS in short) [1,2] as a key circuit  element. The circuits developed in this work can find the location  of the maximum (or minimum) signal among a number of input  data on the continuous-time basis, thus enabling real-time winner  tracking as well as fully-parallel sorting of multiple input data. We  have developed two circuit schemes. One is an ensemble of selfloop-selecting vMOS ring oscillators finding the winner as an oscillating node. The other is an ensemble of yMOS variable threshold  inverters receiving a common ramp-voltage for competitive excitation where data sorting is conducted through consecutive winner  search actions. Test circuits were fabricated by a double-polysilicon  CMOS process and their operation has been experimentally verified.
We present an integrated analog processor for real-time wavelet decomposition and reconstruction of continuous temporal signals covering the  audio frequency range. The processor performs complex harmonic modulation and Gaussian lowpass filtering in 16 parallel channels, each clocked  at a different rate, producing a multiresolution mapping on a logarithmic  frequency scale. Our implementation uses mixed-mode analog and digital circuits, oversampling techniques, and switched-capacitor filters to  achieve a wide linear dynamic range while maintaining compact circuit  size and low power consumption. We include experimental results on the  processor and characterize its components separately from measurements  on a single-channel test chip.
We are developing special-purpose, low-power analog-to-digital  converters for speech and music applications, that feature analog  circuit models of biological audition to process the audio signal  before conversion. This paper describes our most recent converter  design, and a working system that uses several copies of the chip to  compute multiple representations of sound from an analog input.  This multi-representation system demonstrates the plausibility of  inexpensively implementing an auditory scene analysis approach to  sound processing.
A one dimensional model of primate smooth pursuit mechanism has  been implemented in 2 tm CMOS VLSI. The model consolidates  Robinson's negative feedback model with Wyatt and Pola's positive  feedback scheme, to produce a smooth pursuit system which zero's the  velocity of a target on the retina. Furthermore, the system uses the  current eye motion as a predictor for future target motion. Analysis,  stability and biological correspondence of the system are discussed. For  implementation at the focal plane, a local correlation based visual  motion detection technique is used. Velocity measurements, ranging  over 4 orders of magnitude with < 15% variation, provides the input to  the smooth pursuit system. The system performed successful velocity  tracking for high contrast scenes. Circuit design and performance of the  complete smooth pursuit system is presented.
In systems that process sensory data there is frequently a model  matching stage where class hypotheses are combined to recognize a  complex entity. We introduce a new model of parallelism, the Single  Function Multiple Data (SFMD) model, appropriate to this stage.  SFMD functionality can be added with small hardware expense to  certain existing SIMD architectures, and as an incremental addition  to the programming model. Adding SFMD to an SIMD machine  will not only allow faster model matching, but also increase its  flexibility as a general purpose machine and its scope in performing  the initial stages of sensory processing.
We describe two parallel analog VLSI architectures that integrate  optical flow data obtained from arrays of elementary velocity sensors to estimate heading direction and time-to-contact. For heading  direction computation, we performed simulations to evaluate the  most important qualitative properties of the optical flow field and  determine the best functional operators for the implementation of  the architecture. For time-to-contact we exploited the divergence  theorem to integrate data from all velocity sensors present in the  architecture and average out possible errors.
A technique for segmenting sounds using processing based on mammalian early auditory processing is presented. The technique is  based on features in sound which neuron spike recording suggests  are detected in the cochlear nucleus. The sound signal is bandpassed and each signal processed to enhance onsets and offsets.  The onset and offset signals are compressed, then clustered both in  time and across frequency channels using a network of integrateand-fire neurons. Onsets and offsets are signalled by spikes, and  the timing of these spikes used to segment the sound.
An application of laterally interconnected self-organizing maps  (LISSOM) to handwritten digit recognition is presented. The lateral connections learn the correlations of activity between units on  the map. The resulting excitatory connections focus the activity  into local patches and the inhibitory connections decorrelate redundant activity on the map. The map thus forms internal representations that are easy to recognize with e.g. a perceptron network. The  recognition rate on a subset of NIST database 3 is 4.0% higher with  LISSOM than with a regular Self-Organizing Map (SOM) as the  front end, and 15.8% higher than recognition of raw input bitmaps  directly. These results form a promising starting point for building  pattern recognition systems with a LISSOM map as a front end.
This paper describes the training of a recurrent neural network  as the letter posterior probability estimator for a hidden Markov  model, off-line handwriting recognition system. The network estimates posterior distributions for each of a series of frames representing sections of a handwritten word. The supervised training  algorithm, backpropagation through time, requires target outputs  to be provided for each frame. Three methods for deriving these  targets are presented. A novel method based upon the forwardbackward algorithm is found to result in the recognizer with the  lowest error rate.
A method for incorporating context-dependent phone classes in  a connectionist-HMM hybrid speech recognition system is introduced. A modular approach is adopted, where single-layer networks  discriminate between different context classes given the phone class  and the acoustic data. The context networks are combined with a  context-independent (CI) network to generate context-dependent  (CD) phone probability estimates. Experiments show an average  reduction in word error rate of 16% and 13% from the CI system  on ARPA 5,000 word and SQALE 20,000 word tasks respectively.  Due to improved modelling, the decoding speed of the CD system  is more than twice as fast as the CI system.
A new on-line learning algorithm which minimizes a statistical dependency among outputs is derived for blind separation of mixed  signals. The dependency is measured by the average mutual information (MI) of the outputs. The source signals and the mixing  matrix are unknown except for the number of the sources. The  Gram-Charlier expansion instead of the Edgeworth expansion is  used in evaluating the MI. The natural gradient approach is used  to minimize the MI. A novel activation function is proposed for the  on-line learning algorithm which has an equivariant property and  is easily implemented on a neural network like model. The validity  of the new learning algorithm are verified by computer simulations.
A hybrid and contextual radial basis function network/hidden Markov  model off-line handwritten word recognition system is presented. The  task assigned to the radial basis function networks is the estimation of  emission probabilities associated to Markov states. The model is contextual because the estimation of emission probabilities takes into account  the left context of the current image segment as represented by its predecessor in the sequence. The new system does not outperform the previous system without context but acts differently.
Completely parallel object recognition is NP-complete. Achieving  a recognizer with feasible complexity requires a compromise between parallel and sequential processing where a system selectively  focuses on parts of a given image, one after another. Successive  fixations are generated to sample the image and these samples are  processed and abstracted to generate a temporal context in which  results are integrated over time. A computational model based on a  partially recurrent feedforward network is proposed and made credible by testing on the reM-world problem of recognition of handwritten digits with encouraging results.
This paper describes the Kodak Imagelink TM OCR alphanumeric  handprint module. There are two neural network algorithms at its  cc: the first network is trained to find individual characters in an  alphammea'ic field, while the secxmd oe performs the classification.  Both networks we uained on Gabor projections of the original  pixel images, which reintired in high reccL2n_. ition rates and greater  noiso immunity. Compared to its purely mme½ cotrate. art  (Shustxvich and Thrasher, 1995), this version of the system hos a  siEnificant applicatic specie postprocessing module. The system  has beta implemented in specialized parallel hardware, which allows  it to run at 80 charlsec]board. It has been irtts!iod at the Driver and  Vehicle L Agency (DVLA) in the United Kingdom, and its  overall stwss rate ex__,,.ls 96% (character level without rejects),  which tran.glates into 85% field rate. ff approimt_ely 20% of the  fields are rejected, the system achieves 99.8% character and 99.5%  field success rate.
We define a Gamma multi-layer perceptton (MLP) as an MLP  with the usual synaptic weights replaced by gamma filters (as proposed by de Vries and Principe (de Vries and Principe, 1992)) and  associated gain terms throughout all layers. We derive gradient  descent update equations and apply the model to the recognition  of speech phonemes. We find that both the inclusion of gamma  filters in all layers, and the inclusion of synaptic gains, improves  the performance of the Gamma MLP. We compare the Gamma  MLP with TDNN, Back-Tsoi FIR MLP, and Back-Tsoi IIR MLP  architectures, and a local approximation scheme. We find that the  Gamma MLP results in an substantial reduction in error rates.
Matching feature point sets lies at the core of many approaches to  object recognition. We present a framework for non-rigid matching that begins with a skeleton module, affine point matching,  and then integrates multiple features to improve correspondence  and develops an object representation based on spatial regions to  model local transformations. The algorithm for feature matching  iteratively updates the transformation parameters and the correspondence solution, each in turn. The aftme mapping is solved in  closed form, 'which permits its use for data of any dimension. The  correspondence is set via a method for two-way constraint satisfaction, called softassign, which has recently emerged from the neural  network/statistical physics realm. The complexity of the non-rigid  matching algorithm with multiple features is the same as that of  the affine point matching algorithm. Results for synthetic and real  world data are provided for point sets in 2D and 3D, and for 2D  data with multiple types of features and parts.
Intermediate and higher vision processes require selection of a subset of the available sensory information before further processing.  Usually, this selection is implemented in the form of a spatially  circumscribed region of the visual field, the so-called "focus of attention" which scans the visual scene dependent on the input and  on the attentional state of the subject. We here present a model for  the control of the focus of attention in primates, based on a saliency  map. This mechanism is not only expected to model the functionality of biological vision but also to be essential for the understanding  of complex scenes in machine vision.
When a sensory system constructs a model of the environment  from its input, it might need to verify the model's accuracy. One  method of verification is multivariate time-series prediction: a good  model could predict the near-future activity of its inputs, much  as a good scientific theory predicts future data. Such a predicting model would require copious top-down connections to compare  the predictions with the input. That feedback could improve the  model's performance in two ways: by biasing internal activity toward expected patterns, and by generating specific error signals if  the predictions fail. A proof-of-concept model--an event-driven,  computationally efficient layered network, incorporating "cortical"  features like all-excitatory synapses and local inhibition--was constructed to make near-future predictions of a simple, moving stimulus. After unsupervised learning, the network contained units not  only tuned to obvious features of the stimulus like contour orientation and motion, but also to contour discontinuity ("end-stopping")  and illusory contours.
Visual occlusion events constitute a major source of depth information.  This paper presents a self-organizing neural network that learns to detect,  represent, and predict the visibility and invisibility relationships that arise  during occlusion events, after a period of exposure to motion sequences  containing occlusion and disocclusion events. The network develops two  parallel opponent channels or "chains" of lateral excitatory connections  for every resolvable motion trajectory. One channel, the "On" chain or  "visible" chain, is activated when a moving stimulus is visible. The other  channel, the "Off" chain or "invisible" chain, carries a persistent, amodal  representation that predicts the motion of a formerly visible stimulus that  becomes invisible due to occlusion. The learning rule uses disinhibition  from the On chain to trigger learning in the Off chain. The On and  Off chain neurons can learn separate associations with object depth ordering. The results are closely related to the recent discovery (Assad &  Maunsell, 1995) of neurons in macaque monkey posterior parietal cortex  that respond selectively to inferred motion of invisible stimuli.
The Facial Action Coding System, (FACS), devised by Ekman and  Friesen (1978), provides an objective means for measuring the facial  muscle contractions involved in a facial expression. In this paper,  we approach automated facial expression analysis by detecting and  classifying facial actions. We generated a database of over 1100  image sequences of 24 subjects performing over 150 distinct facial  actions or action combinations. We compare three different approaches to classifying the facial actions in these images: Holistic  spatial analysis based on principal components of graylevel images;  explicit measurement of local image features such as wrinkles; and  template matching with motion flow fields. On a dataset containing six individual actions and 20 subjects, these methods had 89%,  57%, and 85% performances respectively for generalization to novel  subjects. When combined, performance improved to 92%.
Visual cognition depends critically on the ability to make rapid eye movements  known as saccades that orient the fovea over targets of interest in a visual  scene. Saccades are known to be ballistic: the pattern of muscle activation  for foveafing a prespecified target location is computed prior to the movement  and visual feedback is precluded. Despite these distinctive properties, there  has been no general model of the saccadic targeting strategy employed by  the human visual system during visual search in natural scenes. This paper  proposes a model for saccadic targeting that uses iconic scene representations  derived from oriented spatial filters at multiple scales. Visual search proceeds  in a coarse-to-fine fashion with the largest scale filter responses being compared  first. The model was empirically tested by comparing its performance with  actual eye movement data from human subjects in a natural visual search task;  preliminary results indicate substantial agreement between eye movements  predicted by the model and those recorded from human subjects.
A model of human motion perception is presented. The model  contains two stages of direction selective units. The first stage contains broadly tuned units, while the second stage contains units  that are narrowly tuned. The model accounts for the motion aftereffect through adapting units at the first stage and inhibitory  interactions at the second stage. The model explains how two populations of dots moving in slightly different directions are perceived  as a single population moving in the direction of the vector sum,  and how two populations moving in strongly different directions are  perceived as transparent motion. The model also explains why the  motion aftereffect in both cases appears as non-transparent motion.
A neural network model of 3-D lightness perception is presented  which builds upon the FACADE Theory Boundary Contour System/Feature Contour System of Grossberg and colleagues. Early  ratio encoding by retinal ganglion neurons as well as psychophysical results on constancy across different backgrounds (background  constancy) are used to provide functional constraints to the theory  and suggest a contrast negation hypothesis which states that ratio  measures between coplanar regions are given more weight in the  determination of lightness of the respective regions. Simulations  of the model address data on lightness perception, including the  coplanar ratio hypothesis, the Benary cross, and White's illusion.
No finite sample is sufficient to determine the density, and therefore  the entropy, of a signal directly. Some assumption about either the  functional form of the density or about its smoothness is necessary.  Both amount to a prior over the space of possible density functions.  By far the most common approach is to assume that the density  has a parametric form.  By contrast we derive a differential learning rule called EMMA  that optimizes entropy by way of kernel density estimation. Entropy and its derivative can then be calculated by sampling from  this density estimate. The resulting parameter update rule is surprisingly simple and efficient.  We will show how EMMA can be used to detect and correct corruption in magnetic resonance images (MRI). This application is  beyond the scope of existing parametric entropy models.
We have developed a foveated gesture recognition system that runs  in an unconstrained office environment with an active camera. Using vision routines previously implemented for an interactive environment, we determine the spatial location of salient body parts  of a user and guide an active camera to obtain images of gestures  or expressions. A hidden-state reinforcement learning paradigm is  used to implement visual attention. The attention module selects  targets to loveate based on the goal of successful recognition, and  uses a new multiple-model Q-learning formulation. Given a set  of target and distractor gestures, our system can learn where to  foveate to maximally discriminate a particular gesture.
A neurally-inspired visual object recognition system is described  called SEEMORE, whose goal is to identify common objects from  a large known set independent of 3-D viewiag angle, distance,  and non-rigid distortion. SEEMORE's database consists of 100 objects that are rigid (shovel), non-rigid (telephone cord), articulated (book), statistical (shrubbery), and complex (photographs of  scenes). Recognition results were obtained using a set of 102 color  and shape feature channels within a simple feedforward network architecture. In response to a test set of 600 novel test views (6 of  each object) presented individually in color video images, SEEMORE  identified the object correctly 97% of the time (chance is 1%) using  a nearest neighbor classifier. Similar levels of performance were  obtained for the subset of 15 non-rigid objects. Generalization behavior reveals emergence of striking natural category structure not  explicit in the input feature dimensions.
We present a neural network-based face detection system. A retinally  connected neural network examines small windows of an image, and  decides whether each window contains a face. The system arbitrates  between multiple networks to improve performance over a single network.  We use a bootstrap algorithm for training, which adds false detections  into the training set as training progresses. This eliminates the difficult  task of manually selecting non-face training examples, which must be  chosen to span the entire space of non-face images. Comparisons with  another state-of-the-art face detection system are presented; our system  has better performance in terms of detection and false-positive rates.
Central to the performance improvement of a committee relative to  individual networks is the error correlation between networks in the  committee. We investigated methods of achieving error independence between the networks by training the networks with different  resampling sets from the original training set. The methods were  tested on the sinwave artificial task and the real-world problems of  hepatoma (liver cancer) and breast cancer diagnoses.
Infants' manipulative exploratory behavior within the environment  is a vehicle of cognitive stimulation[McCall 1974]. During this time,  infants practice and perfect sensorimotor patterns that become behavioral modules which will be seriated and imbedded in more complex actions. This paper explores the development of such primitive  learning systems using an embodied light-weight hand which will  be used for a humanoid being developed at the MIT Artificial Intelligence Laboratory[Brooks and Stein 1993]. Primitive grasping  procedures are learned from sensory inputs using a connectionist  reinforcement algorithm while two submodules preprocess sensory  data to recognize the hardness of objects and detect shear using  competitive learning and back-propagation algorithm strategies,  respectively. This system is not only consistent and quick during the initial learning stage, but also adaptable to new situations  after training is completed.
Learning how to adjust to an opponent's position is critical to  the success of having intelligent agents collaborating towards the  achievement of specific tasks in unfriendly environments. This paper describes our work on a Memory-based technique for to choose  an action based on a continuous-valued state attribute indicating  the position of an opponent. We investigate the question of how an  agent performs in nondeterministic variations of the training situations. Our experiments indicate that when the random variations  fall within some bound of the initial training, the agent performs  better with some initial training rather than from a tabula-rasa.
We report on the development of the modular neural system "SmE^GLI" for the visual guidance of robot pick-and-place actions.  Several neural networks are integrated to a single system that visually recognizes human hand pointing gestures from stereo pairs  of color video images. The output of the hand recognition stage is  processed by a set of color-sensitive neural networks to determine  the cartesian location of the target object that is referenced by the  pointing gesture. Finally, this information is used to guide a robot  to grab the target object and put it at another location that can  be specified by a second pointing gesture. The accuracy of the current system allows to identify the location of the referenced target  object to an accuracy of I cm in a workspace area of 50x50 cm. In  our current environment, this is sufficient to pick and place arbitrarily positioned target objects within the workspace. The system  consists of neural networks that perform the tasks of image segmentation, estimation of hand location, estimation of 3D-pointing  direction, object recognition, and necessary coordinate transforms.  Drawing heavily on the use of learning algorithms, the functions of  all network modules were created from data examples only.
State-of-the-art speech processors in cochlear implants perform  channel selection using a spectral maxima strategy. This strategy  can lead to confusions when high frequency features are needed  to discriminate between sounds. We present in this paper a novel  channel selection strategy based upon pattern recognition which allows "smart" channel selections to be made. The proposed strategy  is implemented using multi-layer perceptrons trained on a multispeaker labelled speech database. The input to the network are the  energy coefficients of N energy channels. The output of the system  are the indices of the M selected channels.  We compare the performance of our proposed system to that of  spectral maxima strategy, and show that our strategy can produce  significantly better results.
Most current methods for prediction of protein secondary structure  use a small window of the protein sequence to predict the structure  of the central amino acid. We describe a new method for prediction  of the non-local structure called/-sheet, which consists of two or  more /-strands that are connected by hydrogen bonds. Since /3strands are often widely separated in the protein chain, a network  with two windows is introduced. After training on a set of proteins  the network predicts the sheets well, but there are many false positives. By using a global energy function the/-sheet prediction is  combined with a local prediction of the three secondary structures  c-helix, fi-strand and coil. The energy function is minimized using  simulated annealing to give a final prediction.
We present results on the use of neural network based autoassociators  which act as novelty or anomaly detectors to detect imminent motor  failures. The autoassociator is trained to reconstruct spectra obtained  from the healthy motor. In laboratory tests, we have demonstrated that the  trained autoassociator has a small reconstruction error on measurements  recorded from healthy motors but a larger error on those recorded from a  motor with a fault. We have designed and built a motor monitoring system  using an autoassociator for anomaly detection and are in the process of  testing the system at three industrial and commercial sites.
We report here that changes in the normalized electroencephalographic (EEG) cross-spectrum can be used in conjunction with  feedforward neural networks to monitor changes in alertness of operators continuously and in near-real time. Previously, we have  shown that EEG spectral amplitudes covary with changes in alertness as indexed by changes in behavioral error rate on an auditory  detection task [6, 4]. Here, we report for the first time that increases  in the frequency of detection errors in this task are also accompanied by patterns of increased and decreased spectral coherence in  several frequency bands and EEG channel pairs. Relationships  between EEG coherence and performance vary between subjects,  but within subjects, their topographic and spectral profiles appear  stable from session to session. Changes in alertness also covary  with changes in correlations among EEG waveforms recorded at  different scalp sites, and neural networks can also estimate alertness from correlation changes in spontaneous and unobtrusivelyrecorded EEG signals.
This paper describes a neural network classifier for the I1000 chip, which  optically reads the E13B font characters at the bottom of checks. The  first layer of the neural network is a hardware linear classifier which  recognizes the characters in this font. A second software neural layer  is implemented on an inexpensive microprocessor to clean up the results of the first layer. The hardware linear classifier is mathematically  specified using constraints and an optimization principle. The weights  of the classifier are found using the active set method, similar to Vapnik's separating hyperplane algorithm. In 7.5 minutes of SPARC 2 time,  the method solves for 1523 Lagrange multipliers, which is equivalent to  training on a data set of approximately 128,000 examples. The resulting network performs quite well: when tested on a test set of 1500 real  checks, it has a 99.995% character accuracy rate.
In this paper, we propose a memory-based Q-learning algorithm  called predictive Q-routing (PQ-routing) for adaptive traffic control. We attempt to address two problems encountered in Q-routing  (Boyan &; Littman, 1994), namely, the inability to fine-tune routing policies under low network load and the inability to learn new  optimal policies under decreasing load conditions. Unlike other  memory-based reinforcement learning algorithms in which memory is used to keep past experiences to increase learning speed,  PQ-routing keeps the best experiences learned and reuses them  by predicting the traffic trend. The effectiveness of PQ-routing  has been verified under various network topologies and traffic conditions. Simulation results show that PQ-routing is superior to  Q-routing in terms of both learning speed and adaptability.
In recent years, the interest of investors has shifted to computerized asset allocation (portfolio management) to exploit the growing  dynamics of the capital markets. In this paper, asset allocation is  formalized as a MarkovJan Decision Problem which can be optimized by applying dlnamic programming or reinforcement learning  based algorithms. Using an artificial exchange rate, the asset allocation strategy optimized with reinforcement learning (Q-Learning)  is shown to be equivalent to a policy computed by dynamic programming. The approach is then tested on the task to invest liquid  capital in the German stock market. Here, neural networks are  used as value function approximators. The resulting asset allocation strategy is superior to a heuristic benchmark policy. This is  a further example which demonstrates the applicability of neural  network based reinforcement learning to a problem setting with a  high dimensional state space.
A patient visits the doctor; the doctor reviews the patient's history,  asks questions, makes basic measurements (blood pressure, ...), and  prescribes tests or treatment. The prescribed course of action is  based on an assessment of patient risk--patients at higher risk are  given more and faster attention. It is also sequential--it is too  expensive to immediately order all tests which might later be of  value. This paper presents two methods that together improve  the accuracy of backprop nets on a pneumoni'a risk assessment  problem by 10-50%. Rankprop improves on backpropagation with  sum of squares error in ranking patients by risk. Multitask learning  takes advantage of future lab tests available in the training set, but  not available in practice when predictions must be made. Both  methods are broadly applicable.
This paper discusses the use of multilayer feedforward neural networks for predicting a stock's excess return based on its exposure  to various technical and fundamental factors. To demonstrate the  effectiveness of the approach a hedged portfolio which consists of  equally capitalized long and short positions is constructed and its  historical returns are benchmarked against T-bill returns and the  S&cP500 index.
This paper describes a neural network based controller for allocating  capacity in a telecommunications network. This system was proposed in  order to overcome a "real time" response constraint. Two basic  architectures are evaluated: 1) a feedforward network-heuristic and; 2) a  feedforward network-recurrent network. These architectures are  compared against a linear programming (LP) optimiser as a benchmark.  This LP optimiser was also used as a teacher to label the data samples  for the feedforward neural network training algorithm. It is found that  the systems are able to provide a traffic throughput of 99% and 95%,  respectively, of the throughput obtained by the linear progranuning  solution. Once trained, the neural network based solutions are found in a  fraction of the time required by the LP optimiser.
Current environmental monitoring systems assume particles to be  spherical, and do not attempt to classify them. A laser-based system developed at the University of Hertfordshire aims at classifying airborne particles through the generation of two-dimensional  scattering profiles. The performances of template matching, and  two types of neural network (HyperNet and semi-linear units) are  compared for image classification. The neural network approach is  shown to be capable of comparable recognition performance, while  offering a number of advantages over template matching.
This paper discusses how a robot can learn goal-directed navigation tasks using local sensory inputs. The emphasis is that such  learning tasks could be formulated as an embedding problem of  dynamical systems: desired trajectories in a task space should be  embedded into an adequate sensory-based internal state space so  that an unique mapping from the internal state space to the motor  command could be established. The paper shows that a recurrent  neural network suffices in self-organizing such an adequate internal  state space from the temporal sensory input. In our experiments,  using a real robot with a laser range sensor, the robot navigated  robustly by achieving dynamical coherence with the environment.  It was also shown that such coherence becomes structurally stable as the global attractor is self-organized in the coupling of the  internal and the environmental dynamics.
This paper describes a policy iteration algorithm for optimizing the  performance of a harmonic function-based controller with respect  to a user-defined index. Value functions are represented as potential distributions over the problem domain, being control policies  represented as gradient fields over the same domain. All intermediate policies are intrinsically safe, i.e. collisions are not promoted  during the adaptation process. The algorithm has efficient implementation in parallel SIMD architectures. One potential application travel distance minimization illustrates its usefulness.
Compliant control is a standard method for performing fine manipulation tasks, like grasping and assembly, but it requires estimation  of the state of contact (s.o.c.) between the robot arm and the objects involved. Here we present a method to learn a model of the  movement from measured data. The method requires little or no  prior knowledge and the resulting model explicitly estimates the  s.o.c. The current s.o.c. is viewed as the hidden state variable of  a discrete HMM. The control dependent transition probabilities  between states are modeled as parametrized functions of the measurement. We show that their parameters can be estimated from  measurements at the same time as the parameters of the movement  in each s.o.c. The learning algorithm is a variant of the EM procedure. The E step is computed exactly; solving the M step exactly  is not possible in general. Here, gradient ascent is used to produce  an increase in likelihood.
A neural network based approach is presented for controlling two distinct  types of nonlinear systems. The first corresponds to nonlinear systems  with parametric uncertainties where the parameters occur nonlinearly.  The second corresponds to systems for which stabilizing control structures cannot be determined. The proposed neural controllers are shown  to result in closed-loop system stability under certain conditions.
This paper describes the application of reinforcement learning (RL)  to the difficult real world problem of elevator dispatching. The elevator domain poses a combination of challenges not seen in most  RL research to date. Elevator systems operate in continuous state  spaces and in continuous time as discrete event dynamic systems.  Their states are not fully observable and they are nonstationary  due to changing passenger arrival rates. In addition, we use a team  of RL agents, each of which is responsible for controlling one elevator car. The team receives a global reinforcement signal which  appears noisy to each agent due to the effects of the actions of the  other agents, the random nature of the arrivals and the incomplete  observation of the state. In spite of these complications, we show  results that in simulation surpass the best of the heuristic elevator  control algorithms of which we are aware. These results demonstrate the power of RL on a very large scale stochastic dynamic  optimization problem of practical utility.
Job-shop scheduling is an important task for manufacturing industries. We are interested in the particular task of scheduling payload  processing for NASA's space shuttle program. This paper summarizes our previous work on formulating this task for solution by the  reinforcement learning algorithm TD(A). A shortcoming of this  previous work was its reliance on hand-engineered input features.  This paper shows how to extend the time-delay neural network  (TDNN) architecture to apply it to irregular-length schedules. Experimental tests show that this TDNN-TD(A) network can match  the performance of our previous hand-engineered system. The tests  also show that both neural network approaches significantly outperform the best previous (non-learning) solution to this problem  in terms of the quality of the resulting schedules and the number  of search steps required to construct them.
In this paper we examine the practical use of hardware neural  networks in an autonomous mobile robot. We have developed a  hardware neural system based around a custom VLSI chip, EPSILON II , designed specifically for embedded hardware neural  applications. We present here a demonstration application of an  autonomous mobile robot that highlights the flexibility of this system. This robot gains basic mobility competence in very few training epochs using an "instinct-rule" training methodology.
On large problems, reinforcement learning systems must use parameterized function approximators such as neural networks in order to generalize between similar situations and actions. In these cses there are  no strong theoretical results on the accuracy of convergence, and computational results have been mixed. In particular, Boyan and Moore  reported at last year's meeting a series of negative results in attempting  to apply dynamic programming together with function approximation  to simple control problems with continuous state spaces. In this paper,  we present positive results for all the control tasks they attempted, and  for one that is significantly larger. The most important differences are  that we used sparse-coarse-coded function approximators (CMACs)  whereas they used mostly global function approximators, and that we  learned online whereas they learned offiine. Boyan and Moore and  others have suggested that the problems they encountered could be  solved by using actual outcomes ("rollouts"), as in classical Monte  Carlo methods, and as in the TD(),) algorithm when ), = 1. However,  in our experiments this always resulted in substantially poorer performance. We conclude that reinforcement learning can work robustly  in conjunction with function approximators, and that there is little  justification at present for avoiding the case of general ).
We consider the solution to large stochastic control problems by  means of methods that rely on compact representations and a variant of the value iteration algorithm to compute approximate costto-go functions. While such methods are known to be unstable in  general, we identify a new class of problems for which convergence,  as well as graceful error bounds, are guaranteed. This class involves linear parameterizations of the cost-to-go function together  with an assumption that the dynamic programming operator is a  contraction with respect to the Euclidean norm when applied to  functions in the parameterized class. We provide a special case  where this assumption is satisfied, which relies on the locality of  transitions in a state space. Other cases will be discussed in a full  length version of this paper.
We describe the reinforcement learning problem, motivate algorithms which seek an approximation to the Q function, and present  new convergence results for two such algorithms.
Improving Policies without Measuring  Merits  Peter Dayan   CBCL  E25-201, MIT  Cambridge, MA 02139  dayan¸ai. mir. edu  Satinder P Singh  Harlequin, Inc
In this paper we introduce new algorithms for optimizing noisy  plants in which each experiment is very expensive. The algorithms  build a global non-linear model of the expected output at the same  time as using Bayesian linear regression analysis of locally weighted  polynomial models. The local model answers queries about confidence, noise, gradient and Hessians, and use them to make automated decisions similar to those made by a practitioner of Response  Surface Methodology. The global and local models are combined  naturally as a locally weighted regression. We examine the question of whether the global model can really help optimization, and  we extend it to the case of time-varying functions. We compare  the new algorithms with a highly tuned higher-order stochastic optimization algorithm on randomly-generated functions and a simulated manufacturing task. We note significant improvements in  total regret, time to converge, and final solution quality.
A continuous-time, continuous-state version of the temporal difference (TD) algorithm is derived in order to facilitate the application  of reinforcement learning to real-world control tasks and neurobiological modeling. An optimal nonlinear feedback control law was  also derived using the derivatives of the value function. The performance of the algorithms was tested in a task of swinging up a  pendulum with limited torque. Both the "critic" that specifies the  paths to the upright position and the "actor" that works as a nonlinear feedback controller were successfully implemented by radial  basis function (RBF) networks.
We present a new algorithm for associative reinforcement learning. The algorithm is based upon the idea of matching a network's  output probability with a probability distribution derived from the  environment 's reward signal. This Probability Matching algorithm  is shown to perform faster and be less susceptible to local minima  than previously existing algorithms. We use Probability Matching to train mixture of experts networks, an architecture for which  other reinforcement learning rules fail to converge reliably on even  simple problems. This architecture is particularly well suited for  our algorithm as it can compute arbitrarily complex functions yet  calculation of the output probability is simple.
The following investigates the use of single-neuron learning algorithms to improve the performance of text-retrieval systems that  accept natural-language queries. A retrieval process is explained  that transforms the natural-language query into the query syntax  of a real retrieval system: the initial query is expanded using statistical and leaxning techniques and is then used for document ranking  and binary classification. The results of experiments suggest that  Kivinen and Warmuth's Exponentiated Gradient Descent learning  algorithm works significantly better than previous approaches.
Although TD-Gammon is one of the major successes in machine learning, it has not led to similar impressive breakthroughs in temporal difference learning for other applications or even other games. We were  able to replicate some of the success of TD-Gammon, developing a  competitive evaluation function on a 4000 parameter feed-forward neural network, without using back-propagation, reinforcement or temporal  difference learning methods. Instead we apply simple hill-climbing in a  relative fitness environment. These results and further analysis suggest  that the surprising success of Tesauro's program had more to do with the  co-evolutionary structure of the learning task and the dynamics of the  backgammon game itself.
We present a connectionist method for representing images that explicitly addresses their hierarchical nature. It blends data from neuroscience about whole-object viewpoint sensitive cells in inferotemporal cortex s and attentional basis-field modulation in V4 3 with  ideas about hierarchical descriptions based on microfeatures. 5' l  The resulting model makes critical use of bottom-up and top-down  pathways for analysis and synthesis? We illustrate the model with  a simple example of representing information about faces.
In order to process incoming sounds efficiently, it is advantageous  for the auditory system to be adapted to the statistical structure of  natural auditory scenes. As a first step in investigating the relation  between the system and its inputs, we study low-order statistical  properties in several sound ensembles using a filter bank analysis.  Focusing on the amplitude and phase in different frequency bands,  we find simple parametric descriptions for their distribution and  power spectrum that are valid for very different types of sounds.  In particular, the amplitude distribution has an exponential tail  and its power spectrum exhibits a modified power-law behavior,  which is manifested by self-similarity and long-range temporal correlations. Furthermore, the statistics for different bands within a  given ensemble are virtually identical, suggesting translation invariance along the cochlear axis. These results show that natural  sounds are highly redundant, and have possible implications to the  neural code used by the auditory system.
We employed a white-noise velocity signal to study the dynamics  of the response of single neurons in the cortical area MT to visual  motion. Responses were quantified using reverse correlation, optimal linear reconstruction filters, and reconstruction signal-to-noise  ratio (SNR). The SNR and lower bound estimates of information  rate were lower than we expected. Ninety percent of the information was transmitted below 18 Hz, and the highest lower bound on  bit rate was 12 bits/s. A simulated opponent motion energy subunit with Poisson spike statistics was able to out-perform the MT  neurons. The temporal integration window, measured from the reverse correlation half-width, ranged from 30-90 ms. The window  was narrower when a stimulus moved faster, but did not change  when temporal frequency was held constant.
In 1990 Poggio and Edelman proposed a view-based model of object recognition that accounts for several psychophysical properties  of certain recognition tasks. The model predicted the existence of  view-tuned and view-invariant units, that were later found by Logothetis et al. (Logothetis et al., 1995) in IT cortex of monkeys  trained with views of specific paperclip objects. The model, however, does not specify the inputs to the view-tuned units and their  internal organization. In this paper we propose a model of these  view-tuned units that is consistent with physiological data from  single cell responses.
Binocular rivalry is the alternating percept that can result when  the two eyes see different scenes. Recent psychophysical evidence  supports an account for one component of binocular rivalry similar  to that for other bistable percepts. We test the hypothesis 19,16.18  that alternation can be generated by competition between topdown cortical explanations for the inputs, rather than by direct  competition between the inputs. Recent neurophysiological evidence shows that some binocular neurons are modulated with  the changing percept; others are not, even if they are selective between the stimuli presented to the eyes. We extend our model to  a hierarchy to address these effects.
We train recurrent networks to control chemotaxis in a computer  model of the nematode C. elegant. The model presented is based  closely on the body mechanics, behavioral analyses, neuroanatomy  and neurophysiology of G. elegans, each imposing constraints relevant for information processing. Simulated worms moving autonomously in simulated chemical environments display a variety  of chemotaxis strategies si_m_ilar to those of biological worms.
The encoding of random time-varying stimuli in single spike trains  of electrosensory neurons in the weakly electric fish Eigenmannia  was investigated using methods of statistical signal processing. At  the first stage of the electrosensory system, spike trains were found  to encode faithfully the detailed time-course of random stimuli,  while at the second stage neurons responded specifically to features  in the temporal waveform of the stimulus. Therefore stimulus information is processed at the second stage of the electrosensory system  by extracting temporal features from the faithfully preserved image  of the environment sampled at the first stage.
We introduce a neurobiologically plausible model of contour integration from visual inputs of individual oriented edges. The model  is composed of interacting excitatory neurons and inhibitory interneurons, receives visual inputs via oriented receptive fields (RFs)  like those in V1. The RF centers are distributed in space. At each  location, a finite number of cells tuned to orientations spanning  180 ø compose a model hypercolumn. Cortical interactions modify  neural activities produced by visual inputs, selectively amplifying  activities for edge elements belonging to smooth input contours. Elements within one contour produce synchronized neural activities.  We show analytically and empirically that contour enhancement  and neural synchrony increase with contour length, smoothness  and closure, as observed experimentally. This model gives testable  predictions, and in addition, introduces a feedback mechanism allowing higher visual centers to enhance, suppress, and segment  contours.
This paper develops arguments for a family of temporal log-linear models  to represent spatio-temporal correlations among the spiking events in a  group of neurons. The models can represent not just pairwise correlations  but also correlations of higher order. Methods are discussed for inferring  the existence or absence of correlations and estimating their strength.  A frequentist and a Bayesian approach to correlation detection are  compared. The frequentist method is based on G 2 statistic with estimates  obtained via the Max-Ent principle. In the Bayesian approach a Markov  Chain Monte Carlo Model Composition (MC 3) algorithm is applied to  search over connectivity structures and Laplace's method is used to  approximate their posterior probability. Performance of the methods was  tested on synthetic data. The methods were applied to experimental data  obtained by the fourth author by means of measurements carried out on  behaving Rhesus monkeys at the Hadassah Medical School of the Hebrew  University. As conjectured, neural connectivity structures need not be  neither hierarchical nor decomposable.  Learning Quasi-synchronization Patterns among Spiking Neurons 77
Biophysical modeling studies have previously shown that cortical  pyramidal cells driven by strong NMDA-type synaptic currents  and/or containing dendritic voltage-dependent Ca ++ or Na + channels, respond more strongly when synapses are activated in several  spatially clustered groups of optimal size in comparison to the  same number of synapses activated diffusely about the dendritic  arbor [8]. The nonlinear intradendritic interactions giving rise to  this "cluster sensitivity" property are akin to a layer of virtual nonlinear "hidden units" in the dendrites, with implications for the cellular basis of learning and memory [7, 6], and for certain classes of  nonlinear sensory processing [8]. In the present study, we show that  a single neuron, with access only to excitatory inputs from unoriented ONand OFF-center cells in the LGN, exhibits the principal  nonlinear response properties of a "complex" cell in primary visual  cortex, namely orientation tuning coupled with translation invariance and contrast insensitivity. We conjecture that this type of  intradendritic processing could explain how complex cell responses  can persist in the absence of oriented simple cell input [13].  84 B. W.. Mel, D. L. Ruderman and K. A. Archie
Recently Sillito and coworkers (Nature 378, pp. 492, 1995) demonstrated that stimulation beyond the classical receptive field (cRF)  can not only modulate, but radically change a neuron's response to  oriented stimuli. They revealed that patch-suppressed cells when  stimulated with contrasting orientations inside and outside their  cRF can strongly respond to stimuli oriented orthogonal to their  nominal preferred orientation. Here we analyze the emergence of  such complex response patterns in a simple model of primary visual cortex. We show that the observed sensitivity for orientation  contrast can be explained by a delicate interplay between local  isotropic interactions and patchy long-range connectivity between  distant iso-orientation domains. In particular we demonstrate that  the observed properties might arise without specific connections between sites with cross-oriented cRFs.
Coarse codes are widely used throughout the brain to encode sensory and motor variables. Methods designed to interpret these  codes, such as population vector analysis, are either inefficient, i.e.,  the variance of the estimate is much larger than the smallest possible variance, or biologically implausible, like maximum likelihood.  Moreover, these methods attempt to compute a scalar or vector  estimate of the encoded variable. Neurons are faced with a similar estimation problem. They must read out the responses of the  presynaptic neurons, but, by contrast, they typically encode the  variable with a further population code rather than as a scalar.  We show how a non-linear recurrent network can be used to perform these estimation in an optimal way while keeping the estimate  in a coarse code format. This work suggests that lateral connections in the cortex may be involved in cleaning up uncorrelated  noise among neurons representing similar variables.
A linear architectural model of cortical simple cells is presented.  The model evidences how mutual inhibition, occurring through  synaptic coupling functions asymmetrically distributed in space,  can be a possible basis for a wide variety of spario-temporal simple  cell response properties, including direction selectivity and velocity  tuning. While spatial asymmetries are included explicitly in the  structure of the inhibitory interconnections, temporal asymmetries  originate from the specific mutual inhibition scheme considered.  Extensive simulations supporting the model are reported.
Neuromodulation can change not only the mean firing rate of a  neuron, but also its pattern of firing. Therefore, a reliable neural coding scheme, whether a rate coding or a spike time based  coding, must be robust in a dynamic neuromodulatory environment. The common observation that cholinergic modulation leads  to a reduction in spike frequency adaptation implies a modification of spike timing, which would make a neural code based on  precise spike timing difficult to maintain. In this paper, the effects  of cholinergic modulation were studied to test the hypothesis that  precise spike timing can serve as a reliable neural code. Using the  whole cell patch-clamp technique in rat neocortical slice preparation and compartmental modeling techniques, we show that cholinergic modulation, surprisingly, preserved spike timing in response  to a fluctuating inputs that resembles in vivo conditions. This result suggests that in vivo spike timing may be much more resistant  to changes in neuromodulator concentrations than previous physiological studies have implied.  112 A. C. Tang, A.M. Bartels and T. J. Sejnowski
A general feature of the cerebral cortex is its massive interconnectivity it has been estimated anatomically [19] that cortical  neurons receive upwards of 5,000 synapses, the majority of which  originate from other nearby cortical neurons. Numerous experiments in primary visual cortex (V1) have revealed strongly nonlinear interactions between stimulus elements which activate classical  and non-classical receptive field regions. Recurrent cortical connections likely contribute substantially to these effects. However,  most theories of visual processing have either assumed a feedforward processing scheme [7], or have used recurrent interactions to  account for isolated effects only [1, 16, 18]. Since nonlinear systems cannot in general be taken apart and analyzed in pieces, it  is not clear what one learns by building a recurrent model that  only accounts for one, or very few phenomena. Here we develop  a relatively simple model of recurrent interactions in V1, that reflects major anatomical and physiological features of intracortical  connectivity, and simultaneously accounts for a wide range of phenomena observed physiologically. All phenomena we address are  strongly nonlinear, and cannot be explained by linear feedforward  models.
The parameter space of neural networks has a Riemannian metric structure. The natural Riemannian gradient should be used  instead of the conventional gradient, since the former denotes the  true steepest descent direction of a loss function in the Riemannian  space. The behavior of the stochastic gradient learning algorithm  is much more effective if the natural gradient is used. The present  paper studies the information-geometrical structure of perceptrons  and other networks, and prove that the on-line learning method  based on the natural gradient is asymptotically as efficient as the  optimal batch algorithm. Adaptive modification of the learning  constant is proposed and analyzed in terms of the Riemannian measure and is shown to be efficient. The natural gradient is finally  applied to blind separation of mixtured independent signal sources.
This paper shows that if a large neural network is used for a pattern  classification problem, and the learning algorithm finds a network  with small weights that has small squared error on the training  patterns, then the generalization performance depends on the size  of the weights rather than the number of weights. More specifically, consider an t-layer feed-forward network of sigmoid units, in  which the sum of the magnitudes of the weights associated with  each unit is bounded by A. The misclassification probability converges to an error estimate (that is closely related to squared error  on the training set) at rate O((cA)t(t+l)/2v/(logn)/m ) ignoring  log factors, where m is the number of training patterns, n is the  input dimension, and c is a constant. This may explain the generalization performance of neural networks, particularly when the  number of training examples is considerably smaller than the number of weights. It also supports heuristics (such as weight decay  and early stopping) that attempt to keep the weights small during  training.
A new method to calculate the full training process of a neural network is introduced. No sophisticated methods like the replica trick  are used. The results are directly related to the actual number of  training steps. Some results are presented here, like the maximal  learning rate, an exact description of early stopping, and the necessary number of training steps. Further problems can be addressed  with this approach.
We study the number of hidden layers required by a multilayer neural network with threshold units to compute a function f from T½d  to {0, 1}. In dimension d = 2, Gibson characterized the functions  computable with just one hidden layer, under the assumption that  there is no "multiple intersection point" and that f is only defined  on a compact set. We consider the restriction of f to the neighborhood of a multiple intersection point or of infinity, and give necessary and sufficient conditions for it to be locally computable with  one hidden layer. We show that adding these conditions to Gibson's assumptions is not sufficient to ensure global computability  with one hidden layer, by exhibiting a new non-local configuration,  the "critical cycle", which implies that f is not computable with  one hidden layer.
A new regression technique based on Vapnik's concept of support  vectors is introduced. We compare support vector regression (SVR)  with a committee regression technique (bagging) based on regression  trees and ridge regression done in feature space. On the basis of these  experiments, it is expected that SVR will have advantages in high  dimensionality space because SVR optimization does not depend on the  dimensionality of the input space.
This article presents a new result about the size of a multilayer  neural network computing real outputs for exact learning of a finite  set of real samples. The architecture of the network is feedforward,  with one hidden layer and several outputs. Starting from a fixed  training set, we consider the network as a function of its weights.  We derive, for a wide family of transfer functions, a lower and an  upper bound on the number of hidden units for exact learning,  given the size of the dataset and the dimensions of the input and  output spaces.
The convergence properties of the gradient descent algorithm in the  case of the linear perceptton may be obtained from the response  function. We derive a general expression for the response function  and apply it to the case of data with simple input correlations. It  is found that correlations severely may slow down learning. This  explains the success of PCA as a method for reducing training time.  Motivated by this finding we furthermore propose to transform the  input data by removing the mean across input variables as well as  examples to decrease correlations. Numerical findings for a medical  classification problem are in fine agreement with the theoretical  results.
We propose a new method to compute prediction intervals. Especially for small data sets the width of a prediction interval does not  only depend on the variance of the target distribution, but also on  the accuracy of our estimator of the mean of the target, i.e., on the  width of the confidence interval. The confidence interval follows  from the variation in an ensemble of neural networks, each of them  trained and stopped on bootstrap replicates of the original data set.  A second improvement is the use of the residuals on validation patterns instead of on training patterns for estimation of the variance  of the target distribution. As illustrated on a synthetic example,  our method is better than existing methods with regard to extrapolation and interpolation in data regimes with a limited amount of  data, and yields prediction intervals which actual confidence levels  are closer to the desired confidence levels.
We study generalization capability of the mixture of experts learning from examples generated by another network with the same  architecture. When the number of examples is smaller than a critical value, the network shows a symmetric phase where the role  of the experts is not specialized. Upon crossing the critical point,  the system undergoes a continuous phase transition to a symmetry breaking phase where the gating network partitions the input  space effectively and each expert is assigned to an appropriate subspace. We also find that the mixture of experts with multiple level  of hierarchy shows multiple phase transitions.
Results of a study of the worst case learning curves for a particular class of probability distribution on input space to MLP with  hard threshold hidden units are presented. It is shown in particular, that in the thermodynamic limit for scaling by the number  of connections to the first hidden layer, although the true learning  curve behaves as  a - for a  1, its VC-dimension based bound  is trivial (= 1) and its VC-entropy bound is trivial for a _< 6.2. It  is also shown that bounds following the true learning curve can be  derived from a formalism based on the density of error patterns.
In this paper we apply the method of complexity regularization to derive estimation bounds for nonlinear function estimation using a single  hidden layer radial basis function network. Our approach differs from  the previous complexity regularization neural network function learning  schemes in that we operate with random covering numbers and l metric  entropy, making it possible to consider much broader families of activation functions, namely functions of bounded variation. Some constraints  previously imposed on the network parameters are also eliminated this  way. The network is trained by means of complexity regularization involving empirical risk minimization. Bounds on the expected risk in  terms of the sample size are obtained for a large class of loss functions.  Rates of convergence to the optimal loss are also derived.
We study a mistake-driven variant of an on-line Bayesian learning algorithm (similar to one studied by Cesa-Bianchi, Helmbold,  and Panizza [CHP96]). This variant only updates its state (learns)  on trials in which it makes a mistake. The algorithm makes binary  classifications using a linear-threshold classifier and runs in time linear in the number of attributes seen by the learner. We have been  able to show, theoretically and in simulations, that this algorithm  performs well under assumptions quite different from those embodied in the prior of the original Bayesian algorithm. It can handle  situations that we do not know how to handle in linear time with  Bayesian algorithms. We expect our techniques to be useful in  deriving and analyzing other apobayesian algorithms.
We exhibit e[ novel we[y of simule[ting sigmoide[l neure[l nets by networks of noisy spiking neurons in tempotell coding. Furthermore  it is shown theit networks of noisy spiking neurons with tempotell  coding helve e[ strictly le[rger compute[tione[l power thein sigmoide[l  neure[1 nets with the se[me number of units.
We introduce a model for noise-robust analog computations with  disirete time that is flexible enough to cover the most important  concrete cases, such as computations in noisy analog neural nets  and networks of noisy spiking neurons. We show that the presence  of arbitrarily small amounts of analog noise reduces the power of  analog computational models to that of finite automata, and we  also prove a new type of upper bound for the VC-dimension of  computational models with analog noise.
We present an algorithm which is expected to realise Bayes optimal  predictions in large feed-forward networks. It is based on mean field  methods developed within statistical mechanics of disordered systems. We give a derivation for the single layer perceptton and show  that the algorithm also provides a leave-one-out cross-validation  test of the predictions. Simulations show excellent agreement with  theoretical results of statistical mechanics.
Stochastic (on-line) learning can be faster than batch learning.  Howevex', at late times, the learning rate must be annealed to remove the noise present in the stochastic weight updates. In this  annealing phase, tile convergence rate (in mean square) is at best  proportional to 1/where is the number of input presentations.  An alternative is to increase the batch size to remove the noise. In  this paper we explore convergence for LMS using 1) small but fixed  batch sizes and 2) an adaptive batch size. We show that the best  adaptive batch schedule is exponential and has a rate of convergence which is the same as for annealing, i.e., at best proportional  to
It is shown that conventional computers can be exponentiall x faster  than planar Hopfield networks: although there are planar Hopfield  networks that take exponential time to converge, a stable state of an  arbitrary planar Hopfield network can be found by a conventional  computer in polynomial time. The theory of P$-completeness  gives strong evidence that such a separation is unlikely for nonplanar Hopfield networks, and it is demonstrated that this is also the  case for several restricted classes of nonplanar Hopfield networks,  including those who interconnection graphs are the class of bipartite graphs, graphs of degree 3, the dual of the knight's graph, the  8-neighbor mesh, the hypercube, the butterfly, the cube-connected  cycles, and the shuffle-exchange graph.
This paper investigates the stationary points of a Hebb learning rule  with a sigmoid nonlinearity in it. We show mathematically that when  the input has a low information content, as measured by the input's  variance, this learning rule suppresses learning, that is, forces the weight  vector to converge to the zero vector. When the information content  exceeds a certain value, the rule will automatically begin to learn a  feature in the input. Our analysis suggests that under certain conditions  it is the first principal component that is learned. The weight vector  length remains bounded, provided the variance of the input is finite.  Simulations confirm the theoretical results derived.
Given unlimited computational resources, it is best to use a criterion of minimal expected generalisation error to select a model and  determine its parameters. However, it may be worthwhile to sacrifice some generalisation performance for higher learning speed.  A method for quantifying sub-optimality is set out here, so that  this choice can be made intelligently. Furthermore, the method  is applicable to a broad class of models, including the ultra-fast  memory-based methods such as RAMnets. This brings the added  benefit of providing, for the first time, the means to analyse the  generalisation properties of such models in a Bayesian framework.
We study the effect of noise and regularization in an on-line  gradient-descent learning scenario for a general two-layer student  network with an arbitrary number of hidden units. Training examples are randomly drawn input vectors labeled by a two-layer  teacher network with an arbitrary number of hidden units; the examples are corrupted by Gaussian noise affecting either the output  or the model itself. We examine the effect of both types of noise  and that of weight-decay regularization on the dynamical evolution of the order parameters and the generalization error in various  phases of the learning process.
Given a multidimensional data set and a model of its density,  we consider how to define the optimal interpolation between two  points. This is done by assigning a cost to each path through space,  based on two competing goals--one to interpolate through regions  of high density, the other to minimize arc length. From this path  functional, we derive the Euler-Lagrange equations for extremal  motion; given two points, the desired interpolation is found by solving a boundary value problem. We show that this interpolation can  be done efficiently, in high dimensions, for Gaussian, Dirichlet, and  mixture models.
We analyse online learning from finite training sets at noninfinitesimal learning rates r/. By an extension of statistical mechanics methods, we obtain exact results for the time-dependent  generalization error of a linear network with a large number of  weights N. We find, for example, that for small training sets of  size p  N, larger learning rates can be used without compromising asymptotic generalization performance or convergence speed.  Encouragingly, for optimal settings of r/ (and, less importantly,  weight decay A) at given final learning time, the generalization performance of online learning is essentially as good as that of offiine  learning.
The Support Vector (SV) method was recently proposed for estimating regressions, constructing multidimensional splines, and  solving linear operator equations [Vapnik, 1995]. In this presentation we report results of applying the SV method to these problems.
The learning properties of a universal approximator, a normalized  committee machine with adjustable biases, are studied for on-line  back-propagation learning. Within a statistical mechanics framework, numerical studies show that this model has features which  do not exist in previously studied two-layer network models without adjustable biases, e.g., attractive suboptimal symmetric phases  even for realizable cases and noiseless data.
For neural networks with a wide class of weight-priors, it can be  shown that in the limit of an infinite number of hidden units the  prior over functions tends to a Gaussian process. In this paper analytic forms are derived for the covariance function of the Gaussian  processes corresponding to networks with sigmoidal and Gaussian  hidden units. This allows predictions to be made efficiently using  networks with an infinite number of hidden units, and shows that,  somewhat paradoxically, it may be easier to compute with infinite  networks than finite ones.
We consider the microscopic equations for learning problems in  neural networks. The aligning fields of an example are obtained  from the cavity fields, which are the fields if that example were  absent in the learning process. In a rough energy landscape, we  assume that the density of the local minima obey an exponential  distribution, yielding macroscopic properties agreeing with the first  step replica symmetry breaking solution. Iterating the microscopic  equations provide a learning algorithm, which results in a higher  stability than conventional algorithms.
We consider the problem of prediction of stationary time series,  using the architecture known as mixtures of experts (MEM). Here  we suggest a mixture which blends several autoregressive models.  This study focuses on some theoretical foundations of the prediction problem in this context. More precisely, it is demonstrated  that this model is a universal approximator, with respect to learning the unknown prediction function. This statement is strengthened as upper bounds on the mean squared error are established.  Based on these results it is possible to compare the MEM to other  families of models (e.g., neural networks and state dependent models). It is shown that a degenerate version of the MEM is in fact  equivalent to a neural network, and the number of experts in the  architecture plays a similar role to the number of hidden units in  the latter model.  310 A. J. Zeevi, R. Meir and R. J. Adler
The genetic algorithm (GA) is a heuristic search procedure based on mechanisms  abstracted from population genetics. In a previous paper [Baluja & Caruana, 1995],  we showed that much simpler algorithms, such as hillclimbing and PopulationBased Incremental Learning (PBIL), perform comparably to GAs on an optimization problem custom designed to benefit from the GA's operators. This paper  extends these results in two directions. First, in a large-scale empirical comparison  of problems that have been reported in GA literature, we show that on many problems, simpler algorithms can perform significantly better than GAs. Second, we  describe when crossover is useful, and show how it can be incorporated into PBIL.
A classifier is called consistent with respect to a given set of classlabeled points if it correctly classifies the set. We consider classitiers defined by unions of local separators and propose algorithms  for consistent classifier reduction. The expected complexities of the  proposed algorithms are derived along with the expected classifier  sizes. In particular, the proposed approach yields a consistent reduction of the nearest neighbor classifier, which performs "firm"  classification, assigning each new object to a class, regardless of  the data structure. The proposed reduction method suggests a  notion of "soft" classification, allowing for indecision with respect  to objects which are insufficiently or ambiguously supported by  the data. The performances of the proposed classifiers in predicting stock behavior are compared to that achieved by the nearest  neighbor method.
The techniques of Bayesian inference have been applied with great  success to many problems in neural computing including evaluation  of regression functions, determination of error bars on predictions,  and the treatment of hyper-parameters. However, the problem of  model comparison is a much more challenging one for which current  techniques have significant limitations. In this paper we show how  an extended form of Markov chain Monte Carlo, called chaining,  is able to provide effective estimates of the relative probabilities of  different models. We present results from the robot arm problem  and compare them with the corresponding results obtained using  the standard Gaussian approximation framework.
The full Bayesian method for applying neural networks to a prediction problem is to set up the prior/hyperprior structure for the  net and then perform the necessary integrals. However, these integrals are not tractable analytically, and Markov Chain Monte Carlo  (MCMC) methods are slow, especially if the parameter space is  high-dimensional. Using Gaussian processes we can approximate  the weight space integral analytically, so that only a small number  of hyperparameters need be integrated over by MCMC methods.  We have applied this idea to classification problems, obtaining excellent results on the real-world problems investigated so far.
In most treatments of the regression problem it is assumed that  the distribution of target data can be described by a deterministic  function of the inputs, together with additive Gaussian noise having constant variance. The use of maximum likelihood to train such  models then corresponds to the minimization of a sum-of-squares  error function. In many applications a more realistic model would  allow the noise variance itself to depend on the input variables.  However, the use of maximum likelihood to train such models would  give highly biased results. In this paper we show how a Bayesian  treatment can allow for an input-dependent variance while overcoming the bias of maximum likelihood.
The Self-Organizing Map (SOM) algorithm has been extensively  studied and has been applied with considerable success to a wide  variety of problems. However, the algorithm is derived from heuristic ideas and this leads to a number of significant limitations. In  this paper, we consider the problem of modelling the probability density of data in a space of several dimensions in terms of  a smaller number of latent, or hidden, variables. We introduce a  novel form of latent variable model, which we call the GTM algorithm (for Generarive Topographic Mapping), which allows general  non-linear transformations from latent space to data space, and  which is trained using the EM (expectation-maximization) algorithm. Our approach overcomes the limitations of the SOM, while  introducing no significant disadvantages. We demonstrate the performance of the GTM algorithm on simulated data from flow diagnostics for a multi-phase oil pipeline.
The power of sampling methods in Bayesian reconstruction of noisy  signals is well known. The extension of sampling to temporal problems is discussed. Efficacy of sampling over time is demonstrated  with visual tracking.
The problem of assigning m points in the n-dimensional real space  R n to k clusters is formulated as that of determining k centers in  R n such that the sum of distances of each point to the nearest  center is minimized. If a polyhedral distance is used, the problem  can be formulated as that of minimizing a piecewise-linear concave  function on a polyhedral set which is shown to be equivalent to  a bilinear program: minimizing a bilinear function on a polyhedral set. A fast finite k-Median Algorithm consisting of solving  few linear programs in closed form leads to a stationary point of  the bilinear program. Computational testing on a number of realworld databases was carried out. On the Wisconsin Diagnostic  Breast Cancer (WDBC) database, k-Median training set correctness was comparable to that of the k-Mean Algorithm, however its  testing set correctness was better. Additionally, on the Wisconsin  Prognostic Breast Cancer (WPBC) database, distinct and clinically important survival curves were extracted by the k-Median  Algorithm, whereas the k-Mean Algorithm failed to obtain such  distinct survival curves for the same database.
Support Vector Learning Machines (SVM) are finding application  in pattern recognition, regression estimation, and operator inversion for ill-posed problems. Against this very general backdrop,  any methods for improving the generalization performance, or for  improving the speed in test phase, of SVMs are of increasing interest. In this paper we combine two such techniques on a pattern  recognition problem. The method for improving generalization performance (the "virtual support vector" method) does so by incorporating known invariances of the problem. This method achieves  a drop in the error rate on 10,000 NIST test digit images of 1.4%  to 1.0%. The method for improving the speed (the "reduced set"  method) does so by approximating the support vector decision surface. We apply this method to achieve a factor of fifty speedup in  test phase over the virtual support vector machine. The combined  approach yields a machine which is both 22 times faster than the  original machine, and which has better generalization performance,  achieving 1.1% error. The virtual support vector method is applicable to any SVM problem with known invariances. The reduced  set method is applicable to any support vector machine.
We describe the notion of "equivalent kernels" and suggest that this  provides a framework for comparing different classes of regression models,  including neural networks and both parametric and non-parametric  statistical techniques. Unfortunately, standard techniques break down when  faced with models, such as neural networks, in which there is more than one  "layer" of adjustable parameters. We propose an algorithm which overcomes  this limitation, estimating the equivalent kernels for neural network models  using a data perturbation approach. Experimental results indicate that the  networks do not use the maximum possible number of degrees of freedom,  that these can be controlled using regularisation techniques and that the  equivalent kernels learnt by the network vary both in "size" and in "shape"  in different regions of the input space.  1
In supervised learning there is usually a clear distinction between  inputs and outputs -inputs are what you will measure, outputs  are what you will predict from those measurements. This paper  shows that the distinction between inputs and outputs is not this  simple. Some features are more useful as extra outputs than as  inputs. By using a feature as an output we get more than just the  case values but CalX learn a mapping from the other inputs to that  feature. For many features this mapping may be more useful than  the feature value itself. We present two regression problems and  one classification problem where performance improves if features  that could have been used as inputs are used as extra outputs  instead. This result is surprising since a feature used as an output  is not used during testing.
The paper is developed in two parts where we discuss a new approach  to self-organization in a single-layer linear feed-forward network. First,  two novel algorithms for self-organization are derived from a two-layer  linear hetero-associative network performing a one-of-m classification,  and trained with the constrained least-mean-squared classification error  criterion. Second, two adaptive algorithms are derived from these selforganizing procedures to compute the principal generalized  eigenvectors of two correlation matrices from two sequences of  random vectors. These novel adaptive algorithms can be implemented  in a single-layer linear feed-forward network. We give a rigorous  convergence analysis of the adaptive algorithms by using stochastic  approximation theory. As an example, we consider a problem of online  signal detection in digital mobile communications.
This work investigates the representational and inductive capabilities of time-delay neural networks (TDNNs) in general, and of two  subclasses of TDNN, those with delays only on the inputs (IDNN),  and those which include delays on hidden units (HDNN). Both architectures are capable of representing the same class of languages,  the definite memory machine (DMM) languages, but the delays on  the hidden units in the HDNN helps it outperform the IDNN on  problems composed of repeated features over short time windows.
A globally convergent homotopy method is defined that is capable  of sequentially producing large numbers of stationary points of the  multi-layer perceptron mean-squared error surface. Using this algorithm large subsets of the stationary points of two test problems  are found. It is shown empirically that the MLP neural network  appears to have an extreme ratio of saddle points compared to  local minima, and that even small neural network problems have  extremely large numbers of solutions.
I describe a querying criterion that attempts to minimize the error  of a learner by minimizing its estimated squared bias. I describe  experiments with locally-weighted regression on two simple problems, and observe that this "bias-only" approach outperforms the  more common "variance-only" exploration approach, even in the  presence of noise.
In many optimization problems, the structure of solutions reflects  complex relationships between the different input parameters. For  example, experience may tell us that certain parameters are closely  related and should not be explored independently. Similarly, experience may establish that a subset of parameters must take on  particular values. Any search of the cost landscape should take  advantage of these relationships. We present MIMIC, a framework  in which we analyze the global structure of the optimization landscape. A novel and efficient algorithm for the estimation of this  structure is derived. We use knowledge of this structure to guide a  randomized search through the solution space and, in turn, to refine our estimate of the structure. Our technique obtains significant  speed gains over other randomized optimization procedures.
A modification is described to the use of mean field approximations in the E step of EM algorithms for analysing data from latent  structure models, as described by Ghahramani (1995), among others. The modification involves second-order Taylor approximations  to expectations computed in the E step. The potential benefits of  the method are illustrated using very simple latent profile models.
This paper describes a new framework for relational graph matching. The starting point is a recently reported Bayesian consistency  measure which gauges structural differences using Hamming distance. The main contributions of the work are threefold. Firstly,  we demonstrate how the discrete components of the cost function can be softened. The second contribution is to show how  the softened cost function can be used to locate matches using  continuous nonlinear optimisation. Finally, we show how the resulting graph matching algorithm relates to the standard quadratic  assignment problem.
The limitations of using self-organizing maps (SOM) for either  clustering/vector quantization (VQ) or multidimensional scaling  (MDS) are being discussed by reviewing recent empirical findings  and the relevant theory. SOM's remaining ability of doing both VQ  and MDS at the same time is challenged by a new combined technique of online K-means clustering plus Sammon mapping of the  cluster centroids. SOM are shown to perform significantly worse in  terms of quantization error, in recovering the structure of the clusters and in preserving the topology in a comprehensive empirical  study using a series of multivariate normal clustering problems.
Real-valued random hidden variables can be useful for modelling  latent structure that explains correlations among observed variables. I propose a simple unit that adds zero-mean Gaussian noise  to its input before passing it through a sigmoidal squashing function. Such units can produce a variety of useful behaviors, ranging  from deterministic to binary stochastic to continuous stochastic. I  show how "slice sampling" can be used for inference and learning  in top-down networks of these units and demonstrate learning on  two simple problems.
We propose a novel approach to automatically growing and pruning  Hierarchical Mixtures of Experts. The constructive algorithm proposed here enables large hierarchies consisting of several hundred  experts to be trained effectively. We show that HME's trained by  our automatic growing procedure yield better generalization performance than traditional static and balanced hierarchies. Evaluation of the algorithm is performed (1) on vowel classification  and (2) within a hybrid version of the JANUS [9] speech recognition system using a subset of the Switchboard large-vocabulary  speaker-independent continuous speech recognition database.
We compare different methods to combine predictions from neural networks trained on different bootstrap samples of a regression  problem. One of these methods, introduced in [6] and which we  here call balancing, is based on the analysis of the ensemble generalization error into an ambiguity term and a term incorporating  generalization performances of individual networks. We show how  to estimate these individual errors from the residuals on validation patterns. Weighting factors for the different networks follow  from a quadratic programming problem. On a real-world problem  concerning the prediction of sales figures and on the well-known  Boston housing data set, balancing clearly outperforms other recently proposed alternatives as bagging [1] and bumping [8].
Standard recurrent nets cannot deal with long minimal time lags  between relevant signals. Several recent NIPS papers propose alternative methods. We first show: problems used to promote various  previous algorithms can be solved more quickly by random weight  guessing than by the proposed algorithms. We then use LSTM,  our own recent algorithm, to solve a hard problem that can neither  be quickly solved by random search nor by any other recurrent net  algorithm we are aware of.
Neural one-unit learning rules for the problem of Independent Component Analysis (ICA) and blind source separation are introduced.  In these new algorithms, every ICA neuron develops into a separator that finds one of the independent components. The learning  rules use very simple constrained Hebbian/anti-Hebbian learning  in which decorrelating feedback may be added. To speed up the  convergence of these stochastic gradient descent rules, a novel computationally efficient fixed-point algorithm is introduced.
We develop a recursive node-elimination formalism for efficiently  approximating large probabilistic networks. No constraints are set  on the network topologies. Yet the formalism can be straightforwardly integrated with exact methods whenever they are/become  applicable. The approximations we use are controlled: they maintain consistently upper and lower bounds on the desired quantities  at all times. We show that Boltzmann machines, sigmoid belief  networks, or any combination (i.e., chain graphs) can be handled  within the same framework. The accuracy of the methods is verified experimentally.
To obtain classification systems with both good generalization performance and efficiency in space and time, we propose a learning  method based on combinations of weak classifiers, where weak classifters are linear classifiers (percepttons) which can do a little better  than making random guesses. A randomized algorithm is proposed  to find the weak classifiers. They' are then combined through a majority vote. As demonstrated through systematic experiments, the  method developed is able to obtain combinations of weak classifiers  with good generalization performance and a fast training time on  a variety of test problems and real applications.
We study a time series model that can be viewed as a decision  tree with Markov temporal structure. The model is intractable for  exact calculations, thus we utilize variational approximations. We  consider three different distributions for the approximation: one in  which the Markov calculations are performed exactly and the layers  of the decision tree are decoupled, one in which the decision tree  calculations are performed exactly and the time steps of the Markov  chain are decoupled, and one in which a Viterbi-like assumption is  made to pick out a single most likely state sequence. We present  simulation results for artificial data and the Bach chorales.
In the present paper, we propose a method to unify information maximization and minimization in hidden units. The information maximization and minimization are performed on two different levels: collective and individual level. Thus, two kinds of information: collective and individual information are defined. By maximizing collective information and by minimizing individual information, simple networks can be generated in terms of the number of connections and the number of hidden units. Obtained networks are expected to give better generalization and improved interpretation of internal representations. This method was applied to the inference of the maximum onset principle of an artificial language. In this problem, it was shown that the individual information minimization is not contradictory to the collective information maximization. In addition, experimental results confirmed improved generalization performance, because over-training can significantly be suppressed. 
Unsupervised leaxning algorithms based on convex and conic encoders are proposed. The encoders find the closest convex or conic  combination of basis vectors to the input. The learning algorithms  produce basis vectors that minimize the reconstruction error of the  encoders. The convex algorithm develops locally linear models of  the input, while the conic algorithm discovers features. Both algorithms are used to model handwritten digits and compared with  vector quantization and principal component analysis. The neural  network implementations involve feedback connections that project  a reconstruction back to the input layer.
We introduce arc-lh, a new algorithm for improvement of ANN classifter performance, which measures the importance of patterns by  aggregated network output errors. On several artificial benchmark  problems, this algorithm compares favorably with other resample  and combine techniques.
Multilayer architectures such as those used in Bayesian belief networks and Helmholtz machines provide a powerful framework for  representing and learning higher order statistical relations among  inputs. Because exact probability calculations with these models are often intractable, there is much interest in finding approximate algorithms. We present an algorithm that efficiently discovers  higher order structure using EM and Gibbs sampling. The model  can be interpreted as a stochastic recurrent network in which ambiguity in lower-level states is resolved through feedback from higher  levels. We demonstrate the performance of the algorithm on benchmark problems.
We couple the tasks of source separation and density estimation  by extracting the local geometrical structure of distributions obtained from mixtures of statistically independent sources. Our  modifications of the self-organizing map (SOM) algorithm results  in purely digital learning rules which perform non-parametric histogram density estimation. The non-parametric nature of the separation allows for source separation of non-linear mixtures. An  anisotropic coupling is introduced into our $OM with the role of  aligning the network locally with the independent component contours. This approach provides an exact verification condition for  source separation with no prior on the source distributions.
Dimension-reducing feature extraction neural network techniques  which also preserve neighbourhood relationships in data have traditionally been the exclusive domain of Kohonen self organising  maps. Recently, we introduced a novel dimension-reducing feature  extraction process, which is also topographic, based upon a Radial  Basis Function architecture. It has been observed that the generalisation performance of the system is broadly insensitive to model  order complexity and other smoothing factors such as the kernel  widths, contrary to intuition derived from supervised neural network models. In this paper we provide an effective demonstration  of this property and give a theoretical justification for the apparent  'self-regularising' behaviour of the 'NEUROSCALE' architecture.  1  'NeuroScale': A Feed-forward Neural Network  Topographic Transformation  Recently an important class of topographic neural network based feature extraction  approaches, which can be related to the traditional statistical methods of Sammon  Mappings (Sammon, 1969) and Multidimensional Scaling (Kruskal, 1964), have  been introduced (Mao and Jain, 1995; Lowe, 1993; Webb, 1995; Lowe and Tipping,  1996). These novel alternatives to Kohonen-like approaches for topographic feature  extraction possess several interesting properties. For instance, the NEUROSCALE  architecture has the empirically observed property that the generalisation perfor544 D. Lowe and M. E. Tipping  mance does not seem to depend critically on model order complexity, contrary to  intuition based upon knowledge of its supervised counterparts. This paper presents  evidence for their 'self-regularising' behaviour and provides an explanation in terms  of the curvature of the trained models.
The classes in classification tasks often have a natural ordering, and the training and testing examples are often incomplete. We propose a nonlinear ordinal model for classification into ordered classes. Predictive, simulation-based approaches are used to learn from past and classify future incomplete examples. These techniques are illustrated by making prognoses for patients who have suffered severe head injuries. 
When triangulating a belief network we aim to obtain a junction  tree of minimum state space. According to (Rose, 1970), searching  for the optimal triangulation can be cast as a search over all the  permutations of the graph's vertices. Our approach is to embed  the discrete set of permutations in a convex continuous domain D.  By suitably extending the cost function over D and solving the  continous nonlinear optimization task we hope to obtain a good  triangulation with respect to the aformentioned cost. This paper  presents two ways of embedding the triangulation problem into  continuous domain and shows that they perform well compared to  the best known heuristic.
When combining a set of learned models to form an improved estimator, the issue of redundancy or multicollinearity in the set of  models must be addressed. A progression of existing approaches  and their limitations with respect to the redundancy is discussed.  A new approach, PCR*, based on principal components regression is proposed to address these limitations. An evaluation of the  new approach on a collection of domains reveals that: 1) PCR*  was the most robust combination method as the redundancy of the  learned models increased, 2) redundancy could be handled without  eliminating any of the learned models, and 3) the principal components of the learned models provided a continuum of "regularized"  weights from which PCR* could choose.
We address statistical classifier design given a mixed training set consisting of a small labelled feature set and a (generally larger) set of  unlabelledfeatures. This situation arises, e.g., for medical images, where  although training features may be plentiful, expensive expertise is required to extract their class labels. We propose a classifier structure  and learning algorithm that make effective use of unlabelled data to improve performance. The learning is based on maximization of the total  data likelihood, i.e. over both the labelled and unlabelled data subsets. Two disinc EM learning algorithms are proposed, differing in the  EM formalism applied for unlabelled data. The classifier, based on a  joint probability model for features and labels, is a "mixture of experts"  structure that is equivalent to the radial basis function (RBF) classifier,  but unlike PuBFs, is amenable to likelihood-based training. The scope of  application for the new method is greatly extended by the observation  that test data, or any new data to classify, is in fact additional, unlabelled  daathus, a combined learning/classification operation much akin to  what is done in image segmentation can be invoked whenever there  is new data to classify. Experiments with data sets from the UC Irvine  database demonstrate that the new learning algorithms and structure  achieve substantial performance gains over alternative approaches.
In this paper we propose a method for learning Bayesian belief  networks from data. The method uses artificial neural networks  as probability estimators, thus avoiding the need for making prior  assumptions on the nature of the probability distributions governing the relationships among the participating variables. This new  method has the potential for being applied to domains containing  both discrete and continuous variables arbitrarily distributed. We  compare the learning performance of this new method with the  performance of the method proposed by Cooper and Herskovits  in [7]. The experimental results show that, although the learning  scheme based on the use of ANN estimators is slower, the learning  accuracy of the two methods is comparable.  Category: Algorithms and Architectures.
Smoothing regularizers for radial basis functions have been studied extensively,  but no general smoothing regularizers for projective basis functions (PBFs), such  as the widely-used sigmoidal PBFs, have heretofore been proposed. We derive new classes of algebraically-simple rn h-order smoothing regularizers for  networks of the form f(W, x) = Y'j%l uj7 [X Tvj '}' Vj0] + It0, with general  projectire basis functions 9[']. These reguladzers are:  N  R(W,,)  ,11vjll 2'- Global Form  j=l  N  Rt(W,m)  2 112,,,  u I lvj al Form  ./=1  These regularizers bound the corresponding rn ø'-order smoothing integral  where W denotes all the network weights { u, uo, v, vo}, and (x) is a weighting function on the D-dimensional input space. The global and local cases are  distinguished by different choices of  The simple algebraic forms R(W, m) enable the direct enforcement of smoothness without the need for cosily Monte-Carlo integrations of S(W, m). The new  regularizers are shown to yield better generalization errors than weight decay  when the implicit assumptions in the latter are wrong. Unlike weight decay, the  new regularizers distinguish between the roles of the input and output weights  .and capture the interactions between them.  *Address as of September 1, 1996: Centre for Computer Architecture, University of Halmstad,  P.O.Box 823, S-301 18 Halmstad, Sweden  586 J. E. Moody and T. S. R6gnvaldsson
The separation of generalization error into two types, bias and variance  (Geman, Bienenstock, Doursat, 1992), leads to the notion of error  reduction by averaging over a "committee" of classifiers (Perrone,  1993). Committee performance decreases with both the average error of  the constituent classifiers and increases with the degree to which the  misclassifications are correlated across the committee. Here, a method  for reducing correlations is introduced, that uses a winner-take-all  procedure similar to competitive learning to drive the individual  networks to different minima in weight space with respect to the  training set, such that correlations in generalization performance will be  reduced, thereby reducing committee error.
An adaptive on-line algorithm extending the learning of learning  idea is proposed and theoretically motivated. Relying only on gradient flow information it can be applied to learning continuous  functions or distributions, even when no explicit loss function is given and the Hessian is not available. Its efficiency is demonstrated  for a non-stationary blind separation task of acoustic signals.
We present an algorithm for fast stochastic gradient descent that  uses a nonlinear adaptive momentum scheme to optimize the late  time convergence rate. The algorithm makes effective use of curvature information, requires only (9(n) storage and computation,  and delivers convergence rates close to the theoretical optimum.  We demonstrate the technique on linear and large nonlinear backprop networks.  Improving Stochastic Search  Learning algorithms that perform gradient descent on a cost function can be formulated in either stochastic (on-line) or batch form. The stochastic version takes  the form  = +  where cot is the current weight estimate, Pt is the learning rate, G is minus the  instantaneous gradient estimate, and xt is the input at time t x. One obtains the  corresponding batch mode learning rule by taking/ constant and averaging G over  all x.  Stochastic learning provides several advantages over batch learning. For large  datasets the batch average is expensive to compute. Stochastic learning eliminates  the averaging. The stochastic update can be regarded as a noisy estimate of the  batch update, and this intrinsic noise can reduce the likelihood of becoming trapped  in poor local optima [1, 2].  We assume that the inputs are i.i.d. This is achieved by random sampling with replacement from the training data.  Using Curvature Information for Fast Stochastic Search 607  The noise must be reduced late in the training to allow weights to converge. After  settling within the basin of a local optimum w., learning rate annealing allows convergence of the weight error v = w w.. It is well-known that the expected squared  weight error, E[[v[ 2] decays at its maximal rate oc 1It with the annealing schedule  Io/t. Furthermore to achieve this rate one must have 0 > Icrit = 1/(2Amin) where  Amin is the smallest eigenvalue of the Hessian at w. [3, 4, 5, and references therein].  Finally the optimal io, which gives the lowest possible value of E[[v[ 2] is 0 = 1/A.  In multiple dimensions the optimal learning rate matrix is (t) = (l/t)7-/-,where  7-/is the Hessian at the local optimum.  Incorporating this curvature information into stochastic learning is difficult for two  reasons. First, the Hessian is not available since the point of stochastic learning is  not to perform averages over the training data. Second, even if the Hessian were  available, optimal learning requires its inverse which is prohibitively expensive to  compute 2  The primary result of this paper is that one can achieve an algorithm that behaves  optimally, i.e. as if one had incorporated the inverse of the full Hessian, without  the storage or computational burden. The algorithm, which requires only O(n)  storage and computation (n = number of weights in the network), uses an adaptive  momentum parameter, extending our earlier work [7] to fully non-linear problems.  We demonstrate the performance on several large back-prop networks trained with  large datasets.  Implementations of stochastic learning typically use a constant learning rate during  the early part of training (what Darken and Moody [4] call the search phase) to obtain exponential convergence towards a local optimum, and then switch to annealed  learning (called the converge phase). We use Darken and Moody's adaptive search  then converge (ASTC) algorithm to determine the point at which to switch to 1It  annealing. ASTC was originally conceived as a means to insure 0 > Icrit during  the annealed phase, and we compare its performance with adaptive momentum as  well. We also provide a comparison with conjugate gradient optimization.
In the square linear blind source separation problem, one must find  a linear unmixing operator which can detangle the result xi(t) of  mixing n unknown independent sources $i(t) through an unknown  n x n mixing matrix A(t) of causal linear filters: xi = j aij * $j.  We cast the problem as one of maximum likelihood density estimation, and in that framework introduce an algorithm that searches  for independent components using both temporal and spatial cues.  We call the resulting algorithm "Contextual ICA," after the (Bell  and Sejnowski 1995) Infomax algorithm, which we show to be a  special case of cICA. Because cICA can make use of the temporal  structure of its input, it is able separate in a number of situations  where standard methods cannot, including sources with low kurtosis, colored Gaussian sources, and sources which have Gaussian  histograms.
The softassign quadratic assignment algorithm has recently  emerged as an effective strategy for a variety of optimization problems in pattern recognition and combinatorial optimization. While  the effectiveness of the algorithm was demonstrated in thousands  of simulations, there was no known proof of convergence. Here,  we provide a proof of convergence for the most general form of the  algorithm.
This paper compares three penalty terms with respect to the efficiency of supervised learning, by using firstand second-order learning algorithms. Our experiments showed that for a reasonably adequate penalty factor, the combination of the squared penalty term  and the second-order learning algorithm drastically improves the  convergence performance more than 20 times over the other combinations, at the same time bringing about a better generalization  performance.
A hint is any piece of side information about the target function to  be learned. We consider the monotonicity hint, which states that  the function to be learned is monotonic in some or all of the input  variables. The application of monotonicity hints is demonstrated  on two real-world problemsa credit card application task, and a  problem in medical diagnosis. A measure of the monotonicity error  of a candidate function is defined and an objective function for the  enforcement of monotonicity is derived from Bayesian principles.  We report experimental results which show that using monotonicity  hints leads to a statistically significant improvement in performance  on both problems.
We present new algorithms for parameter estimation of HMMs. By  adapting a framework used for supervised learning, we construct iterative  algorithms that maximize the likelihood of the observations while also  attempting to stay "close" to the current estimated parameters. We use a  bound on the relative entropy between the two HMMs as a distance measure between them. The result is new iterative training algorithms which  are similar to the EM (Baum-Welch) algorithm for training HMMs. The  proposed algorithms are composed of a step similar to the expectation  step of Baum-Welch and a new update of the parameters which replaces  the maximization (re-estimation) step. The algorithm takes only negligibly more time per iteration and an approximated version uses the same  expectation step as Baum-Welch. We evaluate experimentally the new  algorithms on synthetic and natural speech pronunciation data. For sparse  models, i.e. models with relatively small number of non-zero parameters,  the proposed algorithms require significantly fewer iterations.
This paper discusses a probabilistic model-based approach to clustering sequences, using hidden Markov models (HMMs). The problem can be framed as a generalization of the standard mixture  model approach to clustering in feature space. Two primary issues  are addressed. First, a novel parameter initialization procedure is  proposed, and second, the more difficult problem of determining  the number of clusters K, from the data, is investigated. Experimental results indicate that the proposed techniques are useful for  revealing hidden cluster structure in data sets of sequences.
The algorithm described in this article is based on the OBS algorithm by Hassibi, Stork and Wolff ([1] and [2]). The main disadvantage of OBS is its high complexity. OBS needs to calculate the  inverse Hessian to delete only one weight (thus needing much time  to prune a big net). A better algorithm should use this matrix to  remove more than only one weight, because calculating the inverse  Hessian takes the most time in the OBS algorithm.  The algorithm, called Unit-OBS, described in this article is a  method to overcome this disadvantage. This algorithm only needs  to calculate the inverse Hessian once to remove one whole unit thus  drastically reducing the time to prune big nets.  A further advantage of Unit-OBS is that it can be used to do a  feature extraction on the input data. This can be helpful on the  understanding of unknown problems.
We seek to analyze and manipulate two factors, which we call style  and content, underlying a set of observations. We fit training data  with bilinear models which explicitly represent the two-factor structure. These models can adapt easily during testing to new styles or  content, allowing us to solve three general tasks: extrapolation of a  new style to unobserved content; classification of content observed  in a new style; and translation of new content observed in a new  style. For classification, we embed bilinear models in a probabilistic  framework, Separable Mixture Models (SMMs), which generalizes  earlier work on factoffal mixture models [7, 3]. Significant performance improvement on a benchmark speech dataset shows the  benefits of our approach.
Optimal Brain Damage (OBD) is a method for reducing the number of weights in a neural network. OBD estimates the increase in  cost function if weights are pruned and is a valid approximation  if the learning algorithm has converged into a local minimum. On  the other hand it is often desirable to terminate the learning process before a local minimum is reached (early stopping). In this  paper we show that OBD estimates the increase in cost function  incorrectly if the network is not in a local minimum. We also show  how OBD can be extended such that it can be used in connection with early stopping. We call this new approach Early Brain  Damage, EBD. EBD also allows to revive already pruned weights.  We demonstrate the improvements achieved by EBD using three  publicly available data sets.
Alexandre Pouget  alexsalk. edu  We present a theoretical framework for population codes which  generalizes naturally to the important case where the population  provides information about a whole probability distribution over  an underlying quantity rather than just a single value. We use  the framework to analyze two existing models, and to suggest and  evaluate a third model for encoding such probability distributions.
Two dimensional image motion detection neural networks have been  implemented using a general purpose analog neural computer. The  neural circuits perform spatiotemporal feature extraction based on the  cortical motion detection model of Adelson and Bergen. The neural  computer provides the neurons, synapses and synaptic time-constants  required to realize the model in VLSI hardware. Results show that  visual motion estimation can be implemented with simple sum-andthreshold neural hardware with temporal computational capabilities.  The neural circuits compute general 2D visual motion in real-time.
Many popular learning rules are formulated in terms of continuous, analog inputs and outputs. Biological systems, however, use  action potentials, which are digital-amplitude events that encode  analog information in the inter-event interval. Action-potential  representations are now being used to advantage in neuromorphic  VLSI systems as well. We report on a simple learning rule, based  on the Riccati equation described by Kohonen [1], modified for  action-potential neuronal outputs. We demonstrate this learning  rule in an analog VLSI chip that uses volatile capacitive storage for  synaptic weights. We show that our time-dependent learning rule  is sufficient to achieve approximate weight normalization and can  detect temporal correlations in spike trains.  A Spike Based Learning Neuron in Analog VLSI 693
We use the constant statistics constraint to calibrate an array of  sensors that contains gain and offset variations. This algorithm has  been mapped to analog hardware and designed and fabricated with  a 2um CMOS technology. Measured results from the chip show that  the system achieves invariance to gain and offset variations of the  input signal.
A one-dimensional visual tracking chip has been implemented using neuromorphic, analog VLSI techniques to model selective visual  attention in the control of saccadic and smooth pursuit eye movements. The chip incorporates focal-plane processing to compute  image saliency and a winner-take-all circuit to select a feature for  tracking. The target position and direction of motion are reported  as the target moves across the array. We demonstrate its functionality in a closed-loop system which performs saccadic and smooth  pursuit tracking movements using a one-dimensional mechanical  eye.
The major problem that has prevented practical application of analog  neuro-LSIs has been poor accuracy due to fluctuating analog device  characteristics inherent in each device as a result of manufacturing.  This paper proposes a dynamic control architecture that allows analog  silicon neural networks to compensate for the fluctuating device  characteristics and adapt to a change in input DC level. We have  applied this architecture to compensate for input offset voltages of an  analog CMOS WTA (Winner-Take-All) chip that we have fabricated.  Experimental data show the effectiveness of the architecture.
We have designed, fabricated, and tested an adaptive WinnerTake-All (WTA) circuit based upon the classic WTA of Lazzaro,  et al [1]. We have added a time dimension (adaptation) to this  circuit to make the input derivative an important factor in winner  selection. To accomplish this, we have modified the classic WTA  circuit by adding floating gate transistors which slowly null their  inputs over time. We present a simplified analysis and experimental data of this adaptive WTA fabricated in a standard CMOS 2um  process.
We describe the implementation of a hidden Markov model state  decoding system, a component for a wordspotting speech recognition system. The key specification for this state decoder design is  microwatt power dissipation; this requirement led to a continuoustime, analog circuit implementation. We characterize the operation  of a 10-word (81 state) state decoder test chip.
We propose a neuromorphic architecture for real-time processing of  acoustic transients in analog VLSI. We show how judicious normalization  of a time-frequency signal allows an elegant and robust implementation  of a correlation algorithm. The algorithm uses binary multiplexing instead  of analog-analog multiplication. This removes the need for analog  storage and analog-multiplication. Simulations show that the resulting  algorithm has the same out-of-sample classification performance (-93%  correct) as a baseline template-matching algorithm.
Detection of the periodicity of amplitude modulation is a major step in  the determination of the pitch of a sound. In this article we will  present a silicon model that uses synchronicity of spiking neurons to  extract the fundamental frequency of a sound. It is based on the  observation that the so called 'Choppers' in the mammalian Cochlear  Nucleus synchronize well for certain rates of amplitude modulation,  depending on the cell's intrinsic chopping frequency. Our silicon  model uses three different circuits, i.e., an artificial cochlea, an Inner  Hair Cell circuit, and a spiking neuron circuit.
Humans use visual as well as auditory speech signals to recognize  spoken words. A variety of systems have been investigated for performing this task. The main purpose of this research was to systematically compare the performance of a range of dynamic visual  features on a speechreading task. We have found that normalization of images to eliminate variation due to translation, scale,  and planar rotation yielded substantial improvements in generalization performance regardless of the visual representation used. In  addition, the dynamic information in the difference between successive frames yielded better performance than optical-flow based  approaches, and compression by local low-pass filtering worked surprisingly better than global principal components analysis (PCA).  These results are examined and possible explanations are explored.
We address the difficult problem of separating multiple speakers  with multiple microphones in a real room. We combine the work  of Torkkola and Amari, Cichocki and Yang, to give Natural Gradient information maximisation rules for recurrent (IIR) networks,  blindly adjusting delays, separating and deconvolving mixed signals. While they work well on simulated data, these rules fail  in real rooms which usually involve non-minimum phase transfer  functions, not-invertible using stable IIR filters. An approach that  sidesteps this problem is to perform infomax on a feedforward architecture in the frequency domain (Lambert 1996). We demonstrate  real-room separation of two natural signals using this approach. 
This paper discusses a fairly general adaptation algorithm which  augments a standard neural network to increase its recognition accuracy for a specific user. The basis for the algorithm is that the  output of a neural network is characteristic of the input, even when  the output is incorrect. We exploit this characteristic output by  using an Output Adaptation Module (OAM) which maps this output into the correct user-dependent confidence vector. The OAM  is a simplified Resource Allocating Network which constructs radial basis functions on-line. We applied the OAM to construct  a writer-adaptive character recognition system for on-line handprinted characters. The OAM decreases the word error rate on a  test set by an average of 45%, while creating only 3 to 25 basis  functions for each writer in the test set.
This paper presents a new approach to speech recognition with hybrid  HMM/ANN technology. While the standard approach to hybrid  HMM/ANN systems is based on the use of neural networks as  posterior probability estimators, the new approach is based on the use  of mutual information neural networks trained with a special learning  algorithm in order to maximize the mutual information between the  input classes of the network and its resulting sequence of firing output  neurons during training. It is shown in this paper that such a neural  network is an optimal neural vector quantizer for a discrete hidden  Markov model system trained on Maximum Likelihood principles.  One of the main advantages of this approach is the fact, that such  neural networks can be easily combined with HMM's of any  complexity with context-dependent capabilities. It is shown that the  resulting hybrid system achieves very high recognition rates, which  are now already on the same level as the best conventional HMM  systems with continuous parameters, and the capabilities of the  mutual information neural networks are not yet entirely exploited.
Time series prediction is one of the major applications of neural networks. After a short introduction into the basic theoretical foundations we argue that the iterated prediction of a dynamical system may be interpreted as a model of the system dynamics. By means of RBF neural networks we describe a modeling approach and extend it to be able to model instationary systems. As a practical test for the capabilities of the method we investigate the modeling of musical and speech signals and demonstrate that the model may be used for synthesis of musical and speech signals. 
To reduce the computational complexity of classification systems  using tangent distance, Hastie et al. (HSS) developed an algorithm to devise rich models for representing large subsets of the  data which computes automatically the "best" associated tangent subspace. Schwenk & Milgram proposed a discriminant modular classification system (Diabolo) based on several autoassociative  multilayer percepttons which use tangent distance as error reconstruction measure.  We propose a gradient based constructive learning algorithm for  building a tangent subspace model with discriminant capabilities  which combines several of the the advantages of both HSS and  Diabolo: devised tangent models hold discriminant capabilities,  space requirements are improved with respect to HSS since our  algorithm is discriminant and thus it needs fewer prototype models,  dimension of the tangent subspace is determined automatically by  the constructive algorithm, and our algorithm is able to learn new  transformations.
Prediction, estimation, and smoothing are fundamental to signal  processing. To perform these interrelated tasks given noisy data,  we form a time series model of the process that generates the  data. Taking noise in the system explicitly into account, maximumlikelihood and Kalman frameworks are discussed which involve the  dual process of estimating both the model parameters and the underlying state of the system. We review several established methods in the linear case, and propose several extensions utilizing dual  Kalman filters (DKF) and forward-backward (FB) filters that are  applicable to neural networks. Methods are compared on several  simulations of noisy time series. We also include an example of  nonlinear noise reduction in speech.
This paper investigates a number of ensemble methods for improving the performance of phoneme classification for use in a speech  recognition system. Two ensemble methods are described; boosting  and mixtures of experts, both in isolation and in combination. Results are presented on two speech recognition databases: an isolated  word database and a large vocabulary continuous speech database.  These results show that principled ensemble methods such as boosting and mixtures provide superior performance to more naive ensemble methods such as averaging.
Effective Training of a Neural Network  Character Classifier for Word Recognition  Larry Yaeger  Apple Computer  5540 Bittersweet Rd.  Morgantown, IN 46160  larryy @ apple.con  Richard Lyon  Apple Computer
We have explored two approaches to recognizing faces across  changes in pose. First, we developed a representation of face images  based on independent component analysis (ICA) and compared it  to a principal component analysis (PCA) representation for face  recognition. The ICA basis vectors for this data set were more  spatially local than the PCA basis vectors and the ICA representation had greater invariance to changes in pose. Second, we present  a model for the development of viewpoint invariant responses to  faces from visual experience in a biological system. The temporal  continuity of natural visual experience was incorporated into an  attractor network model by Hebbian learning following a lowpass  temporal filter on unit activities. When combined with the temporal filter, a basic Hebbian update rule became a generalization  of Griniasty et al. (1993), which associates temporally proximal  input patterns into basins of attraction. The system acquired representations of faces that were largely independent of pose.
A biologically motivated model of cortical self-organization is proposed. Context is combined with bottom-up information via a  maximum likelihood cost function. Clusters of one or more units  are modulated by a common contextual gating signal; they thereby  organize themselves into mutually supportive predictors of abstract  contextual features. The model was tested in its ability to discover  viewpoint-invariant classes on a set of real image sequences of centered, gradually rotating faces. It performed considerably better  than supervised back-propagation at generalizing to novel views  from a small number of training examples.
Field (1994) has suggested that neurons with line and edge selectivities  found in primary visual cortex of cats and monkeys form a sparse, distributed representation of natural scenes, and Barlow (1989) has reasoned  that such responses should emerge from an unsupervised learning algorithm  that attempts to find a factorial code of independent visual features. We  show here that non-linear 'infomax', when applied to an ensemble of natural scenes, produces sets of visual filters that are localised and oriented.  Some of these filters are Gabor-like and resemble those produced by the  sparseness-maximisation network of Olshausen & Field (1996). In addition,  the outputs of these filters are as independent as possible, since the infomax network is able to perform Independent Components Analysis (ICA).  We compare the resulting ICA filters and their associated basis functions,  with other decorrelating filters produced by Principal Components Analysis  (PCA) and zero-phase whitening filters (ZCA). The ICA filters have more  sparsely distributed (kurtotic) outputs on natural scenes. They also resemble the receptive fields of simple cells in visual cortex, which suggests that  these neurons form an information-theoretic co-ordinate system for images.
Images are ambiguous at each of many levels of a contextual hierarchy. Nevertheless, the high-level interpretation of most scenes  is unambiguous, as evidenced by the superior performance of humans. This observation argues for global vision models, such as deformable templates. Unfortunately, such models are computationally intractable for unconstrained problems. We propose a compositional model in which primitives are recursively composed, subject  to syntactic restrictions, to form tree-structured objects and object  groupings. Ambiguity is propagated up the hierarchy in the form  of multiple interpretations, which are later resolved by a Bayesian,  equivalently minimum-description-length, cost functional.
This paper describes a new technique for object recognition based on learning  appearance models. The image is decomposed into local regions which are  described by a new texture representation called "Generalized Second Moments" that are derived from the output of multiscale, multiorientation filter  banks. Class-characteristic local texture features and their global composition  is learned by a hierarchical mixture of experts architecture (Jordan & Jacobs).  The technique is applied to a vehicle database consisting of 5 general car  categories (Sedan, Van with back-doors, Van without back-doors, old Sedan,  and Volkswagen Bug). This is a difficult problem with considerable in-class  variation. The new technique has a 6.5% misclassification rate, compared to  eigen-images which give 17.4% misclassification rate, and nearest neighbors  which give 15.7% misclassification rate.
In this paper we propose a model for the lateral connectivity of  orientation-selective cells in the visual cortex based on informationtheoretic considerations. We study the properties of the input signal to the visual cortex and find new statistical structures which  have not been processed in the retino-geniculate pathway. Applying  the idea that the system optimizes the representation of incoming  signals, we derive the lateral connectivity that will achieve this for  a set of local orientation-selective patches, as well as the complete  spatial structure of a layer of such patches. We compare the results  with various physiological measurements.
We study the spatiotemporal correlation in natural time-varying  images and explore the hypothesis that the visual system is concerned with the optimal coding of visual representation through  spatiotemporal decorrelation of the input signal. Based on the  measured spatiotemporal power spectrum, the transform needed to  decorrelate input signal is derived analytically and then compared  with the actual processing observed in psychophysical experiments.
Local disparity information is often sparse and noisy, which creates  two conflicting demands when estimating disparity in an image region: the need to spatially average to get an accurate estimate, and  the problem of not averaging over discontinuities. We have developed a network model of disparity estimation based on disparityselective neurons, such as those found in the early stages of processing in visual cortex. The model can accurately estimate multiple  disparities in a region, which may be caused by transparency or occlusion, in real images and random-dot stereograms. The use of a  selection mechanism to selectively integrate reliable local disparity  estimates results in superior performance compared to standard  back-propagation and cross-correlation approaches. In addition,  the representations learned with this selection mechanism are consistent with recent neurophysiological results of von der Heydt,  Zhou, Friedman, and Poggio [8] for cells in cortical visual area V2.  Combining multi-scale biologically-plausible image processing with  the power of the mixture-of-experts learning algorithm represents  a promising approach that yields both high performance and new  insights into visual system function.  Selective Integration: A Model for Disparity Estimation 867
A self-organizing architecture is developed for image region classification. The system consists of a preprocessor that utilizes multiscale filtering, competition, cooperation, and diffusion to compute a  vector of image boundary and surface properties, notably texture  and brightness properties. This vector inputs to a system that  incrementally learns noisy multidimensional mappings and their  probabilities. The architecture is applied to difficult real-world  image classification problems, including classification of synthetic aperture radar and natural texture images, and outperforms a  recent state-of-the-art system at classifying natural textures.
This paper describes how the early visual process of contour organisation can be realised using the EM algorithm. The underlying  computational representation is based on fine spline coverings. According to our EM approach the adjustment of spline parameters  draws on an iterative weighted least-squares fitting process. The  expectation step of our EM procedure computes the likelihood of  the data using a mixture model defined over the set of spline coverings. These splines are limited in their spatial extent using Gaussian windowing functions. The maximisation of the likelihood leads  to a set of linear equations in the spline parameters which solve the  weighted least squares problem. We evaluate the technique on the  localisation of road structures in aerial infra-red images.
A simple mathematical model for the large-scale circuitry of primary visual cortex is introduced. It is shown that a basic cortical architecture of recurrent local excitation and lateral inhibition can account quantitatively for such properties as orientation tuning. The model can also account for such local effects as cross-orientation suppression. It is also shown that nonlocal state-dependent coupling between similar orientation patches,  when added to the model, can satisfactorily reproduce such effects as non-local iso-orientation suppression, and non-local crossorientation enhancement. Following this an account is given of perceptual phenomena involving object segmentation, such as "popout", and the direct and indirect tilt illusions.
We compare the generalization performance of three distinct representation schemes for facial emotions using a single classification  strategy (neural network). The face images presented to the classifters are represented as: full face projections of the dataset onto  their eigenvectors (eigenfaces); a similar projection constrained to  eye and mouth areas (eigenfeatures); and finally a projection of  the eye and mouth areas onto the eigenvectors obtained from 32x32  random image patches from the dataset. The latter system achieves  86% generalization on novel face images (individuals the networks  were not trained on) drawn from a database in which human subjects consistently identify a single emotion for the face.
We have investigated the possibility that rapid processing in the visual  system could be achieved by using the order of firing in different  neurones as a code, rather than more conventional firing rate schemes.  Using SPIKENET, a neural net simulator based on integrate-and-fire  neurones and in which neurones in the input layer function as analogto-delay converters, we have modeled the initial stages of visual  processing. Initial results are extremely promising. Even with activity  in retinal output cells limited to one spike per neuron per image  (effectively ruling out any form of rate coding), sophisticated processing  based on asynchronous activation was nonetheless possible.
A central theme of computational vision research has been the realization that reliable estimation of local scene properties requires  propagating measurements across the image. Many authors have  therefore suggested solving vision problems using architectures of  locally connected units updating their activity in parallel. Unfortunately, the convergence of traditional relaxation methods on such  architectures has proven to be excruciatingly slow and in general  they do not guarantee that the stable point will be a global minimum.  In this paper we show that an architecture in which Bayesian Beliefs about image properties are propagated between neighboring  units yields convergence times which are several orders of magnitude faster than traditional methods and avoids local minima. In  particular our architecture is non-iterative in the sense of Marr [5]:  at every time step, the local estimates at a given location are optimal given the information which has already been propagated to  that location. We illustrate the algorithm's performance on real  images and compare it to several existing methods.
It has been suggested that long-range intrinsic connections in striate cortex may  play a role in contour extraction (Gilbert et al., 1996). A number of rent  physiological and psychophysical studies have examined the possible role of  long range connections in the modulation of contrast detection thresholds (Polat  and Sagi, 1993,1994; Kapadia et al., 1995; Kovfics and Julesz, 1994) and various  pre-attentive detection tasks (Kovfics and Julesz, 1993; Field et al., 1993). We  have developed a network architture based on the anatomical connectivity of  striate cortex, as well as the temporal dynamics of neuronal processing, that is  able to reproduce the observed experimental results. The network has been tested  on real images and has applications in terms of identifying salient contours in  automatic image processing systems.
We present an algorithm for identifying linear patterns on a twodimensional lattice based on the concept of an orientation selective  cell, a concept borrowed from neurobiology of vision. Constructing a multi-layered neural network with fixed architecture which  implements orientation selectivity, we define output elements corresponding to different orientations, which allow us to make a selection decision. The algorithm takes into account the granularity  of the lattice as well as the presence of noise and inefficiencies. The  method is applied to a sample of data collected with the ZEUS  detector at HERA in order to identify cosmic muons that leave  a linear pattern of signals in the segmented calorimeter. A two  dimensional representation of the relevant part of the detector is  used. The algorithm performs very well. Given its architecture,  this system becomes a good candidate for fast pattern recognition  in parallel processing devices.
This paper presents a method that decides which combinations of traffic  can be accepted on a packet data link, so that quality of service (QoS)  constraints can be met. The method uses samples of QoS results at different load conditions to build a neural network decision function. Previous similar approaches to the problem have a significant bias. This  bias is likely to occur in any real system and results in accepting loads  that miss QoS targets by orders of magnitude. Preprocessing the data to  either remove the bias or provide a confidence level, the method was  applied to sources based on difficult-to-analyze ethernet data traces.  With this data, the method produces an accurate access control function  that dramatically outperforms analytic alternatives. Interestingly, the  results depend on throwing away more than 99% of the data.
Predictions of lifetimes of dynamically allocated objects can be used  to improve time and space efficiency of dynamic memory management in computer programs. Barrett and Zorn [1993] used a simple  lifetime predictor and demonstrated this improvement on a variety  of computer programs. In this paper, we use decision trees to do  lifetime prediction on the same programs and show significantly  better prediction. Our method also has the advantage that during  training we can use a large number of features and let the decision  tree automatically choose the relevant subset.
Artificial Neural Networks can be used to predict future returns  of stocks in order to take financial decisions. Should one build a  separate network for each stock or share the same network for all  the stocks? In this paper we also explore other alternatives, in  which some layers are shared and others are not shared. When  the prediction of future returns for different stocks are viewed as  different tasks, sharing some parameters across stocks is a form  of multi-task learning. In a series of experiments with Canadian  stocks, we obtain yearly returns that are more than 14% above  various benchmarks.
The Neurothermostat is an adaptive controller that regulates indoor air temperature in a residence by switching a furnace on or  off. The task is framed as an optimal control problem in which  both comfort and energy costs are considered as part of the control objective. Because the consequences of control decisions are  delayed in time, the Neurothermostat must anticipate heating demands with predictive models of occupancy patterns and the thermal response of the house and furnace. Occupancy pattern prediction is achieved by a hybrid neural net / look-up table. The Neurothermostat searches, at each discrete time step, for a decision  sequence that minimizes the expected cost over a fixed planning  horizon. The first decision in this sequence is taken, and this process repeats. Simulations of the Neurothermostat were conducted  using artificial occupancy data in which regularity was systematically varied, as well as occupancy data from an actual residence.  The Neurothermostat is compared against three conventional policies, and achieves reliably lower costs. This result is robust to the  relative weighting of comfort and energy costs and the degree of  variability in the occupancy patterns. 
This paper shows how the prices of option contracts traded in financial markets can be tracked sequentially by means of the Extended  Kalman Filter algorithm. I consider call and put option pairs with  identical strike price and time of maturity as a two output nonlinear system. The Black-Scholes approach popular in Finance literature and the Radial Basis Functions neural network are used in  modelling the nonlinear system generating these observations. I  show how both these systems may be identified recursively using  the EKF algorithm. I present results of simulations on some FTSE  100 Index options data and discuss the implications of viewing the  pricing problem in this sequential manner.
Epidemiological data is traditionally analyzed with very simple  techniques. Flexible models, such as neural networks, have the  potential to discover unanticipated features in the data. However,  to be useful, flexible models must have effective control on overfitting. This paper reports on a comparative study of the predictive  quality of neural networks and other flexible models applied to real  and artificial epidemiological data. The results suggest that there  are no major unanticipated complex features in the real data, and  also demonstrate that MacKay's [1995] Bayesian neural network  methodology provides effective control on overfitting while retaining the ability to discover complex features in the artificial data.
In cellular telephone systems, an important problem is to dynamically allocate the communication resource (channels) so as to maximize service in a stochastic caller environment. This problem is  naturally formulated as a dynamic programming problem and we  use a reinforcement learning (RL) method to find dynamic channel  allocation policies that are better than previous heuristic solutions.  The policies obtained perform well for a broad variety of call traffic patterns. We present results on a large cellular system with  approximately 4949 states.  In cellular communication systems, an important problem is to allocate the communication resource (bandwidth) so as to maximize the service provided to a set of  mobile callers whose demand for service changes stochastically. A given geographical area is divided into mutually disjoint cells, and each cell serves the calls that  are within its boundaries (see Figure la). The total. system bandwidth is divided  into channels, with each channel centered around a frequency. Each channel can be  used simultaneously at different cells, provided these cells are sufficiently separated  spatially, so that there is no interference between them. The minimum separation  distance between simultaneous reuse of the same channel is called the channel reuse  constraint.  When a call requests service in a given cell either a free channel (one that does not  violate the channel reuse constraint) may be assigned to the call, or else the call is  blocked from the system; this will happen if no free channel can be found. Also,  when a mobile caller crosses from one cell to another, the call is "handed off" to the  cell of entry; that is, a new free channel is provided to the call at the new cell. If no  such channel is available, the call must be dropped/disconnected from the system.  RL for Dynamic ChanneI Allocation 975  One objective of a channel allocation policy is to allocate the available channels  to calls so that the number of blocked calls is minimized. An additional objective  is to minimize the number of calls that are dropped when they are handed off to  a busy cell. These two objectives must be weighted appropriately to reflect their  relative importance, since dropping existing calls is generally more undesirable than  blocking new calls.  To illustrate the qualitative nature of the channel assignment decisions, suppose  that there are only two channels and three cells arranged in a line. Assume a  channel reuse constraint of 2, i.e., a channel may be used simultaneously in cells  i and 3, but may not be used in channel 2 if it is already used in cell i or in cell  3. Suppose that the system is serving one call in cell i and another call in cell  3. Then serving both calls on the same channel results in a better channel usage  pattern than serving them on different channels, since in the former case the other  channel is free to be used in cell 2. The purpose of the channel assignment and  channel rearrangement strategy is, roughly speaking, to create such favorable usage  patterns that minimize the likelihood of calls being blocked.  We formulate the channel assignment problem as a dynamic programming problem,  which, however, is too complex to be solved exactly. We introduce approximations  based on the methodology of reinforcement learning (RL) (e.g., Barto, Bradtke and  Singh, 1995, or the recent textbook by Bertsekas and Tsitsiklis, 1996). Our method  learns channel allocation policies that outperform not only the most commonly used  policy in cellular systems, but also the best heuristic policy we could find in the  literature.
The mortality related to cervical cancer can be substantially reduced through early detection and treatment. However, current detection techniques, such as Pap smear and colposcopy,  fail to achieve a concurrently high sensitivity and specificity. In  vivo fluorescence spectroscopy is a technique which quickly, noninvasively and quantitatively probes the biochemical and morphological changes that occur in pre-cancerous tissue. RBF ensemble  algorithms based on such spectra provide automated, and near realtime implementation of pre-cancer detection in the hands of nonexperts. The results are more reliable, direct and accurate than  those achieved by either human experts or multivariate statistical  algorithms.
We present a mixture of experts (ME) approach to interpolate sparse,  spatially correlated earth-science data. Kriging is an interpolation  method which uses a global covariation model estimated from the data  to take account of the spatial dependence in the data. Based on the  close relationship between kriging and the radial basis function (RBF)  network (Wan & Bone, 1996), we use a mixture of generalized RBF  networks to partition the input space into statistically correlated  regions and learn the local covariation model of the data in each  region. Applying the ME approach to simulated and real-world data,  we show that it is able to achieve good partitioning of the input space,  learn the local covariation models and improve generalization.
High frequency foreign exchange data can be decomposed into three  components: the inventory effect component, the surprise information  (news) component and the regular information component. The presence  of the inventory effect and news can make analysis of trends due to the  diffusion of information (regular information component) difficult.  We propose a neural-net-based, independent component analysis to separate high frequency foreign exchange data into these three components.  Our empirical results show that our proposed multi-effect decomposition  can reveal the intrinsic price behavior.
Dynamic Programming, Q-learning and other discrete Markov Decision  Process solvers can be applied to continuous d-dimensional state-spaces by  quantizing the state space into an array of boxes. This is often problematic  above two dimensions: a coarse quantization can lead to poor policies, and  fine quantization is too expensive. Possible solutions are variable-resolution  discretization, or function approximation by neural nets. A third option,  which has been little studied in the reintbrcement learning literature, is  interpolation on a coarse grid. In this paper we study interpolation techniques that can result in vast improvements in the online behavior of the  resulting control systems: multilinear interpolation, and an interpolation  algorithm based on an interesting regular triangulation of d-dimensional  space. We adapt these interpolators under three reinforcement learning  paradigms: (i) offline value iteration with a known model, (ii) Q-learning,  and (iii) online value iteration with a previously unknown model learned  from data. We describe empirical results, and the resulting implications for  practical learning of continuous non-linear dynamic control.  GRID-BASED INTERPOLATION TECHNIQUES  Reinforcement learning algorithms generate functions that map states to "cost-togo" values. When dealing with continuous state spaces these functions must be  approximated. The following approximators are frequently used:  Fine grids may be used in one or two dimensions. Above two dimensions,  fine grids are too expensive. Value functions can be discontinuous, which  (as we will see) can lead to suboptimalities even with very fine discretization  in two dimensions.  Neural nets have been used in conjunction with TD [Sutton, 1988] and  Q-learning [Watkins, 1989] in very high dimensional spaces [Tesauro, 1991,  Crites and Barto, 1996]. While promising, it is not always clear that they  produce the accurate value functions that might be needed for fine nearoptimal control of dynamic systems, and the most commonly used methods  of applying value iteration or policy iteration with a neural-net value function are often unstable. [Boyan and Moore, 1995].  1006 S. Davies  Interpolation over points on a coarse grid is another potentially useful approximator  for value functions that has been little studied for reinforcement learning. This  paper attempts to rectify this omission. Interpolation schemes may be particularly  attractive because they are local averagers, and convergence has been proven in  such cases for offline value iteration [Gordon, 1995].  All of the interpolation methods discussed here split the state space into a regular  grid of d-dimensional boxes; data points are associated with the centers or the  corners of the resulting boxes. The value at a given point in the continuous state  space is computed as a weighted average of neighboring data points.  1.1 MULTILINEAR INTERPOLATION  When using multilinear interpolation, data points are situated at the corners of  the grid's boxes. The interpolated value within a box is an appropriately weighted  average of the 2 d datapoints on that box's corners. The weighting scheme assures  global continuity of the interpolated surface, and also guarantees that the interpolated value at any grid corner matches the given value of that corner.  In one-dimensional space, multilinear interpolation simply involves piecewise linear  interpolations between the data points. In a higher-dimensional space, a recursive  (though not terribly efficient) implementation can be described as follows:  Pick an arbitrary axis. Project the query point along this axis to each of the two  opposite faces of the box containing the query point.  Use two (d1)-dimensional multihnear interpolations over the 2 `/- datapoints  on each of these two faces to calculate the values at both of these projected points.  Linearly interpolate between the two values generated in the previous step.  Multilinear interpolation processes 2 d data points for every query, which becomes  prohibitively expensive as d increases.  1.2 SIMPLEX-BASED INTERPOLATION  It is possible to interpolate over d + 1 of the data points for any given query in only  O(dlog d) time and still achieve a continuous surface that fits the datapoints exactly.  Each box is broken into d! hyperdimensional triangles, or simplexes, according to  the Coxeter-Freudenthal-Kuhn triangulation [Moore, 1992].  Assume that the box is the unit hypercube, with one corner at (xx, x2,..., Xd) =  (0, 0,..., 0), and the diagonally opposite corner at (1, 1,..., 1). Then, each simplex  in the Kuhn triangulation corresponds to one possible permutation p of (1, 2,..., d),  and occupies the set of points satisfying the equation  0 5 xp(x) < xp(2) 5 ... 5 xp(d) < I.  Triangulating each box into d! simplexes in this manner generates a conformal mesh:  any two elements with a (d1)-dimensional surface in common have entire faces in  common, which ensures continuity across element boundaries when interpolating.  We use the Kuhn triangulation for interpolation as follows:  Translate and scale to a coordinate system in which the box containing the  query point is the unit hypercube. Let the new coordinate of the query point  be (as,..., as).  ' This tells us the simplex of the  Use a sorting algorithm to rank as through as,/.  Kuhn triangulation in which the query point hes.  Triangulation and Interpolation for Reinforcement Learning 1007  Express (c,...,c) as a convex combination of the coordinates of the relevant  simplex's (d + 1) corners.  Use the coefficients determined in the previous step as the weights for a weighted  sum of the data values stored at the corresponding corners.  At no point do we explicitly represent the d! different simplexes. All of the above  steps can be performed in O(d) time except the second, which can be done in  O(d log d) time using conventional sorting routines.  2 PROBLEM DOMAINS  CAR ON HILL: In the Hillcar domain, the goal is to park a car near the top of  a one-dimensional hill. The hill is steep enough that the driver needs to back up in  order to gather enough speed to get to the goal. The state space is two-dimensional  (position,velocity). See [Moore and Atkeson, 1995] for further details, but note  that our formulation is harder than the usual formulation in that the goal region  is restricted to a narrow range of velocities around 0, and trials start at random  states. The task is specified by a reward of-1 for any action taken outside the goal  region, and 0 inside the goal. No discounting is used, and two actions are available:  maximum thrust backwards, and maximum thrust forwards.  ACROBOT: The Acrobot is a two-link planar robot acting in the vertical plane  under gravity with a weak actuator at its elbow joint joint. The shoulder is unactuated. The goal is to raise the hand to at least one link's height above the  unactuated pivot [Sutton, 1996]. The state space is four-dimensional: two angular  positions and two angular velocities. Trials always start from a stationary position  hanging straight down. This task is formulated in the same way as the car-on-thehill. The only actions allowed are the two extreme elbow torques.  3 APPLYING INTERPOLATION: THREE CASES  3.1 CASE I: OFFLINE VALUE ITERATION WITH A KNOWN  MODEL  First, we precalculate the effect of taking each possible action from each state corresponding to a datapoint in the grid. Then, as suggested in [Gordon, 1995], we use  these calculations to derive a completely discrete MDP. Taking any action from any  state in this MDP results in c possible successor states, where c is the number of  datapoints used per interpolation. Without interpolation, c is 1; with multilinear  interpolation, 2 d; with simplex-based interpolation, d + 1.  We calculate the optimal policy for this derived MDP offline using value iteration [Ross, 1983]; because the value iteration can be performed on a completely  discrete MDP, the calculations are much less computationally expensive than they  would have been with many other kinds of function approximators. The value iteration gives us values for the datapoints of our grid, which we may then use to  interpolate the values at other states during online control.  3.1.1 Hillcar Results: value iteration with known model  We tested the two interpolation methods on a variety of quantization levels by  first performing value iteration offline, and then starting the car from 1000 random  states and averaging the number of steps taken to the goal from those states. We  also recorded the number of backups required before convergence, as well as the  execution time required for the entire value iteration on a 85 MHz Sparc 5. See  Figure 1 for the results. All steps-to-goal values are means with an expected error  of 2 steps.  1008 S. Davies  Grid size  Interpolation Method 112 212 512 3012  None  Steps to Goal: 237 131 133 120  Backups: 2.42K 15.4K 156K 14.3M  Time (sec): 0.4 1.0 4.1 192  MultiLin  Steps to Goal: 134 116 108 107  Backups: 4.84K 18.1K 205K 17.8M  Time (sec): 0.6 1.3 7.1 405  Simplex  Steps to Goal: 134 118 109 107  Backups: 6.17K 18.1K 195K 17.9M  Time (sec): 0.5 1.2 5.7 328  Figure 1: Hillcar: value iteration with known model  Grid size  Interpolation Method 84 94 104 114 124 134 144 154  None  Steps to Goal: 44089 26952 > 100000  Backups: 280K 622K 1.42M  Time (sec): .. 15 30 53  MUi'tiLin  Steps to Goal: 3340 2006 1136 3209 1300 1820 1518 1802  Backups: 233K 1.01M 730K 2.01M 2.03M 3.74M 4.45M 6.78M  Time (sec): 17 43 42 83 99 164 197 284  Simplex  Steps to Goal: 4700 8007 2953 3209 4663 2733 1742 9613  Backups: 196K 1.16M 590K 2.28M 1.62M 4.03M 3.65M 6.73M  Time (sec): 9 24 22 47 47 86 93 142  Figure 2: Acrobot: value iteration with known model  The interpolated functions require more backups for convergence, but this is amply  compensated by dramatic improvement in the policy. Surprisingly, both interpolation methods provide improvements even at extremely high grid resolutions the  noninterpolated grid with 301 datapoints along each axis fared no better than the  interpolated grids with only 21 datapoints along each axis(!).  3.1.2 Acrobot Results: value iteration with known model  We used the same value iteration algorithm in the acrobot domain. In this case our  test trials always began from the same start state, but we ran tests for a larger set  of grid sizes (Figure 2).  Grids with different resolutions place grid cell boundaries at different locations, and  these boundary locations appear to be important in this problem -the performance varies unpredictably as the grid resolution changes. However, in all cases,  interpolation was necessary to arrive at a satisfactory solution; without interpolation, the value iteration often failed to converge at all. With relatively coarse  grids it may be that any trajectory to the goal passes through some grid box more  than once, which would immediately spell disaster for any algorithm associating a  constant value over that entire grid box.  Controllers using multilinear interpolation consistently fared better than those employing the simplex-based interpolation; the smoother value function provided by  multilinear interpolation seems to help. However, value iteration with the simplexbased interpolation was about twice as fast as that with multilinear interpolation.  In higher dimensions this speed ratio will increase.  Triangulation and Interpolation for Reinforcement Learning 1009  3.2 CASE II: Q-LEARNING  Under a second reinforcement learning paradigm, we do not use any model.  Rather, we learn a Q-function that directly maps state-action pairs to long-term  rewards [Watkins, 1989]. Does interpolation help here too?  In this implementation we encourage exploration by optimistically initializing the  Q-function to zero everywhere. After travelling a sufficient distance from our last  decision point, we perform a single backup by changing the grid point values according to a perceptron-like update rule, and then we greedily select the action for  which the interpolated Q-function is highest at the current state.  3.2.1 Hillcar Results: Q-Learning  We used Q-Learning with a grid size of 112. Figure 3 shows learning curves for  three learners using the three different interpolation techniques.  Both interpolation methods provided a significant improvement in both initial and  final online performance. The learner without interpolation achieved a final average performance of about 175 steps to the goal; with multilinear interpolation, 119;  with simplex-based interpolation, 122. Note that these are all significant improvements over the corresponding results for offiine value iteration with a known model.  Inaccuracies in the interpolated functions often cause controllers to enter cycles; because the Q-learning backups are being performed online, however, the Q-learning  controller can escape from these control cycles by depressing the Q-values in the  vicinities of such cycles.  3.2.2 Acrobot Results: Q-Learning  We used the same algorithms on the acrobot domain with a grid size of 154; results  are shown in Figure 3.  400  -,ooooo  No intpl>latltn -,50 100 150 2O0 Z50 30  400 450 500  4O0  Figure 3: Left: Cumulative performance of Q-learning hillcar on an 112 grid. (Multilinear  interpolation comes out on top; no interpolation on the bottom.) Right: Q-learning  acrobot on a 15 4 grid. (The two interpolations come out on top with nearly identical  performance.) For each learner, the y-axis shows the sum of rewards for all trials to date.  The better the average performance, the shallower the gradient. Gradients are always  negative because each state transition before reaching the goal results in a reward of-1.  Both Q-learners using interpolation improved rapidly, and eventually reached the  goal in a relatively small number of steps per trial. The learner using multilinear  interpolation eventually achieved an average of 1,529 steps to the goal per trial;  the learner using simplex-based interpolation achieved 1,727 steps per trial. On  the other hand, the learner not using any interpolation fared much worse, taking  1010 S. Davies  an average of more than 27,000 steps per trial. (A controller that chooses actions  randomly typically takes about the same number of steps to reach the goal.)  Simplex-based interpolation provided on-line performance very close to that provided by multilinear interpolation, but at roughly half the computational cost.  3.3 CASE III: VALUE ITERATION WITH MODEL LEARNING  Here, we use a mode] of the system, but we do not assume that we have one to start  with. Instead, we ]earn a model of the system as we interact with it; we assume this  model is adequate and calculate a value function via the same algorithms we would  use if we knew the true mode]. This approach may be particularly beneficial for  tasks in which data is expensive and computation is cheap. Here, models are learned  using very simple grid-based function approximators without interpolation for both  the reward and transition functions of the model. The same grid resolution is used  for the value function grid and the model approximator. We strongly encourage  exploration by initializing the model so that every state is initially assumed to be  an absorbing state with zero reward.  While making transitions through the state space, we update the model and use  prioritized sweeping [Moore and Atkeson, 1993] to concentrate backups on relevant  parts of the state space. We also occasionally stop to recalculate the effects of  all actions under the updated model and then run value iteration to convergence.  As this is fairly time-consuming, it is done rather rarely; we rely on the updates  performed by prioritized sweeping to guide the system in the meantime.  Figure 4: Left: Cumulative performance, model-learning on hillcar with a 112 grid.  Right: Acrobot with a 15 4 grid. In both cases, multilinear interpolation comes out on  top, while no interpolation winds up on the bottom.  400  3.3.1 Hillcar Results: value iteration with learned model  We used the algorithm described above with an 11-by-11 grid. An average of about  two prioritized sweeping backups were performed per transition; the complete recalculations were performed every 1000 steps throughout the first two trims and  every 5000 steps thereafter. Figure 4 shows the results for the first 500 trials.  Over the first 500 trims, the learner using simplex-based interpolation didn't fare  much better than the learner using no interpolation. However, its performance  on trims 1500-2500 (not shown) was close to that of the learner using multilinear  interpolation, taking an average of 151 steps to the goal per trim while the learner  using multilinear interpolation took 147. The learner using no interpolation did  significantly worse than the others in these later trials, taking 175 steps per trial.  Triangulation and Interpolation for Reinforcement Learning 1011  The model-learners' performance improved more quickly than the Q-learners' over  the first few trials; on the other hand, their final performance was significantly worse  that the Q-learners'.  3.3.2 Acrobot Results: value iteration with learned model  We used the same algorithm with a 15 4 grid on the acrobot domain, this time  performing the complete recalculations every 10000 steps through the first two trials  and every 50000 thereafter. Figure 4 shows the results. In this case, the learner  using no interpolation took so much time per trial that the experiment was aborted  early; after 100 trials, it was still taking an average of more than 45,000 steps  to reach the goal. The learners using interpolation, however, fared much better.  The learner using multilinear interpolation converged to a solution taking 938 steps  per trial; the learner using simplex-based interpolation averaged about 2450 steps.  Again, as the graphs show, these three learners initially improve significantly faster  than did the Q-Learners using similar grid sizes.  4 CONCLUSIONS  We have shown how two interpolation schemes--one based on a weighted average of  the 2 d points in a square cell, the other on a ddimensional triangulation--may be  used in three reinforcement learning paradigms: Optimal policy computation with  a known model, Q-learning, and online value iteration while learning a model. In  each case our empirical studies demonstrate interpolation resoundingly decreasing  the quantization level necessary for a satisfactory solution. Future extensions of  this research will explore the use of variable resolution grids and triangulations,  multiple low-dimensional interpolations in place of one high-dimension interpolation  in a manner reminiscent of CMAC [Albus, 1981], memory-based approximators, and  more intelligent exploration.  This research was funded in part by a National Science Foundation Graduate Fellowship to Scott Davies,  and a Research Initiation Award to Andrew Moore.  References  [Albus, 1981] J. S. Albus. Brains, Behawour and Robotics. BYTE Books, McGraw-Hill, 1981.  [Boyan and Moore, 1995] J. A. Boyan and A. W. Moore. Generalization in Reinforcement Learning:  Safely Approximating the Value Function. In Neural Information Processing Systems 7, 1995.  [Crites and Barto, 1996] R. H. Crites and A. G. Barto. Improving Elevator Performance using Reinforcement Learning. In D. Touretzky, M. Mozer, and M. Hasselmo, editors, Neural Information  Processing Systems 8, 1996.  [Gordon, 1995] G. Gordon. Stable Function Approximation in Dynamic Programming. In Proceedings  of the 12th International Conference on Machine Learning. Morgan Kaufmann, June 1995.  [Moore and Atkeson, 1993] A. W. Moore and C. G. Atkeson. Prioritized Sweeping: Reinforcement  Learning with Less Data and Less Real Time. Machane Learning, 13, 1993.  [Moore and Atkeson, 1995] A. W. Moore and C. G. Atkeson. The Parti-game Algorithm for Variable  Resolution Reinforcement Learning in Multidimensional State-spaces. Machine Learning, 21, 1995.  [Moore, 1992] D. W. Moore. Simplical Mesh Generation with Applications. PhD. Thesis. Report no.  92-1322, Cornell University, 1992.
A new reinforcement learning architecture for nonlinear control is  proposed. A direct feedback controller, or the actor, is trained by  a value-gradient based controller, or the tutor. This architecture  enables both efficient use of the value function and simple computation for real-time implementation. Good performance was verified  in multi-dimensional nonlinear control tasks using Gaussian softmax networks.
In general, procedures for determining Bayes-optimal adaptive  controls for Markov decision processes (MDP's) require a prohibitive amount of computation--the optimal learning problem  is intractable. This paper proposes an approximate approach in  which bandit processes are used to model, in a certain "local" sense,  a given MDP. Bandit processes constitute an important subclass of  MDP's, and have optimal learning strategies (defined in terms of  Gittins indices) that can be computed relatively efficiently. Thus,  one scheme for achieving approximately-optimal learning for general MDP's proceeds by taking actions suggested by strategies that  are optimal with respect to local bandit models.
Closed-loop control relies on sensory feedback that is usually assumed to be free. But if sensing incurs a cost, it may be costeffective to take sequences of actions in open-loop mode. We describe a reinforcement learning algorithm that learns to combine  open-loop and closed-loop control when sensing incurs a cost. Although we assume reliable sensors, use of open-loop control means  that actions must sometimes be taken when the current state of  the controlled system is uncertain. This is a special case of the  hidden-state problem in reinforcement learning, and to cope, our  algorithm relies on short-term memory. The main result of the paper is a rule that significantly limits exploration of possible memory  states by pruning memory states for which the estimated value of  information is greater than its cost. We prove that this rule allows  convergence to an optimal policy.
Reinforcement learning methods for discrete and semi-Markov decision problems such as Real-Time Dynamic Programming can  be generalized for Controlled Diffusion Processes. The optimal  control problem reduces to a boundary value problem for a fully  nonlinear second-order elliptic differential equation of HamiltonJacobi-Bellman (HJB-) type. Numerical analysis provides multigrid methods for this kind of equation. In the case of Learning Control, however, the systems of equations on the various grid-levels are  obtained using observed information (transitions and local cost).  To ensure consistency, special attention needs to be directed toward the type of time and space discretization during the observation. An algorithm for multi-grid observation is proposed. The  multi-grid algorithm is demonstrated on a simple queuing problem.
By now it is widely accepted that learning a task from scratch, i.e., without  any prior knowledge, is a daunting undertaking. Humans, however, rarely attempt to learn from scratch. They extract initial biases as well as strategies  how to approach a learning problem from instructions and/or demonstrations  of other humans. For learning control, this paper investigates how learning  from demonstration can be applied in the context of reinforcement learning.  We consider priming the Q-function, the value function, the policy, and the  model of the task dynamics as possible areas where demonstrations can speed  up learning. In general nonlinear learning problems, only model-based reinforcement learning shows significant speed-up after a demonstration, while in  the special case of linear quadratic regulator (LQR) problems, all methods  profit from the demonstration. In an implementation of pole balancing on a  complex anthropomorphic robot arm, we demonstrate that, when facing the  complexities of real signal processing, model-based reinforcement learning  offers the most robustness for LQR problems. Using the suggested methods,  the robot learns pole balancing in just a single trial after a 30 second long  demonstration of the human instructor.
Model learning combined with dynamic programming has been shown to  be effective for learning control of continuous state dynamic systems. The  simplest method assumes the learned model is correct and applies dynamic  programming to it, but many approximators provide uncertainty estimates  on the fit. How can they be exploited? This paper addresses the case  where the system must be prevented from having catastrophic failures during learning. We propose a new algorithm adapted from the dual control  literature and use Bayesian locally weighted regression models with dynamic programming. A common reinforcement learning assumption is that  aggressive exploration should be encouraged. This paper addresses the converse case in which the system has to reign in exploration. The algorithm  is illustrated on a 4 dimensional simulated control problem.
We have calculated analytical expressions for how the bias and  variance of the estimators provided by various temporal difference  value estimation algorithms change with offline updates over trials  in absorbing Markov chains using lookup table representations. We  illustrate classes of learning curve behavior in various chains, and'  show the manner in which TD is sensitive to the choice of its stepsize and eligibility trace parameters.
Probability models can be used to predict outcomes and compensate for  missing data, but even a perfect model cannot be used to make decisions  unless the utility of the outcomes, or preferences between them, are also  provided. This arises in many real-world problems, such as medical diagnosis, where the cost of the test as well as the expected improvement  in the outcome must be considered. Relatively little work has been done  on learning the utilities of outcomes for optimal decision making. In this  paper, we show how temporal-difference reinforcement learning (TD()0)  can be used to determine decision theoretic utilities within the context of  a mixture model and apply this new approach to a problem in medical diagnosis. TD()Q learning of utilities reduces the number of tests that have  to be done to achieve the same level of performance compared with the  probability model alone, which results in significant cost savings and increased efficiency.
We present a Monte-Carlo simulation algorithm for real-time policy  improvement of an adaptive controller. In the Monte-Carlo simulation, the long-term expected reward of each possible action is  statistically measured, using the initial policy to make decisions in  each step of the simulation. The action maximizing the measured  expected reward is then taken, resulting in an improved policy. Our  algorithm is easily parallelizable and has been implemented on the  IBM SP1 and SP2 parallel-RISC supercomputers.  We have obtained promising initial results in applying this algorithm to the domain of backgammon. Results are reported for a  wide variety of initial policies, ranging from a random policy to  TD-Gammon, an extremely strong multi-layer neural network. In  each case, the Monte-Carlo algorithm gives a substantial reduction,  by as much as a factor of 5 or more, in the error rate of the base  players. The algorithm is also potentially useful in many other  adaptive control applications in which it is possible to simulate the  environment.
We present new results about the temporal-difference learning algorithm, as applied to approximating the cost-to-go function of  a Markov chain using linear function approximators. The algorithm we analyze performs on-line updating of a parameter vector  during a single endless trajectory of an aperiodic irreducible finite  state Markov chain. Results include convergence (with probability  1), a characterization of the limit of convergence, and a bound on  the resulting approximation error. In addition to establishing new  and stronger results than those previously available, our analysis  is based on a new line of reasoning that provides new intuition  about the dynamics of temporal-difference learning. Furthermore,  we discuss the implications of two counter-examples with regards  to the significance of on-line updating and linearly parameterized  function approximators.
We propose and analyze an algorithm that approximates solutions  to the problem of optimal stopping in a discounted irreducible aperiodic Markov chain. The scheme involves the use of linear combinations of fixed basis functions to approximate a Q-function.  The weights of the linear combination are incrementally updated  through an iterative process similar to Q-learning, involving simulation of the underlying Markov chain. Due to space limitations,  we only provide an overview of a proof of convergence (with probability 1) and bounds on the approximation error. This is the first  theoretical result that establishes the soundness of a Q-learninglike algorithm when combined with arbitrary linear function approximators to solve a sequential decision problem. Though this  paper focuses on the case of finite state spaces, the results extend  naturally to continuous and unbounded state spaces, which are addressed in a forthcoming full-length paper.
We have developed a neural network architecture that implements a theory of attention, learning, and trans-cortical communication based on  adaptive synchronization of 5-15 Hz and 30-80 Hz oscillations between  cortical areas. Here we present a specific higher order cortical model of  attentional networks, rhythmic expectancy, and the interaction of h!lgherorder and primar,y, cortical levels of processing. It accounts for the mismatch negativity ' of the auditory ERP and the results of psychological  experiments of Jones showing that auditory stream segregation depends  on the rhythmic structure of inputs. The timing mechanisms of the model  allow us to explain how relative timing information such as the relative  order of events between streams is lost when streams are formed. The  model suggests how the theories of auditory perception and attention of  Jones andBregman may be reconciled.
A novel neural network model of pre-attention processing in visualsearch tasks is presented. Using displays of line orientations taken  from Wolfe's experiments [1992], we study the hypothesis that the  distinction between parallel versus serial processes arises from the  availability of global information in the internal representations of  the visual scene. The model operates in two phases. First, the  visual displays are compressed via principal-component-analysis.  Second, the compressed data is processed by a target detector module in order to identify the existence of a target in the display. Our  main finding is that targets in displays which were found experimentally to be processed in parallel can be detected by the system, while targets in experimentally-serial displays cannot. This  fundamental difference is explained via variance analysis of the  compressed representations, providing a numerical criterion distinguishing parallel from serial displays. Our model yields a mapping  of response-time slopes that is similar to Duncan and Humphreys's  "search surface" [1989], providing an explicit formulation of their  intuitive notion of feature similarity. It presents a neural realization of the processing that may underlie the classical metaphorical  explanations of visual search.  On Parallel versus Serial Processing: A Computational Study of Visual Search
There is strong evidence that face processing is localized in the brain.  The double dissociation between prosopagnosia, a face recognition  deficit occurring after brain damage, and visual object agnosia, difficulty  recognizing other kinds of complex objects, indicates that face and nonface object recognition may be served by partially independent mechanisms in the brain. Is neural specialization innate or learned? We suggest that this specialization could be the result of a competitive learning mechanism that, during development, devotes neural resources to the  tasks they are best at performing. Further, we suggest that the specialization arises as an interaction between task requirements and developmental constraints. In this paper, we present a feed-forward computational  model of visual processing, in which two modules compete to classify  input stimuli. When one module receives low spatial frequency information and the other receives high spatial frequency information, and  the task is to identify the faces while simply classifying the objects, the  low frequency network shows a strong specialization for faces. No other  combination of tasks and inputs shows this strong specialization. We  take these results as support for the idea that an innately-specified face  processing module is unnecessary.
We present a neural model that can perform eye movements to a  particular side of an object regardless of the position and orientation of the object in space, a generalization of a task which has  been recently used by Olson and Gettner [4] to investigate the neural structure of object-centered representations. Our model uses an  intermediate representation in which units have oculocentric receptive fieldsjust like collicular neurons-whose gain is modulated by  the side of the object to which the movement is directed, as well as  the orientation of the object. We show that these gain modulations  are consistent with Olson and Gettner's single cell recordings in the  supplementary eye field. This demonstrates that it is possible to  perform an object-centered task without a representation involving an object-centered map, viz., without neurons whose receptive  fields are defined in object-centered coordinates. We also show that  the same approach can account for object-centered neglect, a situation in which patients with a right parietal lesion neglect the left  side of objects regardless of the orientation of the objects.  Several authors have argued that tasks such as object recognition [3] and manipulation [4] are easier to perform if the object is represented in object-centered coordinates, a representation in which the subparts of the object are encoded with respect  to a frame of reference centered on the object. Compelling evidence for the existence  of such representations in the cortex comes from experiments on hemineglect-a  neurological syndrome resulting from unilateral lesions of the parietal cortex such  that a right lesion, for example, leads patients to ignore stimuli located on the left  side of their egocentric space. Recently, Driver et al. (1994) showed that the deficit  can also be object-centered. Hence, hemineglect patients can detect a gap in the  upper edge of a triangle when this gap is associated with the right side of the object  Neural BaMs of ObjectCentered Representations 25  A. B.  I  Object-centered  cueing  Spatial ,   cueing  2  Three possible locations:  Time  Left of the object Right of the object  Figure 1: ADriver et al. (1994) experiment demonstrating objectscentered neglect.  Subjects were asked to detect a gap in the upper part of the middle triangle, while  fixating at the cross, when the overall figure is tilted clockwise (top) or counterclockwise (bottom). Patients perform worse for the clockwise condition, when the gap  is perceived to be on the left of the overall figure. BSequence of screens presented  on each trial in Olson and Gettner experiment (1995). 1Fixation, 2apparition of  a cue indicating where the saccade should go, either in object-centered coordinates  (object-centered cueing), or in screen coordinates (spatial cueing), 3delay period,  4apparition of the bar in one of three possible locations (dotted lines), and 5saccade to the cued location. CSchematic response of an SEF neuron for 4 different  conditions. Adapted from [4].  but not when it belongs to the left side (figure l-A).  What could be the neural basis of these object-centered representations? The simplest scheme would involve neurons with receptive fields defined in object-centered  coordinates, i.e., the cells respond to a particular side of an object regardless of  the position and orientation of the object. A recent experiment by Olson and Gettner (1995) supports this possibility. They recorded the activity of neurons in the  supplementary eye field (SEF) while the monkey was performing object-directed  saccades. The task consisted of making a saccade to the right or left side of a  bar, independently of the position of the bar on the screen and according to the  instruction provided by a visual cue. For instance, the cue corresponding to the  instruction 'Go to the right side of the bar' was provided by highlighting the right  side of a small bar briefly flashed at the beginning of the trial (step 2 in figure l-B).  By changing the position of the object on the screen, it is possible to compare  the activity of a neuron for movements involving different saccade directions but  directed to the same side of the object, and vice-versa, for movements involving  the same saccade direction but directed to opposite sides of the object. Olson and  Gettner found that many neurons responded more prior to saccades directed to  a particular side of the bar, independently of the direction of the saccades. For  example, some neurons responded more for an upward right saccade directed to the  left side of the bar but not at all for the same upward right saccade directed to the  right side of the bar (column I and 3, figure 1-C). This would suggest that these  neurons have bar-centered receptive 1 fields, i.e., their receptive fields are centered  use the term receptive field in a general sense, meaning either receptive or motor  26 S. Deneve and A. Pouget  Figure 2: Schematic structure of the network with activity patterns in response  to the horizontal bar shown in the V1 map and the command 'Go to the right'.  Only one SEF map is active in this case, the one selective to the right edge of the  bar (where right is defined in retinal coordinates), object orientation of 0 ø and the  command 'Go to the right'. The letter a, b, c and d indicate which map would be  active for the same command but for various orientations of the object, respectively,  0 ø, 90 ø, 180 ø, 270 ø. The dotted lines on the maps indicate the outline of the bar.  Only a few representative connections are shown.  on the bar and not on the retina. This would correspond to what we will call an  explicit object-centered representation.  We argue in this paper that these data are compatible with a different type of  representation which is more suitable for the task performed by the monkey. We  describe a neural network which can perform a saccade to the right, or left, boundary  of an object, regardless of its orientation, position or size-a generalization of the  task used by Olson and Gettner. This network uses units with receptive fields  defined in oculocentric coordinates, i.e., they are selective for the direction and  amplitude of saccades with respect to the fixation point, just like collicular neurons.  These tuning curves, however, are also modulated by two types of signals, the  orientation of the object, and the command indicating the side of the object to  which the saccade should be directed. We show that these response properties are  compatible with the Olson and Gettner data and provide predictions for future  experiments. We also show that a simulated lesion leads to object-centered neglect  as observed by Driver et al. {1994).
Filial imprinting in domestic chicks is of interest in psychology, biology,  and computational modeling because it exemplifies simple, rapid, innately programmed learning which is biased toward learning about some  objects. Horn et al. have recently discovered a naive visual preference  for heads and necks which develops over the course of the first three  days of life. The neurological basis of this predisposition is almost entirely unknown; that of imprinting-related learning is fairly clear. This  project is the first model of the predisposition consistent with what is  known about learning in imprinting. The model develops the predisposition appropriately, learns to "approach" a training object, and replicates  one interaction between the two processes. Future work will replicate  more interactions between imprinting and the predisposition in chicks,  and analyze why the system works.
Human subjects are known to adapt their motor behavior to a  shift of the visual field brought about by wearing prism glasses  over their eyes. We have studied the analog of this effect in speech.  Using a device that can feed back transformed speech signals in  real time, we exposed subjects to alterations of their own speech  feedback. We found that speakers learn to adjust their production  of a vowel to compensate for feedback alterations that change the  vowel's perceived phonetic identity; moreover, the effect generalizes  across consonant contexts and to different vowels.
Singular value decomposition (SVD) can be viewed as a method for  unsupervised training of a network that associates two classes of events  reciprocally by linear connections through a single hidden layer. SVD  was used to learn and represent relations among very large numbers of  words (20k-60k) and very large numbers of natural text passages (lk70k) in which they occurred. The result was 100-350 dimensional  "semantic spaces" in which any trained or newly added word or passage  could be represented as a vector, and similarities were measured by the  cosine of the contained angle between vectors. Good accuracy in  simulating human judgments and behaviors has been demonstrated by  performance on multiple-choice vocabulary and domain knowledge  tests, emulation of expert essay evaluations, and in several other ways.  Examples are also given of how the kind of knowledge extracted by this  method can be applied.
Motivated by the findings of modular structure in the association  cortex, we study a multi-modular model of associative memory that  can successfully store memory patterns with different levels of activity. We show that the segregation of synaptic conductances into  intra-modular linear and inter-modular nonlinear ones considerably  enhances the network's memory retrieval performance. Compared  with the conventional, single-module associative memory network,  the multi-modular network has two main advantages: It is less susceptible to damage to columnar input, and its response is consistent  with the cognitive data pertaining to category specific impairment.
Dual-Route and Connectionist Single-Route models of reading have  been at odds over claims as to the correct explanation of the reading  process. Recent Dual-Route models predict that subjects should  show an increased naming latency for irregular words when the irregularity is earlier in the word (e.g. chef is slower than glow) a  prediction that has been confirmed in human experiments. Since  this would appear to be an effect of the left-to-right reading process,  Coltheart & Rastle (1994) claim that Single-Route parallel connectionist models cannot account for it. A refutation of this claim is  presented here, consisting of network models which do show the  interaction, along with orthographic neighborhood statistics that  explain the effect.
Accounts of neurological disorders often posit damage to a specific  functional pathway of the brain. Farah (1990) has proposed an alternative class of explanations involving partial damage to multiple pathways. We explore this explanation for optic aphasia, a disorder in which  severe performance deficits are observed when patients are asked to  name visually presented objects, but surprisingly, performance is relatively normal on naming objects from auditory cues and on gesturing  the appropriate use of visually presented objects. We model this highly  specific deficit through partial damage to two pathways--one that maps  visual input to semantics, and the other that maps semantics to naming  responses. The effect of this damage is superadditive, meaning that  tasks which require one pathway or the other show little or no performance deficit, but the damage is manifested when a task requires both  pathways (i.e., naming visually presented objects). Our model explains  other phenomena associated with optic aphasia, and makes testable  experimental predictions.  Neuropsychology is the study of disrupted cognition resulting from damage to functional  systems in the brain. Generally, accounts of neuropsychological disorders posit damage to  a particular functional system or a disconnection between systems. Farah (1990) suggested an alternative class of explanations for neuropsychological disorders: partial damage to multiple systems, which is manifested through interactions among the loci of  damage. We explore this explanation for the neuropsychological disorder of optic aphasia.  Optic aphasia, arising from unilateral left posterior lesions, including occipital cortex  and the splenium of the corpus callosum (Schnider, Benson, & Scharre, 1994), is marked  by a deficit in naming visually presented objects, hereafter referred to as visual naming  (Farah, 1990). However, patients can demonstrate recognition of visually presented  objects nonverbally, for example, by gesturing the appropriate use of an object or sorting  visual items into their proper superordinate categories (hereafter, visual gesturing).  Patients can also name objects by nonvisual cues such as a verbal definition or typical  sounds made by the objects (hereafter, auditory naming). The highly specific nature of the  deficit rules out an explanation in terms of damage to a single pathway in a standard model  of visual naming (Figure 1), suggesting that a more complex model is required, involving  A SuperadditiveøImpairment Theory of Optic Aphasia 67  FIGURE 1. A standard box-and-arrow  model of visual naming. The boxes denote  levels of representation, and the arrows  denote pathways mapping from one level of  representation to another. Although optic  aphasia cannot be explained by damage to  the vision-to-semantics pathway or the  semantics-to-naming pathway, Farah  (1990) proposed an explanation in terms of  partial damage to both pathways (the X's).  I semantic I  multiple semantic systems or multiple pathways to visual naming. However, a more parsimonious account is suggested by Farah (1990): Optic aphasia might arise from partial  lesions to two pathways in the standard model--those connecting visual input to semantics, and semantics to naming--and the effect of damage to these pathways is superadditive, meaning that tasks which require only one of these pathways (e.g., visual gesturing,  or auditory naming) will be relatively unimpaired, whereas tasks requiring both pathways  (e.g., visual naming) will show a significant deficit.
A rich body of data exists showing that recollection of specific information makes an important contribution to recognition memory, which  is distinct from the contribution of familiarity, and is not adequately captured by existing unitary memory models. Furthermore, neuropsychological evidence indicates that recollection is subserved by the hippocampus.  We present a model, based largely on known features of hippocampal  anatomy and physiology, that accounts for the following key characteristics of recollection: 1) false recollection is rare (i.e., participants rarely  claim to recollect having studied nonstudied items), and 2) increasing interference leads to less recollection but apparently does not compromise  the quality of recollection (i.e., the extent to which recollected information veridically reflects events that occurred at study).
Given a set of objects in the visual field, how does the the visual system learn  to attend to a particular object of interest while ignoring the rest? How are  occlusions and background clutter so effortlessly discounted for when recognizing a familiar object? In this paper, we attempt to answer these questions in the context of a Kalman filter-based model of visual recognition that  has previously proved useful in explaining certain neurophysiological phenomena such as endstopping and related extra-classical receptive field effects in the visual cortex. By using results from the field of robust statistics,  we describe an extension of the Kalman filter model that can handle multiple  objects in the visual field. The resulting robust Kalman filter model demonstrates how certain forms of attention can be viewed as an emergent property of the interaction between top-down expectations and bottom-up signals. The model also suggests functional interpretations of certain attentionrelated effects that have been observed in visual cortical neurons. Experimental results are provided to help demonstrate the ability of the model  to perform robust segmentation and recognition of objects and image sequences in the presence of varying degrees of occlusions and clutter.
Recently researchers have derived formal complexity analysis of analog  computation in the setting of discrete-time dynamical systems. As an  empirical consWast, training recurrent neural networks (RNNs) produces  seff-organizeA systems that are realizations of analog mechanisms. Previous work showed that a RNN can learn to process a simple context-free  language (CFL) by counting. Herein, we extend that work to show that a  RNN can learn a harder CFL, a simple palindrome, by organizing its resources into a symbol-sensitive counting solution, and we provide a dynamical systems analysis which demonstrates how the network can not  only count, but also copy and store counting information.
We present a study which is concerned with word recognition rates for  heavily degraded documents. We compare human with machine reading capabilities in a series of experiments, which explores the interaction  of word/non-word recognition, word frequency and legality of non-words  with degradation level. We also study the influence of character segmentation, and compare human performance with that of our artificial neural  network model for reading. We found that the proposed computer model  uses word context as efficiently as humans, but performs slightly worse  on the pure character recognition task.
It is known that humans can make finer discriminations between  familiar sounds (e.g. syllables) than between unfamiliar ones (e.g.  different noise segments). Here we show that a corresponding enhancement is present in early auditory processing stages. Based on  previous work which demonstrated that natural sounds had robust  statistical properties that could be quantified, we hypothesize that  the auditory system exploits those properties to construct efficient  neural codes. To test this hypothesis, we measure the information rate carried by auditory spike trains on narrow-band stimuli  whose amplitude modulation has naturalistic characteristics, and  compare it to the information rate on stimuli with non-naturalistic  modulation. We find that naturalistic inputs significantly enhance  the rate of transmitted information, indicating that auditiory neural responses are matched to characteristics of natural auditory  scenes.
The relationship between a neuron's refractory period and the precision of  its response to identical stimuli was investigated. We constructed a model of  a spiking neuron that combines probabilistic firing with a refractory period.  For realistic refractoriness, the model closely reproduced both the average  firing rate and the response precision of a retinal ganglion cell. The model is  based on a "free" firing rate, which exists in the absence of refractoriness.  This function may be a better description of a spiking neuron's response  than the peri-stimulus time histogram.
Conditioning experiments probe the ways that animals make predictions about rewards and punishments and use those predictions to control their behavior. One standard model of conditioning paradigms which involve many conditioned stimuli suggests  that individual predictions should be added together. Various key  results show that this model fails in some circumstances, and motivate an alternative model, in which there is attentional selection  between different available stimuli. The new model is a form of  mixture of experts, has a close relationship with some other existing psychological suggestions, and is statistically well-founded.
While the understanding of the functional role of different classes  of neurons in the awake primary visual cortex has been extensively  studied since the time of Hubel and Wiesel (Hubel and Wiesel, 1962),  our understanding of the feature selectivity and functional role of  neurons in the primary auditory cortex is much farther from complete. Moving bars have long been recognized as an optimal stimulus  for many visual cortical neurons, and this finding has recently been  confirmed and extended in detail using reverse correlation methods  (Jones and Palmer, 1987; Reid and Alonso, 1995; Reid et al., 1991;  Ringach et al., 1997). In this study, we recorded from neurons in the  primary auditory cortex of the awake primate, and used a novel reverse correlation technique to compute receptive fields (or preferred  stimuli), encompassing both multiple frequency components and ongoing time. These spectrotemporal receptive fields make clear that  neurons in the primary auditory cortex, as in the primary visual cortex, typically show considerable structure in their feature processing  properties, often including multiple excitatory and inhibitory regions  in their receptive fields. These neurons can be sensitive to stimulus  edges in frequency composition or in time, and sensitive to stimulus  transitions such as changes in frequency. These neurons also show  strong responses and selectivity to continuous frequency modulated  stimuli analogous to visual drifting gratings.
One of the current challenges to understanding neural information  processing in biological systems is to decipher the "code" carried  by large populations of neurons acting in parallel. We present an  algorithm for automated discovery of stochastic firing patterns in  large ensembles of neurons. The algorithm, from the "Helmholtz  Machine" family, attempts to predict the observed spike patterns in  the data. The model consists of an observable layer which is directly  activated by the input spike patterns, and hidden units that are activated through ascending connections from the input layer. The  hidden unit activity can be propagated down to the observable layer  to create a prediction of the data pattern that produced it. Hidden  units are added incrementally and their weights are adjusted to improve the fit between the predictions and data, that is, to increase a  bound on the probability of the data given the model. This greedy  strategy is not globally optimal but is computationally tractable for  large populations of neurons. We show benchmark data on artificially constructed spike trains and promising early results on neurophysiological data collected from our chronic multi-electrode cortical  implant.
Nystagmus is a pattern of eye movement characterized by smooth rotations of the eye in one direction and rapid rotations in the opposite direction that reset eye position. Periodic alternating nystagmus (PAN) is  a form of uncontrollable nystagmus that has been described as an unstable but amplitude-limited oscillation. PAN has been observed previously only in subjects with vestibulo-cerebellar damage. We describe  results in which PAN can be produced in normal subjects by prolonged  rotation in darkness. We propose a new model in which the neural circuits that control eye movement are inherently unstable, but this instability is kept in check under normal circumstances by the cerebellum.  Circumstances which alter this cerebellar restraint, such as vestibulocerebellar damage or plasticity due to rotation in darkness, can lead to  PAN.
We provide a model of the standard watermaze task, and of a more  challenging task involving novel platform locations, in which rats  exhibit one-trial learning after a few days of training. The model  uses hippocampal place cells to support reinforcement learning,  and also, in an integrated manner, to build and use allocentric  coordinates.
The initial activity-independent formation of a topographic map  in the retinotectal system has long been thought to rely on the  matching of molecular cues expressed in gradients in the retina  and the tectum. However, direct experimental evidence for the  existence of such gradients has only emerged since 1995. The new  data has provoked the discussion of a new set of models in the experimental literature. Here, the capabilities of these models are analyzed, and the gradient shapes they predict in vivo are derived.
In the developing nervous system, gradients of target-derived diffusible factors play an important role in guiding axons to appropriate targets. In this paper, the shape that such a gradient might  have is calculated as a function of distance from the target and the  time since the start of factor production. Using estimates of the  relevant parameter values from the experimental literature, the  spatiotemporal domain in which a growth cone could detect such  a gradient is derived. For large times, a value for the maximum  guidance range of about 1 mm is obtained. This value fits well  with experimental data. For smaller times, the analysis predicts  that guidance over longer ranges may be possible. This prediction  remains to be tested.
Most computational engineering based loosely on biology uses continuous variables to represent neural activity. Yet most neurons communicate with action potentials. The engineering view is equivalent to using  a rate-code for representing information and for computing. An increasing number of examples are being discovered in which biology may not  be using rate codes. Information can be represented using the timing of  action potentials, and efficiently computed with in this representation.  The "analog match" problem of odour identification is a simple problem  which can be efficiently solved using action potential timing and an underlying rhythm. By using adapting units to effect a fundamental change  of representation of a problem, we map the recognition of words (having uniform time-warp) in connected speech into the same analog match  problem. We describe the architecture and preliminary results of such a  recognition system. Using the fast events of biology in conjunction with  an underlying rhythm is one way to overcome the limits of an eventdriven view of computation. When the intrinsic hardware is much faster  than the time scale of change of inputs, this approach can greatly increase  the effective computation per unit time on a given quantity of hardware.
We propose a model for early visual processing in primates. The  model consists of a population of linear spatial filters which interact through non-linear excitatory and inhibitory pooling. Statistical estimation theory is then used to derive human psychophysical  thresholds from the responses of the entire population of units. The  model is able to reproduce human thresholds for contrast and orientation discrimination tasks, and to predict contrast thresholds in  the presence of masks of varying orientation and spatial frequency.
In this paper we present a new method for studying auditory systems based on m-sequences. The method allows us to perturbatively study the linear response of the system in the presence of  various other stimuli, such as speech or sinusoidal modulations.  This allows one to construct linear kernels (receptive fields) at the  same time that other stimuli are being presented. Using the method  we calculate the modulation transfer function of single units in the  inferior colliculus of the cat at different operating points and discuss  nonlinearities in the response.
In normal vision, the inputs from the two eyes are integrated into a single percept. When dissimilar images are  presented to the two eyes, however, perceptual integration gives way to alternation between monocular inputs,  a phenomenon called binocular rivalry. Although recent  evidence indicates that binocular rivalry involves a modulation of neuronal responses in extrastriate cortex, the  basic mechanisms responsible for differential processing of  conflicting and congruent stimuli remain unclear. Using a  neural network that models the mammalian early visual  system, I demonstrate here that the desynchronized firing of cortical-like neurons that first receive inputs from  the two eyes results in rivalrous activity patterns at later  stages in the visual pathway. By contrast, synchronization  of firing among these cells prevents such competition. The  temporal coordination of cortical activity and its effects  on neural competition emerge naturally from the network  connectivity and from its dynamics. These results suggest  that input-related differences in relative spike timing at  an early stage of visual processing may give rise to the  phenomena both of perceptual integration and rivalry in  binocular vision.
In most neural network models, synapses are treated as static weights that  change only on the slow time scales of learning. In fact, however, synapses  are highly dynamic, and show use-dependent plasticity over a wide range  of time scales. Moreover, synaptic transmission is an inherently stochastic  process: a spike arriving at a presynaptic terminal triggers release of a  vesicle of neurotransmitter from a release site with a probability that can  be much less than one. Changes in release probability represent one of the  main mechanisms by which synaptic efficacy is modulated in neural circuits.  We propose and investigate a simple model for dynamic stochastic synapses  that can easily be integrated into common models for neural computation.  We show through computer simulations and rigorous theoretical analysis  that this model for a dynamic stochastic synapse increases computational  power in a nontrivial way. Our results may have implications for the processing of time-varying signals by both biological and artificial neural networks.  A synapse S carries out computations on spike trains, more precisely on trains of spikes  from the presynaptic neuron. Each spike from the presynaptic neuron may or may not  trigger the release of a neurotransmitter-filled vesicle at the synapse. The probability of a  vesicle release ranges from about 0.01 to almost 1. Furthermore this release probability is  known to be strongly "history dependent" [Dobrunz and Stevens, 1997]. A spike causes an  excitatory or inhibitory potential (EPSP or IPSP, respectively) in the postsynaptic neuron  only when a vesicle is released.  A spike train is represented as a sequence _t of firing times, i.e. as increasing sequences  of numbers t < t2 < ... from R + :(z  R: z _ 0) . For each spike train t the output of  synapse S consists of the sequence S(t-) of those ti  t_ on which vesicles are "released" by  $, i.e. of those t i  t_ which cause an excitatory or inhibitory postsynaptic potential (EPSP  or IPSP, respectively). The map t_ - S(t_) may be viewed as a stochastic function that is  computed by synapse S. Alternatively one can characterize the output S(t_) of a synapse  S through its release pattern q qq2...  (R, F)* , where R stands for release and F for  failure of release. For each ti  t_ one sets qi = R if ti  S(_t) , and qi = F if ti  S(_t) .  Dynamic Stochastic Synapses as Computational Units 195
Here we analyze synaptic transmission from an information-theoretic  perspective. We derive closed-form expressions for the lower-bounds on  the capacity of a simple model of a cortical synapse under two explicit  coding paradigms. Under the "signal estimation" paradigm, we assume  the signal to be encoded in the mean firing rate of a Poisson neuron. The  performance of an optimal linear estimator of the signal then provides  a lower bound on the capacity for signal estimation. Under the "signal  detection" paradigm, the presence or absence of the signal has to be detected. Performance of the optimal spike detector allows us to compute  a lower bound on the capacity for signal detection. We find that single  synapses (for empirically measured parameter values) transmit information poorly but significant improvement can be achieved with a small  amount of redundancy.
Hubel and Wiesel (1962) proposed that complex cells in visual cortex are driven by a pool of simple cells with the same preferred  orientation but different spatial phases. However, a wide variety of  experimental results over the past two decades have challenged the  pure hierarchical model, primarily by demonstrating that many  complex cells receive monosynaptic input from unoriented LGN  cells, or do not depend on simple cell input. We recently showed using a detailed biophysical model that nonlinear interactions among  synaptic inputs to an excitable dendritic tree could provide the nonlinear subunit computations that underlie complex cell responses  (Mel, Ruderman, & Archie, 1997). This work extends the result  to the case of complex cell binocular disparity tuning, by demonstrating in an isolated model pyramidal cell (1) disparity tuning  at a resolution much finer than the the overall dimensions of the  cell's receptive field, and (2) systematically shifted optimal disparity values for rivalrous pairs of light and dark bars--both in good  agreement with published reports (Ohzawa, DeAngelis,  Freeman, 1997). Our results reemphasize the potential importance of  intradendritic computation for binocular visual processing in particular, and for cortical neurophysiology in general.  SingleCell Account for Binocular Disparity Tuning
In macaque inferotemporal cortex (IT), neurons have been found to respond selectively to complex shapes while showing broad tuning ("invariance") with respect to stimulus transformations such as translation  and scale changes and a limited tuning to rotation in depth. Training  monkeys with novel, paperclip-like objects, Logothetis et al. 9 could investigate whether these invariance properties are due to experience with  exhaustively many transformed instances of an object or if there are mechanisms that allow the cells to show response invariance also to previously  unseen instances of that object. They found object-selective cells in anterior IT which exhibited limited invariance to various transformations  after training with single object views. While previous models accounted  for the tuning of the cells for rotations in depth and for their selectivity to a specific object relative to a population of distractor objects, 4,   the model described here attempts to explain in a biologically plausible  way the additional properties of translation and size invariance. Using  the same stimuli as in the experiment, we find that model IT neurons  exhibit invariance properties which closely parallel those of real neurons.  Simulations show that the model is capable of unsupervised learning of  view-tuned neurons.  We thank Peter Dayan, Marcus Dill, Shimon Edelman, Nikos Logothetis, Jonathan Mumick and  Randy O'Reilly for useful discussions and comments.  216 M. Riesenhuber and T. Poggio
We discuss a solution to the problem of separating waveforms produced by multiple cells in an extracellular neural recording. We  take an explicitly probabilistic approach, using latent-variable models of varying sophistication to describe the distribution of waveforms produced by a single cell. The models range from a single  Gaussian distribution of waveforms for each cell to a mixture of  hidden Markov models. We stress the overall statistical structure  of the approach, allowing the details of the generative model chosen  to depend on the specific neural preparation.
We have studied the application of an independent component analysis  (ICA) approach to the identification and possible removal of artifacts  from a magnetoencephalographic (MEG) recording. This statistical technique separates components according to the kurtosis of their amplitude  distributions over time, thus distinguishing between strictly periodical  signals, and regularly and irregularly occurring signals. Many artifacts  belong to the last category. In order to assess the effectiveness of the  method, controlled artifacts were produced, which included saccadic eye  movements and blinks, increased muscular tension due to biting and the  presence of a digital watch inside the magnetically shielded room. The  results demonstrate the capability of the method to identify and clearly  isolate the produced artifacts.
We model the responses of cells in visual area V1 during natural  vision. Our model consists of a classical energy mechanism whose  output is divided by nonclassical gain control and texture contrast  mechanisms. We apply this model to review movies, a stimulus  sequence that replicates the stimulation a cell receives during free  viewing of natural images. Data were collected from three cells  using five different review movies, and the model was fit separately  to the data from each movie. For the energy mechanism alone we  find modest but significant correlations (rr -0.41, 0.43, 0.59,  0.35) between model and data. These correlations are improved  somewhat when we allow for suppressive surround effects (rr+G -0.42, 0.56, 0.60, 0.37). In one case the inclusion of a delayed  suppressive surround dramatically improves the fit to the data by  modifying the time course of the model's response.
We prove that the Canonical Distortion Measure (CDM) [2, 3] is the  optimal distance measure to use for 1 nearest-neighbour (1-NN) classification, and show that it reduces to squared Euclidean distance in feature  space for function classes that can be expressed as linear combinations  of a fixed set of features. PAC-like bounds are given on the samplecomplexity required to learn the CDM. An experiment is presented in  which a neural network CDM was learnt for a Japanese OCR environment and then used to do 1-NN classification.
We introduce a new Boolean computing element related to the Linear Threshold element, which is the Boolean version of the neuron.  Instead of the sign function, it computes an arbitrary (with polynomialy many transitions) Boolean function of the weighted sum of  its inputs. We call the new computing element an LTM element,  which stands for Linear Threshold with Multiple transitions.  The paper consists of the following main contributions related to  our study of LTM circuits: (i) the creation of efficient designs of  LTM circuits for the addition of a multiple number of integers and  the product of two integers. In particular, we show how to compute  the addition of m integers with a single layer of LTM elements.  (ii) a proof that the area of the VLSI layout is reduced from O(n 2)  in LT circuits to O(n) in LTM circuits, for n inputs symmetric  Boolean functions, and (iii) the characterization of the computing  power of LTM relative to LT circuits.
Recent theoretical results for pattern classification with thresholded real-valued functions (such as support vector machines, sigmoid networks, and boosting) give bounds on misclassification  probability that do not depend on the size of the classifier, and  hence can be considerably smaller than the bounds that follow from  the VC theory. In this paper, we show that these techniques can  be more widely applied, by representing other boolean functions  as two-layer neural networks (thresholded convex combinations of  boolean functions). For example, we show that with high probability any decision tree of depth no more than d that is consistent with  m training examples has misclassification probability no more than  ( 1 (Neff VCdim(L/) log 2 mlogd)) 1/2) where/g is the class of  node decision functions, and Neff _ N can be thought of as the  effective number of leaves (it becomes small as the distribution on  the leaves induced by the training data gets far from uniform).  This bound is qualitatively different from the VC bound and can  be considerably smaller.  We use the same technique to give similar results for DNF formulae.  * Author to whom correspondence should be addressed  260 M. Gotea, P Bartlett, W. S. Lee and L Mason
A simple linear averaging of the outputs of several networks as  e.g. in bagging [3], seems to follow naturally from a bias/variance  decomposition of the sum-squared error. The sum-squared error of  the average model is a quadratic function of the weighting factors  assigned to the networks in the ensemble [7], suggesting a quadratic  programming algorithm for finding the "optimal" weighting factors.  If we interpret the output of a network as a probability statement,  the sum-squared error corresponds to minus the loglikelihood or  the Kullback-Leibler divergence, and linear averaging of the outputs to logarithmic averaging of the probability statements: the  logarithmic opinion pool.  The crux of this paper is that this whole story about model averaging, bias/variance decompositions, and quadratic programming  to find the optimal weighting factors, is not specific for the sumsquared error, but applies to the combination of probability statements of any kind in a logarithmic opinion pool, as long as the  Kullback-Leibler divergence plays the role of the error measure. As  examples we treat model averaging for classification models under  a cross-entropy error measure and models for estimating variances.
We derive a first-order approximation of the density of maximum  entropy for a continuous 1-D random variable, given a number of  simple constraints. This results in a density expansion which is  somewhat similar to the classical polynomial density expansions  by Gram-Charlier and Edgeworth. Using this approximation of  density, an approximation of 1-D differential entropy is derived.  The approximation of entropy is both more exact and more robust against outliers than the classical approximation based on  the polynomial density expansions, without being computationally  more expensive. The approximation has applications, for example,  in independent component analysis and projection pursuit.
We present a new approximate learning algorithm for Boltzmann  Machines, using a systematic expansion of the Gibbs free energy to  second order in the weights. The linear response correction to the  correlations is given by the Hessian of the Gibbs free energy. The  computational complexity of the algorithm is cubic in the number  of neurons. We compare the performance of the exact BM learning  algorithm with first order (Weiss) mean field theory and second  order (TAP) mean field theory. The learning task consists of a fully  connected Ising spin glass model on 10 neurons. We conclude that  1) the method works well for paramagnetic problems 2) the TAP  correction gives a significant improvement over the Weiss mean field  theory, both for paramagnetic and spin glass problems and 3) that  the inclusion of diagonal weights improves the Weiss approximation  for parame[gnetic problems, but not for spin glass problems.
We study on-line generalized linear regression with multidimensional  outputs, i.e., neural networks with multiple output nodes but no hidden  nodes. We allow at the final layer transfer functions such as the softmax function that need to consider the linear activations to all the output  neurons. We use distance functions of a certain kind in two completely  independent roles in deriving and analyzing on-line learning algorithms  for such tasks. We use one distance function to define a matching loss  function for the (possibly multidimensional) transfer function, which allows us to generalize earlier results from one-dimensional to multidimensional outputs. We use another distance function as a tool for measuring  progress made by the on-line updates. This shows how previously studied algorithms such as gradient descent and exponentiated gradient fit  into a common framework. We evaluate the performance of the algorithms using relative loss bounds that compare the loss of the on-line  algoritm to the best off-line predictor from the relevant model class, thus  completely eliminating probabilistic assumptions about the data.
The generalization ability of a neural network can sometimes be  improved dramatically by regularization. To analyze the improvement one needs more refined results than the asymptotic distribution of the weight vector. Here we study the simple case of  one-dimensional linear regression under quadratic regularization,  i.e., ridge regression. We study the random design, misspecified  case, where we derive expansions for the optimal regularization parameter and the ensuing improvement. It is possible to construct  examples where it is best to use no regularization.
We employ both master equation and order parameter approaches  to analyze the asymptotic dynamics of on-line learning with different learning rate annealing schedules. We examine the relations  between the results obtained by the two approaches and obtain new  results on the optimal decay coefficients and their dependence on  the number of hidden nodes in a two layer architecture.
The problem of time series prediction is studied within the uniform convergence framework of Vapnik and Chervonenkis. The dependence inherent in the temporal structure is incorporated into the analysis, thereby  generalizing the available theory for memoryless processes. Finite sample bounds are calculated in terms of covering numbers of the approximating class, and the tradeoff between approximation and estimation is  discussed. A complexity regularization approach is outlined, based on  Vapnik's method of Structural Risk Minimization, and shown to be applicable in the context of mixing stochastic processes.
We study model feed forward networks as time series predictors  in the stationary limit. The focus is on complex, yet non-chaotic,  behavior. The main question we address is whether the asymptotic  behavior is governed by the architecture, regardless the details of  the weights. We find hierarchies among classes of architectures  with respect to the attractor dimension of the long term sequence  they are capable of generating; larger number of hidden units can  generate higher dimensional attractors. In the case of a perceptron,  we develop the stationary solution for general weights, and show  that the flow is typically one dimensional. The relaxation time  from an arbitrary initial condition to the stationary solution is  found to scale linearly with the size of the network. In multilayer  networks, the number of hidden units gives bounds on the number  and dimension of the possible attractors. We conclude that long  term prediction (in the non-chaotic regime) with such models is  governed 'by attractor dynamics related to the architecture.  Neural networks provide an important tool as model free estimators for the solution  of problems when the real model is unknown, or weakly known. In the last decade  there has been a growing interest in the application of such tools in the area of time  series prediction (see Weigand and Gershenfeld, 1994). In this paper we analyse a  typical class of architectures used in this field, i.e. a feed forward network governed  by the following dynamic rule:  S +1 --Sou t ; S +1 -S_ 1 j = 2,...,N (1)  where Sour is the network's output at time step t and S are the inputs at that time;  N is the size of the delayed input vector. The rational behind using time delayed  vectors as inputs is the theory of state space reconstruction of a dynamic system  316 A. Priel, I. Kanter and D. A. Kessler  using delay coordinates (Takens 1981, Sauer Yorke and Casdagli 1991). This theory address the problem of reproducing a set of states associated with the dynamic  system using vectors obtained from the measured time series, and is widely used for  time series analysis. A similar architecture incorporating time delays is the TDNN  time-delay neural network with a recurrent loop (Waibel et. al. 1989). This type  of networks is known to be appropriate for learning temporal sequences, e.g. speech  signal. In the context of time series, it is mostly used for short term predictions. Our  analysis focuses on the various long-time properties of the sequence generated by a  given architecture and the interplay between them. The aim of such an investigation is the understanding and characterization of the long term sequences generated  by such architectures, and the time scale to reach this asymptotic behavior. Such  knowledge is necessary to define adequate measures for the transition between a  locally dependent prediction and the long term behavior. Though some work has  been done on characterization of a dynamic system from its time series using neural networks, not much analytical results that connect architecture and long-time  prediction are available (see M. Mozer in Weigand and Gershenfeld, 1994). Nevertheless, practical considerations for choosing the architecture were investigated  extensively (Weigand and Gershenfeld, 1994 and references therein). It has been  shown that such networks are capable of generating chaotic like sequences. While  it is possible to reconstruct approximately the phase space of chaotic attractors (at  least in low dimension), it is clear that prediction of chaotic sequences is limited  by the very nature of such systems, namely the divergence of the distance between  nearby trajectories. Therefore one can only speak about short time predictions with  respect to such systems. Our focus is the ability to generate complex sequences,  and the relation between architecture and the dimension of such sequences.
We present a method for determining the globally optimal on-line  learning rule for a soft committee machine under a statistical mechanics framework. This work complements previous results on  locally optimal rules, where only the rate of change in generalization error was considered. We maximize the total reduction in  generalization error over the whole learning process and show how  the resulting rule can significantly outperform the locally optimal  rule.
A Lyapunov function for excitatory-inhibitory networks is constructed.  The construction assumes symmetric interactions within excitatory and  inhibitory populations of neurons, and antisymmetric interactions between populations. The Lyapunov function yields sucient conditions  for the global asymptotic stability of fixed points. If these conditions  axe violated, limit cycles may be stable. The relations of the Lyapunov  function to optimization theory and classical mechanics axe revealed by  minimax and dissipative Hamiltonian forms of the network dynamics.  The dynamics of a neural network with symmetric interactions provably converges to  fixed points under very general assumptions[I, 2]. This mathematical result helped  to establish the paradigm of neural computation with fixed point attractors[3]. But  in reality, interactions between neurons in the brain are asymmetric. Furthermore,  the dynamical behaviors seen in the brain are not confined to fixed point attractors,  but also include oscillations and complex nonperiodic behavior. These other types  of dynamics can be realized by asymmetric networks, and may be useful for neural  computation. For these reasons, it is important to understand the global behavior  of asymmetric neural networks.  The interaction between an excitatory neuron and an inhibitory neuron is clearly  asymmetric. Here we consider a class of networks that incorporates this fundamental asymmetry of the brain's microcircuitry. Networks of this class have distinct  populations of excitatory and inhibitory neurons, with antisymmetric interactions  330 H. S. $eung, T. J. Richardson, J. C. Lagarias and J. J. Hopfield  between populations and symmetric interactions within each population. Such networks display a rich repertoire of dynamical behaviors including fixed points, limit  cycles[4, 5] and traveling waves[6].  After defining the class of excitatory-inhibitory networks, we introduce a Lyapunov  function that establishes sufficient conditions for the global asymptotic stability  of fixed points. The generality of these conditions contrasts with the restricted  nature of previous convergence results, which applied only to linear networks[5], or  to nonlinear networks with infinitely fast inhibition[7].  The use of the Lyapunov function is illustrated with a competitive or winner-take-all  network, which consists of an excitatory population of neurons with recurrent inhibition from a single neuron[8]. For this network, the sufficient conditions for global  stability of fixed points also happen to be necessary conditions. In other words,  we have proved global stability over the largest possible parameter regime in which  it holds, demonstrating the power of the Lyapunov function. There exists another  parameter regime in which numerical simulations display limit cycle oscillations[7].  Similar convergence proofs for other excitatory-inhibitory networks may be obtained  by tedious but straightforward calculations. All the necessary tools are given in the  first half of the paper. But the rest of the paper explains what makes the Lyapunov  function especially interesting, beyond the convergence results it yields: its role in  a conceptual framework that relates excitatory-inhibitory networks to optimization  theory and classical mechanics.  The connection between neural networks and optimization[3] was established by  proofs that symmetric networks could find minima of objective functions[I, 2]. Later  it was discovered that excitatory-inhibitory networks could perform the minimax  computation of finding saddle points[9, 10, 11], though no general proof of this was  given at the time. Our Lyapunov function finally supplies such a proof, and one of  its components is the objective function of the network's minimax computation.  Our Lyapunov function can also be obtained by writing the dynamics of excitatoryinhibitory networks in HamiltonJan form, with extra velocity-dependent terms. If  these extra terms are dissipative, then the energy of the system is nonincreasing,  and is a Lyapunov function. If the extra terms are not purely dissipative, limit  cycles are possible. Previous HamiltonJan formalisms for neural networks made  the more restrictive assumption of purely antisymmetric interactions, and did not  include the effect of dissipation[12].  This paper establishes sufficient conditions for global asymptotic stability of fixed  points. The problem of finding sufficient conditions for oscillatory and chaotic  behavior remains open. The perspectives of minimax and Hamiltonian dynamics  may help in this task.
Perceptron Decision Trees (a! known as Linear Machine DTs,  etc.) are analysed in order that data-dependent Structural Risk  Minlml,ation can be applied. Data-dependent analysis is performed which indicates that choosing the maximal margin hyperplancs at the decision nodes will improve the generalization. The  analysis uses a novel technique to bound the generalization error in  terms of the margins at individual nodes. Experiments performed  on real data sets confirm the validity of the approach.
We derive the correspondence between regularization operators used in  Regularization Networks and Hilbert Schmidt Kernels appearing in Support Vector Machines. More specifically, we prove that the Green's Functions associated with regularization operators are suitable Support Vector  Kernels with equivalent regularization properties. As a by-product we  show that a large number of Radial Basis Functions namely conditionally positive definite functions may be used as Support Vector kernels.
A simple but powerful modification of the standard Gaussian distribution is studied. The variables of the rectified Gaussian are  constrained to be nonnegative, enabling the use of nonconvex energy functions. Two multimodal examples, the competitive and  cooperative distributions, illustrate the representationai power of  the rectified Gaussian. Since the cooperative distribution can represent the translations of a pattern, it demonstrates the potential  of the rectified Gaussian for modeling pattern manifolds.
Online learning is one of the most common forms of neural network training. We present an analysis of online learning from finite  training sets for non-linear networks (namely, soft-committee machines), advancing the theory to more realistic learning scenarios.  Dynamical equations are derived for an appropriate set of order  parameters; these are exact in the limiting case of either linear  networks or infinite training sets. Preliminary comparisons with  simulations suggest that the theory captures some effects of finite  training sets, but may not yet account correctly for the presence of  local minima.
We apply a general algorithm for merging prediction strategies (the  Aggregating Algorithm) to the problem of linear regression with the  square loss; our main assumption is that the response variable is  bounded. It turns out that for this particular problem the Aggregating Algorithm resembles, but is slightly different from, the wellknown ridge estimation procedure. From general results about the  Aggregating Algorithm we deduce a guaranteed bound on the difference between our algorithm's performance and the best, in some  sense, linear regression function's performance. We show that the  AA attains the optimal constant in our bound, whereas the constant attained by the ridge regression procedure in general can be  4 times worse.
We demonstrate that the problem of training neural networks with  small (average) squared error is computationally intractable. Consider a data set of M points (Xi, Y/), i 1, 2,..., M, where Xi are  input vectors from R d, Y/ are real outputs (Y/ & R). For a netM  work f0 in some class : of neural networks, (/4) Ei_-(f0(Xi))2)/.._ in f fe:(1/M) -.iM__(f(Xi )_ yi)2)1[2 is the (avarage) relative error occurs when one tries to fit the data set by f0. We will  prove for several classes Y of neural networks that achieving a relative error smaller than some fixed positive threshold (independent  from the size of the data set) is NP-hard.
We study the storage capacity of a fully-connected committee machine with a large number K of hidden nodes. The storage capacity is obtained by analyzing the geometrical structure of the weight space related to the internal representation. By examining the asymptotic behavior of order parameters in the limit of large K, the storage capacity ac is found to be proportional to K l up to the leading order. This result satisfies the mathematical bound given by Mitchison and Durbin, whereas the replica-symmetric solution in a conventional Gardner's approach violates this bound. 
The inverse of the Fisher information matrix is used in the natural gradient descent algorithm to train single-layer and multi-layer  perceptrons. We have discovered a new scheme to represent the  Fisher information matrix of a stochastic multi-layer perceptron.  Based on this scheme, we have designed an algorithm to compute  the natural gradient. When the input dimension n is much larger  than the number of hidden neurons, the complexity of this algorithm is of order O(n). It is confirmed by simulations that the  natural gradient descent learning rule is not only efficient but also  robust.
Bayesian treatments of learning in neural networks are typically  based either on local Gaussian approximations to a mode of the  posterior weight distribution, or on Markov chain Monte Carlo  simulations. A third approach, called ensemble learning, was introduced by Hinton and van Camp (1993). It aims to approximate  the posterior distribution by minimizing the Kullback-Leibler divergence between the true posterior and a parametric approximating distribution. However, the derivation of a deterministic algorithm relied on the use of a Gaussian approximating distribution  with a diagonal covariance matrix and so was unable to capture  the posterior correlations between parameters. In this paper, we  show how the ensemble learning approach can be extended to fullcovariance Gaussian distributions while remaining computationally  tractable. We also extend the framework to deal with hyperparameters, leading to a simple re-estimation procedure. Initial results  from a standard benchmark problem are encouraging.
Bayesian methods have been successfully applied to regression and  classification problems in multi-layer percepttons. We present a  novel application of Bayesian techniques to Radial Basis Function  networks by developing a Gaussian approximation to the posterior  distribution which, for fixed basis function widths, is analytic in  the parameters. The setting of regularization constants by crossvalidation is wasteful as only a single optimal parameter estimate  is retained. We treat this issue by assigning prior distributions to  these constants, which are then adapted in light of the data under  a simple re-estimation formula.
Recently, a model for supervised learning of probabilistic transducers represented by suffix trees was introduced. However, this algorithm tends to build very large trees, requiring very large amounts  of computer memory. In this paper, we propose a new, more compact, transducer model in which one shares the parameters of distributions associated to contexts yielding similar conditional output  distributions. We illustrate the advantages of the proposed algorithm with comparative experiments on inducing a noun phrase  recognizer.
Exact inference in densely connected Bayesian networks is computationally intractable, and so there is considerable interest in developing effective approximation schemes. One approach which has been adopted is to  bound the log likelihood using a mean-field approximating distribution.  While this leads to a tractable algorithm, the mean field distribution is assumed to be factorial and hence unimodal. In this paper we demonstrate  the feasibility of using a richer class of approximating distributions based  on mixtures of mean field distributions. We derive an efficient algorithm  for updating the mixture parameters and apply it to the problem of learning in sigmoid belief networks. Our results demonstrate a systematic  improvement over simple mean field theory as the number of mixture  components is increased.
We study several statistically and biologically motivated learning  rules using the same visual environment, one made up of natural  scenes, and the same single cell neuronal architecture. This allows  us to concentrate on the feature extraction and neuronal coding  properties of these rules. Included in these rules are kurtosis and  skewness maximization, the quadratic form of the BCM learning  rule, and single cell ICA. Using a structure removal method, we  demonstrate that receptive fields developed using these rules depend on a small portion of the distribution. We find that the  quadratic form of the BCM rule behaves in a manner similar to a  kurtosis maximization rule when the distribution contains kurtotic  directions, although the BCM modification equations are computationally simpler.  424 B. S. BIais, iV. Intrator, H. ShouvaI and L iV. Cooper
We derive and analyse robust optimization schemes for noisy vector  quantization on the basis of deterministic annealing. Starting from a  cost function for central clustering that incorporates distortions from  channel noise we develop a soft topographic vector quantization algorithm (STVQ) which is based on the maximum entropy principle  and which performs a maximum-likelihood estimate in an expectationmaximization (EM) fashion. Annealing in the temperature parameter/3  leads to phase transitions in the existing code vector representation during the cooling process for which we calculate critical temperatures and  modes as a function of eigenvectors and eigenvalues of the covariance  matrix of the data and the transition matrix of the channel noise. A whole  family of vector quantization algorithms is derived from STVQ, among  them a deterministic annealing scheme for Kohonen's self-organizing  map (SOM). This algorithm, which we call SSOM, is then applied to  vector quantization of image data to be sent via a noisy binary symmetric  channel. The algorithm's performance is compared to those of LBG and  STVQ. While it is naturally superior to LBG, which does not take into  account channel noise, its results compare very well to those of STVQ,  which is computationally much more demanding.
In many applications, such as credit default prediction and medical image recognition, test inputs are available in addition to the labeled training examples. We propose a method to incorporate the test inputs into  learning. Our method results in solutions having smaller test errors than  that of simple training solution, especially for noisy problems or small  training sets.
This paper considers the problem of learning the ranking of a set  of alternatives based upon incomplete information (e.g., a limited  number of observations). We describe two algorithms for hypothesis ranking and their application for probably approximately correct (PAC) and expected loss (EL) learning criteria. Empirical  results are provided to demonstrate the effectiveness of these ranking procedures on both synthetic datasets and real-world data from  a spacecraft design optimization problem.
There are many applications in which it is desirable to order rather than classify  instances. Here we consider the problem of learning how to order, given feedback  in the form of preference judgments, i.e., statements to the effect that one instance  should be ranked ahead of another. We outline a two-stage approach in which one  first learns by conventional means a preference function, of the form PREF(u, v),  which indicates whether it is advisable to rank u before v. New instances are  then ordered so as to maximize agreements with the learned preference function. We show that the problem of finding the ordering that agrees best with  a preference function is NP-complete, even under very restrictive assumptions.  Nevertheless, we describe a simple greedy algorithm that is guaranteed to find a  good approximation. We then discuss an on-line learning algorithm, based on the  "Hedge" algorithm, for finding a good linear combination of ranking "experts."  We use the ordering algorithm combined with the on-line learning algorithm to  find a combination of "search experts," each of which is a domain-specific query  expansion strategy for a WWW search engine, and present experimental results  that demonstrate the merits of our approach.
In this paper, we discuss regularisation in online/sequential learning algorithms. In environments where data arrives sequentially,  techniques such as cross-validation to achieve regularisation or  model selection are not possible. Further, bootstrapping to determine a confidence level is not practical. To surmount these  problems, a minimum variance estimation approach that makes use  of the extended Kalman algorithm for training multi-layer perceptrons is employed. The novel contribution of this paper is to show  the theoretical links between extended Kalman filtering, Sutton's  variable learning rate algorithms and Mackay's Bayesian estimation framework. In doing so, we propose algorithms to overcome  the need for heuristic choices of the initial conditions and noise  covariance matrices in the Kalman approach.
Classification of finite sequences without explicit knowledge of their  statistical nature is a fundamental problem with many important  applications. We propose a new information theoretic approach  to this problem which is based on the following ingredients: (i) sequences are similar when they are likely to be generated by the same  source; (ii) cross entropies can be estimated via "universal compression"; (iii) Markovian sequences can be asymptotically-optimally  merged.  With these ingredients we design a method for the classification of  discrete sequences whenever they can be compressed. We introduce  the method and illustrate its application for hierarchical clustering  of languages and for estimating similarities of protein sequences.
A new learning model based on autoassociative neural networks  is developped and applied to face detection. To extend the detection ability in orientation and to decrease the number of false  alarms, different combinations of networks are tested: ensemble,  conditional ensemble and conditional mixture of networks. The  use of a conditional mixture of networks allows to obtain state of  the art results on different benchmark face databases.
Until recently, artificial intelligence researchers have frowned upon  the application of probability propagation in Bayesian belief networks that have cycles. The probability propagation algorithm is  only exact in networks that are cycle-free. However, it has recently  been discovered that the two best error-correcting decoding algorithms are actually performing probability propagation in belief  networks with cycles.
We first describe a hierarchical, generafive model that can be  viewed as a non-linear generalisation of factor analysis and can  be implemented in a neural network. The model performs perceptual inference in a probabilistically consistent manner by using  top-down, bottom-up and lateral connections. These connections  can be learned using simple rules that require only locally available information. We then show how to incorporate lateral connections into the generafive model. The model extracts a sparse,  distributed, hierarchical representation of depth from simplified  random-dot stereograms and the localised disparity detectors in  the first hidden layer form a topographic map. When presented  with image patches from natural scenes, the model develops topographically organised local feature detectors.
Regression with Input-dependent Noise:  A Gaussian Process Treatment  Paul W. Goldberg  Department of Computer Science  University of Warwick  Coventry, CV4 7AL, UK  pgdcs. arick. ac. uk  Christopher K.I. Williams  Neural Computing Research Group  Aston University  Birmingham B4 7ET, UK  ½. k. i. williamsaston. a½. uk  Christopher M. Bishop  Microsoft Research  St. George House
Some learning techniques for classification tasks work indirectly, by first trying  to fit a full probabilistic model to the observed data. Whether this is a good idea  or not depends on the robustness with respect to deviations from the postulated  model. We study this question experimentally in a restricted, yet non-trivial and  interesting case: we consider a conditionally independent attribute (CIA) model  which postulates a single binary-valued hidden variable z on which all other  attributes (i.e., the target and the observables) depend. In this model, finding the  most likely value of any one variable (given known values for the others) reduces  to testing a linear function of the observed values.  We learn CIA with two techniques: the standard EM algorithm, and a new  algorithm we develop based on covariances. We compare these, in a conu'olled  fashion, against an algorithm (a version of Winnow) that attempts to find a good  linear classifier directly. Our conclusions help delimit the fragility of using the  CIA model for classification: once the data departs from this model, performance  quickly degrades and drops below that of the directly-learned linear classifier.
We discuss a strategy for polychotomous classification that involves  estimating class probabilities for each pair of classes, and then coupling the estimates together. The coupling model is similar to the  Bradley-Terry method for paired comparisons. We study the nature of the class probability estimates that arise, and examine the  performance of the procedure in simulated datasets. The classifiers  used include linear discriminants and nearest neighbors: application to support vector machines is also briefly described.
An adaptive on-line algorithm is proposed to estimate hierarchical  data structures for non-stationary data sources. The approach  is based on the principle of minimum cross entropy to derive a  decision tree for data clustering and it employs a metalearning idea  (learning to learn) to adapt to changes in data characteristics. Its  efficiency is demonstrated by grouping non-stationary artifical data  and by hierarchical segmentation of LANDSAT images.
We address the problem of learning structure in nonlinear Markov networks  with continuous variables. This can be viewed as non-Gaussian multidimensional density estimation exploiting certain conditional independencies  in the variables. Markov networks are a graphical way of describing conditional independencies well suited to model relationships which do not exhibit a natural causal ordering. We use neural network structures to model  the quantitative relationships between variables. The main focus in this paper will be on learning the structure for the purpose of gaining insight into  the underlying process. Using two data sets we show that interesting structures can be found using our approach. Inference will be briefly addressed.
Active data clustering is a novel technique for clustering of proximity data which utilizes principles from sequential experiment design  in order to interleave data generation and data analysis. The proposed active data sampling strategy is based on the expected value  of information, a concept rooting in statistical decision theory. This  is considered to be an important step towards the analysis of largescale data sets, because it offers a way to overcome the inherent  data sparseness of proximity data. We present applications to unsupervised texture segmentation in computer vision and information  retrieval in document databases.
We present a computationally efficient algorithm for function approximation with piecewise linear sigmoidal nodes. A one hidden  layer network is constructed one node at a time using the method of  fitting the residual. The task of fitting individual nodes is accomplished using a new algorithm that searchs for the best fit by solving  a sequence of Quadratic Programming problems. This approach offers significant advantages over derivative-based search algorithms  (e.g. backpropagation and its extensions). Unique characteristics  of this algorithm include: finite step convergence, a simple stopping criterion, a deterministic methodology for seeking "good" local  minima, good scaling properties and a robust numerical implementation.
A new class of plug in classification techniques have recently been developed in the statistics and machine learning literature. A plug in classiftcation technique (PACT) is a method that takes a standard classifier  (such as LDA or TREES) and plugs it into an algorithm to produce a  new classifier. The standard classifier is known as the Plug in Classifier (PiC). These methods often produce large improvements over using  a single classifier. In this paper we investigate one of these methods and  give some motivation for its success.
The S-Map is a network with a simple learning algorithm that combines the self-organization capability of the Self-Organizing Map  (SOM) and the probabilistic interpretability of the Generative Topographic Mapping (GTM). The simulations suggest that the SMap algorithm has a stronger tendency to self-organize from random initial configuration than the GTM. The S-Map algorithm  can be further simplified to employ pure Hebbian learning, without changing the qualitative behaviour of the network.
We derive a learning algorithm for inferring an overcomplete basis  by viewing it as probabilistic model of the observed data. Overcomplete bases allow for better approximation of the underlying  statistical density. Using a Laplacian prior on the basis coefficients  removes redundancy and leads to representations that are sparse  and are a nonlinear function of the data. This can be viewed as  a generalization of the technique of independent component analysis and provides a method for blind source separation of fewer  mixtures than sources. We demonstrate the utility of overcomplete representations on natural speech and show that compared  to the traditional Fourier basis the inferred representations potentially have much greater coding efficiency.  A traditional way to represent real-values signals is with Fourier or wavelet bases.  A disadvantage of these bases, however, is that they are not specialized for any  particular dataset. Principal component analysis (PCA) provides one means for  finding an basis that is adapted for a dataset, but the basis vectors are restricted  to be orthogonal. An extension of PCA called independent component analysis  (Jutten and Herault, 1991; Comon et al., 1991; Bell and Sejnowski, 1995) allows  the learning of non-orthogonal bases. All of these bases are complete in the sense  that they span the input space, but they are limited in terms of how well they can  approximate the dataset's statistical density.  Representations that are overcomplete, i.e. more basis vectors than input variables,  can provide a better representation, because the basis vectors can be specialized for  Learning Nonlinear Overcomplete Representations for Efficient Coding 557  a larger variety of features present in the entire ensemble of data. A criticism of  overcomplete representations is that they are redundant, i.e. a given data point may  have many possible representations, but this redundancy is removed by the prior  probability of the basis coeffcients which specifies the probability of the alternative  representations.  Most of the overcomplete bases used in the literature are fixed in the sense that  they are not adapted to the structure in the data. Recently Olshausen and Field  (1996) presented an algorithm that allows an overcomplete basis to be learned. This  algorithm relied on an approximation to the desired probabilistic objective that had  several drawbacks, including tendency to breakdown in the case of low noise levels  and when learning bases with higher degrees of overcompleteness. In this paper, we  present an improved approximation to the desired probabilistic objective and show  that this leads to a simple and robust algorithm for learning optimal overcomplete  bases.
The mathematical framework for factorizing equivalence classes of  multivariate functions is formulated in this paper. Independent  component analysis is shown to be a special case of this decomposition. Using only the local geometric structure of a class representative, we derive an analytic solution for the factorization. We  demonstrate the factorization solution with numerical experiments  and present a preliminary tie to decorrelation.
Multiple-instance learning is a variation on supervised learning, where the  task is to learn a concept given positive and negative bags of instances.  Each bag may contain many instances, but a bag is labeled positive even  if only one of the instances in it falls within the concept. A bag is labeled  negative only if all the instances in it are negative. We describe a new  general framework, called Diverse Density, for solving multiple-instance  learning problems. We apply this framework to learn a simple description  of a person from a series of images (bags) containing that person, to a stock  selection problem, and to the drug activity prediction problem.
Applications of Gaussian mixture models occur frequently in the  fields of statistics and artificial neural networks. One of the key  issues arising from any mixture model apphcation is how to estimate the optimum number of mixture components. This paper  extends the Reversible-Jump Markov Chain Monte Carlo (MCMC)  algorithm to the case of multivariate spherical Gaussian mixtures  using a hierarchical prior model. Using this method the number  of mixture components is no longer fixed but becomes a parmeter of the model which we shall estimate. The Reversible-Jump  MCMC algorithm is capable of moving between parameter subspaces which correspond to models with different numbers of mixture components. As a result a sample from the full joint distribution of all unknown model parameters is generated. The technique  is then demonstrated on a simulated example and a well known  vowel dataset.
This paper introduces a probability model, the mixture of trees that can  account for sparse, dynamically changing dependence relationships. We  present a family of efficient algorithms that use EM and the Minimum  Spanning Tree algorithm to find the ML and MAP mixture of trees for a  variety of priors, including the Dirichlet and the MDL priors.
Several effective methods for improving the performance of a single learning algorithm have been developed recently. The general  approach is to create a set of learned models by repeatedly applying the algorithm to different versions of the training data, and  then combine the learned models' predictions according to a prescribed voting scheme. Little work has been done in combining the  predictions of a collection of models generated by many learning  algorithms having different representation and/or search strategies.  This paper describes a method which uses the strategies of stacking and correspondence analysis to model the relationship between  the learning examples and the way in which they are classified by  a collection of learned models. A nearest neighbor method is then  applied within the resulting representation to classify previously  unseen examples. The new algorithm consistently performs as well  or better than other combining techniques on a suite of data sets.
We propose diffusion networks, a type of recurrent neural network with probabilistic dynamics, as models for learning natural signals that are continuous in time and space. We give a formula for the gradient of the log-likelihood of a path with respect to the drift parameters for a diffusion network. This gradient can be used to optimize diffusion networks in the nonequilibrium regime for a wide variety of problems paralleling techniques which have succeeded in engineering fields such as system identification, state estimation and signal filtering. An aspect of this work which is of particular interest to computational neuroscience and hardware design is that with a suitable choice of activation function, e.g., quasi-linear sigmoidal, the gradient formula is local in space and time. 
Up-propagation is an algorithm for inverting and learning neural network  generative models. Sensory input is processed by inverting a model that  generates patterns from hidden variables using top-down connections.  The inversion process is iterative, utilizing a negative feedback loop that  depends on an error signal propagated by bottom-up connections. The  error signal is also used to learn the generative model from examples.  The algorithm is benchmarked against principal component analysis in  experiments on images of handwritten digits.  In his doctrine of unconscious inference, Helmholtz argued that perceptions are  formed by the interaction of bottom-up sensory data with top-down expectations.  According to one interpretation of this doctrine, perception is a procedure of sequential hypothesis testing. We propose a new algorithm, called up-propagation, that  realizes this interpretation in layered neural networks. It uses top-down connections  to generate hypotheses, and bottom-up connections to revise them.  It is important to understand the difference between up-propagation and its ancestor, the backpropagation algorithm[I]. Bckpropagation is a learning algorithm  for recognition models. As shown in Figure la, bottom-up connections recognize  patterns, while top-down connections propagate an error signal that is used to learn  the recognition model.  In contrast, up-propagation is an algorithm for inverting ad learning generatire  models, as shown in Figure lb. Top-down connections generate patterns from a  set of hidden variables. Sensory input is processed by inverting the generative  model, recovering hidden variables that could have generated the sensory data.  This operation is called either pattern recognition or pattern analysis, depending  on the meaning of the hidden variables. Inversion of the generafive model is done  iteratively, through a negative feedback loop driven by an error signal from the  bottom-up connections. The error signal is also used for learning the connections  606 J-H. Oh and H. $. Seung  error  (a)  recognition  generation  (b)  error  Figure 1: Bottom-up and top-down processing in neural networks. (a) Backprop  network (b) Up-prop network  in the generarive model.  Up-propagation can be regarded as a generalization of principal component analysis  (PCA) emd its variants like Conic[2] to nonlinear, multilayer generafive models. Our  experiments with images of handwritten digits demonstrate that up-propagation  learns a global, nonlinear model of a pattern metalloid. With its global parametrization, this model is distinct from locally linear models of pattern manifolds[3].
We consider the general problem of learning multi-category classification from labeled examples. We present experimental results for  a nearest neighbor algorithm which actively selects samples from  different pattern classes according to a querying rule instead of the  a priori class probabilities. The amount of improvement of this  query-based approach over the passive batch approach depends on  the complexity of the Bayes rule. The principle on which this algorithm is based is general enough to be used in any learning algorithm which permits a model-selection criterion and for which the  error rate of the classifier is calculable in terms of the complexity  of the model.
Existing proofs demonstrating the computational limitations of Recurrent Cascade Correlation and similar networks (Fahlman, 1991;  Bachtach, 1988; Mozer, 1988) explicitly limit their results to units  having sigmoidal or hard-threshold transfer functions (Giles et al.,  1995; and Kremer, 1996). The proof given here shows that for  any finite, discrete transfer function used by the units of an RCC  network, there are finite-state automata (FSA) that the network  cannot model, no matter how many units are used. The proof also  applies to continuous transfer functions with a finite number of  fixed-points, such as sigmoid and radial-basis functions.
I present an expectation-maximization (EM) algorithm for principal  component analysis (?CA). The algorithm allows a few eigenvectors and  eigenvalues to be extracted from large collections of high dimensional  data. It is computationally very efficient in space and time. It also naturally accommodates missing information. I also introduce a new variant  of ?CA called sensible principal component analysis (S?CA) which defines a proper density model in the data space. Learning for S?CA is also  done with an EM algorithm. I report results on synthetic and real data  showing that these EM algorithms correctly and efficiently find the leading eigenvectors of the covariance of datasets in a few iterations using up  to hundreds of thousands of datapoints in thousands of dimensions.
If globally high dimensional data has locally only low dimensional distributions, it is advantageous to perform a local dimensionality reduction before  further processing the data. In this paper we examine several techniques for  local dimensionality reduction in the context of locally weighted linear regression. As possible candidates, we derive local versions of factor analysis  regression, principle component regression, principle component regression  on joint distributions, and partial least squares regression. After outlining the  statistical bases of these methods, we perform Monte Carlo simulations to  evaluate their robustness with respect to violations of their statistical assumptions. One surprising outcome is that locally weighted partial least  squares regression offers the best average results, thus outperforming even  factor analysis, the theoretically most appealing of our candidate techniques.  1 TRODUCTION  Regression tasks involve mapping a n-dimensional continuous input vector x  filn onto  a m-dimensional output vector y  fil m. They form a ubiquitous class of problems found  in fields including process control, sensorimotor control, coordinate transformations, and  various stages of information processing in biological nervous systems. This paper will  focus on spatially localized learning techniques, for example, kernel regression with  Gaussian weighting functions. Local learning offer advantages for real-time incremental  learning problems due to fast convergence, considerable robustness towards problems of  negative interference, and large tolerance in model selection (Atkeson, Moore, & Schaal,  1997; Schaal & Atkeson, in press). Local learning is usually based on interpolating data  from a local neighborhood around the query point. For high dimensional learning problems, however, it suffers from a bias/variance dilemma, caused by the nonintuitive fact  that "... [in high dimensions] if neighborhoods are local, then they are almost surely  empty, whereas if a neighborhood is not empty, then it is not local." (Scott, 1992, p. 198).  Global learning methods, such as sigmoidal feedforward networks, do not face this  634 S. SchaaI, S. Vijayakumar and C. G. Atkeson  problem as they do not employ neighborhood relations, although they require strong  prior knowledge about the problem at hand in order to be successful.  Assuming that local learning in high dimensions is a hopeless, however, is not necessarily warranted: being globally high dimensional does not imply that data remains high dimensional if viewed locally. For example, in the control of robot arms and biological  arms we have shown that for estimating the inverse dynamics of an arm, a globally 21dimensional space reduces on average to 4-6 dimensions locally (Vijayakumar & Schaal,  1997). A local learning system that can robustly exploit such locally low dimensional  distributions should be able to avoid the curse of dimensionality.  In pursuit of the question of what, in the context of local regression, is the "fight"  method to perform local dimensionality reduction, this paper will derive and compare  several candidate techniques under i) perfectly fulfilled statistical prerequisites (e.g.,  Gaussian noise, Gaussian input distributions, perfectly linear data), and ii) less perfect  conditions (e.g., non-Gaussian distributions, slightly quadratic data, incorrect guess of  the dimensionality of the true data distribution). We will focus on nonlinear function approximation with locally weighted linear regression (LWR), as it allows us to adapt a variety of global linear dimensionality reduction techniques, and as LWR has found widespread application in several local learning systems (Atkeson, Moore, & Schaal, 1997;  Jordan & Jacobs, 1994; Xu, Jordan, & Hinton, 1996). In particular, we will derive and  investigate locally weighted principal component regression (LWPCR), locally weighted  joint data principal component analysis (LWPCA), locally weighted factor analysis  (LWFA), and locally weighted partial least squares (LWPLS). Section 2 will briefly outline these methods and their theoretical foundations, while Section 3 will empirically  evaluate the robustness of these methods using synthetic data sets that increasingly violate some of the statistical assumptions of the techniques.  2 METHODS OF DIMENSIONAI,ITY REDUCTION  We assume that our regression data originate from a generating process with two sets of  observables, the "inputs" i and the "outputs" . The characteristics of the process ensure a functional relation  = f(i). Both i and  are obtained through some measurement device that adds independent mean zero noise of different magnitude in each observable, such that x = i + c x and y = y + cy. For the sake of simplicity, we will only focus on one-dimensional output data (rn=l) and functions f that are either linear or  slightly quadratic, as these cases are the most common in nonlinear function approximation with locally linear models. Locality of the regression is ensured by weighting the error of each data point with a weight from a Gaussian kernel:  x denotes the query point, and D a positive semi-definite distance metric which deterrmnes the size and shape of the neighborhood contributing to the regression (Atkeson et  al., 1997). The parameters xq and D can be determined in the framework of nonparametric statistics (Schaal & Atkeson, in press) or parametric maximum likelihood estimations  (Xu et al, 1995). for the present study they are determined manually since their origin is  secondary to the results of this paper. Without loss of generality, all our data sets will set  xq to the zero vector, compute the weights, and then translate the input data such that the  lbcally weighted mean,  = E w, xi /E wi, is zero. The output data is equally translated to  be mean zero. Mean zero data is necessary for most of techniques considered below. The  (translated) input data is summarized in the rows of the matrix X, the corresponding  (translated) outputs are the elements of the vector y, and the corresponding weights are in  the diagonal matrix W. In some cases, we need the joint input and output data, denoted  as Z=[X y].  Local DimensionaIity Reduction 635  2.1 FACTOR ANALYSIS (LWFA)  Factor analysis (Everitt, 1984) is a technique of dimensionality reduction which is the  most appropriate given the generating process of our regression data. It assumes the observed data z was produced by a mean zero independently distributed k -dimensional  vector of factors v, transformed by the matrix U, and contaminated by mean zero independent noise e with diagonal covariance matrix  z=Uv+e, where z= xr,y and e= ex, (2)  If both v and  are normally distributed, the parameters C and U can be obtained iteratively by the Expectation-Maximization algorithm (EM) (Rubin & Thayer, 1982). For a  linear regression problem, one assumes that z was generated with U=[I,/5 ]r and v =  where/ denotes the vector of regression coefficients of the linear model y =/Yx, and I  the identity matrix. After calculating C and U by EM in joint data space as formulated in  (2), an estimate of / can be derived from the conditional probability P{yl x). As all  distributions are assumed to be normal, the expected value ofy is the mean of this conditional distribution. The locally weighted version (LWFA) of/ can be obtained together  with an estimate of the factors v from the joint weighted covariance matrix W of z and v:  U r [2(=(m+k) xn) 22(=(m+k)x(m+k)).]  (3)  where E{.} denotes the expectation operator and B a matrix of coefficients involved in  estimating the factors v. Note that unless the noise e is zero, the estimated/ is different  from the true ]3 as it tries to average out the noise in the data.  2.2 JOINT-SPACE PRINCIPAL COMPONENT ANALYSIS (LWPCA)  An alternative way of determining the parameters/ in a reduced space employs locally  weighted principal component analysis (LWPCA) in the joint data space. By defining the  largest k+l principal components of the weighted covariance matrix of Z as U:  U=[eigertvectors(Zwi(zi_Xzi_)T/Zwi)]max(l:k+l) (4)  and noting that the eigenvectors in U are unit length, the matrix inversion theorem (Horn  & Johnson, 1994) provides a means to derive an efficient estimate of/  [Ux(= n x k)]  / = U(Uy r( I)-' where [Uy(=mxk)J  Uy T UyUy T VyUyT 1 e-In our one dimensional output case, Uy is just a (1 x k)-dimensional row vector and the  evaluation of (5) does not require a matrix inversion anymore but rather a division.  If one assumes normal distributions in all variables as in LWFA, LWPCA is the special  case of LWFA where the noise covariance f is spherical, i.e., the same magnitude of  noise in all observables. Under these circumstances, the subspaces spanned by U in both  methods will be the same. However, the regression coefficients of LWPCA will be different from those of LWFA unless the noise level is zero, as LWFA optimizes the coefficients according to the noise in the data (Equation (3)). Thus, for normal distributions  and a correct guess of k, LWPCA is always expected to perform worse than LWFA.  636 $. $chaal, $. Vijayakumar and C. G. Atkeson  2.3 PARTIAL LEAST SQUARES (LWPLS, LWPLS_I)  Partial least squares (Wold, 1975; Frank & Friedman, 1993) recursively computes orthogonal projections of the input data and performs single variable regressions along  these projections on the residuals of the previous iteration step. A locally weighted version of partial least squares (LWPLS) proceeds as shown in Equation (6) below.  As all single variable regressions are ordinary uniFor Training: For Lookup:  variate least-squares minim izations, LWPLS Initialize: Initialize:  makes the same statistical assumption as ordinary  linear regressions, i.e., that only output variables Do = X, e 0 = y d o = x, y = 0  have additive noise, but input variables are noiseFor i = 1 to k: For i = 1 to k:  less. The choice of the projections u, however, introduces an element in LWPLS that remains staffsui = D,'r-Wei- s = dr_u  tically still debated (Frank & Friedman, 1993), als = Di_u i y = y +/3is   though, interestingly, there exists a strong similarsrWei_ d = d4 -sip  ity with the way projections are chosen in Cascade /3 i _  Correlation (Fahlman & Lebiere, 1990). A peculisrWs  arity of LWPLS is that it also regresses the inputs Dr_ws  of the previous step against the projected inputs s Pi srWs  in order to ensure the orthogonality of all the projections u. Since LWPLS chooses projections in a D = D_ sip r (6)  very powerful way, it can accomplish optimal  function fits with only one single projections (i.e.,  k=-l) for certain input distributions. We will address this issue in our empirical evaluations by comparing k-step LWPLS with 1-step LWPLS, abbreviated LWPLS_I.  2.4 PRINCIPAL COMPONENT REGRESSION (LWPCR)  Although not optimal, a computationally efficient techniques of dimensionality reduction  for linear regression is principal component regression (LWPCR) (Massy, 1965). The inputs are projected onto the largest k principal components of the weighted covariance  matrix of the input data by the matrix U:  g=[eigertvectoFs(Zwi(xi-XXi-)T/Ewi)]max(l:k)  The regression coefficients/3 are thus calculated as:  = (UrXrWXU) UrXrWy  (7)  (8)  Equation (8) is inexpensive to evaluate since after projecting X with U, UrXrWXU becomes a diagonal matrix that is easy to invert. LWPCR assumes that the inputs have additive spherical noise, which includes the zero noise case. As during dimensionality reduction LWPCR does not take into account the output data, it is endangered by clipping  input dimensions with low variance which nevertheless have important contribution to  the regression output. However, from a statistical point of view, it is less likely that low  variance inputs have significant contribution in a linear regression, as the confidence  bands of the regression coefficients increase inversely proportionally with the variance of  the associated input. If the input data has non-spherical noise, LWPCR is prone to focus  the regression on irrelevant projections.  3 MONTE CARLO EVALUATIONS  In order to evaluate the candidate methods, data sets with 5 inputs and 1 output were randomly generated. Each data set consisted of 2,000 training points and 10,000 test points,  distributed either uniformly or nonuniformly in the unit hypercube. The outputs were  Local Dimensionality Reduction 637  generated by either a linear or quadratic function. Afterwards, the 5-dimensional input  space was projected into a 10-dimensional space by a randomly chosen distance preserving linear transformation. Finally, Gaussian noise of various magnitudes was added  to both the 10-dimensional inputs and one dimensional output. For the test sets, the additive noise in the outputs was omitted. Each regression technique was localized by a  Gaussian kernel (Equation (1)) with a 10-dimensional distance metric D=10*I (D was  manually chosen to ensure that the Gaussian kernel had sufficiently many data points and  no "data holes" in the fringe areas of the kernel). The precise experimental conditions  followed closely those suggested by Frank and Friedman (1993):  ß 2 kinds of linear functions y = ]3irx for: i) ]3i, . =[1,1,1,1,1] r, ii) ]3i. =[1,2,3,4,5] r  T T 2 2 2 2 2 T  ß 2 kinds of quadratic functions y = ]3ii.x + ]3,a[xl, x2, x3, x4, xs ] for:  i) 13i .= [1,1,1,1,1] r and ]3qua = 0.111,1, 1,1,1] r, and ii) 13z .= [1,2,3,4,5] r and 13q, -0.111,4,9,16,25] r  ß 3 kinds of noise conditions, each with 2 sub-conditions:  i) only output noise: a) low noise: local signal/noise ratio lsnr=20,  and b) high noise: lsnr=2,  ii) equal noise in inputs and outputs:  a) low noise ex,.= y = N(0,0'012), n [1,2 ..... 10],  and b) high noise ex..= . = N(0,0.12), n [1,2 ..... 10],  iii) unequal noise in inputs and outputs:  a) low noise: e,.= N(0,(0.01n)2), n [1,2 ..... 10] and lsnr=20,  and b) high noise: e,.= N(0,(0.0ln)2), n [1,2,...,10] and lsnr=2,  ß 2 kinds of input distributions: i) uniform in unit hyper cube, ii) uniform in unit hyper cube excluding data  points which activate a Gaussian weighting function (1) at c = [0.5,0,0,0,0] r with D=10*I more than  w=0.2 (this forms a "hyper kidney" shaped distribution)  Every algorithm was ran* 30 times on each of the 48 combinations of the conditions.  Additionally, the complete test was repeated for three further conditions varying the di~  mensionality called factors in accordance with LWFA that the algorithms assumed to  be the true dimensionality of the 1 O-dimensional data from k--4 to 6, i.e., too few, correct,  and too many factors. The average results are summarized in Figure 1.  Figure 1 a,b,c show the summary results of the three factor conditions. Besides averaging  over the 30 trials per condition, each mean of these charts also averages over the two input distribution conditions and the linear and quadratic function condition, as these four  cases are frequently observed violations of the statistical assumptions in nonlinear function approximation with locally linear models. In Figure lb the number of factors equals  the underlying dimensionality of the problem, and all algorithms are essentially performing equally well. For perfectly Gaussian distributions in all random variables (not  shown separately), LWFA's assumptions are perfectly fulfilled and it achieves the best  results, however, almost indistinguishable closely followed by LWPLS. For the "unequal  noise condition", the two PCA based techniques, LWPCA and LWPCR, perform the  worst since as expected they choose suboptimal projections. However, when violating the statistical assumptions, LWFA loses parts of its advantages, such that the summary results become fairly balanced in Figure 1 b.  The quality of function fitting changes significantly when violating the correct number of  factors, as illustrated in Figure I a,c. For too few factors (Figure 1 a), LWPCR performs  worst because it randomly omits one of the principle components in the input data, without respect to how important it is for the regression. The second worse is LWFA: according to its assumptions it believes that the signal it cannot model must be noise, leading to a degraded estimate of the data's subspace and, consequently, degraded regression  results. LWPLS has a clear lead in this test, closely followed by LWPCA and LWPLS_I.  Except for LWFA, all methods can evaluate a data set in non-iterative calculations. LWFA was mined with EM for maximally 1000 iterations or until the log-likelihood increased less than l.e-10 in one iteration.  638 S. SchaaI, S. Vijayakumar and C. G. Atkeson  For too many factors than necessary (Figure 1 c), it is now LWPCA which degrades. This  effect is due to its extracting one very noise contaminated projection which strongly influences the recovery of the regression parameters in Equation (4). All other algorithms  perform almost equally well, with LWFA and LWPLS taking a small lead.  Only Output Equal Noise In all Unequal Noise In all  Noise Inputs and Outputs Inputs and Outputs  1  u) 0.1Io  tU 0.01 0.001  0.0001  3=1,>O 3=1,>>O 1.>O l.r;>>O 3=1.>0 3=1.>>0 1.>O 1.>>O Jl,a>O Jl,a>>O 1.>O l.a>>O  a) Regression Results with 4 Factors  .  o.1  o.ol  o.oolll  0.0001   b) Regrssslon Results with 5 Factors  0.01  0.001  0.0001  c) Regression Results with 6 Factors  1 o.1I.-tU 0.01  0.001  0.0001  d) Summary Results  Figure 1: Average summary results of Monte Carlo experiments. Each chart is primarily  divided into the three major noise conditions, of. headers in chart (a). In each noise condition, there are four further subdivision: i) coefficients of linear or quadratic model are  equal with low added noise; ii) like i) with high added noise; iii) coefficients of linear or  quadratic model are different with low noise added; iv) like iii) with high added noise.  Refer to text and descriptions of Monte Carlo studies for further explanations.  Local DimensionaIity Reduction 639  4 SUMMARY AND CONCLUSIONS  Figure 1 d summarizes all the Monte Carlo experiments in a final average plot. Except for  LWPLS, every other technique showed at least one clear weakness in one of our "robustness" tests. It was particularly an incorrect number of factors which made these weaknesses apparent. For high-dimensional regression problems, the local dimensionality, i.e.,  the number of factors, is not a clearly defined number but rather a varying quantity, depending on the way the generating process operates. Usually, this process does not need  to generate locally low dimensional distributions, however, it often "chooses" to do so,  for instance, as human ann movements follow stereotypic patterns despite they could  generate arbitrary ones. Thus, local dimensionality reduction needs to find autonomously  the appropriate number of local factor. Locally weighted partial least squares turned out  to be a surprisingly robust technique for this purpose, even outperforming the statistically  appealing probabilistic factor analysis. As in principal component analysis, LWPLS's  number of factors can easily be controlled just based on a variance-cutoff threshold in input space (Frank & Friedman, 1993), while factor analysis usually requires expensive  cross-validation techniques. Simple, variance-based control over the number of factors  can actually improve the results of LWPCA and LWPCR in practice, since, as shown in  Figure 1 a, LWPCR is more robust towards overestimating the number of factors, while  LWPCA is more robust towards an underestimation. If one is interested in dynamically  growing the number of factors while obtaining already good regression results with too  few factors, LWPCA and, especially, LWPLS seem to be appropriate it should be  noted how well one factor LWPLS (LWPLS_I) already performed in Figure 1 !  In conclusion, since locally weighted partial least squares was equally robust as local  weighted factor analysis towards additive noise in both input and output data, and,  moreover, superior when mis-guessing the number of factors, it seems to be a most favorable technique for local dimensionality reduction for high dimensional regressions.  Acknowledgments  The authors are grateful to Geoffrey Hinton for reminding them of parfal least squares. This work was supported by the ATR Human Information Processing Research Laboratories. S. Schaal's support includes the  German Research Association, the Alexander von Humboldt Foundation, and the German Scholarship Foundation. S. Vijayakumar was supported by the Japanese Ministry of Education, Science, and Culture (Monbusho).  C. G. Atkeson acknowledges the Air Force Office of Scientific Research grant F49-6209410362 and a National  Science Foundation Presidential Young Investigators Award.  References  Atkeson, C. G., Moore, A. W., & Schaal, S, (1997a).  "Locally weighted learning." Artificial Intelligence Review, 11, 1-5, pp. 11-73.  Atkeson, C. G., Moore, A. W., & Schaal, S, (1997c).  "Locally weighted learning for control." Artificial Intelligence Review, 11, 1-5, pp.75-113.  Belsley, D. A., Kuh, E., & Welsch, R. E, (1980). Regression diagnostics: Identiing influential data and  sources ofcollinearity. New York: Wiley.
We explore methods for incorporating prior knowledge about a problem  at hand in Support Vector learning machines. We show that both invariances under group transformations and prior knowledge about locality in  images can be incorporated by constructing appropriate kernel functions.
"Boosting" is a general method for improving the performance of any  learning algorithm that consistently generates classifiers which need to  perform only slightly better than random guessing. A recently proposed  and very promising boosting algorithm is AdaBoost [5]. It has been applied with great success to several benchmark machine learning problems  using rather simple learning algorithms [4], and decision trees [ 1, 2, 6].  In this paper we use AdaBoost to improve the performances of neural  networks. We compare training methods based on sampling the training  set and weighting the cost function. Our system achieves about 1.4%  error on a data base of online handwritten digits from more than 200  writers. Adaptive boosting of a multi-layer network achieved 1.5% error  on the UCI Letters and 8.1% error on the UCI satellite data set.
One approach to invariant object recognition employs a recurrent neural network as an associative memory. In the standard depiction of the  network's state space, memories of objects are stored as attractive fixed  points of the dynamics. I argue for a modification of this picture: if an  object has a continuous family of instantiations, it should be represented  by a continuous attractor. This idea is illustrated with a network that  learns to complete patterns. To perform the task of filling in missing information, the network develops a continuous attractor that models the  manifold from which the patterns are drawn. From a statistical viewpoint, the pattern completion task allows a formulation of unsupervised  learning in terms of regression rather than density estimation.  A classic approach to invariant object recognition is to use a recurrent neural network as an associative memory[1]. In spite of the intuitive appeal and biological  plausibility of this approach, it has largely been abandoned in practical applications.  This paper introduces two new concepts that could help resurrect it: object representation by continuous attractors, and learning attractors by pattern completion.  In most models of associative memory, memories are stored as attractive fixed points  at discrete locations in state space[1]. Discrete attractors may not be appropriate for  patterns with continuous variability, like the images of a three-dimensional object  from different viewpoints. When the instantiations of an object lie on a continuous  pattern manifold, it is more appropriate to represent objects by attractive manifolds  of fixed points, or continuous attractors.  To make this idea practical, it is important to find methods for learning attractors  from examples. A naive method is to train the network to retain examples in shortterm memory. This method is deficient because it does not prevent the network  from storing spurious fixed points that are unrelated to the examples. A superior  method is to train the network to restore examples that have been corrupted, so  that it learns to complete patterns by filling in missing information.  Learning Continuous Attractors in Recurrent Networks 655  (a)  (b)  Figure 1: Representing objects by dynamical attractors. (a) Discrete attractors.  (b) Continuous attractors.  Learning by pattern completion can be understood from both dynamical and statistical perspectives. Since the completion task requires a large basin of attraction  around each memory, spurious fixed points are suppressed. The completion task  also leads to a formulation of unsupervised learning as the regression problem of  estimating functional dependences between variables in the sensory input.  Density estimation, rather than regression, is the dominant formulation of unsupervised learning in stochastic neural networks like the Boltzmann machine[2]. Density  estimation has the virtue of suppressing spurious fixed points automatically, but it  also has the serious drawback of being intractable for many network architectures.  Regression is a more tractable, but nonetheless powerful, alternative to density  estimation.  In a number of recent neurobiological models, continuous attractors have been used  to represent continuous quantities like eye position-[3], direction of reaching[4], head  direction[5], and orientation of a visual stimulus[6]. Along with these models, the  present work is part of a new paradigm for neural computation based on continuous  attractors.
Monotonicity is a constraint which arises in many application domains. We present a machine learning model, the monotonic network, for which monotonicity can be enforced exactly, i.e., by virtue  of functional form. A straightforward method for implementing and  training a monotonic network is described. Monotonic networks  are proven to be universal approximators of continuous, differentiable monotonic functions. We apply monotonic networks to a  real-world task in corporate bond rating prediction and compare  them to other approaches.
In this paper, the technique of stacking, previously only used for  supervised learning, is applied to unsupervised learning. Specifically, it is used for non-parametric multivariate density estimation,  to combine finite mixture model and kernel density estimators. Experimental results on both simulated data and real world data sets  clearly demonstrate that stacked density estimation outperforms  other strategies such as choosing the single best model based on  cross-validation, combining with uniform weights, and even the single best model chosen by "cheating" by looking at the data used  for independent testing.
Similarity based fault tolerant retrieval in neural associative memories (NAM) has not lead to wiedespread applications. A drawback of the efficient Willshaw model for sparse patterns [Ste61,  WBLH69], is that the high asymptotic information capacity is of  little practical use because of high cross talk noise arising in the  retrieval for finite sizes. Here a new bidirectional iterative retrieval  method for the Willshaw model is presented, called crosswise bidirectional (CB) retrieval, providing enhanced performance. We discuss its asymptotic capacity limit, analyze the first step, and compare it in experiments with the Willshaw model. Applying the very  efficient CB memory model either in information retrieval systems  or as a functional model for reciprocal cortico-cortical pathways  requires more than robustness against random noise in the input:  Our experiments show also the segmentation ability of CB-retrieval  with addresses containing the superposition of pattens, provided  even at high memory load.
Nonlinear dimensionality reduction is formulated here as the problem of trying to  find a Euclidean feature-space embedding of a set of observations that preserves  as closely as possible their intrinsic metric structurethe distances between points  on the observation manifold as measured along geodesic paths. Our isometric  feature mapping procedure, or isomap, is able to reliably recover low-dimensional  nonlinear structure in realistic perceptual data sets, such as a manifold of face  images, where conventional global mapping methods find only local minima.  The recovered map provides a canonical set of globally meaningful features,  which allows perceptual transformations such as interpolation, extrapolation, and  analogy highly nonlinear transformations in the original observation space to  be computed with simple linear operations in feature space.
Our aim in this paper is to develop a Bayesian flamework for matching hierarchical relational models. The goal is to make discrete label assignments so as to optimise a global cost function that draws  information concerning the consistency of match from different levels of the hierarchy. Our Bayesian development naturally distinguishes between intra-level and inter-level constraints. This allows  the impact of reassigning a match to be assessed not only at its  own (or peer) level of representation, but also upon its parents and  children in the hierarchy.
For blind source separation, when the Fisher information matrix is  used as the Riemannian metric tensor for the parameter space, the  steepest descent algorithm to maximize the likelihood function in  this Riemannian parameter space becomes the serial updating rule  with equivariant property. This algorithm can be further simplified  by using the asymptotic form of the Fisher information matrix  around the equilibrium.
An asynchronous PDM (Pulse-Density-Modulating) digital neural  network system has been developed in our laboratory. It consists  of one thousand neurons that are physically interconnected via one  million 7-bit synapses. It can solve one thousand simultaneous  nonlinear first-order differential equations in a fully parallel and  continuous fashion. The performance of this system was measured  by a winner-take-all network with one thousand neurons. Although  the magnitude of the input and network parameters were identical for each competing neuron, one of them won in 6 milliseconds.  This processing speed amounts to 360 billion connections per second. A broad range of neural networks including spatiotemporal  filtering, feedforward, and feedback networks can be run by loading  appropriate network parameters from a host system.
This paper describes a small, compact circuit that captures the  temporal and adaptation properties both of the photoreceptor and  of the laminar layers of the fly. This circuit uses only six transistors and two capacitors. It is operated in the subthreshold domain.  The circuit maintains a high transient gain by using adaptation to  the background intensity as a form of gain control. The adaptation time constant of the circuit can be controlled via an external  bias. Its temporal filtering properties change with the background  intensity or signal-to-noise conditions. The frequency response of  the circuit shows that in the frequency range of I to 100 Hz, the  circuit response goes from highpass filtering under high light levels  to lowpass filtering under low light levels (i.e., when the signal-tonoise ratio is low). A chip with 20x20 pixels has been fabricated  in 1.2um ORBIT CMOS nwell technology.
We have a developed an analog VLSI system that models the coordination of neurobiological segmental oscillators. We have implemented and  tested a system that consists of a chain of eleven pattern generating circuits that are synaptically coupled to their nearest neighbors. Each pattern generating circuit is implemented with two silicon Morris-Lecar  neurons that are connected in a reciprocally inhibitory network. We discuss the mechanisms of oscillations in the two-cell network and explore  system behavior based on isotropic and anisotropic coupling, and frequency gradients along the chain of oscillators.
We describe the design, fabrication and test results of an analog CMOS  VLSI neural network prototype chip intended for phase-based machine  vision algorithms. The chip implements an image filtering operation  similar to Gabor-filtering. Because a Gabor filter's output is complex  valued, it can be used to define a phase at every pixel in an image. This  phase can be used in robust algorithms for disparity estimation and binocular stereo vergence control in stereo vision and for image motion  analysis. The chip reported here takes an input image and generates two  outputs at every pixel corresponding to the real and imaginary parts of  the output.
We present a method for the analysis of nonstationary time series with multiple operating modes. In particular, it is possible to  detect and to model both a switching of the dynamics and a less  abrupt, time consuming drift from one mode to another. This is  achieved in two steps. First, an unsupervised training method provides prediction experts for the inherent dynamical modes. Then,  the trained experts are used in a hidden Markov model that allows  to model drifts. An application to physiological wake/sleep data  demonstrates that analysis and modeling of real-world time series  can be improved when the drift paradigm is taken into account.
We discuss the problem of catastrophic fusion in multimodal recognition systems. This problem arises in systems that need to fuse  different channels in non-stationary environments. Practice shows  that when recognition modules within each modality are tested in  contexts inconsistent with their assumptions, their influence on the  fused product tends to increase, with catastrophic results. We explore a principled solution to this problem based upon Bayesian  ideas of competitive models and inference robustification: each  sensory channel is provided with simple white-noise context models, and the perceptual hypothesis and context are jointly estimated. Consequent]y, context deviations are interpreted as changes  in white noise contamination strength, automatically adjusting the  influence of the module. The approach is tested on a fixed lexicon  automatic audiovisual speech recognition problem with very good  results.
Hidden Markov models (HMMs) for automatic speech recognition  rely on high dimensional feature vectors to summarize the shorttime properties of speech. Correlations between features can arise  when the speech signal is non-stationary or corrupted by noise. We  investigate how to model these correlations using factor analysis,  a statistical method for dimensionality reduction. Factor analysis  uses a small number of parameters to model the covariance structure of high dimensional data. These parameters are estimated  by an Expectation-Maximization (EM) algorithm that can be embedded in the training procedures for HMMs. We evaluate the  combined use of mixture densities and factor analysis in HMMs  that recognize alphanumeric strings. Holding the total number of  parameters fixed, we find that these methods, properly combined,  yield better models than either method on its own.
We apply information maximization / maximum likelihood blind  source separation [2, 6] to complex valued signals mixed with complex valued nonstationary matrices. This case arises in radio communications with baseband signals. We incorporate known source  signal distributions in the adaptation, thus making the algorithms  less "blind". This results in drastic reduction of the amount of data  needed for successful convergence. Adaptation to rapidly changing  signal mixing conditions, such as to fading in mobile communications, becomes now feasible as demonstrated by simulations.
In this paper, we present a novel hybrid architecture for continuous speech  recognition systems. It consists of a continuous HMM system extended  by an arbitrary neural network that is used as a preprocessor that takes  several frames of the feature vector as input to produce more discriminative feature vectors with respect to the underlying HMM system. This  hybrid system is an extension of a state-of-the-art continuous HMM system, andin fact, it is the first hybrid system that really is capable ofoutperforming these standard systems with respect to the recognition accuracy.  o  Experimental results show an relative error reduction of about 10 Yo that  we achieved on a remarkably good recognition system based on continuous HMMs for the Resource Management 1000-word continuous speech  recognition task.
The observed distribution of natural images is far from uniform.  On the contrary, real images have complex and important structure that can be exploited for image processing, recognition and  analysis. There have been many proposed approaches to the principled statistical modeling of images, but each has been limited in  either the complexity of the models or the complexity of the images. We present a non-parametric multi-scale statistical model for  images that can be used for recognition, image de-noising, and in  a "generatire mode" to synthesize high quality textures.
This paper describes a new approach to extracting 3D perspective  structure from 2D point-sets. The novel feature is to unify the  tasks of estimating transformation geometry and identifying pointcorrespondence matches. Unification is realised by constructing a  mixture model over the bi-partite graph representing the correspondence match and by effecting optimisation using the EM algorithm.  According to our EM framework the probabilities of structural correspondence gate contributions to the expected likelihood function  used to estimate maximum likelihood perspective pose parameters.  This provides a means of rejecting structural outliers.
Image intensity variations can result from several different object  surface effects, including shading from 3-dimensional relief of the  object, or paint on the surface itself. An essential problem in vision,  which people solve naturally, is to attribute the proper physical  cause, e.g. surface relief or paint, to an observed image. We addressed this problem with an approach combining psychophysical  and Bayesian computational methods.  We assessed human performance on a set of test images, and found  that people made fairly consistent judgements of surface properties.  Our computational model assigned simple prior probabilities to  different relief or paint explanations for an image, and solved for  the most probable interpretation in a Bayesian framework. The  ratings of the test images by our algorithm compared surprisingly  well with the mean ratings of our subjects.
An image is often represented by a set of detected features. We get  an enormous compression by representing images in this way. Furthermore, we get a representation which is little affected by small  amounts of noise in the image. However, features are typically  chosen in an ad hoc manner. We show how a good set of features can be obtained using sufficient statistics. The idea of sparse  data representation naturally arises. We treat the 1-dimensional  and 2-dimensional signal reconstruction problem to make our ideas  concrete.
A model of motion detection is presented. The model contains  three stages. The first stage is unoriented and is selective for contrast polarities. The next two stages work in parallel. A phase  insensitive stage pools across different contrast polarities through  a spatiotemporal filter and thus can detect first and second order  motion. A phase sensitive stage keeps contrast polarities separate,  each of which is filtered through a spatiotemporal filter, and thus  only first order motion can be detected. Differential phase sensitivity can therefore account for the detection of first and second order  motion. Phase insensitive detectors correspond to cortical complex  cells, and phase sensitive detectors to simple cells.
A neural network approach to stereovision is presented based on  aliasing effects of simple disparity estimators and a fast coherencedetection scheme. Within a single network structure, a dense disparity map with an associated validation map and, additionally,  the fused cyclopean view of the scene are available. The network  operations are based on simple, biological plausible circuitry; the  algorithm is fully parallel and non-iterative.
We derive a learning algorithm for inferring an overcomplete basis  by viewing it as probabilistic model of the observed data. Overcomplete bases allow for better approximation of the underlying  statistical density. Using a Laplacian prior on the basis coefficients  removes redundancy and leads to representations that are sparse  and are a nonlinear function of the data. This can be viewed as  a generalization of the technique of independent component analysis and provides a method for blind source separation of fewer  mixtures than sources. We demonstrate the utility of overcomplete representations on natural speech and show that compared  to the traditional Fourier basis the inferred representations potentially have much greater coding efficiency.  A traditional way to represent real-values signals is with Fourier or wavelet bases.  A disadvantage of these bases, however, is that they are not specialized for any  particular dataset. Principal component analysis (PCA) provides one means for  finding an basis that is adapted for a dataset, but the basis vectors are restricted  to be orthogonal. An extension of PCA called independent component analysis  (Jutten and Herault, 1991; Comon et al., 1991; Bell and Sejnowski, 1995) allows  the learning of non-orthogonal bases. All of these bases are complete in the sense  that they span the input space, but they are limited in terms of how well they can  approximate the dataset's statistical density.  Representations that are overcomplete, i.e. more basis vectors than input variables,  can provide a better representation, because the basis vectors can be specialized for  Learning Nonlinear Overcomplete Representations for Efficient Coding 557  a larger variety of features present in the entire ensemble of data. A criticism of  overcomplete representations is that they are redundant, i.e. a given data point may  have many possible representations, but this redundancy is removed by the prior  probability of the basis coeffcients which specifies the probability of the alternative  representations.  Most of the overcomplete bases used in the literature are fixed in the sense that  they are not adapted to the structure in the data. Recently Olshausen and Field  (1996) presented an algorithm that allows an overcomplete basis to be learned. This  algorithm relied on an approximation to the desired probabilistic objective that had  several drawbacks, including tendency to breakdown in the case of low noise levels  and when learning bases with higher degrees of overcompleteness. In this paper, we  present an improved approximation to the desired probabilistic objective and show  that this leads to a simple and robust algorithm for learning optimal overcomplete  bases.
We implement a model of obstacle avoidance in flying insects on a small,  monocular robot. The result is a system that is capable of rapid navigation  through a dense obstacle field. The key to the system is the use of zigzag  behavior to articulate the body during movement. It is shown that this behavior  compensates for a parallax blind spot surrounding the focus of expansion normally found in systems without parallax behavior. The system models the cooperation of several behaviors: halteres-ocular response (similar to VOR),  optomotor response, and the parallax field computation and mapping to motor  system. The resulting system is neurally plausible, very simple, and should be  easily hosted on aVLSI hardware.
Converging evidence has shown that human object recognition  depends on familiarity with the images of an object. Further,  the greater the similarity between objects, the stronger is the  dependence on object appearance, and the more important twodimensional (2D) image information becomes. These findings, however, do not rule out the use of 3D structural information in recognition, and the degree to which 3D information is used in visual  memory is an important issue. Liu, Knill, & Kersten (1995) showed  that any model that is restricted to rotations in the image plane  of independent 2D templates could not account for human performance in discriminating novel object views. We now present results  from models of generalized radial basis functions (GRBF), 2D nearest neighbor matching that allows 2D affine transformations, and  a Bayesian statistical estimator that integrates over all possible 2D  affine transformations. The performance of the human observers  relative to each of the models is better for the novel views than  for the familiar template views, suggesting that humans generalize  better to novel views from template views. The Bayesian estimator yields the optimal performance with 2D arline transformations  and independent 2D templates. Therefore, models of 2D arline  matching operations with independent 2D templates are unlikely  to account for human recognition performance.
Scale invariance is a fundamental property of ensembles of natural images [1]. Their non Gaussian properties [15, 16] are less  well understood, but they indicate the existence of a rich statistical structure. In this work we present a detailed study of the  marginal statistics of a variable related to the edges in the images.  A numerical analysis shows that it exhibits extended self-similarity  [3, 4, 5]. This is a scaling property stronger than self-similarity:  all its moments can be expressed as a power of any given moment.  More interesting, all the exponents can be predicted in terms of  a multiplicative log-Poisson process. This is the very same model  that was used very recently to predict the correct exponents of  the structure functions of turbulent flows [6]. These results allow  us to study the underlying multifractal singularities. In particular  we find that the most singular structures are one-dimensional: the  most singular manifold consists of sharp edges.  Category: Visual Processing.
The ability to rely on similarity metrics invariant to image transformations is an important issue for image classification tasks such as face or  character recognition. We analyze an invariant metric that has performed  well for the latter the tangent distance and study its limitations when  applied to regular images, showing that the most significant among these  (convergence to local minima) can be drastically reduced by computing  the distance in a multiresolution setting. This leads to the multiresolution  tangent distance, which exhibits significantly higher invariance to image transformations, and can be easily combined with robust estimation  procedures.
Estimating motion in scenes containing multiple moving objects  remains a difficult problem in computer vision. A promising approach to this problem involves using mixture models, where the  motion of each object is a component in the mixture. However, existing methods typically require specifying in advance the number  of components in the mixture, i.e. the number of objects in the  scene.  Here we show that the number of objects can be estimated automatically in a maximum likelihood framework, given an assumption  about the level of noise in the video sequence. We derive analytical  results showing the number of models which maximize the likelihood for a given noise level in a given sequence. We illustrate these  results on a real video sequence, showing how the phase transitions  correspond to different perceptual organizations of the scene.  Figure la depicts a scene where motion estimation is difficult for many computer  vision systems. A semi-transparent surface partially occludes a second surface,  and the camera is translating horizontally. Figure lb shows a slice through the  horizontal component of the motion generated by the camera points that are  closer to the camera move faster than those further away. In practice, the local  motion information would be noisy as shown in figure lc and this imposes conflicting  demands on a motion analysis system reliable estimates require pooling together  many measurements while avoiding mixing together measurements derived from the  two different surfaces.  Phase Transitions and the Perceptual Organization of Video Sequences 851  b c d  Figure 1: a: A simple scene that can cause problems for motion estimation. One surface  partially occludes another surface. b: A cross section through the horizontal motion field  generated when the camera translates horizontally. Points closer to the camera move  faster. c: Noisy motion field. In practice each local measurement will be somewhat noisy  and pooling of information is required. d: A cross section through the output of a multiple  motion analysis system. Points are assigned to surfaces (denoted by different plot symbols)  and the motion of each surface is estimated.  Figure 2: The "correct" number of surfaces in a given scene is often ambiguous. Was the  motion here generated by one or two surfaces?  Significant progress in the analysis of such scenes has been achieved by multiple  motion analyzers systems that simultaneously segment the scene into surfaces and  estimating the motion of each surface [9]. Mixture models are a commonly used  framework for performing multiple motion estimation [5, 1, 10]. Figure ld shows  a slice through the output of a multiple motion analyzer on this scene pixels are  assigned to one of two surfaces and motion information is only combined for pixels  belonging to the same surface.  The output shown in figure ld was obtained by assuming the scene contains two  surfaces. In general, of course, one does not know the number of surfaces in the  scene in advance. Figure 2 shows the difficulty in estimating this number. It is not  clear whether this is very noisy data generated by a single surface, or less noisy  data generated by two surfaces. There seems no reason to prefer one description  over another. Indeed, the description where there are as many surfaces as pixels is  also a valid interpretation of this data.  Here we take the approach that there is no single "correct" number of surfaces for  a given scene in the absence of any additional assumptions. However, given an  assumption about the noise in the sequence, there are more likely and less likely  interpretations. Intuitively, if we know that the data in figure 2a was taken with  a very noisy camera, we would tend to prefer the one surface solution adding  additional surfaces would cause us to fit the noise rather than the data. However, if  we know that there is little noise in the sequence, we would prefer solutions that use  many surfaces, there is a lot less danger of "overfitting". In this paper I we show,  A longer version of this paper is available on the author's web page.  852 Y. Weiss  following [6, 8] that this intuition regarding the dependence of number of surfaces to  assumed noise level is captured in the maximum likelihood framework. We derive  analytical results for the critical values of noise levels where the likelihood function  undergoes a "phase transition" from being maximized by a single model to being  maximized by multiple models. We illustrate these transitions on synthetic and real  video data.
In many real world tasks, only a small fraction of the available inputs are important  at any particular time. This paper presents a method for ascertaining the relevance  of inputs by exploiting temporal coherence and predictability. The method proposed in this paper dynamically allocates relevance to inputs by using expectations  of their future values. As a model of the task is learned, the model is simultaneously extended to create task-specific predictions of the future values of inputs.  Inputs which are either not relevant, and therefore not accounted for in the model,  or those which contain noise, will not be predicted accurately. These inputs can be  de-emphasized, and, in turn, a new, improved, model of the task created. The techniques presented in this paper have yielded significant improvements for the  vision-based autonomous control of a land vehicle, vision-based hand tracking in  cluttered scenes, and the detection of faults in the etching of semiconductor wafers.
A new algorithm is presented which approximates the perceived  visual similarity between images. The images are initially transformed into a feature space which captures visual structure, texture and color using a tree of filters. Similarity is the inverse of  the distance in this perceptual feature space. Using this algorithm  we have constructed an image database system which can perform  example based retrieval on large image databases. Using carefully  constructed target sets, which limit variation to only a single visual  characteristic, retrieval rates are quantitatively compared to those  of standard methods.
A 80 x 78 pixel general purpose vision chip for spatial focal plane  processing is presented. The size and configuration of the processing  receptive field are programmable. The chip's architecture allows the  photoreceptor cells to be small and densely packed by performing all  computation on the read-out, away from the array. In addition to the  raw intensity image, the chip outputs four processed images in parallel.  Also presented is an application of the chip to line segment orientation  detection, as found in the retinal receptive fields of toads.
Flies are capable of rapidly detecting and integrating visual motion information in behaviorly-relevant ways. The first stage of visual motion  processing in flies is a retinotopic array of functional units known as elementary motion detectors (EMDs). Several decades ago, Reichardt and  colleagues developed a correlation-based model of motion detection that  described the behavior of these neural circuits. We have implemented a  variant of this model in a 2.0-/tin analog CMOS VLSI process. The result is a low-power, continuous-time analog circuit with integrated photoreceptors that responds to motion in real time. The responses of the  circuit to drifting sinusoidal gratings qualitatively resemble the temporal  frequency response, spatial frequency response, and direction selectivity  of motion-sensitive neurons observed in insects. In addition to its possible engineering applications, the circuit could potentially be used as a  building block for constructing hardware models of higher-level insect  motion integration.
MELONET I is a multi-scale neural network system producing  baroque-style melodic variations. Given a melody, the system invents a four-part chorale harmonization and a variation of any  chorale voice, after being trained on music pieces of composers like  J. S. Bach and J. Pachelbel. Unlike earlier approaches to the learning of melodic structure, the system is able to learn and reproduce  high-order structure like harmonic, motif and phrase structure in  melodic sequences. This is achieved by using mutually interacting  feedforward networks operating at different time scales, in combination with Kohonen networks to classify and recognize musical  structure. The results are chorale partitas in the style of J. Pachelbel. Their quality has been judged by experts to be comparable to  improvisations invented by an experienced human organist.
Severe contamination of electroencephalographic (EEG) activity  by eye movements, blinks, muscle, heart and line noise is a serious  problem for EEG interpretation and analysis. Rejecting contaminated EEG segments results in a considerable loss of information  and may be impractical for clinical data. Many methods have been  proposed to remove eye movement and blink artifacts from EEG  recordings. Often regression in the time or frequency domain is  performed on simultaneous EEG and electrooculographic (EOG)  recordings to derive parameters characterizing the appearance and  spread of EOG artifacts in the EEG channels. However, EOG  records also contain brain signals [1, 2], so regressing out EOG activity inevitably involves subtracting a portion of the relevant EEG  signal from each recording as well. Regression cannot be used to  remove muscle noise or line noise, since these have no reference  channels. Here, we propose a new and generally applicable method  for removing a wide variety of artifacts from EEG records. The  method is based on an extended version of a previous Independent Component Analysis (ICA) algorithm [3, 4] for performing  blind source separation on linear mixtures of independent source  signals with either sub-Gaussian or super-Gaussian distributions.  Our results show that ICA can effectively detect, separate and remove activity in EEG records from a wide variety of artifactual  sources, with results comparing favorably to those obtained using  regression-based methods.  Extended ICA Removes Artifacts from EEG Recordings 895
We present a novel generic approach to the problem of Event Related  Potential identification and classification, based on a competitive Neural Net architecture. The network weights converge to the embedded  signal patterns, resulting in the formation of a matched filter bank.  The network performance is analyzed via a simulation study, exploring  identification robustness under low SNR conditions and compared to  the expected performance from an information theoretic perspective.  The classifier is applied to real event-related potential data recorded  during a classic odd-ball type paradigm; for the first time, withinsession variable signal patterns are automatically identified, dismissing the strong and limiting requirement of a-priori stimulus-related  selective grouping of the recorded data.  902 D. H. Lange, H. T. Siegelmann, H. Pratt and G. F. Inbar  1
We have constructed an inexpensive, video-based, motorized tracking system that learns to track a head. It uses real time graphical  user inputs or an auxiliary infrared detector as supervisory signals  to train a convolutional neural network. The inputs to the neural  network consist of normalized luminance and chrominance images  and motion information from frame differences. Subsampled images are also used to provide scale invariance. During the online  training phase, the neural network rapidly adjusts the input weights  depending upon the reliability of the different channels in the surrounding environment. This quick adaptation allows the system to  robustly track a head even when other objects are moving within  a cluttered background.
In this work, we tackle the problem of time-series modeling of video  traffic. Different from the existing methods which model the timeseries in the time domain, we model the wavelet coefficients in the  wavelet domain. The strength of the wavelet model includes (1) a  unified approach to model both the long-range and the short-range  dependence in the video traffic simultaneously, (2) a computationally efficient method on developing the model and generating high  quali_ty video traffic, and (3) feasibility of performance analysis using the model.
In integrated service communication networks, an important problem is  to exercise call admission control and routing so as to optimally use the  network resources. This problem is naturally formulated as a dynamic  programming problem, which, however, is too complex to be solved exactly. We use methods of reinforcement learning (RL), together with a  decomposition approach, to find call admission control and routing policies. The performance of our policy for a network with approximately  10 45 different feature configurations is compared with a commonly used  heuristic policy.
Program execution speed on modem computers is sensitive, by a factor of  two or more, to the order in which instructions are presented to the processor. To realize potential execution efficiency, an optimizing compiler must  employ a heuristic algorithm for instruction scheduling. Such algorithms  are painstakingly hand-crafted, which is expensive and time-consuming. We  show how to cast the instruction scheduling problem as a learning task, obtaining the heuristic scheduling algorithm automatically. Our focus is the  narrower problem of scheduling straight-line code (also called basic blocks  of instructions). Our empirical results show that just a few features are adequate for quite good performance at this task for a real modem processor,  and that any of several supervised learning methods perform nearly optimally with respect to the features used.
This paper enhances the Q-learning algorithm for optimal asset allocation proposed in (Netmeier, 1996 [6]). The new formulation simplifies  the approach by using only one value-function for many assets and allows model-free policy-iteration. After testing the new algorithm on  real data, the possibility of risk management within the framework of  Markov decision problems is analyzed. The proposed methods allows  the construction of a multi-period portfolio management system which  takes into account transaction costs, the risk preferences of the investor,  and several constraints on the allocation.
With the rapid expansion of computer networks during the past few years,  security has become a crucial issue for modern computer systems. A  good way to detect illegitimate use is through monitoring unusual user  activity. Methods of intrusion detection based on hand-coded rule sets or  predicting commands on-line are laborous to build or not very reliable.  This paper proposes a new way of applying neural networks to detect  intrusions. We believe that a user leaves a 'print' when using the system;  a neural network can be used to learn this print and identify each user  much like detectives use thumbprints to place people at crime scenes. If  a user's behavior does not match his/her print, the system administrator  can be alerted of a possible security breech. A backpropagation neural  network called NNID (Neural Network Intrusion Detector) was trained  in the identification task and tested experimentally on a system of 10  users. The system was 96% accurate in detecting unusual activity, with  7% false alarm rate. These results suggest that learning user profiles is  an effective way for detecting intrusions.
In this paper we propose a technique to incorporate contextual information into object classification. In the real word there are cases where the  identity of an object is ambiguous due to the noise in the measurements  based on which the classification should be made. It is helpful to reduce the ambiguity by utilizing extra information referred to as context,  which in our case is the identities of the accompanying objects. This  technique is applied to white blood cell classification. Comparisons are  made against "no context" approach, which demonstrates the superior  classification performance achieved by using context. In our particular  application, it significantly reduces false alarm rate and thus greatly reduces the cost due to expensive clinical tests.  *Author for correspondence.  Incorporating Contextual Information in White Blood Cell Identification 951
We describe a system for learning J. S. Bach's rules of musical harmony. These rules are learned from examples and are expressed  as rule-based neural networks. The rules are then applied in realtime to generate new accompanying harmony for a live performer.  Real-time functionality imposes constraints on the learning and  harmonizing processes, including limitations on the types of information the system can use as input and the amount of processing  the system can perform. We demonstrate algorithms for generating and refining musical rules from examples which meet these  constraints. We describe a method for including a priori knowledge into the rules which yields significant performance gains. We  then describe techniques for applying these rules to generate new  music in real-time. We conclude the paper with an analysis of  experimental results.
This paper reports about an application of Bayes' inferred neural network classifiers in the field of automatic sleep staging. The  reason for using Bayesian learning for this task is two-fold. First,  Bayesian inference is known to embody regularization automatically. Second, a side effect of Bayesian learning leads to larger  variance of network outputs in regions without training data. This  results in well known moderation effects, which can be used to  detect outliers. In a 5 fold cross-validation experiment the full  Bayesian solution found with R. Neals hybrid Monte Carlo algorithm, was not better than a single maximum a-posteriori (MAP)  solution found with D.J. MacKay's evidence approximation. In a  second experiment we studied the properties of both solutions in  rejecting classification of movement artefacts.  Experiences with Bayesian Learning in a Real World Application
***We consider neural network models for stochastic nonlinear dynamical  systems where measurements of the variable of interest are only available at irregular intervals i.e. most realizations are missing. Difficulties  arise since the solutions for prediction and maximum likelihood learning with missing data lead to complex integrals, which even for simple  cases cannot be solved analytically. In this paper we propose a specific combination of a nonlinear recurrent neural predictive model and  a linear error model which leads to tractable prediction and maximum  likelihood adaptation rules. In particular, the recurrent neural network  can be trained using the real-time recurrent learning rule and the linear  error model can be trained by an EM adaptation rule, implemented using forward-backward Kalman filter equations. The model is applied to  predict the glucose/insulin metabolism of a diabetic patient where blood  glucose measurements are only available a few times a day at irregular  intervals. The new model shows considerable improvement with respect  to both recurrent neural networks trained with teacher forcing or in a free  running mode and various linear models.  1 TRODUCTION  In many physiological dynamical systems measurements are acquired at irregular intervals.  Consider the case of blood glucose measurements of a diabetic who only measures blood  glucose levels a few times a day. At the same time physiological systems are typically  highly nonlinear and stochastic such that recurrent neural networks are suitable models.  Typically, such networks are either used purely free running in which the networks predictions are iterated, or in a teacher forcing mode in which actual measurements are substituted  * {volker. tre...
We discuss the development of a Multi-Layer Perceptron neural  network classifier for use in preoperative differentiation between  benign and malignemt ovarian tumors. As the Mean Squared classiftcation Error is not sufficient to make correct and objective assessments about the performance of the neural classifier, the concepts of sensitivity and specificity are introduced and combined  in Receiver Operating Characteristic curves. Based on objective  observations such as sonomorphologic criteria, color Doppler imaging and results from serum tumor markers, the neural network is  able to make reliable predictions with a discriminating performemce  comparable to that of experienced gynecologists.
This paper presents a new approach to the problem of modelling daily  rainfall using neural networks. We first model the conditional distributions of rainfall amounts, in such a way that the model itself determines  the order of the process, and the time-dependent shape and scale of the  conditional distributions. After integrating over particular weather patterns, we are able to extract seasonal variations and long-term trends.
We explain how the training data can be separated into clean information and unexplainable noise. Analogous to the data, the neural network  is separated into a time invariant structure used for forecasting, and a  noisy part. We propose a unified theory connecting the optimization algorithms for cleaning and learning together with algorithms that control  the data noise and the parameter noise. The combined algorithm allows  a data-driven local control of the liability of the network parameters and  therefore an improvement in generalization. The approach is proven to  be very useful at the task of forecasting the German bond market.
Prioritized sweeping is a model-based reinforcement learning method  that attempts to focus an agent's limited computational resources to  achieve a good estimate of the value of environment states. To choose effectively where to spend a costly planning step, classic prioritized sweeping uses a simple heuristic to focus computation on the states that are  likely to have the largest errors. In this paper, we introduce generalized  prioritized sweeping, a principled method for generating such estimates  in a representation-specific manner. This allows us to extend prioritized  sweeping beyond an explicit, state-based representation to deal with compact representations that are necessary for dealing with large state spaces.  We apply this method for generalized model approximators (such as  Bayesian networks), and describe preliminary experiments that compare  our approach with classical prioritized sweeping.
This paper describes some of the interactions of model learning  algorithms and planning algorithms we have found in exploring  model-based reinforcement learning. The paper focuses on how local trajectory optimizers can be used effectively with learned nonparametric models. We find that trajectory planners that are fully  consistent with the learned model often have difficulty finding reasonable plans in the early stages of learning. Trajectory planners  that balance obeying the learned model with minimizing cost (or  maximizing reward) often do better, even if the plan is not fully  consistent with the learned model.
A new policy iteration algorithm for partially observable Markov  decision processes is presented that is simpler and more efficient than  an earlier policy iteration algorithm of Sondik (1971,1978). The key  simplification is representation of a policy as a finite-state controller.  This representation makes policy evaluation straightforward. The paper's contribution is to show that the dynamic-programming update  used in the policy improvement step can be interpreted as the transformation of a finite-state controller into an improved finite-state controller. The new algorithm consistently outperforms value iteration  as an approach to solving infinite-horizon problems.
Initial experiments described here were directed toward using reinforcement learning (RL) to develop an automated recovery system (ARS) for  high-agility aircraft. An ARS is an outer-loop flight-control system designed to bring an aircraft from a range of out-of-control states to straightand-level flight in minimum time while satisfying physical and physiological constraints. Here we report on results for a simple version  of the problem involving only single-axis (pitch) simulated recoveries.  Through simulated control experience using a medium-fidelity aircraft  simulation, the RL system approximates an optimal policy for pitch-stick  inputs to produce minimum-time transitions to straight-and-level flight in  unconstrained cases while avoiding ground-strike. The RL system was  also able to adhere to a pilot-station acceleration constraint while executing simulated recoveries.  Automated Aircraft Recovery via Reinforcement Learning 1023
This paper is concerned with the problem of Reinforcement Learning (RL) for continuous state space and time stochastic control  problems. We state the Hamilton-Jacobi-Bellman equation satisfied by the value function and use a Finite-Difference method for  designing a convergent approximation scheme. Then we propose a  RL algorithm based on this scheme and prove its convergence to  the optimal solution.
We propose local error estimates together with algorithms for adaptive a-posteriori grid and time refinement in reinforcement learning. We consider a deterministic system with continuous state and  time with infinite horizon discounted cost functional. For grid refinement we follow the procedure of numerical methods for the  Bellman-equation. For time refinement we propose a new criterion,  based on consistency estimates of discrete solutions of the Bellmanequation. We demonstrate, that an optimal ratio of time to space  discretization is crucial for optimal learning rates and accuracy of  the approximate optimal value function.
We present a new approach to reinforcement learning in which the policies considered by the learning process are constrained by hierarchies of  partially specified machines. This allows for the use of prior knowledge  to reduce the search space and provides a framework in which knowledge  can be transferred across problems and in which component solutions  can be recombined to solve larger and more complicated problems. Our  approach can be seen as providing a link between reinforcement learning and "behavior-based" or "teleo-reactive" approaches to control. We  present provably convergent algorithms for problem-solving and learning with hierarchical machines and demonstrate their effectiveness on a  problem with several thousand states.
Planning 1051  primitive, one-step action to an abstract action, an arbitrary, closed-loop policy. Whereas  prior work modeled the behavior of the agent-environment system under a single, given  policy, here we learn different models for a set of different policies. For each possible way  of behaving, the agent learns a separate model of what will happen. Then, in planning, it  can choose between these overall policies as well as between primitive actions.  To illustrate the kind of advance we are trying to make, consider the example shown in  Figure 1. This is a standard grid world in which the primitive actions are to move from one  grid cell to a neighboring cell. Imagine the learning agent is repeatedly given new tasks  in the form of new goal locations to travel to as rapidly as possible. If the agent plans at  the level of primitive actions, then its plans will be many actions long and take a relatively  long time to compute. Planning could be much faster if abstract actions could be used to  plan for moving from room to room rather than from cell to cell. For each room, the agent  learns two models for two abstract actions, one for traveling efficiently to each adjacent  room. We do not address in this paper the question of how such abstract actions could be  discovered without help; instead we focus on the mathematical theory of abstract actions.  In particular, we define a very general semantics for themina property that seems to be  required in order for them to be used in the general kind of planning typically used with  Markov decision processes. At the end of this paper we illustrate the theory in this example  problem, showing how room-to-room abstract actions can substantially speed planning.  4 unreliable  primitive actions  up  left --'- right Fail 33%  o the time  down  8 abstract actions  (to each room's 2 haftways)  Figure 1: Example Task. The Natural abstract actions are to move from room to room.
We are frequently called upon to perform multiple tasks that compete for our attention and resource. Often we know the optimal  solution to each task in isolation; in this paper, we describe how  this knowledge can be exploited to efficiently find good solutions  for doing the tasks in parallel. We formulate this problem as that of  dynamically merging multiple Markov decision processes (MDPs)  into a composite MDP, and present a new theoretically-sound dynamic programming algorithm for finding an optimal policy for the  composite MDP. We analyze various aspects of our algorithm and  illustrate its use on a simple merging problem.  Every day, we are faced with the problem of doing multiple tasks in parallel, each  of which competes for our attention and resource. If we are running a job shop,  we must decide which machines to allocate to which jobs, and in what order, so  that no jobs miss their deadlines. If we are a mail delivery robot, we must find the  intended recipients of the mail while simultaneously avoiding fixed obstacles (such  as walls) and mobile obstacles (such as people), and still manage to keep ourselves  sufficiently charged up.  Frequently we know how to perform each task in isolation; this paper considers how  we can take the information we have about the individual tasks and combine it to  efficiently find an optimal solution for doing the entire set of tasks in parallel. More  importantly, we describe a theoretically-sound algorithm for doing this merging  dynamically; new tasks (such as a new job arrival at a job shop) can be assimilated  online into the solution being found for the ongoing set of simultaneous tasks.  1058 S. Singh and D. Cohn
In this paper we show that for discounted MDPs with discount  factor 3'  1/2 the asymptotic rate of convergence of Q-learning  is O(1/t R(-v)) if R(13')  1/2 and O(v/loglogt/t) otherwise  provided that the state-action pairs are sampled from a fixed probability distribution. Here R -Pmin/Pmax is the ratio of the minimum and maximum state-action occupation frequencies. The results extend to convergent on-line learning provided that Pmin  0,  where Pmin and Pmax now become the minimum and maximum  state-action occupation frequencies corresponding to the stationary distribution.
A learning system composed of linear control modules, reinforcement learning modules and selection modules (a hybrid reinforcement learning system) is proposed for the fast learning of real-world  control problems. The selection modules choose one appropriate  control module dependent on the state. This hybrid learning system was applied to the control of a stilt-type biped robot. It learned  the control on a sloped floor more quickly than the usual reinforcement learning because it did not need to learn the control on a  fiat floor, where the linear control module can control the robot.  When it was trained by a 2-step learning (during the first learning  step, the selection module was trained by a training procedure controlled only by the linear controller), it learned the control more  quickly. The average number of trials (about 50) is so small that  the learning system is applicable to real robot control.
Based on computational principles, the concept of an internal  model for adaptive control has been divided into a forward and an  inverse model. However, there is as yet little evidence that learning  control by the CNS is through adaptation of one or the other. Here  we examine two adaptive control architectures, one based only on  the inverse model and other based on a combination of forward and  inverse models. We then show that for reaching movements of the  hand in novel force fields, only the learning of the forward model  results in key characteristics of performance that match the kinematics of human subjects. In contrast, the adaptive control system  that relies only on the inverse model fails to produce the kinematic  patterns observed in the subjects, despite the fact that it is more  stable. Our results provide evidence that learning control of novel  dynamics is via formation of a forward model.
As a benchmark task, the spiral problem is well known in neural networks. Unlike previous work that emphasizes learning, we approach  the problem from a generic perspective that does not involve learning.  We point out that the spiral problem is intrinsically connected to the inside/outside problem. A generic solution to both problems is proposed  based on oscillatory correlation using a time delay network. Our simulation results are qualitatively consistent with human performance, and  we interpret human limitations in terms of synchrony and time delays,  both biologically plausible. As a special case, our network without time  delays can always distinguish these figures regardless of shape, position,  size, and orientation.
Despite the fact that mental arithmetic is based on only a few hundred basic facts and some simple algorithms, humans have a difficult time mastering the subject, and even experienced individuals  make mistakes. Associative multiplication, the process of doing  multiplication by memory without the use of rules or algorithms,  is especially problematic. Humans exhibit certain characteristic  phenomena in performing associative multiplications, both in the  type of error and in the error frequency. We propose a model for  the process of associative multiplication, and compare its performance in both these phenomena with data from normal humans  and from the model proposed by Anderson et al (1994).
We compare the ability of three exemplar-based memory models, each  using three different face stimulus representations, to account for the  probability a human subject responded "old" in an old/new facial memory experiment. The models are 1) the Generalized Context Model, 2)  SimSample, a probabilistic sampling model, and 3) MMOM, a novel  model related to kernel density estimation that explicitly encodes stimulus distinctiveness. The representations are 1) positions of stimuli in  MDS "face space," 2) projections of test faces onto the "eigenfaces" of  the study set, and 3) a representation based on response to a grid of Gabor  filter jets. Of the 9 model/representation combinations, only the distinctiveness model in MDS space predicts the observed "morph familiarity  inversion" effect, in which the subjects' false alarm rate for morphs between similar faces is higher than their hit rate for many of the studied  faces. This evidence is consistent with the hypothesis that human memory for faces is a kernel density estimation task, with the caveat that distinctive faces require larger kernels than do typical faces.
Humans demonstrate a remarkable ability to generate accurate and  appropriate motor behavior under many different and often uncertain  emqronmental conditions. This paper describes a new modular approach to human motor learning and control, based on multiple pairs of  inverse (controller) and forward (predictor) models. This architecture  simultaneously learns the multiple inverse models necessary for control  as well as how to select the inverse models appropriate for a given environment. Simulations of object manipulation demonstrates the ability  to learn multiple objects, appropriate generalization to novel objects  and the inappropriate activation of motor programs based on visual  cues, followed by on-line correction, seen in the "size-weight illusion".
Historically, connectionist systems have not excelled at representing and manipulating complex structures. How can a system composed of simple neuron-like computing elements encode complex  relations? Recently, researchers have begun to appreciate that representations can extend in both time and space. Many researchers  have proposed that the synchronous firing of units can encode complex representations. I identify the limitations of this approach  and present an asynchronous model of binding that effectively represents complex structures. The asynchronous model extends the  synchronous approach. I argue that our cognitive architecture utilizes a similar mechanism.
The learning of many visual perceptual tasks has been shown to be  specific to practiced stimuli, while new stimuli require re-learning  from scratch. Here we demonstrate generalization using a novel  paradigm in motion discrimination where learning has been previously shown to be specific. We trained subjects to discriminate  the directions of moving dots, and verified the previous results  that learning does not transfer from the trained direction to a new  one. However, by tracking the subjects' performance across time  in the new direction, we found that their rate of learning doubled.  Therefore, learning generalized in a task previously considered too  difficult for generalization. We also replicated, in the second experiment, transfer following training with "easy" stimuli.  The specificity of perceptual learning and the dichotomy between  learning of "easy" vs. "difficult" tasks were hypothesized to involve  different learning processes, operating at different visual cortical  areas. Here we show how to interpret these results in terms of signal  detection theory. With the assumption of limited computational  resources, we obtain the observed phenomena -direct transfer  and change of learning rate -for increasing levels of task'difficulty.  It appears that human generalization concurs with the expected  behavior of a generic discrimination system.
Structure in a visual scene can be described at many levels of granularity. At a coarse level, the scene is composed of objects; at a finer level,  each object is made up of parts, and the parts of subparts. In this work, I  propose a simple principle by which such hierarchical structure can be  extracted from visual scenes: Regularity in the relations among different  parts of an object is weaker than in the internal structure of a part. This  principle can be applied recursively to define part-whole relationships  among elements in a scene. The principle does not make use of object  models, categories, or other sorts of higher-level knowledge; rather,  part-whole relationships can be established based on the statistics of a  set of sample visual scenes. I illustrate with a model that performs unsupervised decomposition of simple scenes. The model can account for  the results from a human learning experiment on the ontogeny of partwhole relationships.
I consider the problem of learning concepts from small numbers of positive examples, a feat which humans perform routinely but which computers are rarely capable of. Bridging machine learning and cognitive  science perspectives, I present both theoretical analysis and an empirical  study with human subjects for the simple task of learning concepts corresponding to axis-aligned rectangles in a multidimensional feature space.  Existing learning models, when applied to this task, cannot explain how  subjects generalize from only a few examples of the concept. I propose  a principled Bayesian model based on the assumption that the examples  are a random sample from the concept to be learned. The model gives  precise fits to human behavior on this simple task and provides qualitative  insights into more complex, realistic cases of concept learning.
Recent experimental data indicate that the strengthening or weakening of  synaptic connections between neurons depends on the relative timing of  preand postsynaptic action potentials. A Hebbian synaptic modification  rule based on these data leads to a stable state in which the excitatory and  inhibitory inputs to a neuron are balanced, producing an irregular pattern  of firing. It has been proposed that neurons in vivo operate in such a  mode.
The contrast response function (CRF) of many neurons in the primary visual cortex saturates and shifts towards higher contrast values following  prolonged presentation of high contrast visual stimuli. Using a recurrent  neural network of excitatory spiking neurons with adapting synapses we  show that both effects could be explained by a fast and a slow component in the synaptic adaptation. (i) Fast synaptic depression leads to saturation of the CRF and phase advance in the cortical response to high  contrast stimuli. (ii) Slow adaptation of the synaptic transmitter release  probability is derived such that the mutual information between the input  and the output of a cortical neuron is maximal. This component--given  by infomax learning rule--explains contrast adaptation of the averaged  membrane potential (DC component) as well as the surprising experimental result, that the stimulus modulated component (F1 component)  of a cortical cell's membrane potential adapts only weakly. Based on our  results, we propose a new experiment to estimate the strength of the effective excitatory feedback to a cortical neuron, and we also suggest a  relatively simple experimental test to justify our hypothesized synaptic  mechanism for contrast adaptation.
Visually-guided arm reaching movements are produced by distributed  neural networks within parietal and frontal regions of the cerebral cortex.  Experimental data indicate that (1) single neurons in these regions are  broadly tuned to parameters of movement; (2) appropriate commands are  elaborated by populations of neurons; (3) the coordinated action of neurons can be visualized using a neuronal population vector (NPV). However, the NPV provides only a rough estimate of movement parameters  (direction, velocity) and may even fail to reflect the parameters of movement when arm posture is changed. We designed a model of the cortical  motor command to investigate the relation between the desired direction  of the movement, the actual direction of movement and the direction of  the NPV in motor cortex. The model is a two-layer self-organizing neural  network which combines broadly-tuned (muscular) proprioceptive and  (cartesian) visual information to calculate (angular) motor commands for  the initial part of the movement of a two-link arm. The network was  trained by motor babbling in 5 positions. Simulations showed that (1)  the network produced appropriate movement direction over a large part  of the workspace; (2) small deviations of the actual trajectory from the  desired trajectory existed at the extremities of the workspace; (3) these  deviations were accompanied by large deviations of the NPV from both  trajectories. These results suggest the NPV does not give a faithful image  of cortical processing during arm reaching movements.  * to whom correspondence should be addressed  84 P Baraduc, E. Guigon and Y. Burnod
Cortical amplification has been proposed as a mechanism for enhancing  the selectivity of neurons in the primary visual cortex. Less appreciated  is the fact that the same form of amplification can also be used to de-tune  or broaden selectivity. Using a network model with recurrent cortical  circuitry, we propose that the spatial phase invariance of complex cell  responses arises through recurrent amplification of feedforward input.  Neurons in the network respond like simple cells at low gain and complex ceils at high gain. Similar recurrent mechanisms may play a role  in generating invariant representations of feedforward input elsewhere in  the visual processing pathway.
Human and animal studies show that mammalian brain undergoes  massive synaptic pruning during childhood, removing about half of  the synapses until puberty. We have previously shown that maintaining network memory performance while synapses are deleted,  requires that synapses are properly modified and pruned, removing the weaker synapses. We now show that neuronal regulation, a  mechanism recently observed to maintain the average neuronal input field, results in weight-dependent synaptic modification. Under  the correct range of the degradation dimension and synaptic upper bound, neuronal regulation removes the weaker synapses and  judiciously modifies the remaining synapses. It implements near  optimal synaptic modification, and maintains the memory performance of a network undergoing massive synaptic pruning. Thus,  this paper shows that in addition to the known effects of Hebbian  changes, neuronal regulation may play an important role in the  self-organization of brain networks during development.
Gain control by divisive inhibition, a.k.a. divisive normalization,  has been proposed to be a general mechanism throughout the visual cortex. We explore in this study the statistical properties  of this normalization in the presence of noise. Using simulations,  we show that divisive normalization is a close approximation to a  maximum likelihood estimator, which, in the context of population  coding, is the same as an ideal observer. We also demonstrate analytically that this is a general property of a large class of nonlinear  recurrent networks with line attractors. Our work suggests that  divisive normalization plays a critical role in noise filtering, and  that every cortical layer may be an ideal observer of the activity in  the preceding layer.  Information processing in the cortex is often formalized as a sequence of a linear  stages followed by a nonlinearity. In the visual cortex, the nonlinearity is best described by squaring combined with a divisive pooling of local activities. The divisive  part of the nonlinearity has been extensively studied by Heeger and colleagues [1],  and several authors have explored the role of this normalization in the computation  of high order visual features such as orientation of edges or first and second order  motion[4]. We show in this paper that divisive normalization can also play a role in  noise filtering. More specifically, we demonstrate through simulations that networks  implementing this normalization come close to performing maximum likelihood estimation. We then demonstrate analytically that the ability to perform maximum  likelihood estimation, and thus efficiently extract information from a population of  noisy neurons, is a property exhibited by a large class of networks.  Maximum likelihood estimation is a framework commonly used in the theory of  ideal observers. A recent example comes from the work of Itti et al., 1998, who have  shown that it is possible to account for the behavior of human subjects in simple  discrimination tasks. Their model comprised two distinct stages: 1) a network  Divisive Normalization, Line Attractor Networks and Ideal Observers 105  which models the noisy response of neurons with tuning curves to orientation and  spatial frequency combined with divisive normalization, and 2) an ideal observer (a  maximum likelihood estimator) to read out the population activity of the network.  Our work suggests that there is no need to distinguish between these two stages,  since, as we will show, divisive normalization comes close to providing a maximum  likelihood estimation. More generally, we propose that there may not be any part  of the cortex that acts as an ideal observer for patterns of activity in sensory areas  but, instead, that each cortical layer acts as an ideal observer of the activity in the  preceding layer.
Determining the relationship between the activity of a single nerve  cell to that of an entire population is a fundamental question that  bears on the basic neural computation paradigms. In this paper  we apply an information theoretic approach to quantify the level  of cooperative activity among cells in a behavioral context. It is  possible to discriminate between synergetic activity of the cells vs.  redundant activity, depending on the difference between the information they provide when measured jointly and the information  they provide independently. We define a synergy value that is positive in the first case and negative in the second and show that the  synergy value can be measured by detecting the behavioral mode of  the animal from simultaneously recorded activity of the cells. We  observe that among cortical cells positive synergy can be found,  while cells from the basal ganglia, active during the same task, do  not exhibit similar synergetic activity.  litay, tishby} @cs.huji.ac.il  Permanent address: Institute of Computer Science and Center for Neural Computation, The Hebrew University, Jerusalem 91904, Israel.  112 I. Gat and N. Tishby  1
Event-related potentials (ERPs), are portions of electroencephalographic (EEG) recordings that are both timeand phase-locked  to experimental events. ERPs are usually averaged to increase  their signal/noise ratio relative to non-phase locked EEG activity, regardless of the fact that response activity in single epochs  may vary widely in time course and scalp distribution. This study  applies a linear decomposition tool, Independent Component Analysis (ICA) [1], to multichannel single-trial EEG records to derive  spatial filters that decompose single-trial EEG epochs into a sum  of temporally independent and spatially fixed components arising  from distinct or overlapping brain or extra-brain networks. Our  results on normal and autistic subjects show that ICA can separate artifactual, stimulus-locked, response-locked, anal non-event  related background EEG activities into separate components, allowing (1) removal of pervasive artifacts of all types from single-trial  EEG records, and (2) identification of both stimulusand responselocked EEG components. Second, this study proposes a new visualization tool, the 'ERP image', for investigating variability in latencies and amplitudes of event-evoked responses in spontaneous EEG  or MEG records. We show that sorting single-trial ERP epochs in  order of reaction time and plotting the potentials in 2-D clearly  reveals underlying patterns of response variability linked to performance. These analysis and visualization tools appear broadly  applicable to electrophyiological research on both normal and clinical populations.  Analyzing and Visualizing Single-Trial Event-Related Potentials 119
A correlation-based learning rule at the spike level is formulated,  mathematically analyzed, and compared to learning in a firing-rate  description. A differential equation for the learning dynamics is  derived under the assumption that the time scales of learning and  spiking can be separated. For a linear Poissonian neuron model  which receives time-dependent stochastic input we show that spike  correlations on a millisecond time scale play indeed a role. Correlations between input and output spikes tend to stabilize structure  formation, provided that the form of the learning window is in  accordance with Hebb's principle. Conditions for an intrinsic normalization of the average synaptic weight are discussed.
Here we derive measures quantifying the information loss of a synaptic  signal due to the presence ofneuronal noise sources, as it electrotonically  propagates along a weakly-active dendrite. We model the dendrite as an  infinite linear cable, with noise sources distributed along its length. The  noise sources we consider are thermal noise, channel noise arising from  the stochastic nature of voltage-dependent ionic channels (K + and Na +)  and synaptic noise due to spontaneous background activity. We assess the  efficacy of information transfer using a signal detection paradigm where  the objective is to detect the presence/absence of a presynaptic spike from  the post-synaptic membrane voltage. This allows us to analytically assess  the role of each of these noise sources in information transfer. For our  choice of parameters, we find that the synaptic noise is the dominant  noise source which limits the maximum length over which information  be reliably transmitted.
Lateral competition within a layer of neurons sharpens and localizes the  response to an input stimulus. Here, we investigate a model for the activity dependent development of ocular dominance maps which allows  to vary the degree of lateral competition. For weak competition, it resembles a correlation-based learning model and for strong competition,  it becomes a self-organizing map. Thus, in the regime of weak competition the receptive fields are shaped by the second order statistics of the  input patterns, whereas in the regime of strong competition, the higher  moments and "features" of the individual patterns become important.  When correlated localized stimuli from two eyes drive the cortical development we find (i) that a topographic map and binocular, localized  receptive fields emerge when the degree of competition exceeds a critical  value and (ii) that receptive fields exhibit eye dominance beyond a second critical value. For anti-correlated activity between the eyes, the second order statistics drive the system to develop ocular dominance even  for weak competition, but no topography emerges. Topography is established only beyond a critical degree of competition.
A new paradigm is proposed for sorting spikes in multi-electrode  data using ratios of transfer functions between cells and electrodes.  It is assumed that for every cell and electrode there is a stable  linear relation. These are dictated by the properties of the tissue,  the electrodes and their relative geometries. The main advantage  of the method is that it is insensitive to variations in the shape and  amplitude of a spike. Spike sorting is carried out in two separate  steps. First, templates describing the statistics of each spike type  are generated by clustering transfer function ratios then spikes are  detected in the data using the spike statistics. These techniques  were applied to data generated in the escape response system of  the cockroach.
We examine the statistics of natural monochromatic images decomposed  using a multi-scale wavelet basis. Although the coefficients of this representation are nearly decorrelated, they exhibit important higher-order  statistical dependencies that cannot be eliminated with purely linear processing. In particular, rectified coefficients corresponding to basis functions at neighboring spatial positions, orientations and scales are highly  correlated. A method of removing these dependencies is to divide each  coefficient by a weighted combination of its rectified neighbors. Several successful models of the steady-state behavior of neurons in primary  visual cortex are based on such "divisive normalization" computations,  and thus our analysis provides a theoretical justification for these models.  Perhaps more importantly, the statistical measurements explicitly specify  the weights that should be used in computing the normalization signal.  We demonstrate that this weighting is qualitatively consistent with recent physiological experiments that characterize the suppressive effect  of stimuli presented outside of the classical receptive field. Our observations thus provide evidence for the hypothesis that early visual neural  processing is well matched to these statistical properties of images.  An appealing hypothesis for neural processing states that sensory systems develop in response to the statistical properties of the signals to which they are exposed [e.g., 1, 2].  This has led many researchers to look for a means of deriving a model of cortical processing purely from a statistical characterization of sensory signals. In particular, many such  attempts are based on the notion that neural responses should be statistically independent.  The pixels of digitized natural images are highly redundant, but one can always find a  linear decomposition (i.e., principal component analysis) that eliminates second-order cotResearch supported by an Alfred P. Sloan Fellowship to EPS, and by the Sloan Center for Theoretical  Neurobiology at NYU.  154 E. P Simoncelli and O. Schwartz  relation. A number of researchers have used such concepts to derive linear receptive fields  similar to those determined from physiological measurements [e.g., 16, 20]. The principal  components decomposition is, however, not unique. Because of this, these early attempts  required additional constraints, such as spatial locality and/or symmetry, in order to achieve  functions approximating cortical receptive fields.  More recently, a number of authors have shown that one may use higher-order statistical measurements to uniquely constrain the choice of linear decomposition [e.g., 7, 9].  This is commonly known as independent components analysis. Vision researchers have  demonstrated that the resulting basis functions are similar to cortical receptive fields, in  that they are localized in spatial position, orientation and scale [e.g., 17, 3]. The associated coefficients of such decompositions are (second-order) decorrelated, highly kurtotic,  and generally more independent than principal components.  But the response properties of neurons in primary visual cortex are not adequately described  by linear processes. Even if one chooses to describe only the mean firing rate of such  neurons, one must at a minimum include a rectifying, saturating nonlinearity. A number of  authors have shown that a gain control mechanism, known as divisive normalization, can  explain a wide variety of the nonlinear behaviors of these neurons [ 18, 4, 11, 12, 6]. In most  instantiations of normalization, the response of each linear basis function is rectified (and  typically squared) and then divided by a uniformly weighted sum of the rectified responses  of all other neurons. Physiologically, this is hypothesized to occur via feedback shunting  inhibitory mechanisms [e.g., 13, 5]. Ruderman and Bialek [19] have discussed divisive  normalization as a means of increasing entropy.  In this paper, we examine the joint statistics of coeffÉcients of an orthonormal wavelet image decomposition that approximates the independent components of natural images. We  show that the coefficients are second-order decorrelated, but not independent. In particular, pairs of rectified responses are highly correlated. These pairwise dependencies may  be eliminated by dividing each coefficient by a weighted combination of the rectified responses of other neurons, with the weighting determined from image statistics. We show  that the resulting model, with all parameters determined from the statistics of a set of images, can account for recent physiological observations regarding suppression of cortical  responses by stimuli presented outside the classical receptive field. These concepts have  been previously presented in [21, 25].
Information from the senses must be compressed into the limited range  of firing rates generated by spiking nerve cells. Optimal compression  uses all firing rates equally often, implying that the nerve cell's response  matches the statistics of naturally occurring stimuli. Since changing  the voltage-dependent ionic conductances in the cell membrane alters  the flow of information, an unsupervised, non-Hebbian, developmental  learning rule is derived to adapt the conductances in Hodgkin-Huxley  model neurons. By maximizing the rate of information transmission,  each firing rate within the model neuron's limited dynamic range is used  equally often. 
We study the effect of correlated noise on the accuracy of population coding using a model of a population of neurons that are  broadly tuned to an angle in two-dimension. The fluctuations in  he neuronat activity is modeled as a Gaussian noise with pairwise  correlations which decays exponentially with the difference between  the preferred orientations of the pair. By calculating the Fisher information of the system, we show that in the biologically relevant  regime of parameters positive correlations decrease the estimation  capability of the network relative to the uncorrelated population.  Moreover strong positive correlations result in information capacity which saturates to a finite value as the number of cells in the  population grows. In contrast, negative correlations substantially  increase the information capacity of the neuronal population.
Most theoretical and empirical studies of population codes make  the assumption that underlying neuronal activities is a unique and  unambiguous value of an encoded quantity. However, population  activities can contain additional information about such things as  multiple values of or uncertainty about the quantity. We have previously suggested a method to recover extra information by treating the activities of the population of cells as coding for a complete distribution over the coded quantity rather than just a single  value. We now show how this approach bears on psychophysical and neurophysiological studies of population codes for motion direction in tasks involving transparent motion stimuli. We  show that, unlike standard approaches, it is able to recover multiple motions from population responses, and also that its output  is consistent with both correct and erroneous human performance  on psychophysical tasks.  A population code can be defined as a set of units whose activities collectively  encode some underlying variable (or variables). The standard view is that population codes are useful for accurately encoding the underlying variable when the  individual units are noisy. Current statistical approaches to interpreting population activity reflect this view, in that they determine the optimal single value that  explains the observed activity pattern given a particular model of the noise (and  possibly a loss function).  In our work, we have pursued an alternative hypothesis, that the population encodes additional information about the underlying variable, including multiple  values and uncertainty. The Distributional Population Coding (DPC) framework  finds the best probability distribution across values that fits the population activity  (Zemel, Dayan, & Pouget, 1998).  The DPC framework is appealing since it makes clear how extra information can  be conveyed in a population code. In this paper, we use it to address a particuDistributional Population Codes and Multiple Motion Models 175  1 o o 501ooA0: 30 ø 10050o  -180  AO: 90 ø  t  -,io b ,)o :so  A0:60 ø  100'  A0: 120 ø  -so -% i, :so  Figure 1: Each of the four plots depicts a single MT cell response (spikes per second) to a transparent motion stimulus of a fixed directional difference (A0) between the two motion directions. The x-axis gives the average direction of stimulus motion relative to the cell's preferred direction (0ø). From Treue, personal  communication.  lar body of experimental data on transparent motion perception, due to Treue and  colleagues (Hol & Treue, 1997; Rauber & Treue, 1997). These transparent motion  experiments provide an ideal test of the DPC framework, in that the neurophysiological data reveal how the population responds to multiple values in the stimuli,  and the psychophysical data describe how these values are actually decoded, putatively from the population response. We investigate how standard methods fare  on these data, and compare their performance to that of DPC.
Graphical models provide a broad probabilistic flamework with applications in speech recognition (Hidden Markov Models), medical  diagnosis (Belief networks) and artificial intelligence (Boltzmann  Machines). However, the computing time is typically exponential  in the number of nodes in the graph. Within the variational flamework for approximating these models, we present two classes of distributions, decimatable Boltzmann Machines and Tractable Belief  Networks that go beyond the standard factorized approach. We  give generalised mean-field equations for both these directed and  undirected approximations. Simulation results on a small benchmark problem suggest using these richer approximations compares  favorably against others previously reported in the literature.
We compute upper and lower bounds on the VC dimension of  feedforward networks of units with piecewise polynomial activation functions. We show that if the number of layers is fixed, then  the VC dimension grows as W log W, where W is the number of  parameters in the network. This result stands in opposition to the  case where the number of layers is unbounded, in which case the  VC dimension grows as W 2.
We study the dynamics of supervised learning in layered neural networks, in the regime where the size p of the training set is proportional  to the number N of inputs. Here the local fields are no longer described  by Gaussian distributions. We use dynamical replica theory to predict  the evolution of macroscopic observables, including the relevant error  measures, incorporating the old formalism in the limit pin  oz.
The kernel-parameter is one of the few tunable parameters in Support Vector machines, controlling the complexity of the resulting  hypothesis. Its choice amounts to model selection and its value is  usually found by means of a validation set. We present an algorithm which can automatically perform model selection with little  additional computational cost and with no need of a validation set.  In this procedure model selection and learning are not separate,  but kernels are dynamically adjusted during the learning process  to find the kernel parameter which provides the best possible upper  bound on the generalisation error. Theoretical results motivating  the approach and experimental results confirming its validity are  presented.
We solve the dynamics of Hopfield-type neural networks which store sequences of patterns, close to saturation. The asymmetry of the interaction  matrix in such models leads to violation of detailed balance, ruling out an  equilibrium statistical mechanical analysis. Using generating functional  methods we derive exact closed equations for dynamical order parameters, viz. the sequence overlap and correlation and response functions,  in the limit of an infinite system size. We calculate the time translation  invariant solutions of these equations, describing stationary limit-cycles,  which leads to a phase diagram. The effective retarded self-interaction  usually appearing in symmetric models is here found to vanish, which  causes a significantly enlarged storage capacity of acm 0.269, compared to acm 0.139 for Hopfield networks s[oring static patterns. Our  results are tested against extensive computer simulations and excellent  agreement is found.  212 A. Diring, A. C. C. Coolen and D. Sherrington
Gaussian process (GP) prediction suffers from O(n 3) scaling with the  data set size n. By using a finite-dimensional basis to approximate the  GP predictor, the computational complexity can be reduced. We derive optimal finite-dimensional predictors under a number of assumptions, and show the superiority of these predictors over the Projected  Bayes Regression method (which is asymptotically optimal). We also  show how to calculate the minimal model size for a given n. The  calculations are backed up by numerical experiments.
We describe a unifying method for proving relative loss bounds for online linear threshold classification algorithms, such as the Perceptron and  the Winnow algorithms. For classification problems the discrete loss is  used, i.e., the total number of prediction mistakes. We introduce a continuous loss function, called the "linear hinge loss", that can be employed  to derive the updates of the algorithms. We first prove bounds w.r.t. the  linear hinge loss and then convert them to the discrete loss. We introduce a notion of "average margin" of a set of examples. We show how  relative loss bounds based on the linear hinge loss can be converted to  relative loss bounds i.t.o. the discrete loss using the average margin.
Recent works in parameter estimation and neural coding have  demonstrated that optimal performance are related to the mutual  information between parameters and data. We consider the mutual  information in the case where the dependency in the parameter (a  vector 0) of the conditional p.d.f. of each observation (a vector  ), is through the scalar product 0. only. We derive bounds and  asymptotic behaviour for the mutual information and compare with  results obtained on the same model with the "replica technique".
The W-S (Wake-Sleep) algorithm is a simple learning rule for the models  with hidden variables. It is shown that this algorithm can be applied to  a factor analysis model which is a linear version of the Helmholtz machine. But even for a factor analysis model, the general convergence is  not proved theoretically. In this article, we describe the geometrical understanding of the W-S algorithm in contrast with the EM (ExpectationMaximization) algorithm and the era algorithm. As the result, we prove  the convergence of the W-S algorithm for the factor analysis model. We  also show the condition for the convergence in general models.
We show the similarity between belief propagation and TAP, for  decoding corrupted messages encoded by Sourlas's method. The  latter is a special case of the Gallager error-correcting code, where  the code word comprises products of Ix' bits selected randomly from  the original message. We examine the efficacy of solutions obtained  by the two methods for various values of Ix' and show that solutions  for I( > 3 may be sensitive to the choice of initial conditions in  the case of unbiased patterns. Good approximations are obtained  generally for I, = 2 and for biased patterns in the case of Ix' > 3,  especially when Nishimori's temperature is being used.
Following recent results [9, 8] showing the importance of the fatshattering dimension in explaining the beneficial effect of a large  margin on generalization performance, the current paper investigates the implications of these results for the case of imbalanced  datasets and develops two approaches to setting the threshold.  The approaches are incorporated into ThetaBoost, a boosting algorithm for dealing with unequal loss functions. The performance  of ThetaBoost and the two approaches are tested experimentally.  Keywords: Computational Learning Theory, Generalization, fat-shattering, large  margin, pac estimates, unequal loss, imbalanced datasets
We study probabilistic inference in large, layered Bayesian networks represented as directed acyclic graphs. We show that the  intractability of exact inference in such networks does not preclude  their effective use. We give algorithms for approximate probabilistic inference that exploit averaging phenomena occurring at nodes  with large numbers of parents. We show that these algorithms  compute rigorous lower and upper bounds on marginal probabilities of interest, prove that these bounds become exact in the limit  of large networks, and provide rates of convergence.
We analyze the asymptotic behavior of autoregressive neural network (AR-NN) processes using techniques from Markov chains and  non-linear time series analysis. It is shown that standard AR-NNs  without shortcut connections are asymptotically stationary. If linear shortcut connections are allowed, only the shortcut weights  determine whether the overall system is stationary, hence standard  conditions for linear AR processes can be used.
Symmetrically connected recurrent networks have recently been  used as models of a host of neural computations. However, because of the separation between excitation and inhibition, biological neural networks are asymmetrical. We study characteristic  differences between asymmetrical networks and their symmetrical counterparts, showing that they have dramatically different  dynamical behavior and also how the differences can be exploited  for computational ends. We illustrate our results in the case of a  network that is a selective amplifier.
We consider recurrent analog neural nets where each gate is subject to  Gaussian noise, or any other common noise distribution whose probability density function is nonzero on a large set. We show that many regular  languages cannot be recognized by networks of this type, for example  the language {w C {0, 1}* I w begins with 0}, and we give a precise  characterization of those languages which can be recognized. This result  implies severe constraints on possibilities for constructing recurrent analog neural nets that are robust against realistic types of analog noise. On  the other hand we present a method for constructingfeedforward analog  neural nets that are robust with regard to analog noise of this type.
Many learning algorithms for pattern classification minimize some cost function of the training data, with the aim of minimizing error (the probability of misclassifying an example). One example of such a cost function is simply the classifier's error on the training data. Recent results have examined alternative cost functions that provide better error estimates in some cases.
We study the approximation of functions by two-layer feedforward neural networks, focusing on incremental algorithms which greedily add  units, estimating single unit parameters at each stage. As opposed to  standard algorithms for fixed architectures, the optimization at each stage  is performed over a small number of parameters, mitigating many of the  difficult numerical problems inherent in high-dimensional non-linear optimization. We establish upper bounds on the error incurred by the algorithm, when approximating functions from the Sobolev class, thereby  extending previous results which only provided rates of convergence for  functions in certain convex hulls of functional spaces. By comparing our  results to recently derived lower bounds, we show that the greedy algorithms are nearly optimal. Combined with estimation error results for  greedy algorithms, a strong case can be made for this type of approach.
Based on a simple convexity lemma, we develop bounds for different types of Bayesian prediction errors for regression with Gaussian  processes. The basic bounds are formulated for a fixed training set.  Simpler expressions are obtained for sampling from an input distribution which equals the weight function of the covariance kernel,  yielding asymptotically tight results. The results are compared  with numerical experiments.
We discuss the application of TAP mean field methods known from  the Statistical Mechanics of disordered systems to Bayesian classification models with Gaussian processes. In contrast to previous approaches, no knowledge about the distribution of inputs is needed.  Simulation results for the Sonar data set are given.
We solve the dynamics of on-line Hebbian learning in perceptrons  exactly, for the regime where the size of the training set scales  linearly with the number of inputs. We consider both noiseless  and noisy teachers. Our calculation cannot be extended to nonHebbian rules, but the solution provides a nice benchmark to test  more general and advanced theories for solving the dynamics of  learning with restricted training sets.
O(ws(s log d q-log(dqh/s))) and O(ws((h/s) log q)qlog(dqh/s)) are  upper bounds for the VC-dimension of a set of neural networks of  units with piecewise polynomial activation functions, where s is  the depth of the network, h is the number of hidden units, w is  the number of adjustable parameters, q is the maximum of the  number of polynomial segments of the activation function, and d is  the maximum degree of the polynomials; also fl(wslog(dqh/s)) is  a lower bound for the VC-dimension of such a network set, which  are tight for the cases s ©(h) and s is constant. For the special  case q -1, the VC-dimension is ©(ws log d).
A new algorithm for Support Vector regression is described. For a priori  chosen , it automatically adjusts a flexible tube of minimal radius to the  data such that at most a fraction  of the data points lie outside. Moreover, it is shown how to use parametric tube shapes with non-constant  radius. The algorithm is analysed theoretically and experimentally.
We present exact analytical equilibrium solutions for a class of recurrent neural network models, with both sequential and parallel neuronal  dynamics, in which there is a tunable competition between nearestneighbour and long-range synaptic interactions. This competition is  found to induce novel coexistence phenomena as well as discontinuous  transitions between pattern recall states, 2-cycles and non-recall states.
I consider the problem of calculating learning curves (i.e., average  generalization performance) of Gaussian processes used for regression. A simple expression for the generalization error in terms of  the eigenvalue decomposition of the covariance function is derived,  and used as the starting point for several approximation schemes.  I identify where these become exact, and compare with existing  bounds on learning curves; the new approximations, which can  be used for any input space dimension, generally get substantially  closer to the truth.
I present a theory of mean field approximation based on information geometry. This theory includes in a consistent way the naive mean field  approximation, as well as the TAP approach and the linear response theorem in statistical physics, giving clear information-theoretic interpretations to them.
Many belief networks have been proposed that are composed of  binary units. However, for tasks such as object and speech recognition which produce real-valued data, binary network models are  usually inadequate. Independent component analysis (ICA) learns  a model from real data, but the descriptive power of this model  is severly limited. We begin by describing the independent factor  analysis (IFA) technique, which overcomes some of the limitations  of ICA. We then create a multilayer network by cascading singlelayer IFA models. At each level, the IFA network extracts realvalued latent variables that are non-linear functions of the input  data with a highly adaptive functional form, resulting in a hierarchical distributed representation of these data. Whereas exact  maximum-likelihood learning of the network is intractable, we derive an algorithm that maximizes a lower bound on the likelihood,  based on a variational approach.
We introduce a semi-supervised support vector machine (S3VM)  method. Given a training set of labeled data and a working set  of unlabeled data, SgVM constructs a support vector machine using both the training and working sets. We use SgVM to solve  the transduction problem using overall risk minimization (ORM)  posed by Vapnik. The transduction problem is to estimate the  value of a classification function at the given points in the working  set. This contrasts with the standard inductive learning problem  of estimating the classification function at all possible values and  then using the fixed function to deduce the classes of the working  set data. We propose a general SgVM model that minimizes both  the misclassification error and the function capacity based on all  the available data. We show how the S3VM model for I-norm linear support vector machines can be converted to a mixed-integer  program and then solved exactly using integer programming. Resuits of SgVM and the standard 1-norm support vector machine  approach are compared on ten data sets. Our computational results support the statistical learning theory results showing that  incorporating working data improves generalization when insufficient training information is available. In every case, SgVM either  improved or showed no significant difference in generalization compared to the traditional approach.  Semi-Supervised Support Vector Machines 369
Lazy learning is a memory-based technique that, once a query is received, extracts a prediction interpolating locally the neighboring examples of the query which are considered relevant according to a distance  measure. In this paper we propose a data-driven method to select on a  query-by-query basis the optimal number of neighbors to be considered  for each prediction. As an efficient way to identify and validate local  models, the recursive least squares algorithm is introduced in the context of local approximation and lazy learning. Furthermore, beside the  winner-takes-all strategy for model selection, a local combination of the  most promising models is explored. The method proposed is tested on  six different datasets and compared with a state-of-the-art approach.
The technique of principal component analysis (PCA) has recently been  expressed as the maximum likelihood solution for a generative latent  variable model. In this paper we use this probabilistic reformulation  as the basis for a Bayesian treatment of PCA. Our key result is that effective dimensionality of the latent space (equivalent to the number of  retained principal components) can be determined automatically as part  of the Bayesian inference procedure. An important application of this  framework is to mixtures of probabilistic PCA models, in which each  component can determine its own effective complexity.
Standard techniques (eg. Yule-Walker) are available for learning  Auto-Regressive process models of simple, directly observable, dynamical processes. When sensor noise means that dynamics are  observed only approximately, learning can still been achieved via  Expectation-Maximisation (EM) together with Kalman Filtering.  However, this does not handle more complex dynamics, involving  multiple classes of motion. For that problem, we show here how  EM can be combined with the CONDENSATION algorithm, which  is based on propagation of random sample-sets. Experiments have  been performed with visually observed juggling, and plausible dynamical models are found to emerge from the learning process.
Inference is a key component in learning probabilistic models from partially observable data. When learning temporal models, each of the  many inference phases requires a traversal over an entire long data sequence; furthermore, the data structures manipulated are exponentially  large, making this process computationally expensive. In [2], we describe  an approximate inference algorithm for monitoring stochastic processes,  and prove bounds on its approximation error. In this paper, we apply this  algorithm as an approximate forward propagation step in an EM algorithm  for learning temporal Bayesian networks. We provide a related approximation for the backward step, and prove error bounds for the combined  algorithm. We show empirically that, for a real-life domain, EM using  our inference algorithm is much faster than EM using exact inference,  with almost no degradation in quality of the learned model. We extend  our analysis to the online learning task, showing a bound on the error  resulting from restricting attention to a small window of observations.  We present an online EM learning algorithm for dynamic systems, and  show that it learns much faster than standard offiine EM.
We present Monte-Carlo generalized EM equations for learning in nonlinear state space models. The difficulties lie in the Monte-Carlo E-step  which consists of sampling from the posterior distribution of the hidden  variables given the observations. The new idea presented in this paper is  to generate samples from a Gaussian approximation to the true posterior  from which it is easy to obtain independent samples. The parameters of  the Gaussian approximation are either derived from the extended Kalman  filter or the Fisher scoring algorithm. In case the posterior density is multimodal we propose to approximate the posterior by a sum of Gaussians  (mixture of modes approach). We show that sampling from the approximate posterior densities obtained by the above algorithms leads to better  models than using point estimates for the hidden states. In our experiment, the Fisher scoring algorithm obtained a better approximation of  the posterior mode than the EKF. For a multimodal distribution, the mixture of modes approach gave superior results.
We propose a novel strategy for training neural networks using sequential sampling-importance resampling algorithms. This global  optimisation strategy allows us to learn the probability distribution of the network weights in a sequential framework. It is well  suited to applications involving on-line, nonlinear, non-Gaussian or  non-stationary signal processing.
We examine the problem of estimating the parameters of a multinomial  distribution over a large number of discrete outcomes, most of which  do not appear in the training data. We analyze this problem from a  Bayesian perspective and develop a hierarchical prior that incorporates  the assumption that the observed outcomes constitute only a small subset  of the possible outcomes. We show how to efficiently perform exact  inference with this form of hierarchical prior and compare it to standard  approaches.
We present a stochastic clustering algorithm based on pairwise similarity of datapoints. Our method extends existing deterministic  methods, including agglomerative algorithms, min-cut graph algorithms, and connected components. Thus it provides a common  framework for all these methods. Our graph-based method differs  from existing stochastic methods which are based on analogy to  physical systems. The stochastic nature of our method makes it  more robust against noise, including accidental edges and small  spurious clusters. We demonstrate the superiority of our algorithm  using an example with 3 spiraling bands and a lot of noise.
The Expectation-Maximization (EM) algorithm is an iterative procedure for maximum likelihood parameter estimation from data  sets with missing or hidden variables [2]. It has been applied to  system identification in linear stochastic state-space models, where  the state variables are hidden from the observer and both the state  and the parameters of the model have to be estimated simultaneously [9]. We present a generalization of the EM algorithm for  parameter estimation in nonlinear dynamical systems. The "expectation" step makes use of Extended Kalman Smoothing to estimate  the state, while the "maximization" step re-estimates the parameters using these uncertain state estimates. In general, the nonlinear  maximization step is dicult because it requires integrating out the  uncertainty in the states. However, if Gaussian radial basis function (RBF) approximators are used to model the nonlinearities,  the integrals become tractable and the maximization step can be  solved via systems of linear equations.
Classification on Pairwise Proximity Data  Thore Graepel t, Ralf Herbrich t,  Peter Bollmann-Sdorra t, Klaus Obermayer*  Technical University of Berlin,   Statistics Research Group, Sekr. FR 6-9,
Adaptive Ridge is a special form of Ridge regression, balancing the  quadratic penalization on each parameter of the model. It was shown to  be equivalent to Lasso (least absolute shrinkage and selection operator),  in the sense that both procedures produce the same estimate. Lasso can  thus be viewed as a particular quadratic penalizer.  From this observation, we derive a fixed point algorithm to compute the  Lasso solution. The analogy provides also a new hyper-parameter for tuning effectively the model complexity. We finally present a series of possible extensions of lasso performing sparse regression in kernel smoothing,  additive modeling and neural net training.
Cluster analysis is a fundamental principle in exploratory data  analysis, providing the user with a description of the group structure of given data. A key problem in this context is the interpretation and visualization of clustering solutions in high-dimensional  or abstract data spaces. In particular, probabilistic descriptions  of the group structure, essential to capture inter-cluster relationships, are hardly assessable by simple inspection of the probabilistic  assignment variables. We present a novel approach to the visualization of group structure. It is based on a statistical model of the  object assignments which have been observed or estimated by a  probabilistic clustering procedure. The objects or data points are  embedded in a low dimensional Euclidean space by approximating  the observed data statistics with a Gaussian mixture model. The  algorithm provides a new approach to the visualization of the inherent structure for a broad variety of data types, e.g. histogram data,  proximity data and co-occurrence data. To demonstrate the power  of the approach, histograms of textured images are visualized as an  example of a large-scale data mining application.
This paper reveals a previously ignored connection between two  important fields: regularization and independent component analysis (ICA). We show that at least one representative of a broad  class of algorithms (regularizers that reduce network complexity)  extracts independent features as a by-product. This algorithm is  Flat Minimum Search (FMS), a recent general method for finding  low-complexity networks with high generalization capability. FMS  works by minimizing both training error and required weight precision. According to our theoretical analysis the hidden layer of  an FMS-trained autoassociator attempts at coding each input by  a sparse code with as few simple features as possible. In experiments the method extracts optimal codes for difficult versions of  the "noisy bars" benchmark problem by separating the underlying  sources, whereas ICA and PCA fail. Real world images are coded  with fewer bits per pixel than by ICA or PCA.
Dyadzc data refers to a domain with two finite sets of objects in  which observations are made for dyads, i.e., pairs with one element  from either set. This type of data arises naturally in many application ranging from computational linguistics and information  retrieval to preference analysis and computer vision. In this paper,  we present a systematic, domain-independent framework of learning from dyadic data by statistical mixture models. Our approach  covers different models with fiat and hierarchical latent class structures. We propose an annealed version of the standard EM algorithm for model fitting which is empirically evaluated on a variety  of data sets from different domains.
Sparse coding is a method for finding a representation of data in  which each of the components of the representation is only rarely  significantly active. Such a representation is closely related to redundancy reduction and independent component analysis, and has  some neurophysiological plausibility. In this paper, we show how  sparse coding can be used for denoising. Using maximum likelihood  estimation of nongaussian variables corrupted by gaussian noise, we  show how to apply a shrinkage nonlinearity on the components of  sparse coding so as to reduce noise. Furthermore, we show how to  choose the optimal sparse coding basis for denoising. Our method  is closely related to the method of wavelet shrinkage, but has the  important benefit over wavelet methods that both the features and  the shrinkage parameters are estimated directly from the data.
The task in text retrieval is to find the subset of a collection of documents relevant  to a user's information request, usually expressed as a set of words. Classically,  documents and queries are represented as vectors of word counts. In its simplest  form, relevance is defined to be the dot product between a document and a query  vector-a measure of the number of common terms. A central difficulty in text  retrieval is that the presence or absence of a word is not sufficient to determine  relevance to a query. Linear dimensionality reduction has been proposed as a technique for extracting underlying structure from the document collection. In some  domains (such as vision) dimensionality reduction reduces computational complexity. In text retrieval it is more often used to improve retrieval performance.  We propose an alternative and novel technique that produces sparse representations constructed from sets of highly-related words. Documents and queries  are represented by their distance to these sets, and relevance is measured by the  number of common clusters. This technique significantly improves retrieval performance, is efficient to compute and shares properties with the optimal linear  projection operator and the independent components of documents.
Generative probability models such as hidden Markov models provide a principled way of treating missing information and dealing  with variable length sequences. On the other hand, discriminative  methods such as support vector machines enable us to construct  flexible decision boundaries and often result in classification performance superior to that of the model based approaches. An ideal  classifier should combine these two complementary approaches. In  this paper, we develop a natural xvay of achieving this combination by deriving kernel functions for use in discriminative methods  such as support vector machines from generative probability models. We provide a theoretical justification for this combination as  well as demonstrate a substantial improvement in the classification  performance in the context of DNA and protein sequence analysis.
We present the CEM (Conditional xpectation Maximization) algorithm as an extension of the EM (xpectation Maximization)  algorithm to conditional density estimation under missing data. A  bounding and maximization process is given to specifically optimize  conditional likelihood instead of the usual joint likelihood. We apply the method to conditioned mixture models and use bounding  techniques to derive the models update rules. Monotonic convergence, computational efficiency and regression results superior to  EM are demonstrated.
Principal curves have been defined as "self consistent" smooth curves  which pass through the "middle" of a d-dimensional probability distribution or data cloud. Recently, we [ 1] have offered a new approach by  defining principal curves as continuous curves of a given length which  minimize the expected squared distance between the curve and points of  the space randomly chosen according to a given distribution. The new  definition made it possible to carry out a theoretical analysis of learning  principal curves from training data. In this paper we propose a practical  construction based on the new definition. Simulation results demonstrate  that the new algorithm compares favorably with previous methods both  in terms of performance and computational complexity.
We present an unsupervised classification algorithm based on an  ICA mixture model. The ICA mixture model assumes that the  observed data can be categorized into several mutually exclusive  data classes in which the components in each class are generated  by a linear mixture of independent sources. The algorithm finds  the independent sources, the mixing matrix for each class and also  computes the class membership probability for each data point.  This approach extends the Gaussian mixture model so that the  classes can have non-Gaussian structure. We demonstrate that  this method can learn efficient codes to represent images of natural  scenes and text. The learned classes of basis functions yield a better  approximation of the underlying distributions of the data, and thus  can provide greater coding efficiency. We believe that this method  is well suited to modeling structure in high-dimensional data and  has many potential applications.
A directed generative model for binary data using a small number  of hidden continuous units is investigated. A clipping nonlinearity distinguishes the model from conventional principal components  analysis. The relationships between the correlations of the underlying continuous Gaussian variables and the binary output variables  are utilized to learn the appropriate weights of the network. The  advantages of this approach are illustrated on a translationally invariant binary distribution and on handwritten digit images.
We introduce two new techniques for density estimation. Our approach poses the problem as a supervised learning task which can  be performed using Neural Networks. We introduce a stochastic method for learning the cumulative distribution and an analogous deterministic technique. We demonstrate convergence of our  methods both theoretically and experimentally, and provide comparisons with the Parzen estimate. Our theoretical results demonstrate better convergence properties than the Parzen estimate.
Two developments of nonlinear latent variable models based on radial  basis functions are discussed: in the first, the use of priors or constraints  on allowable models is considered as a means of preserving data structure  in low-dimensional representations for visualisation purposes. Also, a  resampling approach is introduced which makes more effective use of  the latent samples in evaluating the likelihood.
Kernel PCA as a nonlinear feature extractor has proven powerful as a  preprocessing step for classification algorithms. But it can also be considered as a natural generalization of linear principal component analysis. This gives rise to the question how to use nonlinear features for  data compression, reconstruction, and de-noising, applications common  in linear PCA. This is a nontrivial task, as the results provided by kernel PCA live in some high dimensional feature space and need not have  pre-images in input space. This work presents ideas for finding approximate pre-images, focusing on Gaussian kernels, and shows experimental  results using these pre-images in data reconstruction and de-noising on  toy examples as well as on real world data.
C. lustering is important in many fields ilcluding nanufac[uring,  biology, finance, and astronolny. Mixt. ure models are a popular approach due to their st. atist. ical foundat. ions, and EM is a very popular method for finding mixt. ure models. EM, however, requires  many accesses of the data, and thus has been di.missed as impractical (e.g. [.9]) for data mining of enormous dat, aset.s. We present a  new algorit. hm, based on the nmltiresolut. ion/cd-trees of [5], which  dramatically reduces the cost of EM-based clustering, wit, h savings  rising linearly with the nmnber of datapoints. Although present. ed  here for maxinmm likelihood est. imat.ion of Gaussian mixt, ure models, it, isalso applicable t.o non-(4aussian models (provided class  densit.ies are monotonic in Mahalanobis dist, ance), mixed categorical/nnmeric (:lust. ers. and Bayesian met. hods such as Autoclass [1].
We present a new energy-minimization framework for the graph  isomorphism problem which is based on an equivalent maximum  clique formulation. The approach is centered around a fundamental  result proved by Motzkin and Straus in the mid-1960s, and recently  expanded in various ways, which allows us to formulate the maximum clique problem in terms of a standard quadratic program. To  solve the program we use "replicator" equations, a class of simple  continuousand discrete-time dynamical systems developed in various branches of theoretical biology. We show how, despite their  inability to escape from local solutions, they nevertheless provide  experimental results which are competitive with those obtained using more elaborate mean-field annealing heuristics.
Training a Support Vector Machine (SVM) requires the solution of a very large quadratic programming (QP) problem. This paper proposes an algorithm for training SVMs: Sequential Minimal Optimization, or SMO. SMO breaks the large QP problem into a series of smallest possible QP problems which are analytically solvable. Thus, SMO does not require a numerical QP library. SMO's computation time is dominated by evaluation of the kernel, hence kernel optimizations substantially quicken SMO. For the MNIST database, SMO is 1.7 times as fast as PCG chunking; while for the UCI Adult database and linear SVMs, SMO can be 1500 times faster than the PCG chunking algorithm. 
Boosting methods maximize a hard classification margin and are  known as powerful techniques that do not exhibit overfitting for low  noise cases. Also for noisy data boosting will try to enforce a hard  margin and thereby give too much weight to outliers, which then  leads to the dilemma of non-smooth fits and overfitting. Therefore  we propose three algorithms to allow for soft margin classification  by introducing regularization with slack variables into the boosting  concept: (1) AdaBoostreg and regularized versions of (2) linear  and (3) quadratic programming AdaBoost. Experiments show the  usefulness of the proposed algorithms in comparison to another soft  margin classifier: the support vector machine.
Signal processing and pattern recognition algorithms make extensive use of convolution. In many cases, computational accuracy is  not as important as computational speed. In feature extraction,  for instance, the features of interest in a signal are usually quite  distorted. This form of noise justifies some level of quantization in  order to achieve faster feature extraction. Our approach consists  of approximating regions of the signal with low degree polynomials, and then differentiating the resulting signals in order to obtain  impulse functions (or derivatives of impulse functions). With this  representation, convolution becomes extremely simple and can be  implemented quite effectively. The true convolution can be recovered by integrating the result of the convolution. This method  yields substantial speed up in feature extraction and is applicable  to convolutional neural networks.
We describe a new iterative method for parameter estimation of Gaussian mixtures. The new method is based on a framework developed by  Kivinen and Warmuth for supervised on-line learning. In contrast to gradient descent and EM, which estimate the mixture's covariance matrices,  the proposed method estimates the inverses of the covariance matrices.  Furthermore, the new parameter estimation procedure can be applied in  both on-line and batch settings. We show experimentally that it is typically faster than EM, and usually requires about half as many iterations  as EM.
Semiparametric models are useful tools in the case where domain  knowledge exists about the function to be estimated or emphasis is  put onto understandability of the model. We extend two learning  algorithms Support Vector machines and Linear Programming  machines to this case and give experimental results for SV machines.
We present a probabilistic latent-variable framework for data visualisation, a key feature of which is its applicability to binary and  categorical data types for which few established methods exist. A  variational approximation to the likelihood is exploited to derive a  fast algorithm for determining the model parameters. Illustrations  of application to real and synthetic binary data sets are given.
We present a split and merge EM (SMEM) algorithm to overcome the local  maximum problem in parameter estimation of finite mixture models. In the  case of mixture models, non-global maxima often involve having too many  components of a mixture model in one part of the space and too few in another, widely separated part of the space. To escape from such configurations  we repeatedly perform simultaneous split and merge operations using a new  criterion for efficiently selecting the split and merge candidates. We apply  the proposed algorithm to the training of Gaussian mixtures and mixtures of  factor analyzers using synthetic and real data and show the effectiveness of  using the split and merge operations to improve the likelihood of both the  training data and of held-out test data.
The hierarchical representation of data has various applications in domains such as data mining, machine vision, or information retrieval. In  this paper we inlxoduce an extension of the Expectation-Maximization  (EM) algorithm that learns mixture hierarchies in a computationally efficient manner. Efficiency is achieved by progressing in a bottom-up  fashion, i.e. by clustering the mixture components of a given level in the  hierarchy to obtain those of the level above. This clustering requires only  knowledge of the mixture parameters, there being no need to resort to  intermediate samples. In addition to practical applications, the algorithm  allows a new interpretation of EM that makes clear the relationship with  non-parametric kernel-based estimation methods, provides explicit conIxol over the trade-off between the bias and variance of EM estimates, and  offers new insights about the behavior of deterministic annealing methods  commonly used with EM to escape local minima of the likelihood.
In Gaussian process regression the covariance between the outputs  at input locations x and x' is usually assumed to depend on the  distance (x x') T W (x x'), where W is a positive definite matrix. W is often taken to be diagonal, but if we allow W to be a  general positive definite matrix which can be tuned on the basis of  training data, then an eigen-analysis of W shows that we are effectively creating hidden features, where the dimensionality of the  hidden-feature space is determined by the data. We demonstrate  the superiority of predictions using the general matrix over those  based on a diagonal matrix on two test problems.
We propose a new in-sample cross validation based method (randomized  GACV) for choosing smoothing or bandwidth parameters that govern the  bias-variance or fit-complexity tradeoff in 'soft' classification. Soft classification refers to a learning procedure which estimates the probability  that an example with a given attribute vector is in class 1 vs class 0. The  target for optimizing the the tradeoff is the Kullback-Liebler distance  between the estimated probability distribution and the 'true' probability distribution, representing knowledge of an infinite population. The  method uses a randomized estimate of the trace of a Hessian and mimics  cross validation at the cost of a single relearning with perturbed outcome  data.
A wavelet basis selection procedure is presented for wavelet regression. Both the basis and threshold are selected using crossvalidation. The method includes the capability of incorporating  prior knowledge on the smoothness (or shape of the basis functions)  into the basis selection procedure. The results of the method are  demonstrated using widely published sampled functions. The results of the method are contrasted with other basis function based  methods.
In this paper we introduce a new class of image models, which we  call dynamic trees or DTs. A dynamic tree model specifies a prior  over a large number of trees, each one of which is a tree-structured  belief net (TSBN). Experiments show that DTs are capable of  generating images that are less blocky, and the models have better  translation invariance properties than a fixed, "balanced" TSBN.  We also show that Simulated Annealing is effective at finding trees  which have high posterior probability.
This paper formulates the problem of visual search as Bayesian  inference and defines a Bayesian ensemble of problem instances.  In particular, we address the problem of the detection of visual  contours in noise/clutter by optimizing a global criterion which  combines local intensity and geometry information. We analyze  the convergence rates of A* search algorithms using results from  information theory to bound the probability of rare events within  the Bayesian ensemble. This analysis determines characteristics of  the domain, which we call order parameters, that determine the  convergence rates. In particular, we present a specific admissible  A* algorithm with pruning which converges, with high probability,  with expected time O(N) in the size of the problem. In addition, we briefly summarize extensions of this work which address  fundamental limits of target contour detectability (i.e. algorithm  independent results) and the use of non-admissible heuristics.
In this paper we present a novel approach to multichannel blind  separation/generalized deconvolution, assuming that both mixing  and demixing models are described by stable linear state-space systems. We decompose the blind separation problem into two process: separation and state estimation. Based on the minimization  of Kullback-Leibler Divergence, we develop a novel learning algorithm to train the matrices in the output equation. To estimate the  state of the demixing model, we introduce a new concept, called  hidden innovation, to numerically implement the Kalman filter.  Computer simulations are given to show the validity and high effectiveness of the state-space approach.
We present an analog VLSI cellular architecture implementing a simpli-fled version of the Boundary Contour System (BCS) for real-time image  processing. Inspired by neuromorphic models across several layers of  visual cortex, the design integrates in each pixel the functions of simple cells, complex cells, hyper-complex cells, and bipole cells, in three  orientations interconnected on a hexagonal grid. Analog current-mode  CMOS circuits are used throughout to perform edge detection, local inhibition, directionally selective long-range diffusive kernels, and renormalizing global gain control. Experimental results from a fabricated 12 x 10  pixel prototype in 1.2/zm CMOS technology demonstrate the robustness  of the architecture in selecting image contours in a cluttered and noisy  background.
A modular analogue neuro-chip set with on-chip learning capability is  developed for active noise canceling. The analogue neuro-chip set  incorporates the error backpropagation learning rule for practical  applications, and allows pin-to-pin interconnections for multi-chip  boards. The developed neuro-board demonstrated active noise  canceling without any digital signal processor. Multi-path fading of  acoustic channels, random noise, and nonlinear distortion of the loud  speaker are compensated by the adaptive learning circuits of the  neuro-chips. Experimental results are reported for cancellation of car  noise in real time.
In this paper we describe the architecture, implementation and experimental results for an Intracardiac Electrogram (ICEG) classification and  compression chip. The chip processes and vector-quantises 30 dimensional analogue vectors while consuming a maximum of 2.5 W power  for a heart rate of 60 beats per minute (1 vector per second) from a 3.3 V  supply. This represents a significant advance on previous work which  achieved ultra low power supervised morphology classification since the  template matching scheme used in this chip enables unsupervised blind  classification of abnormal rhythms and the computational support for low  bit rate data compression. The adaptive template matching scheme used  is tolerant to amplitude variations, and interand intra-sample time shifts.
The performance of dedicated VLSI neural processing hardware depends  critically on the design of the implemented algorithms. We have previously proposed an algorithm for acoustic transient classification [1].  Having implemented and demonstrated this algorithm in a mixed-mode  architecture, we now investigate variants on the algorithm, using time  and frequency channel differencing, input and output normalization, and  schemes to binarize and train the template values, with the goal of achieving optimal classification performance for the chosen hardware.
A circuit for fast, compact and low-power focal-plane motion centroid  localization is presented. This chip, which uses mixed signal CMOS  components to implement photodetection, edge detection, ON-set  detection and centroid localization, models the retina and superior  colliculus. The centroid localization circuit uses time-windowed  asynchronously triggered row and column address events and two  linear resistive grids to provide the analog coordinates of the motion  centroid. This VLSI chip is used to realize fast lightweight  autonavigating vehicles. The obstacle avoiding line-following  algorithm is discussed.
We describe the first single microphone sound localization system  and its inspiration from theories of human monaural sound localization. Reflections and diffractions caused by the external ear (pinna)  allow humans to estimate sound source elevations using only one  ear. Our single microphone localization model relies on a specially  shaped reflecting structure that serves the role of the pinna. Specially designed analog VLSI circuitry uses echo-time processing to  localize the sound. A CMOS integrated circuit has been designed,  fabricated, and successfully demonstrated on actual sounds.
A robust, integrative algorithm is presented for computing the position of  the focus of expansion or axis of rotation (the singular point) in optical  flow fields such as those generated by self-motion. Measurements are  shown of a fully parallel CMOS analog VLSI motion sensor array which  computes the direction of local motion (sign of optical flow) at each pixel  and can directly implement this algorithm. The flow field singular point  is computed in real time with a power consumption of less than 2 roW.  Computation of the singular point for more general flow fields requires  measures of field expansion and rotation, which it is shown can also be  computed in real-time hardware, again using only the sign of the optical  flow field. These measures, along with the location of the singular point,  provide robust real-time self-motion information for the visual guidance  of a moving platform such as a robot.
In 1986, Tanner and Mead [1] implemented an interesting constraint satisfaction circuit for global motion sensing in aVLSI. We report here a  new and improved aVLSI implementation that provides smooth optical  flow as well as global motion in a two dimensional visual field. The computation of optical flow is an ill-posed problem, which expresses itself as  the aperture problem. However, the optical flow can be estimated by the  use of regularization methods, in which additional constraints are introduced in terms of a global energy functional that must be minimized. We  show how the algorithmic constraints of Horn and Schunck [2] on computing smooth optical flow can be mapped onto the physical constraints  of an equivalent electronic network.
This paper presents a novel and fast k-NN classifier that is based on a  binary CMM (Correlation Matrix Memory) neural network. A robust  encoding method is developed to meet CMM input requirements. A  hardware implementation of the CMM is described, which gives over 200  times the speed of a current mid-range workstation, and is scaleable to  very large problems. When tested on several benchmarks and compared  with a simple k-NN method, the CMM classifier gave less than 1% lower  /tccuracy and over 4 and 12 times speed-up in software and hardware  respectively.
We introduce a novel framework for simultaneous structure and parameter learning in  hidden-variable conditional probability models, based on an entropic prior and a solution  for its maximum a posteriori (MAP) estimator. The MAP estimate minimizes uncertainty  in all respects: cross-entropy between model and data; entropy of the model; entropy  of the data's descriptive statistics. Iterative estimation extinguishes weakly supported  parameters, compressing and sparsifying the model. Trimming operators accelerate this  process by removing excess parameters and, unlike most pruning schemes, guarantee  an increase in posterior probability. Entropic estimation takes a overcomplete random  model and simplifies it, inducing the structure of relations between hidden and observed  variables. Applied to hidden Markov models (HMMs), it finds a concise finite-state  machine representing the hidden structure of a signal. We entropically model music,  handwriting, and video time-series, and show that the resulting models are highly concise,  structured, predictive, and interpretable: Surviving states tend to be highly correlated  with meaningful partitions of the data, while surviving transitions provide a low-perplexity  model of the signal dynamics.
A common way to represent a time series is to divide it into shortduration blocks, each of which is then represented by a set of basis  functions. A limitation of this approach, however, is that the temporal alignment of the basis functions with the underlying structure  in the time series is arbitrary. We present an algorithm for encoding  a time series that does not require blocking the data. The algorithm  finds an efficient representation by inferring the best temporal positions for functions in a kernel basis. These can have arbitrary  temporal extent and are not constrained to be orthogonal. This  allows the model to capture structure in the signal that may occur  at arbitrary temporal positions and preserves the relative temporal  structure of underlying events. The model is shown to be equivalent  to a very sparse and highly overcomplete basis. Under this model,  the mapping from the data to the representation is nonlinear, but  can be computed efficiently. This form also allows the use of existing methods for adapting the basis itself to data. This approach  is applied to speech data and results in a shift invariant, spike-like  representation that resembles coding in the cochlear nerve.
This paper introduces a method for regularization of HMM systems that  avoids parameter overfitting caused by insufficient training data. Regularization is done by augmenting the EM training method by a penalty  term that favors simple and smooth HMM systems. The penalty term  is constructed as a mixture model of negative exponential distributions  that is assumed to generate the state dependent emission probabilities of  the HMMs. This new method is the successful transfer of a well known  regularization approach in neural networks to the HMM domain and can  be interpreted as a generalization of traditional state-tying for HMM systems. The effect of regularization is demonstrated for continuous speech  recognition tasks by improving overfitted triphone models and by speaker  adaptation with limited training data.
We describe Maximum-Likelihood Continuity Mapping (MALCOM), an  alternative to hidden Markov models (HMMs) for processing sequence  data such as speech. While HMMs have a discrete "hidden" space constrained by a fixed finite-automaton architecture, MALCOM has a continuous hidden space--a continuity map that is constrained only by a  smoothness requirement on paths through the space. MALCOM fits into  the same probabilistic framework for speech recognition as HMMs, but  it represents a more realistic model of the speech production process.  To evaluate the extent to which MALCOM captures speech production  information, we generated continuous speech continuity maps for three  speakers and used the paths through them to predict measured speech  articulator data. The median correlation between the MALCOM paths  obtained from only the speech acoustics and articulator measurements  was 0.77 on an independent test set not used to train MALCOM or the  predictor. This unsupervised model achieved correlations over speakers and articulators only 0.02 to 0.15 lower than those obtained using an  analogous supervised method which used articulatory measurements as  well as acoustics..
We investigate a probabilistic framework for automatic speech  recognition based on the intrinsic geometric properties of curves.  In particular, we analyze the setting in which two variables--one  continuous (a), one discrete (s)--evolve jointly in time. We suppose that the vector a traces out a smooth multidimensional curve  and that the variable s evolves stochastically as a function of the  arc length traversed along this curve. Since arc length does not  depend on the rate at which a curve is traversed, this gives rise  to a family of Markov processes whose predictions, Pr[sla], are  invariant to nonlinear warpings of time. We describe the use of  such models, known as Markov processes on curves (MPCs), for  automatic speech recognition, where a are acoustic feature trajectories and s are phonetic transcriptions. On two tasks--recognizing  New Jersey town names and connected alpha-digits--we find that  MPCs yield lower word error rates than comparably trained hidden  Markov models.
There has been much recent work on measuring image statistics  and on learning probability distributions on images. We observe  that the mapping from images to statistics is many-to-one and  show it can be quantified by a phase space factor. This phase  space approach throws light on the Minimax Entropy technique for  learning Gibbs distributions on images with potentials derived from  image statistics and elucidates the ambiguities that are inherent to  determining the potentials. In addition, it shows that if the phase  factor can be approximated by an analytic distribution then this  approximation yields a swift "Minutemax" algorithm that vastly  reduces the computation time for Minimax entropy learning. An  illustration of this concept, using a Gaussian to approximate the  phase factor, gives a good approximation to the results of Zhu  and Mumford (1997) in just seconds of CPU time. The phase  space approach also gives insight into the multi-scale potentials  found by Zhu and Mumford (1997) and suggests that the forms of  the potentials are influenced greatly by phase space considerations.  Finally, we prove that probability distributions learned in feature  space alone are equivalent to Minimax Entropy learning with a  multinomial approximation of the phase factor.
We present a method for learning complex appearance mappings, such  as occur with images of articulated objects. Traditional interpolation  networks fail on this case since appearance is not necessarily a smooth  function nor a linear manifold for articulated objects. We define an appearance mapping from examples by constructing a set of independently  smooth interpolation networks; these networks can cover overlapping regions of parameter space. A set growing procedure is used to find example clusters which are well-approximated within their convex hull;  interpolation then proceeds only within these sets of examples. With this  method physically valid images are produced even in regions of parameter space where nearby examples have different appearances. We show  results generating both simulated and real arm images.
We seek the scene interpretation that best explains image data.  For example, we may want to infer the projected velocities (scene)  which best explain two consecutive image frames (image). From  synthetic data, we model the relationship between image and scene  patches, and between a scene patch and neighboring scene patches.  Given' a new image, we propagate likelihoods in a Markov network  (ignoring the effect of loops) to infer the underlying scene. This  yields an efficient method to form low-level scene interpretations.  We demonstrate the technique for motion analysis and estimating  high resolution images from low-resolution ones.
Finding articulated objects, like people, in pictures presents a particularly difficult object recognition probleln. We show how to  find people by finding putative body segments, and then constructing assemblies of those segments that are consistent with the constraints on the appearance of a person that result froill kinematic  properties. Since a reasonable model of a person requires at. lea.st  nine segments, it is not possible to present every group to a classifier. Instead, the search can be pruned by using projected versions  of a classifier that accepts groups corresponding to people. We  describe an efficient projection algorithm for one popular classifier, and demonstrate that our approach can be used to deterlnine  whether images of real scenes contain people.
We previously proposed a quantitative model of early visual processing in primates, based on non-linearly interacting visual filters  and statistically efficient decision. We now use this model to interpret the observed modulation of a range of human psychophysical  thresholds with and without focal visual attention. Our model calibrated by an automatic fitting procedure simultaneously reproduces thresholds for four classical pattern discrimination tasks,  performed while attention was engaged by another concurrent task.  Our model then predicts that the seemingly complex improvements  of certain thresholds, which we observed when attention was fully  available for the discrimination tasks, can best be explained by a  strengthening of competition among early visual filters.
Visual search is the task of finding a target in an image against a  background of distractors. Unique features of targets enable them  to pop out against the background, while targets defined by lacks of  features or conjunctions of features are more difficult to spot. It is  known that the ease of target detection can change when the roles  of figure and ground are switched. The mechanisms underlying  the ease of pop out and asymmetry in visual search have been  elusive. This paper shows that a model of segmentation in V1 based  on intracortical interactions can explain many of the qualitative  aspects of visual search.
Face recognition is a K class problem, where K is the number of known  individuals; and support vector machines (SVMs) are a binary classification method. By reformulating the face recognition problem and reinterpreting the output of the SVM classifier, we developed a SVM-based  face recognition algorithm. The face recognition problem is formulated  as a problem in difference space, which models dissimilarities between  two facial images. In difference space we formulate face recognition as a  two class problem. The classes are: dissimilarities between faces of the  same person, and dissimilarities between faces of different people. By  modifying the interpretation of the decision surface generated by SVM,  we generated a similarity metric between faces that is learned from examples of differences between faces. The SVM-based algorithm is compared with a principal component analysis (PCA) based algorithm on a  difficult set of images from the FERET database. Performance was measured for both verification and identification scenarios. The identification  performance for SVM is 77-78% versus 54% for PCA. For verification,  the equal error rate is 7% for SVM and 13% for PCA.
One of the most important problems in visual perception is that of visual invariance: how are objects perceived to be the same despite undergoing transformations such as translations, rotations or scaling? In this paper, we describe a  Bayesian method for learning invariances based on Lie group theory. We show  that previous approaches based on first-order Taylor series expansions of inputs  can be regarded as special cases of the Lie group approach, the latter being capable of handling in principle arbitrarily large transformations. Using a matrixexponential based generative model of images, we derive an unsupervised algorithm for learning Lie group operators from input data containing infinitesimal transformations. The on-line unsupervised learning algorithm maximizes  the posterior probability of generating the training data. We provide experimental results suggesting that the proposed method can learn Lie group operators for  handling reasonably large 1-D translations and 2-D rotations.
We suggest a working definition of texture: Texture is stuff that is  more compactly represented by its statistics than by specifying the  configuration of its parts. This definition suggests that to find  texture we look for outliers to the local statistics, and label as  texture the regions with no outliers. We present a method, based  upon this idea, for labeling points in natural scenes as belonging to  texture regions, while simultaneously allowing us to label lowlevel, bottom-up cues for visual attention. This method is based  upon recent psychophysics results on processing of texture and  popout.
We present a probabilistic method for fusion of images produced  by multiple sensors. The approach is based on an image formation  model in which the sensor images are noisy, locally linear functions  of an underlying, true scene. A Bayesian framework then provides  for maximum likelihood or maximum a posteriori estimates of the  true scene from the sensor images. Maximum likelihood estimates  of the parameters of the image formation model involve (local)  second order image statistics, and thus are related to local principal  component analysis. We demonstrate the efficacy of the method  on images from visible-band and infrared sensors.
A recent neural model of illusory contour formation is based on  a distribution of natural shapes traced by particles moving with  constant speed in directions given by Brownian motions. The input  to that model consists of pairs of position and direction constraints  and the output consists of the distribution of contours joining all  such pairs. In general, these contours will not be closed and their  distribution will not be scale-invariant. In this paper, we show  how to compute a scale-invariant distribution of closed contours  given position constraints alone and use this result to explain a  well known illusory contour effect.
A key question in vision is how to represent our knowledge of previously  encountered objects to classify new ones. The answer depends on how we  determine the similarity of two objects. Similarity tells us how relevant  each previously seen object is in determining the category to which a new  object belongs. Here a dichotomy emerges. Complex notions of similarity appear necessary for cognitive models and applications, while simple  notions of similarity form a tractable basis for current computational approaches to classification. We explore the nature of this dichotomy and  why it calls for new approaches to well-studied problems in learning.  We begin this process by demonstrating new computational methods  for supervised learning that can handle complex notions of similarity.  (1) We discuss how to implement parametric methods that represent a  class by its mean when using non-metric similarity functions; and (2)  We review non-parametric methods that we have developed using nearest neighbor classification in non-metric spaces. Point (2), and some of  the background of our work have been described in more detail in [8].
This paper describes a simple and efficient method to make template-based  object classification invariant to in-plane rotations. The task is divided into two  parts: orientation discrimination and classification. The key idea is to pertbrm  the orientation discrimination before the classification. This can be accomplished by hypothesizing, in turn, that the input image belongs to each class of  interest. The image can then be rotated to maximize its similarity to the training images in each class (these contain the prototype object in an upright orientation). This process yields a set of images, at least one of which will have the  object in an upright position. The resulting images can then be classified by  models which have been trained with only upright examples. This approach  has been successfully applied to two real-world vision-based tasks: rotated  handwritten digit recognition and rotated face detection in cluttered scenes.
This paper presents probabilistic modeling methods to solve the problem of discriminating between five facial orientations with very little labeled data. Three  models are explored. The first model maintains no inter-pixel dependencies, the  second model is capable of modeling a set of arbitrary pair-wise dependencies,  and the last model allows dependencies only between neighboring pixels. We  show that for all three of these models, the accuracy of the learned models can  be greatly improved by augmenting a small number of labeled training images  with a large set of unlabeled images using Expectation-Maximization. This is  important because it is often difficult to obtain image labels, while many unlabeled images are readily available. Through a large set of empirical tests, we  examine the benefits of unlabeled data for each of the models. By using only  two randomly selected labeled examples per class, we can discriminate between  the five facial orientations with an accuracy of 94%; with six labeled examples,  we achieve an accuracy of 98%.
Gaussian Processes provide good prior models for spatial data, but can  be too smooth. In many physical situations there are discontinuities  along bounding surfaces, for example fronts in near-surface wind fields.  We describe a modelling method for such a constrained discontinuity  and demonstrate how to infer the model parameters in wind fields with  MCMC sampling.
In High Energy Physics experiments one has to sort through a high  flux of events, at a rate of tens of MHz, and select the few that are  of interest. One of the key factors in making this decision is the  location of the vertex where the interaction, that led to the event,  took place. Here we present a novel solution to the problem of  finding the location of the vertex, based on two feedforward neural networks with fixed architectures, whose parameters are chosen  so as to obtain a high accuracy. The system is tested on simulated data sets, and is shown to perform better than conventional  algorithms.
The ARTMAP-FD neural network performs both identification  (placing test patterns in classes encountered during training) and  familiarity discrimination (judging whether a test pattern belongs  to any of the classes encountered during training). The performance of ARTMAP-FD is tested on radar pulse data obtained in  the field, and compared to that of the nearest-neighbor-based NEN  algorithm and to a k ) I extension of NEN.
Computer animation through the numerical simulation of physics-based  graphics models offers unsurpassed realism, but it can be computationally demanding. This paper demonstrates the possibility of replacing the  numerical simulation of nontrivial dynamic models with a dramatically  more efficient "NeuroAnimator" that exploits neural networks. NeuroAnimators are automatically trained off-line to emulate physical dynamics through the observation of physics-based models in action. Depending on the model, its neural network emulator can yield physically  realistic animation one or two orders of magnitude faster than conventional numerical simulation. We demonstrate NeuroAnimators for a variety of physics-based models.
Fraud causes substantial losses to telecommunication carriers. Detection systems which automatically detect illegal use of the network can be  used to alleviate the problem. Previous approaches worked on features  derived from the call patterns of individual users. In this paper we present  a call-based detection system based on a hierarchical regime-switching  model. The detection problem is formulated as an inference problem on  the regime probabilities. Inference is implemented by applying the junction tree algorithm to the underlying graphical model. The dynamics are  learned from data using the EM algorithm and subsequent discriminative  training. The methods are assessed using fraud data from a real mobile  communication network.
This paper describes a Bayesian graph matching algorithm for  data-mining from large structural data-bases. The matching algorithm uses edge-consistency and node attribute similarity to determine the a posterJori probability of a query graph for each of the  candidate matches in the data-base. The node feature-vectors are  constructed by computing normalised histograms of pairwise geometric attributes. Attribute similarity is assessed by computing  the Bhattacharyya distance between the histograms. Recognition  is realised by selecting the candidate from the data-base which has  the largest a posterJori probability. We illustrate the recognition  technique on a data-base containing 2500 line patterns extracted  from real-world imagery. Here the recognition technique is shown  to significantly outperform a number of algorithm alternatives.
The execution order of a block of computer instructions can make a  difference in its running time by a factor of two or more. In order to  achieve the best possible speed, compilers use heuristic schedulers appropriate to each specific architecture implementation. However, these  heuristic schedulers are time-consuming and expensive to build. In this  paper, we present results using both rollouts and reinforcement learning  to construct heuristics for scheduling basic blocks. The rollout scheduler  outperformed a commercial scheduler, and the reinforcement learning  scheduler performed almost as well as the commercial scheduler.
In previous work [6, 9, 10], we advanced a new technique for direct  visual matching of images for the purposes of face recognition  and image retrieval, using a probabilistic measure of similarity  based primarily on a Bayesian (MAP) analysis of image differences, leading to a "dual" basis similar to eigenfaces [13]. The  performance advantage of this probabilistic matching technique  over standard Euclidean nearest-neighbor eigenface matching was  recently demonstrated using results from DARPA's 1996 "FERET"  face recognition competition, in which this probabilistic matching  algorithm was found to be the top performer. We have further  developed a simple method of replacing the costly compution of  nonlinear (online) Bayesian similarity measures by the relatively  inexpensive computation of linear (offiine) subspace projections  and simple (online) Euclidean norms, thus resulting in a significant  computational speed-up for implementation with very large image  databases as typically encountered in real-world applications.
We propose to train trading systems by optimizing financial objective functions via reinforcement learning. The performance functions that we consider are profit or wealth, the Sharpe ratio and  our recently proposed differential Sharpe ratio for online learning. In Moody & Wu (1997), we presented empirical results that  demonstrate the advantages of reinforcement learning relative to  supervised learning. Here we extend our previous work to compare Q-Learning to our Recurrent Reinforcement Learning (RRL)  algorithm. We provide new simulation results that demonstrate  the presence of predictability in the monthly S&P 500 Stock Index  for the 25 year period 1970 through 1994, as well as a sensitivity  analysis that provides economic insight into the trader's structure.
We describe a real-time computer vision and machine learning system for modeling and recognizing human actions and interactions.  Two different domains are explored: recognition of two-handed  motions in the martial art 'Tai Chi', and multiple-person interactions in a visual surveillance task. Our system combines top-down  with bottom-up information using a feedback loop, and is formulated with a Bayesian framework. Two different graphical models  (HMMs and Coupled HMMs) are used for modeling both individual  actions and multiple-agent interactions, and CHMMs are shown to  work more efficiently and accurately for a given amount of training. Finally, to overcome the limited amounts of training data,  we demonstrate that 'synthetic agents' (Alife-style agents) can be  used to develop flexible prior models of the person-to-person interactions.
Calcium (Ca'+)is an ubiquitous intracellular messenger which regulates cellular processes, such as secretion, contraction, and cell  proliferation. A number of different cell types respond to hormonal  stimuli with periodic oscillations of the intracellular free calcium  concentration ([Ca'+]i). These Ca '+ signals are often organized  in complex temporal and spatial patterns even under conditions  of sustained stimulation. Here we study the spario-temporal aspects of intracellular calcium ([Ca'+]i) oscillations in clonal 3-cells  (hamster insulin secreting cells, HIT) under pharmacological stimulation (SchSfl et al., 1996). We use a novel fast fixed-point algorithm (Hyv/irinen and Oja, 1997) for Independent Component  Analysis (ICA) to blind source separation of the spario-temporal  dynamics of [Ca'+]i in a HIT-cell. Using this approach we find two  significant independent components out of five differently mixed input signals: one [Ca'+]i signal with a mean oscillatory period of  68s and a high frequency signal with a broadband power spectrum  with considerable spectral density. This results is in good agreement with a study on high-frequency [Ca'+]i oscillations (PaluS  et al., 1998) Further theoretical and experimental studies have to  be performed to resolve the question on the functional impact of  intracellular signaling of these independent [Ca'+]i signals.  932 K. Prank et al.
We have previously presented a coarse-to-fine hierarchical pyramid/neural network (HPNN) architecture which combines multiscale image processing techniques with neural networks. In this  paper we present applications of this general architecture to two  problems in mammographic Computer-Aided Diagnosis (CAD).  The first application is the detection of microcalcifications. The  coarse-to-fine HPNN was designed to learn large-scale context infbrmation fbr detecting small objects like microcalcifications. Receiver operating characteristic (ROC) analysis suggests that the  hierarchical architecture improves detection performance of a well  established CAD system by roughly 50 %. The second application  is to detect mammographic masses directly. Since masses are large,  extended objects, the coarse-to-fine HPNN architecture is not suitable for this problem. Instead we construct a fine-to-coarse HPNN  architecture which is designed to learn small-scale detail structure  associated with the extended objects. Our initial results applying  the fine-to-coarse HPNN to mass detection are encouraging, with  detection perfbrmance improvements of about 36 %. We conclude  that the ability of the HPNN architecture to integrate information  across scales, both coarse-to-fine and fine-to-coarse, makes it well  suited tbr detecting objects which may have contextual clues or  detail structure occurring at scales other than the natural scale of  the object.
This paper applies the Mixture of Gaussians probabilistic model, combined with Expectation Maximization optimization to the task of summarizing three dimensional range data for a mobile robot. This provides  a flexible way of dealing with uncertainties in sensor information, and al-
A COllective INtelligence (COIN) is a set of interacting reinforcement learning (RL) algorithms designed in an automated fashion  so that their collective behavior optimizes a global utility function.  We summarize the theory of COINs, then present experiments using that theory to design COINs to control internet traffic routing.  These experiments indicate that COINs outperform all previously  investigated RL-based, shortest path routing algorithms.
Patti-game (Moore 1994a; Moore 1994b; Moore and Atkeson 1995) is a  reinforcement learning (RL) algorithm that has a lot of promise in overcoming the curse of dimensionality that can plague RL algorithms when  applied to high-dimensional problems. In this paper we introduce modifications to the algorithm that further improve its performance and robustness. In addition, while patti-game solutions can be improved locally  by standard local path-improvement techniques, we introduce an add-on  algorithm in the same spirit as parti-game that instead tries to improve  solutions in a non-local manner.
A simple learning rule is derived, the VAPS algorithm, which can  be instantiated to generate a wide range of new reinforcementlearning algorithms. These algorithms solve a number of open  problems, define several new approaches to reinforcement learning,  and unify different approaches to reinforcement learning under a  single theory. These algorithms all have guaranteed convergence,  and include modifications of several existing algorithms that were  known to fail to converge on simple MDPs. These include Qlearning, SARSA, and advantage learning. In addition to these  value-based algorithms it also generates pure policy-search  reinforcement-learning algorithms, which learn optimal policies  without learning a value function. In addition, it allows policysearch and value-based algorithms to be combined, thus unifying  two very different approaches to reinforcement learning into a  single Value and Policy Search (VAPS) algorithm. And these  algorithms converge for POMDPs without requiring a proper belief  state. Simulations results are given, and several areas for future  research are discussed.
A non-linear modification to PI control is motivated by a model  of a signal transduction pathway active in mammalian blood pressure regulation. This control algorithm, labeled PII (proportional  with intermittent integral), is appropriate for plants requiring exact set-point matching and disturbance attenuation in the presence  of infrequent step changes in load disturbances or set-point. The  proportional aspect of the controller is independently designed to  be a disturbance attenuator and set-point matching is achieved  by intermittently invoking an integral controller. The mechanisms  observed in the Angiotensin II/AT1 signaling pathway are used to  control the switching of the integral control. Improved performance  over PI control is shown on a model of cyclopentenol production.  A sign change in plant gain at the desirable operating point causes  traditional PI control to result in an unstable system. Application of this new approach to this problem results in stable exact  set-point matching for achievable set-points.  Biological processes have evolved sophisticated mechanisms for solving difficult control problems. By analyzing and understanding these natural systems it is possible  that principles can be derived which are applicable to general control systems. This  approach has already been the basis for the field of artificial neural networks, which  are loosely based on a model of the electrical signaling of neurons. A suitable candidate system for analysis is blood pressure control. Tight control of blood pressure  is critical for survival of an animal. Chronically high levels can lead to premature  death. Low blood pressure can lead to oxygen and nutrient deprivation and sudden  load changes must be quickly responded to or loss of consciousness can result. The  barorefiex, reflexive change of heart rate in response to blood pressure challenge,  has been previously studied in order to develop some insights into biological control  systems [1, 2, 3].  *lyndøn'j'brøwn@usa'dupønt'cøm Address correspondence to this author  Gregory. E.Gonye_PHD@usa.dupont.com James'S'Scwhaber@usa'dupønt'cøm  976 L. d. Brown, G. E. Gonye and d. S. Schwaber  Neurons exhibit complex dynamic behavior that is not directly revealed by their  electrical behavior, but is incorporated in biochemical signal transduction pathways. This is an important basis for plasticity of neural networks. The area of the  brain to which the baroreceptor afferents project is the nucleus of tractus solitarus  (NTS). The neurons in the NTS are rich with diverse receptors for signaling pathways. It is logical that this richness and diversity play a crucial role in the signal  processing that occurs here. Hormonal and neurotransmitter signals can activate  signal transduction pathways in the cell, which result in physical modification of  some components of a cell, or altered gene regulation. Fuxe et al [4] have shown the  presence of the angiotensin II/AT1 receptor pathway in NTS neurons, and Herbert  [5] has demonstrated its ability to affect the baroreflex.  To develop understanding of the effects of biochemical pathways, a detailed kinetic  model of the angiotensin/AT1 pathway was developed. Certain features of this  model and the baroreflex have interesting characteristics from a control engineering  perspective. These features have been used to develop a novel control strategy.  The resulting control algorithm utilizes a proportional controller that intermittently  invokes integral action to achieve set-point matching. Thus the controller will be  labeled PII.  The use of integral control is popular as it guarantees cancellation of offsets and  ensures exact set-point matching. However, the use of integral control does have  drawbacks. It introduces significant laõ in the feedback system, which limits the  bandwidth of the system. Increasing the integral gain, in order to improve response  time, can lead to systems with excessive overshoot, excessive settling times, and  less robustness to plant changes or uncertainty. Many processes in the chemical  industry have a steady-state response curve with a maximum and frequently, the  optimal operating condition is at this peak. Unfortunately, any controller with true  integral action will be unstable at this operating point.  In a crude sense, the integrator learns the constant control action required to achieve  set-point matching. If the integral control is viewed as a simple learning device, than  a logical step is to remove it from the feedback loop once the necessary offset has  been learned. If the offset is being successfully compensated for, only noise remains  as a source for learning. It has been well established that learning based on nothing  but noise leads to undesirable results. The maxim, 'garbage in, garbage out' will  apply. Without integral control, the proportional controller can be made more aggressive while maintaining stability margins and/or control actions at similar levels.  This control strategy will be appropriate for plants with infrequent step changes in  set-points or loads. The challenge becomes deciding when, and how to perform this  switching so that the resulting controller provides significant improvements.
This paper examines the application of reinforcement learning to a  telecommunications networking problem. The problem requires that revenue be maximized while simultaneously meeting a quality of service  constraint that forbids entry into certain states. We present a general  solution to this multi-criteria problem that is able to earn significantly  higher revenues than alternatives.
Classifier systems are now viewed disappointing because of their problems such as the rule strength vs rule set performance problem and the  credit assignment problem. In order to solve the problems, we have developed a hybrid classifier system: GLS (Generalization Learning System). In designing GLS, we view CSs as model free learning in POMDPs  and take a hybrid approach to finding the best generalization, given the  total number of rules. GLS uses the policy improvement procedure by  Jaakkola et al. for an locally optimal stochastic policy when a set of  rule conditions is given. GLS uses GA to search for the best set of rule  conditions.
In this paper, we address two issues of long-standing interest in the reinforcement learning literature. First, what kinds of performance guarantees can be made for Q-learning after only a finite number of actions?  Second, what quantitative comparisons can be made between Q-learning  and model-based (indirect) approaches, which use experience to estimate  next-state distributions for off-line value iteration?  We first show that both Q-learning and the indirect approach enjoy  rather rapid convergence to the optimal policy as a function of the number of state transitions observed. In particular, on the order of only  (Nlog(1/e)/e2)(log(N) + loglog(I/e)) transitions are sufficient for both  algorithms to come within e of the optimal policy, in an idealized model  that assumes the observed transitions are "well-mixed" throughout an  N-state MDP. Thus, the two approaches have roughly the same sample  complexity. Perhaps surprisingly, this sample complexity is far less than  what is required for the model-based approach to actually construct a good  approximation to the next-state distribution. The result also shows that  the amount of memory required by the model-based approach is closer to  N than to N 2.  For either approach, to remove the assumption that the observed transitions are well-mixed, we consider a model in which the transitions are  determined by a fixed, arbitrary exploration policy. Bounds on the number  of transitions required in order to achieve a desired level of performance  are then related to the stationary distribution and mixing time of this  policy.
Learning Real-Time A* (LRTA*) is a popular control method that interleaves planning and plan execution and has been shown to solve search problems in known  environments efficiently. In this paper, we apply LRTA* to the problem of getting to  a given goal location in an initially unknown environment. Uninformed LRTA* with  maximal lookahead always moves on a shortest path to the closest unvisited state,  that is, to the closest potential goal state. This was believed to be a good exploration  heuristic, but we show that it does not minimize the worst-case plan-execution time  compared to other uninformed exploration methods. This result is also of interest to  reinforcement-learning researchers since many reinforcement learning methods use  asynchronous dynamic programming, interleave planning and plan execution, and  exhibit optimism in the face of uncertainty, just like LRTA*.
Agents acting in the real world are confronted with the problem of  making good decisions with limited knowledge of the environment.  Partially observable Markov decision processes (POMDPs) model  decision problems in which an agent tries to maximize its reward in the  face of limited sensor feedback. Recent work has shown empirically that  a reinforcement learning (RL) algorithm called Sarsa(.) can efficiently  find optimal memoryless policies, which map current observations to  actions, for POMDP problems (Loch and Singh 1998). The Sarsa().)  algorithm uses a form of short-term memory called an eligibility trace,  which distributes temporally delayed rewards to observation-action  pairs which lead up to the reward. This paper explores the effect of  eligibility traces on the ability of the Sarsa(.) algorithm to find optimal  memoryless policies. A variant of Sarsa(.) called k-step truncated  Sarsa(.) is applied to four test problems taken from the recent work of  Littman, Littman, Cassandra and Kaelbling, Parr and Russell, and  Chrisman. The empirical results show that eligibility traces can be  significantly truncated without affecting the ability of Sarsa(.) to find  optimal memoryless policies for POMDPs.
Reinforcement learning methods can be used to improve the performance  of local search algorithms for combinatorial optimization by learning  an evaluation function that predicts the outcome of search. The evaluation function is therefore able to guide search to low-cost solutions  better than can the original cost function. We describe a reinforcement  learning method for enhancing local search that combines aspects of previous work by Zhang and Dietterich (1995) and Boyan and Moore (1997,  Boyan 1998). In an off-line learning phase, a value function is learned  that is useful for guiding search for multiple problem sizes and instances.  We illustrate our technique by developing several such functions for the  Dial-A-Ride Problem. Our learning-enhanced local search algorithm exhibits an improvement of more then 30% over a standard local search  algorithm.
In order to find the optimal control of continuous state-space and  time reinforcement learning (RL) problems, we approximate the  value function (VF) with a particular class of functions called the  barycentric interpolators. We establish sufficient conditions under  which a RL algorithm converges to the optimal VF, even when we  use approximate models of the state dynamics and the reinforcement functions.
As already known, the expected return of a policy in Markov Decision Problems is not always the most suitable optimality criterion. For  many applications control strategies have to meet various constraints like  avoiding very bad states (risk-avoiding) or generating high profit within  a short time (risk-seeking) although this might probably cause significant  costs. We propose a modified Q-learning algorithm which uses a single  continuous parameter  E [-1, 1] to determine in which sense the resulting policy is optimal. For  = 0, the policy is optimal with respect  to the usual expected return criterion, while   1 generates a solution  which is optimal in worst case. Analogous, the closer  is to 1 the more  risk seeking the policy becomes. In contrast to other related approaches  in the field of MDPs we do not have to transform the cost model or to  increase the state space in order to take risk into account. Our new approach is evaluated by computing optimal investment strategies for an  artificial stock market.
In order to grasp an object, we need to solve the inverse kinematics problem, i.e., the coordinate transformation from the visual  coordinates to the joint angle vector coordinates of the arm. Although several models of coordinate transformation learning have  been proposed, they suffer from a number of drawbacks. In human  motion control, the learning of the hand position error feedback  controller in the inverse kinematics solver is important. This paper  proposes a novel model of the coordinate transformation learning  of the human visual feedback controller that uses the change of  the joint angle vector and the corresponding change of the square  of the hand position error norm. The feasibility of the proposed  model is illustrated using numerical simulations.
We present a method for automatically constructing macro-actions from  scratch from primitive actions during the reinforcement learning process.  The overall idea is to reinforce the tendency to perform action b after  action a if such a pattern of actions has been rewarded. We test the  method on a bicycle task, the car-on-the-hill task, the race-track task and  some grid-world tasks. For the bicycle and race-track tasks the use of  macro-actions approximately halves the learning time, while for one of  the grid-world tasks the learning time is reduced by a factor of 5. The  method did not work for the car-on-the-hill task for reasons we discuss  in the conclusion.
In this article, we propose a new reinforcement learning (RL)  method based on an actor-critic architecture. The actor and  the critic are approximated by Normalized Gaussian Networks  (NGnet), which are networks of local linear regression units. The  NGnet is trained by the on-line EM algorithm proposed in our previous paper. We apply our RL method to the task of swinging-up  and stabilizing a single pendulum and the task of balancing a double pendulum near the upright position. The experimental results  show that our RL method can be applied to optimal control problems having continuous state/action spaces and that the method  achieves good control with a small number of trial-and-errors.
We describe a Reinforcement Learning algorithm for partially observable environments using short-term memory, which we call BLHT. Since  BLHT learns a stochastic model based on Bayesian Learning, the overfitting problem is reasonably solved. Moreover, BLHT has an efficient  implementation. This paper shows that the model learned by BLHT converges to one which provides the most accurate predictions of percepts  and rewards, given short-term memory.
In robotics and other control applications it is commonplace to have a preexisting set of controllers for solving subtasks, perhaps hand-crafted or previously learned or planned, and still face a difficult problem of how to choose and switch among the controllers to solve an overall task as well as possible. In this paper we present a framework based on Markov decision processes and semi-Markov decision processes for phrasing this problem, a basic theorem regarding the improvement in performance that can be obtained by switching flexibly between given controllers, and example applications of the theorem. In particular, we show how an agent can plan with these high-level controllers and then use the results of such planning to find an even better plan, by modifying the existing controllers, with negligible additional cost and no re-planning. In one of our examples, the complexity of the problem is reduced from 24 billion state-action pairs to less than a million state-controller pairs. 
Partially Observable Markov Decision Processes (POMDPs) constitute  an important class of reinforcement learning problems which present  unique theoretical and computational difficulties. In the absence of the  Markov property, popular reinforcement learning algorithms such as  Q-learning may no longer be effective, and memory-based methods  which remove partial observability via state-estimation are notoriously  expensive. An alternative approach is to seek a stochastic memoryless  policy which for each observation of the environment prescribes a  probability distribution over available actions that maximizes the  average reward per timestep. A reinforcement learning algorithm  which learns a locally optimal stochastic memoryless policy has been  proposed by Jaakkola, Singh and Jordan, but not empirically verified.  We present a variation of this algorithm, discuss its implementation,  and demonstrate its viability using four test problems.
Virtual reality (VR) provides immersive and controllable experimental environments. It expands the bounds of possible evoked potential  (EP) experiments by providing complex, dynamic environments in order to study cognition without sacrificing environmental control. VR  also serves as a safe dynamic testbed for brain-computer interface (BCI)  research. However, there has been some concern about detecting EP signals in a complex VR environment. This paper shows that EPs exist at  red, green, and yellow stop lights in a virtual driving environment. Experimental results show the existence of the P3 EP at "go" and "stop"  lights and the contingent negative variation (CNV) EP at "slow down"  lights. In order to test the feasibility of on-line recognition in VR, we  looked at recognizing the P3 EP at red stop lights and the absence of this  signal at yellow slow down lights. Recognition results show that the P3  may successfully be used to control the brakes of a VR car at stop lights.
The psychophysical evidence for "selective attention" originates mainly  from visual search experiments. In this work, we formulate a hierarchical system of interconnected modules consisting in populations of neurons for modeling the underlying mechanisms involved in selective  visual attention. We demonstrate that our neural system for visual  search works across the visual field in parallel but due to the different  intrinsic dynamics can show the two experimentally observed modes of  visual attention, namely: the serial and the parallel search mode. In  other words, neither explicit model of a focus of attention nor saliencies  maps are used. The focus of attention appears as an emergent property  of the dynamic behavior of the system. The neural population dynamics  are handled in the framework of the mean-field approximation. Consequently, the whole process can be expressed as a system of coupled differential equations.
Spatial information comes in two forms: direct spatial information (for  example, retinal position) and indirect temporal contiguity information,  since objects encountered sequentially are in general spatially close. The  acquisition of spatial information by a neural network is investigated  here. Given a spatial layout of several objects, networks are trained on a  prediction task. Networks using temporal sequences with no direct spatial information are found to develop internal representations that show  distances correlated with distances in the external layout. The influence  of spatial information is analyzed by providing direct spatial information  to the system during training that is either consistent with the layout or  inconsistent with it. This approach allows examination of the relative  contributions of spatial and temporal contiguity.
Quantitative data on the speed with which animals acquire behavioral responses during classical conditioning experiments should  provide strong constraints on models of learning. However, most  models have simply ignored these data; the few that have attempted to address them have failed by at least an order of magnitude.  We discuss key data on the speed of acquisition, and show how to  account for them using a statistically sound model of learning, in  which differential reliabilities of stimuli play a crucial role.
In many classification tasks, recognition accuracy is low because input  patrems are corrupted by noise or are spatially or temporally  overlapping. We propose an approach to overcoming these limitations  based on a model of human selective attention. The model, an early  selection filter guided by top-down attentional control, entertains each  candidate output class in sequence and adjusts attentional gain  coefficients in order to produce a strong response for that class. The  chosen class is then the one that obtains the strongest response with the  least modulation of attention. We present simulation results on  classification of corrupted and superimposed handwritten digit pattems,  showing a significant improvement in recognition rates. The algorithm  has also been applied in the domain of speech recognition, with  comparable results.
A figure-ground segregation network is proposed based on a novel  boundary pair representation. Nodes in the network are boundary segments obtained through local grouping. Each node is excitatorily coupled with the neighboring nodes that belong to the  same region, and inhibitorily coupled with the corresponding paired  node. Gestalt grouping rules are incorporated by modulating connections. The status of a node represents its probability being  figural and is updated according to a differential equation. The  system solves the figure-ground segregation problem through temporal evolution. Different perceptual phenomena, such as modal  and amodal completion, virtual contours, grouping and shape decomposition are then explained through local diffusion. The system  eliminates combinatorial optimization and accounts for many psychophysical results with a fixed set of parameters.
We examine a psychophysical law that describes the influence of  stimulus and context on perception. According to this law choice  probability ratios factorize into components independently controlled by stimulus and context. It has been argued that this pattern of results is incompatible with feedback models of perception.  In this paper we examine this claim using neural network models  defined via stochastic differential equations. We show that the law  is related to a condition named channel separability and has little  to do with the existence of feedback connections. In essence, channels are separable if they converge into the response units without  direct lateral connections to other channels and if their sensors are  not directly contaminated by external inputs to the other channels. Implications of the analysis for cognitive and computational  neurosicence are discussed.
We introduce a novel method of constructing language models,  which avoids some of the problems associated with recurrent neural networks. The method of creating a Prediction Fractal Machine  (PFM) [1] is briefly described and some experiments are presented  which demonstrate the suitability of PFMs for language modeling.  PFMs distinguish reliably between minimal pairs, and their behavior is consistent with the hypothesis [4] that wellformedness is  'graded' not absolute. A discussion of their potential to offer fresh  insights into language acquisition and processing follows.
This paper argues that two apparently distinct modes of generalizing concepts abstracting rules and computing similarity to exemplars should  both be seen as special cases of a more general Bayesian learning framework. Bayes explains the specific workings of these two modes which  rules are abstracted, how similarity is measured as well as why generalization should appear ruleor similarity-based in different situations.  This analysis also suggests why the rules/similarity distinction, even if  not computationally fundamental, may still be useful at the algorithmic  level as part of a principled approximation to fully Bayesian learning.
Recent theories suggest that language acquisition is assisted by the  evolution of languages towards forms that are easily learnable. In  this paper, we evolve combinatorial languages which can be learned  by a recurrent neural network quickly and from relatively few examples. Additionally, we evolve languages for generalization in  different "worlds", and for generalization from specific examples.  We find that languages can be evolved to facilitate different forms  of impressive generalization for a minimally biased, general purpose learner. The results provide empirical support for the theory  that the language itself, as well as the language environment of a  learner, plays a substantial role in learning: that there is far more  to language acquisition than the language acquisition device.
In this paper, we question the necessity of levels of expert-guided  abstraction in learning hard, statistically neutral classification  tasks. We focus on two tasks, date calculation and parity-12, that  are claimed to require intermediate levels of abstraction that must  be defined by a human expert. We challenge this claim by demonstrating empirically that a single hidden-layer BP-SOM network can  learn both tasks without guidance. Moreover, we analyze the network's solution for the parity-12 task and show that its solution  makes use of an elegant intermediary checksum computation.
Attractor networks, which map an input space to a discrete output space, are useful for pattern completion. However, designing  a net to have a given set of attractors is notoriously tricky; training  procedures are CPU intensive and often produce spurious attractors and ill-conditioned attractor basins. These difficulties occur  because each connection in the network participates in the encoding of multiple attractors. We describe an alternative formulation  of attractor networks in which the encoding of knowledge is local,  not distributed. Although localist attractor networks have similar  dynamics to their distributed counterparts, they are much easier  to work with and interpret. We propose a statistical formulation of  localist attractor net dynamics, which yields a convergence proof  and a mathematical interpretation of model parameters.  Attractor networks map an input space, usually continuous, to a sparse output  space composed of a discrete set of alternatives. Attractor networks have a long  history in neural network research.  Attractor networks are often used for pattern completion, which involves filling in  missing, noisy; or incorrect features in an input pattern. The initial state of the  attractor net is typically determined by the input pattern. Over time, the state is  drawn to one of a predefined set of statesrathe attractors. Attractor net dynamics can be described by a state trajectory (Figure la). An attractor net is generally  implemented by a set of visible units whose activity represents the instantaneous  state, and optionally, a set of hidden units that assist in the computation. Attractor  dynamics arise from interactions among the units. In most formulations of attractor nets, e,3 the dynamics can be characterized by gradient descent in an energy  landscape, allowing one to partition the output space into attractor basins. Instead  of homogeneous attractor basins, it is often desirable to sculpt basins that depend  on the recent history of the network and the arrangement of attractors in the space.  In psychological models of human cognition, for example, priming is fundamental:  after the model visits an attractor, it should be faster to fall into the same attractor  in the near future, i.e., the attractor basin should be broadened. l, 6  Another property of attractor nets is key to explaining behavioral data in psychological and neurobiological models: the gang effect, in which the strength of an  attractor is influenced by other attractors in its neighborhood. Figure lb illustrates  the gang effect: the proximity of the two rightmost attractors creates a deeper attractor basin, so that if the input starts at the origin it will get pulled to the right.  Generaave Model for ,4ttractor Dynamics 81  Figure 1: (a) A two-dimensional space can be carved into three regions (dashed  lines) by an attractor net. The dynamics of the net cause an input pattern (the X)  to be mapped to one of the attractors (the O's). The solid line shows the temporal trajectory of the network state. (b) the actual energy landscape for a localist  attractor net as a function of ,, when the input is fixed at the origin and there are  three attractors, w = ((-1, 0), (1, 0), (1,-.4)), with a uniform prior. The shapes of  attractor basins are influenced by the proximity of attractors to one another (the  gang effect). The origin of the space (depicted by a point) is equidistant from the  attractor on the left and the attractor on the upper right, yet the origid dearly lies  in the basin of the right attractors.  This effect is an emergent property of the distribution of attractors, and is the basis  for interesting dynamics; it produces the mutuall reinforcing or inhibitory influY  ence of similar items in domains such as semantics, 9 memory, ø' 2 and olfaction. 4  Training an attractor net is notoriously tricky. Training procedures are CPU intensive and often produce spurious attractors and ill-conditioned attractor basins. 5.    Indeed, we are aware of no existing procedure that can robustly translate an arbitrary specification of an attractor landscape into a set of weights. These difficulties  are due to the fact that each connection partialpates in the specification of multiple  attractors; thus, knowledge in the net is distributed over connections.  We describe an alternative attractor network model in which knowledge is localized, hence the name localist attractor network. The model has many virtues, including: a trivial procedure for wiring up the architechn given an attractor landscape;  eliminating spurious attractors; achieving gang effects; providing a dear mathematical interpretation of the model parameters, which clarifies how the parameters  control the qualitative behavior of the model (e.g., the magnitude of gang effects);  and proofs of convergence and stability.  A localist attractor net consists of a set of n state units and m attractor units. Parameters associated with an attractor unit i encode the location of the attractor,  denoted wi, and its "pull"or strength, denoted rri, which influence the shape of  the attractor basin. Its activity at time t, qi (t), reflects the normalized distance from  the attractor center to the current state, y(t), weighted by the attractor strength:  qi(t) = ti#(y(t),wi,(t)) (1)  y'j rd#(y(t), wj, r(t))  g(y,w,r) = exp(-ly-wl2/2r 2) (2)  Thus, the attractors form a layer of normalized radial-basis-function units.  The input to the net, , serves as the initial value of the state, and thereafter the  state is pulled toward attractors in proportion to their activity. A straightforward  82 R. S. Zemel and M. C. Mozer  expression of this behavior is:  y(t + 1) = a(t) + (1 a(t)) y qi(t)wi.  i  (3)  where a(1) = 1 on the first update and a(t) = 0 fort > 1. More generally, however,  one might want to gradually reduce a over time, allowing for a persistent effect of  the external input on the asymptotic state. The variables tr(t) and a(t) are not free  parameters of the model, but can be derived from the formalism we present below.  The localist attractor net is motivated by a generative model of the input based on  the attractor distribution, and the network dynamics corresponds to a search for  a maximum likelihood interpretation of the observation. In the following section,  we derive this result, and then present simulation studies of the architecture.
We investigate the short term dynamics of the recurrent competition and  neural activity in the primary visual cortex in terms of information processing and in the context of orientation selectivity. We propose that after stimulus onset, the strength of the recurrent excitation decreases due  to fast synaptic depression. As a consequence, the network shifts from  an initially highly nonlinear to a more linear operating regime. Sharp  orientation tuning is established in the first highly competitive phase. In  the second and less competitive phase, precise signaling of multiple orientations and long range modulation, e.g., by intraand inter-areal connections becomes possible (surround effects). Thus the network first extracts the salient features from the stimulus, and then starts to process  the details. We show that this signal processing strategy is optimal if  the neurons have limited bandwidth and their objective is to transmit the  maximum amount of information in any time interval beginning with the  stimulus onset.
This paper revisits the classical neuroscience paradigm of Hebbian  learning. We find that a necessary requirement for effective associative memory learning is that the efcacies of the incoming  synapses should be uncorrelated. This requirement is difficult to  achieve in a robust manner by Hebbian synaptic learning, since it  depends on network level information. Effective learning can yet be  obtained by a neuronal process that maintains a zero sum of the incoming synaptic efcacies. This normalization drastically improves  the memory capacity of associative networks, from an essentially  bounded capacity to one that linearly scales with the network's size.  It also enables the effective storage of patterns with heterogeneous  coding levels in a single network. Such neuronal normalization can  be successfully carried out by activity-dependent homeostasis of the  neuron's synaptic efcacies, which was recently observed in cortical  tissue. Thus, our findings strongly suggest that effective associative learning with Hebbian synapses alone is biologically implausible and that Hebbian synapses must be continuously remodeled by  neuronally-driven regulatory processes in the brain.
The complexity of conical circuits may be characterized by the number  of synapses per neuron. We study the dependence of complexity on the  fraction of the conical volume that is made up of"wire" (that is, of axons  and dendrites), and find that complexity is maximized when wire takes  up about 60% of the conical volume. This prediction is in good agreement with experimental observations. A consequence of our arguments  is that any rearrangement of neurons that takes more wire would sacrifice  computational power.
I consider a topographic projection between two neuronal layers with different densities of neurons. Given the number of output neurons connected to each input neuron (divergence or fan-out) and the number of  input neurons synapsing on each output neuron (convergence or fan-in) I  determine the widths of axonal and dendritic arbors which minimize the  total volume of axons and dendrites. My analytical results can be summarized qualitatively in the following rule: neurons of the sparser layer  should have arbors wider than those of the denser layer. This agrees with  the anatomical data from retinal and cerebellar neurons whose morphology and connectivity are known. The rule may be used to infer connectivity of neurons from their morphology.
The encoding accuracy of a population of stochastically spiking neurons  is studied for different distributions of their tuning widths. The situation  of identical radially symmetric receptive fields for all neurons, which  is usually considered in the literature, turns out to be disadvantageous  from an information-theoretic point of view. Both a variability of tuning widths and a fragmentation of the neural population into specialized  subpopulations improve the encoding accuracy.
We first show how to represent sharp posterior probability distributions using real valued coefficients on broadly-tuned basis functions.  Then we show how the precise times of spikes can be used to convey the real-valued coefficients on the basis functions quickly and  accurately. Finally we describe a simple simulation in which spiking neurons learn to model an image sequence by fitting a dynamic  generafive model.
We investigate the behavior of a Hebbian cell assembly of spiking  neurons formed via a temporal synaptic learning curve. This learning function is based on recent experimental findings. It includes  potentiation for short time delays between preand post-synaptic  neuronal spiking, and depression for spiking events occuring in the  reverse order. The coupling between the dynamics of the synaptic  learning and of the neuronal activation leads to interesting results.  We find that the cell assembly can fire asynchronously, but may  also function in complete synchrony, or in distributed synchrony.  The latter implies spontaneous division of the Hebbian cell assembly into groups of cells that fire in a cyclic manner. We invetigate  the behavior of distributed synchrony both by simulations and by  analytic calculations of the resulting synaptic distributions.
When a visual image consists of a figure against a background, V1  cells are physiologically observed to give higher responses to image  regions corresponding to the figure relative to their responses to  the background. The medial axis of the figure also induces relatively higher responses compared to responses to other locations  in the figure (except for the boundary between the figure and the  background). Since the receptive fields of V1 cells are very small compared with the global scale of the figure-ground and medial  axis effects, it has been suggested that these effects may be caused  by feedback from higher visual areas. I show how these effects can  be accounted for by V1 mechanisms when the size of the figure  is small or is of a certain scale. They are a manifestation of the  processes of pre-attentive segmentation which detect and highlight  the boundaries between homogeneous image regions.
Stochastic fluctuations of voltage-gated ion channels generate current  and voltage noise in neuronal membranes. This noise may be a critical determinant of the efficacy of information processing within neural  systems. Using Monte-Carlo simulations, we carry out a systematic investigation of the relationship between channel kinetics and the resulting membrane voltage noise using a stochastic Markov version of the  Mainen-Sejnowski model of dendritic excitability in cortical neurons.  Our simulations show that kinetic parameters which lead to an increase  in membrane excitability (increasing channel densities, decreasing temperature) also lead to an increase in the magnitude of the sub-threshold  voltage noise. Noise also increases as the membrane is depolarized from  rest towards threshold. This suggests that channel fluctuations may interfere with a neuron's ability to function as an integrator of its synaptic  inputs and may limit the reliability and precision of neural information  processing.
Long-term potentiation (LTP) has long been held as a biological  substrate for associative learning. Recently, evidence has emerged  that long-term depression (LTD) results when the presynaptic cell  fires after the postsynaptic cell. The computational utility of LTD  is explored here. Synaptic modification kernels for both LTP and  LTD have been proposed by other laboratories based studies of one  postsynaptic unit. Here, the interaction between time-dependent  LTP and LTD is studied in small networks.
Previous biophysical modeling work showed that nonlinear interactions among nearby synapses located on active dendritic trees can  provide a large boost in the memory capacity of a cell (Mel, 1992a,  1992b). The aim of our present work is to quantify this boost by  estimating the capacity of (1) a neuron model with passive dendritic integration where inputs are combined linearly across the  entire cell followed by a single global threshold, and (2) an active  dendrite model in which a threshold is applied separately to the  output of each branch, and the branch subtotals are combined linearly. We focus here on the limiting case of binary-valued synaptic  weights, and derive expressions which measure model capacity by  estimating the number of distinct input-output functions available  to both neuron types. We show that (1) the application of a fixed  nonlinearity to each dendritic compartment substantially increases  the model's flexibility, (2) for a neuron of realistic size, the capacity  of the nonlinear cell can exceed that of the same-sized linear cell by  more than an order of magnitude, and (3) the largest capacity boost  occurs for cells with a relatively large number of dendritic subunits  of relatively small size. We validated the analysis by empirically  measuring memory capacity with randomized two-class classification problems, where a stochastic delta rule was used to train both  linear and nonlinear models. We found that large capacity boosts  predicted for the nonlinear dendritic model were readily achieved  in practice.  *http://lnc.usc.edu  158 P Poirazi and B. 144. Mel
Neocortical circuits are dominated by massive excitatory feedback: more  than eighty percent of the synapses made by excitatory cortical neurons  are onto other excitatory cortical neurons. Why is there such massive recurrent excitation in the neocortex and what is its role in cortical computation? Recent neurophysiological experiments have shown that the plasticity of recurrent neocortical synapses is governed by a temporally asymmetric Hebbian learning rule. We describe how such a rule may allow  the cortex to modify recurrent synapses for prediction of input sequences.  The goal is to predict the next cortical input from the recent past based on  previous experience of similar input sequences.. We show that a temporal  difference learning rule for prediction used in conjunction with dendritic  back-propagating action potentials reproduces the temporally asymmetric Hebbian plasticity observed physiologically. Biophysical simulations  demonstrate that a network of cortical neurons can learn to predict moving stimuli and develop direction selective responses as a consequence of  learning. The space-time response properties of model neurons are shown  to be similar to those of direction selective cells in alert monkey V1.
A very simple model of two reciprocally connected attractor neural networks is studied analytically in situations similar to those encountered  in delay match-to-sample tasks with intervening stimuli and in tasks of  memory guided attention. The model qualitatively reproduces many of  the experimental data on these types of tasks and provides a framework  for the understanding of the experimental observations in the context of  the attractor neural network scenario.
The reliability and accuracy of spike trains have been shown to  depend on the nature of the stimulus that the neuron encodes.  Adding ion channel stochasticity to neuronal models results in a  macroscopic behavior that replicates the input-dependent reliability and precision of real neurons. We calculate the amount of information that an ion channel based stochastic Hodgkin-Huxley (HH)  neuron model can encode about a wide set of stimuli. We show that  both the information rate and the information per spike of the stochastic model are similar to the values reported experimentally.  Moreover, the amount of information that the neuron encodes is  correlated with the amplitude of fluctuations in the input, and less  so with the average firing rate of the neuron. We also show that for  the HH ion channel density, the information capacity is robust to  changes in the density of ion channels in the membrane, whereas  changing the ratio between the Na + and K + ion channels has a  considerable effect on the information that the neuron can encode.  Finally, we suggest that neurons may maximize their information  capacity by appropriately balancing the density of the different ion  channels that underlie neuronal excitability.
Human reaction times during sensory-motor tasks vary considerably. To begin to understand how this variability arises, we examined neuronal populational response time variability at early versus  late visual processing stages. The conventional view is that precise temporal information is gradually lost as information is passed  through a layered network of mean-rate "units." We tested in humans whether neuronal populations at different processing stages  behave like mean-rate "units". A blind source separation algorithm  was applied to MEG signals from sensory-motor integration tasks.  Response time latency and variability for multiple visual sources  were estimated by detecting single-trial stimulus-locked events for  each source. In two subjects tested on four visual reaction time  tasks, we reliably identified sources belonging to early and late visual processing stages. The standard deviation of response latency  was smaller for early rather than late processing stages. This supports the hypothesis that human populational response time variability increases from early to late visual processing stages.
We study a population decoding paradigm in which the maximum likelihood inference is based on an unfaithful decoding model (UMLI). This  is usually the case for neural population decoding because the encoding  process of the brain is not exactly known, or because a simplified decoding model is preferred for saving computational cost. We consider  an unfaithful decoding model which neglects the pair-wise correlation  between neuronal activities, and prove that UMLI is asymptotically efficient when the neuronal correlation is uniform or of limited-range. The  performance of UMLI is compared with that of the maximum likelihood  inference based on a faithful model and that of the center of mass decoding method. It turns out that UMLI has advantages of decreasing  the computational complexity remarkablely and maintaining a high-level  decoding accuracy at the same time. The effect of correlation on the  decoding accuracy is also discussed.
We analyze the conditions under which synaptic learning rules based  on action potential timing can be approximated by learning rules based  on firing rates. In particular, we consider a form of plasticity in which  synapses depress when a presynaptic spike is followed by a postsynaptic  spike, and potentiate with the opposite temporal ordering. Such differential anti-Hebbianplasticity can be approximated under certain conditions  by a learning rule that depends on the time derivative of the postsynaptic  firing rate. Such a learning rule acts to stabilize persistent neural activity  patterns in recurrent neural networks.
This paper presents a novel practical framework for Bayesian model  averaging and model selection in probabilistic graphical models.  Our approach approximates full posterior distributions over model  parameters and structures, as well as latent variables, in an analytical manner. These posteriors fall out of a free-form optimization  procedure, which naturally incorporates conjugate priors. Unlike  in large sample approximations, the posteriors are generally nonGaussian and no Hessian needs to be computed. Predictive quantities are obtained analytically. The resulting algorithm generalizes  the standard Expectation Maximization algorithm, and its convergence is guaranteed. We demonstrate that this approach can be  applied to a large class of models in several domains, including  mixture models and source separation.
Unsupervised learning algorithms are designed to extract structure from data samples. Reliable and robust inference requires a  guarantee that extracted structures are typical for the data source,  i.e., similar structures have to be inferred from a second sample  set of the same data source. The overfitting phenomenon in maximum entropy based annealing algorithms is exemplarily studied  for a class of histogram clustering models. Bernstein's inequality  for large deviations is used to determine the maximally achievable  approximation quality parameterized by a minimal temperature.  Monte Carlo simulations support the proposed model selection criterion by finite temperature annealing.
We give necessary and sufficient conditions for uniqueness of the  support vector solution for the problems of pattern recognition and  regression estimation, for a general class of cost functions. We show  that if the solution is not unique, all support vectors are necessarily  at bound, and we give some simple examples of non-unique solutions. We note that uniqueness of the primal (dual) solution does  not necessarily imply uniqueness of the dual (primal) solution. We  show how to compute the threshold b when the solution is unique,  but when all support vectors are at bound, in which case the usual  method for determining b does not work.
New functionals for parameter (model) selection of Support Vector Machines are introduced based on the concepts of the span of support vectors and rescaling of the feature space. It is shown that using these functionals, one can both predict the best choice of parameters of the model  and the relative quality of performance for any value of parameter.
We generalize a recent formalism to describe the dynamics of supervised  learning in layered neural networks, in the regime where data recycling  is inevitable, to the case of noisy teachers. Our theory generates reliable  predictions for the evolution in time of trainingand generalization errors, and extends the class of mathematically solvable learning processes  in large neural networks to those situations where overfitting can occur.
We show that the recently proposed variant of the Support Vector  machine (SVM) algorithm, known as y-SVM, can be interpreted  as a maximal separation between subsets of the convex hulls of the  data, which we call soft convex hulls. The soft convex hulls are  controlled by choice of the parameter y. If the intersection of the  convex hulls is empty, the hyperplane is positioned halfway between  them such that the distance between convex hulls, measured along  the normal, is maximized; and if it is not, the hyperplane's normal  is similarly determined by the soft convex hulls, but its position  (perpendicular distance from the origin) is adjusted to minimize  the error sum. The proposed geometric interpretation of y-SVM  also leads to necessary and sufficient conditions for the existence of  a choice of y for which the y-SVM solution is nontrivial.
We present three simple approximations for the calculation of  the posterior mean in Gaussian Process classification. The first  two methods are related to mean field ideas known in Statistical  Physics. The third approach is based on Bayesian online approach  which was motivated by recent results in the Statistical Mechanics  of Neural Networks. We present simulation results showing: 1. that  the mean field Bayesian evidence may be used for hyperparameter  tuning and 2. that the online approach may achieve a low training  error fast.
Recent interpretations of the Adaboost algorithm view it as performing a gradient descent on a potential function. Simply changing the potential function allows one to create new algorithms related to AdaBoost. However, these new algorithms are generally  not known to have the formal boosting property. This paper exmines the question of which potential functions lead to new algorithms that are boosters. The two main results are general sets  of conditions on the potential; one set implies that the resulting  algorithm is a booster, while the other implies that the algorithm  is not. These conditions are applied to previously studied potential  functions, such as those used by LogitBoost and Doom II.
Bayesian predictions are stochastic just like predictions of any other  inference scheme that generalize from a finite sample. While a simple variational argument shows that Bayes averaging is generalization optimal given that the prior matches the teacher parameter  distribution the situation is less clear if the teacher distribution is  unknown. I define a class of averaging procedures, the temperated  likelihoods, including both Bayes averaging with a uniform prior  and maximum likelihood estimation as special cases. I show that  Bayes is generalization optimal in this family for any teacher distribution for two learning problems that are analytically tractable:  learning the mean of a Gaussian and asymptotics of smooth learners.
The performance of regular and irregular Gallager-type errorcorrecting code is investigated via methods of statistical physics.  The transmitted codeword comprises products of the original message bits selected by two randomly-constructed sparse matrices;  the number of non-zero row/column elements in these matrices  constitutes a family of codes. We show that Shannon's channel  capacity may be saturated in equilibrium for many of the regular  codes while slightly lower performance is obtained for others which  may be of higher practical relevance. Decoding aspects are considered by employing the TAP approach which is identical to the  commonly used belief-propagation-based decoding. We show that  irregular codes may saturate Shannon's capacity but with improved  dynamical properties.
Gaussian mixtures (or so-called radial basis function networks) for  density estimation provide a natural counterpart to sigmoidal neural networks for function fitting and approximation. In both cases,  it is possible to give simple expressions for the iterative improvement of performance as components of the network are introduced  one at a time. In particular, for mixture density estimation we show  that a k-component mixture estimated by maximum likelihood (or  by an iterative likelihood improvement that we introduce) achieves  log-likelihood within order 1/k of the log-likelihood achievable by  any convex combination. Consequences for approximation and estimation using Kullback-Leibler risk are also given. A Minimum  Description Length principle selects the optimal number of components k that minimizes the risk bound.
An important issue in neural computing concerns the description of  learning dynamics with macroscopic dynamical variables. Recent progress on on-line learning only addresses the often unrealistic  case of an infinite training set. We introduce a new framework to  model batch learning of restricted sets of examples, widely applicable to any learning cost function, and fully taking into account the  temporal correlations introduced by the recycling of the examples.  For illustration we analyze the effects of weight decay and early  stopping during the learning of teacher-generated examples.
Everybody "knows" that neural networks need more than a single layer  of nonlinear units to compute interesting functions. We show that this is  false if one employs winner-take-all as nonlinear unit:  Any boolean function can be computed by a single k-winner-takeall unit applied to weighted sums of the input variables.  Any continuous function can be approximated arbitrarily well by  a single soft winner-take-all unit applied to weighted sums of the  input variables.  Only positive weights are needed in these (linear) weighted sums.  This may be of interest from the point of view of neurophysiology,  since only 15% of the synapses in the cortex are inhibitory. In addition it is widely believed that there are special microcircuits in the  cortex that compute winner-take-all.  Our results support the view that winner-take-all is a very useful  basic computational unit in Neural VLSI:  [] it is wellknown that winner-take-all of n input variables can  be computed very efficiently with 2n transistors (and a total wire length and area that is linear in n) in analog VLSI  [Lazzaro et al., 1989]  [] we show that winner-take-all is not just useful for special purpose computations, but may serve as the only nonlinear unit for  neural circuits with universal computational power  [] we show that any multi-layer perceptron needs quadratically in  n many gates to compute winner-take-all for n input variables,  hence winner-take-all provides a substantially more powerful  computational unit than a perceptron (at about the same cost  of implementation in analog VLSI).  Complete proofs and further details to these results can be found in  [Maass, 2000].  294 W. Maass
It is known that decision tree learning can be viewed as a form  of boosting. However, existing boosting theorems for decision tree  learning allow only binary-branching trees and the generalization to  multi-branching trees is not immediate. Practical decision tree algorithms, such as CART and C4.5, implement a trade-off between  the number of branches and the improvement in tree quality as  measured by an index function. Here we give a boosting justification for a particular quantitative trade-off curve. Our main theorem  states, in essence, that if we require an improvement proportional  to the log of the number of branches then top-down greedy construction of decision trees remains an effective boosting algorithm.
In order to to compare learning algorithms, experimental results reported  in the machine learning litterature often use statistical tests of significance. Unfortunately, most of these tests do not take into account the  variability due to the choice of training set. We perform a theoretical  investigation of the variance of the cross-validation estimate of the generalization error that takes into account the variability due to the choice  of training sets. This allows us to propose two new ways to estimate  this variance. We show, via simulations, that these new statistics perform  well relative to the statistics considered by Dietterich (Dietterich, 1998).
We study here a simple stochastic single neuron model with delayed  self-feedback capable of generating spike trains. Simulations show  that its spike trains exhibit resonant behavior between "noise" and  "delay". In order to gain insight into this resonance, we simplify  the model and study a stochastic binary element whose transition  probability depends on its state at a fixed interval in the past.  With this simplified model we can analytically compute interspike  interval histograms, and show how the resonance between noise and  delay arises. The resonance is also observed when such elements  are coupled through delayed interaction.
In this article we study the effects of introducing structure in the  input distribution of the data to be learnt by a simple perceptron.  We determine the learning curves within the framework of Statistical Mechanics. Stepwise generalization occurs as a function of  the number of examples when the distribution of patterns is highly  anisotropic. Although extremely simple, the model seems to capture the relevant features of a class of Support Vector Machines  which was recently shown to present this behavior.
We calculate lower bounds on the size of sigmoidal neural networks  that approximate continuous functions. In particular, we show  that for the approximation of polynomials the network size has  to grow as ((log k) U4) where k is the degree of the polynomials.  This bound is valid for any input dimension, i.e. independently of  the number of variables. The result is obtained by introducing a  new method employing upper bounds on the Vapnik-Chervonenkis  dimension for proving lower bounds on the size of networks that  approximate continuous functions.
In this paper we define a probabilistic computational model which  generalizes many noisy neural network models, including the recent  work of Maass and Sontag [5]. We identify weak ergodic.ity as the  mechanism responsible for restriction of the computational power  of probabilistic models to definite languages, independent of the  characteristics of the noise: whether it is discrete or analog, or if  it depends on the input or not, and independent of whether the  variables are discrete or continuous. We give examples of weakly  ergodic models including noisy computational systems with noise  depending on the current state and inputs, aggregate models, and  computational systems which update in continuous time.
Effective methods of capacity control via uniform convergence bounds  for function expansions have been largely limited to Support Vector machines, where good bounds are obtainable by the entropy number approach. We extend these methods to systems with expansions in terms of  arbitrary (parametrized) basis functions and a wide range of regularization methods covering the whole range of general linear additive models.  This is achieved by a data dependent analysis of the eigenvalues of the  corresponding design matrix.
I describe a framework for interpreting Support Vector Machines  (SVMs) as maximum a posterJori (MAP) solutions to inference  problems with Gaussian Process priors. This can provide intuitive  guidelines for choosing a 'good' SVM kernel. It can also assign  (by evidence maximization) optimal values to parameters such as  the noise level C which cannot be determined unambiguously from  properties of the MAP solution alone (such as cross-validation error). I illustrate this using a simple approximate expression for the  SVM evidence. Once C has been determined, error bars on SVM  predictions can also be obtained.
Hierarchical learning machines are non-regular and non-identifiable  statistical models, whose true parameter sets are analytic sets with  singularities. Using algebraic analysis, we rigorously prove that  the stochastic complexity of a non-identifiable learning machine  is asymptotically equal to Allogn(ml 1)loglogn q-const.,  where n is the number of training samples. Moreover we show that  the rational number A1 and the integer ml can be algorithmically  calculated using resolution of singularities in algebraic geometry.  Also we obtain inequalities 0  /1  d/2 and I _< ml _< d, where d  is the number of parameters.
In this paper we discuss the semiparametric statistical model for blind  deconvolution. First we introduce a Lie Group to the manifold of noncausal FIR filters. Then blind deconvolution problem is formulated in  the framework of a semiparametric model, and a family of estimating  functions is derived for blind deconvolution. A natural gradient learning algorithm is developed for training noncausal filters. Stability of the  natural gradient algorithm is also analyzed in this framework.
Recently, sample complexity bounds have been derived for problems involving linear functions such as neural networks and support vector machines. In this paper, we extend some theoretical results in this area by  deriving dimensional independent covering number bounds for regularized linear functions under certain regularization conditions. We show  that such bounds lead to a class of new methods for training linear classifiers with similar theoretical advantages of the support vector machine.  Furthermore, we also present a theoretical analysis for these new methods from the asymptotic statistical point of view. This technique provides  better description for large sample behaviors of these algorithms.
In this paper, we propose a full Bayesian model for neural networks.  This model treats the model dimension (number of neurons), model  parameters, regularisation parameters and noise parameters as random variables that need to be estimated. We then propose a reversible jump Markov chain Monte Carlo (MCMC) method to perform the necessary computations. We find that the results are not  only better than the previously reported ones, but also appear to  be robust with respect to the prior specification. Moreover, we  present a geometric convergence theorem for the algorithm.
We present a new technique for time series analysis based on dynamic probabilistic networks. In this approach, the observed data  are modeled in terms of unobserved, mutually independent factors,  as in the recently introduced technique of Independent Factor Analysis (IFA). However, unlike in IFA, the factors are not i.i.d.; each  factor has its own temporal statistical characteristics. We derive a  family of EM algorithms that learn the structure of the underlying  factors and their relation to the data. These algorithms perform  source separation and noise reduction in an integrated manner, and  demonstrate superior performance compared to IFA.
Layered Sigmoid Belief Networks are directed graphical models  in which the local conditional probabilities are parameterised by  weighted sums of parental states. Learning and inference in such  networks are generally intractable, and approximations need to be  considered. Progress in learning these networks has been made by  using variational procedures. We demonstrate, however, that variational procedures can be inappropriate for the equally important  issue of inference that is, calculating marginMs of the network.  We introduce an alternative procedure, based on assuming that the  weighted input to a node is approximately Gaussian distributed.  Our approach goes beyond previous Gaussian field assumptions in  that we take into account correlations between parents of nodes.  This procedure is specialized for calculating marginals and is significantly faster and simpler than the variational procedure.
Samy Bengio*  IDIAP  CP 592, rue du Simplon 4,  1920 Martigny, Switzerland  bengioOidiap. ch  The curse of dimensionality is severe when modeling high-dimensional  discrete data: the number of possible combinations of the variables explodes exponentially. In this paper we propose a new architecture for  modeling high-dimensional data that requires resources (parameters and  computations) that grow only at most as the square of the number of variables, using a multi-layer neural network to represent the joint distribution of the variables as the product of conditional distributions. The neural network can be interpreted as a graphical model without hidden random variables, but in which the conditional distributions are tied through  the hidden units. The connectivity of the neural network can be pruned by  using dependency tests between the variables. Experiments on modeling  the distribution of several discrete data sets show statistically significant  improvements over other methods such as naive Bayes and comparable  Bayesian networks, and show that significant improvements can be obtained by pruning the network.
We replace the commonly used Gaussian noise model in nonlinear  regression by a more flexible noise model based on the Student-tdistribution. The degrees of freedom of the t-distribution can be chosen  such that as special cases either the Gaussian distribution or the Cauchy  distribution are realized. The latter is commonly used in robust regression. Since the t-distribution can be interpreted as being an infinite mixture of Gaussians, parameters and hyperparameters such as the degrees  of freedom of the t-distribution can be learned from the data based on an  EM-leaming algorithm. We show that modeling using the t-distribution  leads to improved predictors on real world data sets. In particular, if  outliers are present, the t-distribution is superior to the Gaussian noise  model. In effect, by adapting the degrees of freedom, the system can  "learn" to distinguish between outliers and non-outliers. Especially for  online learning tasks, one is interested in avoiding inappropriate weight  changes due to measurement outliers to maintain stable online learning capability. We show experimentally that using the t-distribution as  a noise model leads to stable online learning algorithms and outperforms  state-of-the art online learning methods like the extended Kalman filter  algorithm.
We consider the problem of reconstructing a temporal discrete sequence  of multidimensional real vectors when part of the data is missing, under  the assumption that the sequence was generated by a continuous process. A particular case of this problem is multivariate regression, which  is very difficult when the underlying mapping is one-to-many. We propose an algorithm based on a joint probability model of the variables  of interest, implemented using a nonlinear latent variable model. Each  point in the sequence is potentially reconstructed as any of the modes  of the conditional distribution of the missing variables given the present  variables (computed using an exhaustive mode search in a Gaussian mixture). Mode selection is determined by a dynamic programming search  that minimises a geometric measure of the reconstructed sequence, derived from continuity constraints. We illustrate the algorithm with a toy  example and apply it to a real-world inverse problem, the acoustic-toarticulatory mapping. The results show that the algorithm outperforms  conditional mean imputation and multilayer perceptrons.
We introduce an algorithm for estimating the values of a function  at a set of test points Xt+l, ß ß ß, Xt+ra given a set of training points  (Xl, Yl),-.., (xt, Yt) without estimating (as an intermediate step)  the regression function. We demonstrate that this direct (transducrive) way for estimating values of the regression (or classification  in pattern recognition) can be more accurate than the traditional one based on two steps, first estimating the function and then  calculating the values of this function at the points of interest.
The nonnegative Boltzmann machine (NNBM) is a recurrent neural network model that can describe multimodal nonnegative data. Application  of maximum likelihood estimation to this model gives a learning rule that  is analogous to the binary Boltzmann machine. We examine the utility of  the mean field approximation for the NNBM, and describe how Monte  Carlo sampling techniques can be used to learn its parameters. Reflective slice sampling is particularly well-suited for this distribution, and  can efficiently be implemented to sample the distribution. We illustrate  learning of the NNBM on a translationally invariant distribution, as well  as on a generative model for images of human faces.
For many problems, the correct behavior of a model depends not only on  its input-output mapping but also on properties of its Jacobian matrix, the  matrix of partial derivatives of the model's outputs with respect to its inputs. We introduce the J-prop algorithm, an efficient general method for  computing the exact partial derivatives of a variety of simple functions of  the Jacobian of a model with respect to its free parameters. The algorithm  applies to any parametrized feedforward model, including nonlinear regression, multilayer perceptrons, and radial basis function networks.
Ever since Pearl's probability propagation algorithm in graphs with  cycles was shown to produce excellent results for error-correcting  decoding a few years ago, we have been curious about whether  local probability propagation could be used successfully for machine learning. One of the simplest adaptive models is the factor  analyzer, which is a two-layer network that models bottom layer  sensory inputs as a linear combination of top layer factors plus independent Gaussian sensor noise. We show that local probability  propagation in the factor analyzer network usually takes just a few  iterations to perform accurate inference, even in networks with 320  sensors and 80 factors. We derive an expression for the algorithm's  fixed point and show that this fixed point matches the exact solution in a variety of networks, even when the fixed point is unstable.  We also show that this method can be used successfully to perform  inference for approximate EM and we give results on an online face  recognition task.
We present an algorithm that infers the model structure of a mixture of factor analysers using an efficient and deterministic variational approximation to full Bayesian integration over model parameters. This procedure can automatically determine the optimal number of components and the local dimensionality of each  component (i.e. the number of factors in each factor analyser).  Alternatively it can be used to infer posterior distributions over  number of components and dimensionalities. Since all parameters  are integrated out the method is not prone to overfitting. Using a  stochastic procedure for adding components it is possible to perform the variational optimisation incrementally and to avoid local  maxima. Results show that the method works very well in practice  and correctly infers the number and dimensionality of nontrivial  synthetic examples.  By importance sampling from the variational approximation we  show how to obtain unbiased estimates of the true evidence, the  exact predictive density, and the KL divergence between the variational posterior and the true posterior, not only in this model but  for variational approximations in general.
Transduction is an inference principle that takes a training sample and aims at estimating the values of a function at given points  contained in the so-called working sample as opposed to the whole  of input space for induction. Transduction provides a confidence  measure on single predictions rather than classifiers -a feature  particularly important for risk-sensitive applications. The possibly  infinite number of functions is reduced to a finite number of equivalence classes on the working sample. A rigorous Bayesian analysis  reveals that for standard classification loss we cannot benefit from  considering more than one test point at a time. The probability  of the label of a given test point is determined as the posterior  measure of the corresponding subset of hypothesis space. We consider the PAC setting of binary classification by linear discriminant  functions (perceptrons) in kernel space such that the probability of  labels is determined by the volume ratio in version space. We  suggest to sample this region by an ergodic billiard. Experimental results on real world data indicate that Bayesian Transduction  compares fa-vourably to the well-known Support Vector Machine,  in particular if the posterior probability of labellings is used as a  confidence measure to exclude test points of low confidence.
We describe a class of probabilistic models that we call credibility  networks. Using parse trees as internal representations of images,  credibility networks are able to perform segmentation and recognition simultaneously, removing the need for ad hoc segmentation  heuristics. Promising results in the problem of segmenting handwritten digits were obtained.
We present a general framework for discriminative estimation based  on the maximum entropy principle and its extensions. All calculations involve distributions over structures and/or parameters rather  than specific settings and reduce to relative entropy projections.  This holds even when the data is not separable within the chosen  parametric class, in the context of anomaly detection rather than  classification, or when the labels in the training set are uncertain or  incomplete. Support vector machines are naturally subsumed under this class and we provide several extensions. We are also able  to estimate exactly and efficiently discriminative distributions over  tree structures of class-conditional models within this flamework.  Preliminary experimental results are indicative of the potential in  these techniques.
Invariance to topographic transformations such as translation and  shearing in an image has been successfully incorporated into feedforward mechanisms, e.g., "convolutional neural networks", "tangent propagation". We describe a way to add transformation invariance to a generafive density model by approximating the nonlinear  transformation manifold by a discrete set of transformations. An  EM algorithm for the original model can be extended to the new  model by computing expectations over the set of transformations.  We show how to add a discrete transformation variable to Gaussian  mixture modeling, factor analysis and mixtures of factor analysis.  We give results on filtering microscopy images, face and facial pose  clustering, and handwritten digit modeling and recognition.
A new decomposition algorithm for training regression Support  Vector Machines (SVM) is presented. The algorithm builds on  the basic principles of decomposition proposed by Osuna et. al.,  and addresses the issue of optimal working set selection. The new  criteria for testing optimality of a working set are derived. Based  on these criteria, the principle of "maximal inconsistency" is proposed to form (approximately) optimal working sets. Experimental  results show superior performance of the new algorithm in comparison with traditional training of regression SVM without decomposition. Similar results have been previously reported on decomposition algorithms for pattern recognition SVM. The new algorithm is  also applicable to advanced SVM formulations based on regression,  such as density estimation and integral equation SVM.
A latent variable generative model with finite noise is used to describe several different algorithms for Independent Components Analysis (ICA). In particular, the Fixed Point ICA algorithm is shown to  be equivalent to the Expectation-Maximization algorithm for maximum  likelihood under certain constraints, allowing the conditions for global  convergence to be elucidated. The algorithms can also be explained by  their generic behavior near a singular point where the size of the optimal generarive bases vanishes. An expansion of the likelihood about this  singular point indicates the role of higher order correlations in determining the features discovered by ICA. The application and convergence of  these algorithms are demonstrated on a simple illustrative example.
We describe a new incremental algorithm for training linear threshold functions: the Relaxed Online Maximum Margin Algorithm, or  ROMMA. ROMMA can be viewed as an approximation to the algorithm  that repeatedly chooses the hyperplane that classifies previously seen examples correctly with the maximum margin. It is known that such a  maximum-margin hypothesis can be computed by minimizing the length  of the weight vector subject to a number of linear constraints. ROMMA  works by maintaining a relatively simple relaxation of these constraints  that can be efficiently updated. We prove a mistake bound for ROMMA  that is the same as that proved for the perceptron algorithm. Our analysis  implies that the more computationally intensive maximum-margin algorithm also satisfies this mistake bound; this is the first worst-case performance guarantee for this algorithm. We describe some experiments using ROMMA and a variant that updates its hypothesis more aggressively  as batch algorithms to recognize handwritten digits. The computational  complexity and simplicity of these algorithms is similar to that of perceptron algorithm, but their generalization is much better. We describe a  sense in which the performance of ROMMA converges to that of SVM  in the limit if bias isn't considered.
In recent years, Bayesian networks have become highly successful tool for diagnosis, analysis, and decision making in real-world domains. We present an  efficient algorithm for learning Bayes networks from data. Our approach constructs Bayesian networks by first identifying each node's Markov blankets, then  connecting nodes in a maximally consistent way. In contrast to the majority of  work, which typically uses hill-climbing approaches that may produce dense and  causally incorrect nets, our approach yields much more compact causal networks  by heeding independencies in the data. Compact causal networks facilitate fast inference and are also easier to understand. We prove that under mild assumptions,  our approach requires time polynomial in the size of the data and the number of  nodes. A randomized variant, also presented here, yields comparable results at  much higher speeds.
We provide an abstract characterization of boosting algorithms as  gradient decsent on cost-functionals in an inner-product function  space. We prove convergence of these functional-gradient-descent  algorithms under quite weak conditions. Following previous theoretical results bounding the generalization performance of convex  combinations of classifiers in terms of general cost functions of the  margin, we present a new algorithm (DOOM II) for performing a  gradient descent optimization of such cost functions. Experiments  on several data sets from the UC Irvine repository demonstrate  that DOOM II generally outperforms AdaBoost, especially in high  noise situations, and that the overfitting behaviour of AdaBoost is  predicted by our cost functions.
In this paper, we present Committee, a new multi-class learning algorithm related to the Winnow family of algorithms. Committee is an algorithm for combining the predictions of a set of sub-experts in the online mistake-bounded model of learning. A sub-expert is a special type of  attribute that predicts with a distribution over a finite number of classes.  Committee learns a linear function of sub-experts and uses this function  to make class predictions. We provide bounds for Committee that show  it performs well when the target can be represented by a few relevant  sub-experts. We also show how Committee can be used to solve more  traditional problems composed of attributes. This leads to a natural extension that learns on multi-class problems that contain both traditional  attributes and sub-experts.
Invariant Feature Extraction and  Classification in Kernel Spaces  Sebastian Mika , Gunnar Ritsch  , Jason Weston 2,  Bernhard Sch51kopf 3, Alex Smola 4, and Klaus-Robert Miiller 
We present a class of approximate inference algorithms for graphical  models of the QMR-DT type. We give convergence rates for these algorithms and for the Jaakkola and Jordan (1999) algorithm, and verify  these theoretical predictions empirically. We also present empirical results on the difficult QMR-DT network problem, obtaining performance  of the new algorithms roughly comparable to the Jaakkola and Jordan  algorithm.
Local linear regression performs very well in many low-dimensional  forecasting problems. In high-dimensional spaces, its performance  typically decays due to the well-known "curse-of-dimensionality".  A possible way to approach this problem is by varying the "shape"  of the weighting kernel. In this work we suggest a new, data-driven  method to estimating the optimal kernel shape. Experiments using an artificially generated data set and data from the UC Irvine  repository show the benefits of kernel shaping.
We present a new learning architecture: the Decision Directed Acyclic Graph (DDAG), which is used to combine many two-class classifiers into a multiclass classifier. For an N-class problem, the DDAG contains N(N - 1)/2 classifiers, one for each pair of classes. We present a VC analysis of the case when the node classifiers are hyperplanes; the resulting bound on the test error depends on N and on the margin achieved at the nodes, but not on the dimension of the space. This motivates an algorithm, DAGSVM, which operates in a kernel-induced feature space and uses two-class maximal margin hyperplanes at each decision-node of the DDAG. The DAGSVM is substantially faster to train and evaluate than either the standard algorithm or Max Wins, while maintaining comparable accuracy to both of these algorithms. 
In a Bayesian mixture model it is not necessary a priori to limit the number of components to be finite. In this paper an infinite Gaussian mixture  model is presented which neatly sidesteps the difficult problem of finding the "right" number of mixture components. Inference in the model is  done using an efficient parameter-free Markov Chain that relies entirely  on Gibbs sampling.
AdaBoost and other ensemble methods have successfully been applied to a number of classification tasks, seemingly defying problems of overfitting. AdaBoost performs gradient descent in an error  function with respect to the margin, asymptotically concentrating  on the patterns which are hardest to learn. For very noisy problems, however, this can be disadvantageous. Indeed, theoretical  analysis has shown that the margin distribution, as opposed to just  the minimal margin, plays a crucial role in understanding this phenomenon. Loosely speaking, some outliers should be tolerated if  this has the benefit of substantially increasing the margin on the  remaining points. We propose a new boosting algorithm which allows for the possibility of a pre-specified fraction of points to lie in  the margin area or even on the wrong side of the decision boundary.
Fishers linear discriminant analysis (LDA) is a classical multivariate technique both for dimension reduction and classification. The  data vectors are transformed into a low dimensional subspace such  that the class centroids are spread out as much as possible. In  this subspace LDA works as a simple prototype classifier with linear decision boundaries. However, in many applications the linear  boundaries do not adequately separate the classes. We present a  nonlinear generalization of discriminant analysis that uses the kernel trick of representing dot products by kernel functions. The presented algorithm allows a simple formulation of the EM-algorithm  in terms of kernel functions which leads to a unique concept for unsupervised mixture analysis, supervised discriminant analysis and  semi-supervised discriminant analysis with partially unlabelled observations in feature spaces.
We provide an analysis of the turbo decoding algorithm (TDA)  in a setting involving Gaussian densities. In this context, we are  able to show that the algorithm converges and that somewhat  surprisingly though the density generated by the TDA may differ  significantly from the desired posterior density, the means of these  two densities coincide.
Suppose you are given some dataset drawn from an underlying probability distribution P and you want to estimate a "simple" subset $ of input  space such that the probability that a test point drawn from P lies outside  of $ equals some a priori specified v between 0 and 1.  We propose a method to approach this problem by trying to estimate a  function f which is positive on $ and negative on the complement. The  functional form of f is given by a kernel expansion in terms of a potentially small subset of the training data; it is regularized by controlling the  length of the weight vector in an associated feature space. We provide a  theoretical analysis of the statistical performance of our algorithm.  The algorithm is a natural extension of the support vector algorithm to  the case of unlabelled data.
This paper describes bidirectional recurrent mixture density networks, which can model multi-modal distributions of the type  P(xtly T) and P(xtlxl,x2,...,xt_,y T) without any explicit assumptions about the use of context. These expressions occur frequently in pattern recognition problems with sequential data, for  example in speech recognition. Experiments show that the proposed generative models give a higher likelihood on test data compared to a traditional modeling approach, indicating that they can  summarize the statistical properties of the data better.
I present a simple variation of importance sampling that explicitly searches for important regions in the target distribution. I prove that the technique yields unbiased estimates, and show empirically it can reduce the  variance of standard Monte Carlo estimators. This is achieved by concentrating samples in more significant regions of the sample space.
We present a variational Bayesian method for model selection over  families of kernels classifiers like Support Vector machines or Gaussian processes. The algorithm needs no user interaction and is able  to adapt a large number of kernel parameters to given data without  having to sacrifice training cases for validation. This opens the possibility to use sophisticated families of kernels in situations where  the small "standard kernel" classes are clearly inappropriate. We  relate the method to other work done on Gaussian processes and  clarify the relation between Support Vector machines and certain  Gaussian process models.
We describe an iterative algorithm for building vector machines used in  classification tasks. The algorithm builds on ideas from support vector  machines, boosting, and generalized additive models. The algorithm can  be used with various continuously differential functions that bound the  discrete (0-1) classification loss and is very simple to implement. We test  the proposed algorithm with two different loss functions on synthetic and  natural data. We also describe a norm-penalized version of the algorithm  for the exponential loss function used in AdaBoost. The performance of  the algorithm on natural data is comparable to support vector machines  while typically its running time is shorter than of SVM.
We introduce a novel distributional clustering algorithm that maximizes the mutual information per cluster between data and given categories. This algorithm can be considered as a bottom up  hard version of the recently introduced "Information Bottleneck  Method". The algorithm is compared with the top-down soft version of the information bottleneck method and a relationship between the hard and soft results is established. We demonstrate the  algorithm on the 0 Newsgroups data set. For a subset of two newsgroups we achieve compression by 3 orders of magnitudes loosing  only 10% of the original mutual information.
In this paper, we consider the problem of active learning in trigonometric polynomial networks and give a necessary and sufficient condition of  sample points to provide the optimal generalization capability. By analyzing the condition from the functional analytic point of view, we clarify  the mechanism of achieving the optimal generalization capability. We  also show that a set of training examples satisfying the condition does  not only provide the optimal generalization but also reduces the computational complexity and memory required for the calculation of learning  results. Finally, examples of sample points satisfying the condition are  given and computer simulations are performed to demonstrate the effectiveness of the proposed active learning method.
Gaussian Processes are powerful regression models specified by  parametrized mean and covariance functions. Standard approaches  to estimate these parameters (known by the name Hyperparameters) are Maximum Likelihood (ML) and Maximum APosterior  (MAP) approaches. In this paper, we propose and investigate predictive approaches, namely, maximization of Geisser's Surrogate  Predictive Probability (GPP) and minimization of mean square error with respect to GPP (referred to as Geisser's Predictive mean  square Error (GPE)) to estimate the hyperparameters. We also  derive results for the standard Cross-Validation (CV) error and  make a comparison. These approaches are tested on a number of  problems and experimental results show that these approaches are  strongly competitive to existing approaches.
In this paper we will treat input selection for a radial basis function  (RBF) like classifier within a Bayesian framework. We approximate  the a-posteriori distribution over both model coefficients and input  subsets by samples drawn with Gibbs updates and reversible jump  moves. Using some public datasets, we compare the classification  accuracy of the method with a conventional ARD scheme. These  datasets are also used to infer the a-posteriori probabilities of different input subsets.
We propose a novel approach for building finite memory predictive models similar in spirit to variable memory length Markov models (VLMMs).  The models are constructed by first transforming the n-block structure of  the training sequence into a spatial structure of points in a unit hypercube,  such that the longer is the common suffix shared by any two n-blocks,  the closer lie their point representations. Such a transformation embodies  a Markov assumption n-blocks with long common suffixes are likely  to produce similar continuations. Finding a set of prediction contexts is  formulated as a resource allocation problem solved by vector quantizing  the spatial n-block representation. We compare our model with both the  classical and variable memory length Markov models on three data sets  with different memory and stochastic components. Our models have a  superior performance, yet, their construction is fully automatic, which is  shown to be problematic in the case of VLMMs.
The support vector machine (SVM) is a state-of-the-art technique  for regression and classification, combining excellent generalisation  properties with a sparse kernel representation. However, it does  suffer from a number of disadvantages, notably the absence of probabilistic outputs, the requirement to estimate a trade-off parameter  and the need to utilise 'Mercer' kernel functions. In this paper we  introduce the Relevance Vector Machine (RVM), a Bayesian treatment of a generalised linear model of identical functional form to  the SVM. The RVM suffers from none of the above disadvantages,  and examples demonstrate that for comparable generalisation performance, the RVM requires dramatically fewer kernel functions.
A new method for multivariate density estimation is developed  based on the Support Vector Method (SVM) solution of inverse  ill-posed problems. The solution has the form of a mixture of densities. This method with Gaussian kernels compared favorably to  both Parzen's method and the Gaussian Mixture Model method.  For synthetic data we achieve more accurate estimates for densities  of 2, 6, 12, and 40 dimensions.
Dual estimation refers to the problem of simultaneously estimating the  state of a dynamic system and the model which gives rise to the dynamics. Algorithms include expectation-maximization (EM), dual Kalman  filtering, and joint Kalman methods. These methods have recently been  explored in the context of nonlinear modeling, where a neural network  is used as the functional form of the unknown model. Typically, an extended Kalman filter (EKF) or smoother is used for the part of the algorithm that estimates the clean state given the current estimated model.  An EKF may also be used to estimate the weights of the network. This  paper points out the flaws in using the EKF, and proposes an improvement based on a new approach called the unscented transformation (UT)  [3]. A substantial performance gain is achieved with the same order of  computational complexity as that of the standard EKF. The approach is  illustrated on several dual estimation methods.
Local "belief propagation" rules of the sort proposed by Pearl [15] are  guaranteed to converge to the correct posterior probabilities in singly  connected graphical models. Recently, a number of researchers have empirically demonstrated good performance of "1oopy belief propagation"using these same rules on graphs with loops. Perhaps the most dramatic  instance is the near Shannon-limit performance of "Turbo codes", whose  decoding algorithm is equivalent to loopy belief propagation.  Except for the case of graphs with a single loop, there has been little theoretical understanding of the performance of 1oopy propagation. Here we  analyze belief propagation in networks with arbitrary topologies when  the nodes in the graph describe jointly Gaussian random variables. We  give an analytical formula relating the true posterior probabilities with  those calculated using loopy propagation. We give sufficient conditions  for convergence and show that when belief propagation converges it gives  the correct posterior means for all graph topologies, not just networks  with a single loop.  The related "max-product" belief propagation algorithm finds the maximum posterior probability estimate for singly connected networks. We  show that, even for non-Gaussian probability distributions, the convergence points of the max-product algorithm in loopy networks are maxima over a particular large local neighborhood of the posterior probability. These results help clarify the empirical performance results and  motivate using the powerful belief propagation algorithm in a broader  class of networks.  Problems involving probabilistic belief propagation arise in a wide variety of applications,  including error correcting codes, speech recognition and medical diagnosis. If the graph  is singly connected, there exist local message-passing schemes to calculate the posterior  probability of an unobserved variable given the observed variables. Pearl [15] derived such  a scheme for singly connected Bayesian networks and showed that this "belief propagation"  algorithm is guaranteed to converge to the correct posterior probabilities (or "beliefs").  Several groups have recently reported excellent experimental results by running algorithms  674 Y. Weiss and W T. Freeman  equivalent to Pearl's algorithm on networks with loops [8, 13, 6]. Perhaps the most dramatic  instance of this performance is for "Turbo code" [2] error correcting codes. These codes  have been described as "the most exciting and potentially important development in coding  theory in many years" [12] and have recently been shown [10, 11] to utilize an algorithm  equivalent to belief propagation in a network with loops.  Progress in the analysis of loopy belief propagation has been made for the case of networks  with a single loop [17, 18, 4, 1]. For these networks, it can be shown that (1) unless  all the compatabilities are deterministic, 1oopy belief propagation will converge. (2) The  difference between the loopy beliefs and the true beliefs is related to the convergence rate  of the messages -the faster the convergence the more exact the approximation and (3) If  the hidden nodes are binary, then the loopy beliefs and the true beliefs are both maximized  by the same assignments, although the confidence in that assignment is wrong for the loopy  beliefs.  In this paper we analyze belief propagation in graphs of arbitrary topology, for nodes describing jointly Gaussian random variables. We give an exact formula relating the correct  marginal posterior probabilities with the ones calculated using 1oopy belief propagation.  We show that if belief propagation converges, then it will give the correct posterior means  for all graph topologies, not just networks with a single loop. We show that the covariance estimates will generally be incorrect but present a relationship between the error in  the covariance estimates and the convergence speed. For Gaussian or non-Gaussian variables, we show that the "max-product" algorithm, which calculates the MAP estimate in  singly connected networks, only converges to points that are maxima over a particular large  neighborhood of the posterior probability of loopy networks.
There are many hierarchical clustering algorithms available, but these  lack a firm statistical basis. Here we set up a hierarchical probabilistic  mixture model, where data is generated in a hierarchical tree-structured  manner. Markov chain Monte Carlo (MCMC) methods are demonstrated  which can be used to sample from the posterior distribution over trees  containing variable numbers of hidden units.
Data visualization and feature selection methods are proposed  based on the joint mutual information and ICA. The visualization  methods can find many good 2-D projections for high dimensional  data interpretation, which cannot be easily found by the other existing methods. The new variable selection method is found to be  better in eliminating redundancy in the inputs than other methods  based on simple mutual information. The efficacy of the methods  is illustrated on a radar signal analysis problem to find 2-D viewing  coordinates for data visualization and to select inputs for a neural  network classifier.  Keywords: feature selection, joint mutual information, ICA, visualiz ation, classification.
We propose a new Markov Chain Monte Carlo algorithm which is a generalization of the stochastic dynamics method. The algorithm performs  exploration of the state space using its intrinsic geometric structure, facilitating efficient sampling of complex distributions. Applied to Bayesian  learning in neural networks, our algorithm was found to perform at least  as well as the best state-of-the-art method while consuming considerably  less time.
The Parallel Problems Server: an Interactive Tool  for Large Scale Machine Learning  Charles Lee Isbell, Jr.  isbell @research.att.com  AT&T Labs  180 Park Avenue Room A255  Florham Park, NJ 07932-0971  Parry Husbands  PJRHusbands@lbl.gov  Lawrence Berkeley National Laboratory/NERSC
A system emulating the functionality of a moving eye hence the name  oculo-motor system--has been built and successfully tested. It is made  of an optical device for shifting the field of view of an image sensor by up  to 45 o in any direction, four neuromorphic analog VLSI circuits implementing an oculo-motor control loop, and some off-the-shelf electronics.  The custom integrated circuits communicate with each other primarily by  non-arbitrated address-event buses. The system implements the behaviors of saliency-based saccadic exploration, and smooth pursuit of light  spots. The duration of saccades ranges from 45 ms to 100 ms, which is  comparable to human eye performance. Smooth pursuit operates on light  sources moving at up to 50 ø/s in the visual field.
I describe a silicon network consisting of a group of excitatory neurons and a global inhibitory neuron. The output of the inhibitory  neuron is normalized with respect to the input strengths. This output models the normalization property of the wide-field directionselective cells in the fly visual system. This normalizing property is  also useful in any system where we wish the output signal to code  only the strength of the inputs, and not be dependent on the number of inputs. The circuitry in each neuron is equivalent to that in  Lazzaro's winner-take-all (WTA) circuit with one additional transistor and a voltage reference. Just as in Lazzaro's circuit, the  outputs of the excitatory neurons code the neuron with the largest  input. The difference here is that multiple winners can be chosen.  By varying the voltage reference of the neuron, the network can  transition between a soft-max behavior and a hard WTA behavior. I show results from a fabricated chip of 20 neurons in a 1.2pm  CMOS technology.
We have developed and tested an analog/digital VLSI system that models the coordination of biological segmental oscillators underlying axial  locomotion in animals such as leeches and lampreys. In its current form  the system consists of a chain of twelve pattern generating circuits that  are capable of arbitrary contralateral inhibitory synaptic coupling. Each  pattern generating circuit is implemented with two independent silicon  Morris-Lecar neurons with a total of 32 programmable (floating-gate  based) inhibitory synapses, and an asynchronous address-event interconnection element that provides synaptic connectivity and implements  axonal delay. We describe and analyze the data from a set of experiments exploring the system behavior in terms of synaptic coupling.
We have developed a VLSI silicon neuron and a corresponding mathematical model that is a two state-variable system. We describe the circuit implementation and compare the behaviors observed in the silicon  neuron and the mathematical model. We also perform bifurcation analysis of the mathematical model by varying the externally applied current  and show that the behaviors exhibited by the silicon neuron under corresponding conditions are in good agreement to those predicted by the  bifurcation analysis.
This paper presents an electronic system that extracts the  periodicity of a sound. It uses three analogue VLSI building  blocks: a silicon cochlea, two inner-hair-cell circuits and two  spiking neuron chips. The silicon cochlea consists of a cascade of  filters. Because of the delay between two outputs from the silicon  cochlea, spike trains created at these outputs are synchronous only  for a narrow range of periodicities. In contrast to traditional bandpass filters, where an increase in' selectivity has to be traded off  against a decrease in response time, the proposed system responds  quickly, independent of selectivity.
A neural model is described which uses oscillatory correlation to  segregate speech from interfering sound sources. The core of the model  is a two-layer neural oscillator network. A sound stream is represented  by a synchronized population of oscillators, and different streams are  represented by desynchronized oscillator populations. The model has  been evaluated using a corpus of speech mixed with interfering sounds,  and produces an improvement in signal-to-noise ratio for every mixture.
We present a Hidden Markov Model (HMM) for inferring the hidden  psychological state (or neural activity) during single trial fMRI activation experiments with blocked task paradigms. Inference is based on  Bayesian methodology, using a combination of analytical and a variety  of Markov Chain Monte Carlo (MCMC) sampling techniques. The advantage of this method is that detection of short time learning effects between repeated trials is possible since inference is based only on single  trial experiments.
This paper examines the role of biological constraints in the human auditory localization process. A psychophysical and neural system modeling  approach was undertaken in which performance comparisons between  competing models and a human subject explore the relevant biologically plausible "realism constraints". The directional acoustical cues,  upon which sound localization is based, were derived from the human  subject's head-related transfer functions (HRTFs). Sound stimuli were  generated by convolving bandpass noise with the HRTFs and were presented to both the subject and the model. The input stimuli to the model  was processed using the Auditory Image Model of cochlear processing.  The cochlear data was then analyzed by a time-delay neural network  which integrated temporal and spectral information to determine the spatial location of the sound source. The combined cochlear model and  neural network provided a system model of the sound localization process. Human-like localization performance was qualitatively achieved  for broadband and bandpass stimuli when the model architecture incorporated frequency division (or tonotopicity), and was trained using variable bandwidth and center-frequency sounds.
The differential contribution of the monaural and interaural spectral  cues to human sound localization was examined using a combined psychophysical and analytical approach. The cues to a sound's location  were correlated on an individual basis with the human localization responses to a variety of spectrally manipulated sounds. The spectral cues  derive from the acoustical filtering of an individual's auditory periphery  which is characterized by the measured head-related transfer functions  (HRTFs). Auditory localization performance was determined in virtual  auditory space (VAS). Psychoacoustical experiments were conducted in  which the amplitude spectra of the sound stimulus was varied independently at each ear while preserving the normal timing cues, an impossibility in the free-field environment. Virtual auditory noise stimuli were generated over earphones for a specified target direction such that there was  a "false" flat spectrum at the left eardrum. Using the subject's HRTFs,  the sound spectrum at the right eardrum was then adjusted so that either  the true right monaural spectral cue or the true interaural spectral cue  was preserved. All subjects showed systematic mislocalizations in both  the true right and true interaural spectral conditions which was absent in  their control localization performance. The analysis of the different cues  along with the subjects' localization responses suggests there are significant differences in the use of the monaural and interaural spectral cues  and that the auditory system's reliance on the spectral cues varies with  the sound condition.
N wideband sources recorded using N closely spaced receivers can  feasibly be separated based only on second order statistics when using  a physical model of the mixing process. In this case we show that the  parameter estimation problem can be essentially reduced to considering  directions of arrival and attenuations of each signal. The paper presents  two demixing methods operating in the time and frequency domain and  experimentally shows that it is always possible to demix signals arriving at  different angles. Moreover, one can use spatial cues to solve the channel  selection problem and a post-processing Wiener filter to ameliorate the  artifacts caused by demixing.
By thinking of each state in a hidden Markov model as corresponding to some  spatial region of a fictitious topology space it is possible to naturally define neighbouring states as those which are connected in that space. The transition matrix  can then be constrained to allow transitions only between neighbours; this means  that all valid state sequences correspond to connected paths in the topology space.  I show how such constrained HMMs can learn to discover underlying structure  in complex sequences of high dimensional data, and apply them to the problem  of recovering mouth movements from acoustics in continuous speech.
Stochastic meta-descent (SMD) is a new technique for online adaptation of local learning rates in arbitrary twice-differentiable systems. Like matrix momentum it uses full second-order information  while retaining O(n) computational complexity by exploiting the  efficient computation of Hessian-vector products. Here we apply  SMD to independent component analysis, and employ the resulting algorithm for the blind separation of time-varying mixtures.  By matching individual learning rates to the rate of change in each  source signal's mixture coefficients, our technique is capable of simultaneously tracking sources that move at very different, a priori  unknown speeds.
The speech waveform can be modelled as a piecewise-stationary linear  stochastic state space system, and its parameters can be estimated using  an expectation-maximisation (EM) algorithm. One problem is the initialisation of the EM algorithm. Standard initialisation schemes can lead  to poor formant trajectories. But these trajectories however are important for vowel intelligibility. The aim of this paper is to investigate the  suitability of subspace identification methods to initialise EM.  The paper compares the subspace state space system identification  (4SID) method with the EM algorithm. The 4SID and EM methods are  similar in that they both estimate a state sequence (but using Kalman filters and Kalman smoothers respectively), and then estimate parameters  (but using least-squares and maximum likelihood respectively). The similarity of 4SID and EM motivates the use of 4SID to initialise EM. Also,  4SID is non-iterative and requires no initialisation, whereas EM is iterative and requires initialisation. However 4SID is sub-optimal compared  to EM in a probabilistic sense. During experiments on real speech, 4SID  methods compare favourably with conventional initialisation techniques.  They produce smoother formant trajectories, have greater frequency resolution, and produce higher likelihoods.  Work done while in Cambridge Engineering Dept., UK.  Speech Modelling Using Subspace and EM Techniques 797
In this paper, we use mutual information to characterize the distributions of phonetic and speaker/channel information in a timefrequency space. The mutual information (MI) between the phonetic label and one feature, and the joint mutual information (JMI)  between the phonetic label and two or three features are estimated.  The Miller's bias formulas for entropy and mutual information estimates are extended to include higher order terms. The MI and  the JMI for speaker/channel recognition are also estimated. The  results are complementary to those for phonetic classification. Our  results show how the phonetic information is locally spread and  how the speaker/channel information is globally spread in time  and frequency.
Psychophysical and physiological evidence shows that sound localization of acoustic signals is strongly influenced by their synchrony  with visual signals. This effect, known as ventriloquism, is at work  when sound coming from the side of a TV set feels as if it were  coming from the mouth of the actors. The ventriloquism effect  suggests that there is important information about sound location  encoded in the synchrony between the audio and video signals. In  spite of this evidence, audiovisual synchrony is rarely used as a  source of information in computer vision tasks. In this paper we  explore the use of audio visual synchrony to locate sound sources.  We developed a system that searches for regions of the visual landscape that correlate highly with the acoustic signals and tags them  as likely to contain an acoustic source. We discuss our experience  implementing the system, present results on a speaker localization  task and discuss potential applications of the approach.
The three-dimensional motion of humans is underdetermined when the  observation is limited to a single camera, due to the inherent 3D ambiguity of 2D video. We present a system that reconstructs the 3D motion  of human subjects from single-camera video, relying on prior knowledge  about human motion, learned from training data, to resolve those ambiguities. After initialization in 2D, the tracking and 3D reconstruction  is automatic; we show results for several video sequences. The results  show the power of treating 3D body tracking as an inference problem.
Independent component analysis of natural images leads to emergence of simple cell properties, i.e. linear filters that resemble  wavelets or Gabor functions. In this paper, we extend ICA to  explain further properties of V1 cells. First, we decompose natural  images into independent subspaces instead of scalar components.  This model leads to emergence of phase and shift invariant features, similar to those in V1 complex cells. Second, we define a  topography between the linear components obtained by ICA. The  topographic distance between two components is defined by their  higher-order correlations, so that two components are close to each  other in the topography if they are strongly dependent on each  other. This leads to simultaneous emergence of both topography  and invariances similar to complex cell properties.
In this paper, we propose that information maximization can provide a unified framework for understanding saccadic eye movements. In this framework, the mutual information among the cortical representations of the retinal image, the priors constructed  from our long term visual experience, and a dynamic short-term  internal representation constructed from recent saccades provides  a map for guiding eye navigation. By directing the eyes to locations of maximum complexity in neuronal ensemble responses at  each step, the automatic saccadic eye movement system greedily  collects information about the external world, while modifying the  neural representations in the process. This framework attempts  to connect several psychological phenomena, such as pop-out and  inhibition of return, to long term visual experience and short term  working memory. It also provides an interesting perspective on  contextual computation and formation of neural representation in  the visual system.
We describe a method for learning an overcomplete set of basis  functions for the purpose of modeling sparse structure in images.  The sparsity of the basis function coefficients is modeled with a  mixture-of-Gaussians distribution. One Gaussian captures nonactive coefficients with a small-variance distribution centered at  zero, while one or more other Gaussians capture active coefficients  with a large-variance distribution. We show that when the prior is  in such a form, there exist efficient methods for learning the basis  functions as well as the parameters of the prior. The performance  of the algorithm is demonstrated on a number of test cases and  also on natural images. The basis functions learned on natural  images are similar to those obtained with other methods, but the  sparse form of the coefficient distribution is much better described.  Also, since the parameters of the prior are adapted to the data, no  assumption about sparse structure in the images need be made a  priori, rather it is learned from the data.
We formulate a model for probability distributions on image spaces. We  show that any distribution of images can be factored exactly into conditional distributions of feature vectors at one resolution (pyramid level)  conditioned on the image information at lower resolutions. We would  like to factor this over positions in the pyramid levels to make it tractable,  but such factoring may miss long-range dependencies. To fix this, we introduce hidden class labels at each pixel in the pyramid. The result is  a hierarchical mixture of conditional probabilities, similar to a hidden  Markov model on a tree. The model parameters can be found with maximum likelihood estimation using the EM algorithm. We have obtained  encouraging preliminary results on the problems of detecting various objects in SAR images and target recognition in optical aerial images.
The statistics of photographic images, when represented using  multiscale (wavelet) bases, exhibit two striking types of nonGaussian behavior. First, the marginal densities of the coefficients  have extended heavy tails. Second, the joint densities exhibit variance dependencies not captured by second-order models. We examine properties of the class of Gaussian scale mixtures, and show  that these densities can accurately characterize both the marginal  and joint distributions of natural image wavelet coefficients. This  class of model suggests a Markov structure, in which wavelet coefficients are linked by hidden scaling variables corresponding to local  image structure. We derive an estimator for these hidden variables,  and show that a nonlinear "normalization" procedure can be used  to Gaussianize the coefficients.  Recent years have witnessed a surge of interest in modeling the statistics of natural  images. Such models are important for applications in image processing and computer vision, where many techniques rely (either implicitly or explicitly) on a prior  density. A number of empirical studies have demonstrated that the power spectra  of natural images follow a 1If v law in radial frequency, where the exponent  is  typically close to two [e.g., 1]. Such second-order characterization is inadequate,  however, because images usually exhibit highly non-Gaussian behavior. For instance, the marginals of wavelet coefficients typically have much heavier tails than  a Gaussian [2]. Furthermore, despite being approximately decorrelated (as suggested by theoretical analysis of 1If processes [3]), orthonormal wavelet coefficients  exhibit striking forms of statistical dependency [4, 5]. In particular, the standard  deviation of a wavelet coefficient typically scales with the absolute values of its  neighbors [5].  A number of researchers have modeled the marginal distributions of wavelet coefficients with generalized Laplacians, p¾(y) c exp(-ly/AI p) [e.g. 6, 7, 8]. Special  cases include the Gaussian (p 2) and the Laplacian (p 1), but appropriate exResearch supported by NSERC 1969 fellowship 160833 to MJW, and NSF CAREER grant  MIP-9796040 to EPS.  856 M. J. Wainwright and E. P Sirnoncelli  Mixing density  Positive, V/ stable  No explicit form  GSM density GSM char. function  symmetrized Gamma  Student:  , 1  [1/(), + >  a-stable  generalized Laplacian:  exp(-[y/XlP), pe (0,2]  t2  (l+2-X , >0  No explicit form  exp (-Itla), a e (0,2]  No explicit form  Table 1. Example densities from the class of Gaussian scale mixtures. Z(7 ) denotes a positive gamma variable, with density p(z)= [1/F(y)]z *- exp(-z).  The characteristic function of a random variable x is defined as  opt(t) -- f_øøoo p(x) exp (jxt) dx.  ponents for natural images are typically less than one. Simoncelli [5, 9] has modeled  the variance dependencies of pairs of wavelet coefficients. Romberg et al. [10] have  modeled wavelet densities using two-component mixtures of Gaussians. Huang and  Mumford [11] have modeled marginal densities and cross-sections of joint densities  with multi-dimensional generalized Laplacians.  In the following sections, we explore the semi-parametric class of Gaussian scale  mixtures. We show that members of this class satisfy the dual requirements of  being heavy-tailed, and exhibiting multiplicative scaling between coefficients. We  also show that a particular member of this class, in which the multiplier variables  are distributed according to a gamma density, captures the range of joint statistical  behaviors seen in wavelet coefficients of natural images. We derive an estimator for  the multipliers, and show that a nonlinear "normalization" procedure can be used  to Gaussianize the wavelet coefficients. Lastly, we form random cascades by linking  the multipliers on a multiresolution tree.
A novel learning approach for human face detection using a network  of linear units is presented. The SNoW learning architecture is a  sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning  in the presence of a very large number of features. A wide range of  face images in different poses, with different expressions and under  different lighting conditions are used as a training set to capture  the variations of human faces. Experimental results on commonly  used benchmark data sets of a wide range of face images show that  the SNoW-based approach outperforms methods that use neural  networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based  method are significantly more efficient than with other methods.
We develop a hierarchical generative model to study cue combination. The model maps a global shape parameter to local cuespecific parameters, which in turn generate an intensity image.  Inferring shape from images is achieved by inverting this model.  Inference produces a probability distribution at each level; using  distributions rather than a single value of underlying variables at  each stage preserves information about the validity of each local  cue for the given image. This allows the model, unlike standard  combination models, to adaptively weight each cue based on general cue reliability and specific image context. We describe the  results of a cue combination psychophysics experiment we conducted that allows a direct comparison with the model. The model  provides a good fit to our data and a natural account for some interesting aspects of cue combination.  Understanding cue combination is a fundamental step in developing computational models of visual perception, because many aspects of perception naturally  involve multiple cues, such as binocular stereo, motion, texture, and shading. It is  often formulated as a problem of inferring or estimating some relevant parameter,  e.g., depth, shape, position, by combining estimates from individual cues.  An important finding of psychophysical studies of cue combination is that cues  vary in the degree to which they are used in different visual environments. Weights  assigned to estimates derived from a particular cue seem to reflect its estimated  reliability in the current scene and viewing conditions. For example, motion  and stereo are weighted approximately equally at near distances, but motion is  weighted more at far distances, presumably due to distance limits on binocular  disparity. s Experiments have also found these weightings sensitive to image manipulations; if a cue is weakened, such as by adding noise, then the uncontaminated cue is utilized more in making depth judgments. 9 A recent study 2 has shown  that observers can adjust the weighting they assign to a cue based on its relative  utility for a particular task. From these and other experiments, we can identify two  types of information that determine relative cue weightings: (1) cue reliability: its  relative utility in the context of the task and general viewing conditions; and (2)  region informativeness: cue information available locally in a given image.  A central question in computational models of cue combination then concerns how  these forms of uncertainty can be combined. We propose a hierarchical generative  870 Z. Yang and R. S. Zemel  model. Generative models have a rich history in cue combination, as they underlie  models of Bayesian perception that have been developed in this area?, 5The novelty in the generative model proposed here lies in its hierarchical nature and use  of distributions throughout, which allows for both context-dependent and imagespecific uncertainty to be combined in a principled manner.  Our aims in this paper are dual: to develop a combination model that incorporates  cue reliability and region informativeness (estimated across and within images),  and to use this model to account for data and provide predictions for psychophysical experiments. Another motivation for the approach here stems from our recent  probabilistic framework,  which posits that every step of processing entails the  representation of an entire probability distribution, rather than just a single value  of the relevant underlying variable(s). Here we use separate local probability distributions for each cue estimated directly from an image. Combination then entails  transforming representations and integrating distributions across both space and  cues, taking acrossand within-image uncertainty into account.
A fundamental problem with the modeling of chaotic time series data is that  minimizing short-term prediction errors does not guarantee a match  between the reconstructed attractors of model and experiments. We  introduce a modeling paradigm that simultaneously learns to short-term  predict and to locate the outlines of the attractor by a new way of nonlinear  principal component analysis. Closed-loop predictions are constrained to  stay within these outlines, to prevent divergence from the attractor. Learning  is exceptionally fast: parameter estimation for the 1000 sample laser data  from the 1991 Santa Fe time series competition took less than a minute on  a 166 MHz Pentium PC.
The Facial Action Coding System (FACS) (9) is an objective  method for quantifying facial movement in terms of component  actions. This system is widely used in behavioral investigations  of emotion, cognitive processes, and social interaction. The coding is presently performed by highly trained human experts. This  paper explores and compares techniques for automatically recognizing facial actions in sequences of images. These methods include  unsupervised learning techniques for finding basis images such as  principal component analysis, independent component analysis and  local feature analysis, and supervised learning techniques such as  Fisher's linear discriminants. These data-driven bases are compared to Gabor wavelets, in which the basis images are predefined.  Best performances were obtained using the Gabor wavelet representation and the independent component representation, both of  which achieved 96% accuracy for classifying 12 facial actions. The  ICA representation employs 2 orders of magnitude fewer basis images than the Gabor representation and takes 90% less CPU time  to compute for new images. The results provide converging support  for using local basis images, high spatial frequencies, and statistical  independence for classifying facial actions.
This paper examines the application of reinforcement learning to a wireless communication problem. The problem requires that channel utility be maximized while simultaneously minimizing battery usage. We  present a solution to this multi-criteria problem that is able to significantly reduce power consumption. The solution uses a variable discount  factor to capture the effects of battery usage.
We discuss an information theoretic approach for categorizing and modeling dynamic processes. The approach can learn a compact and informative statistic which summarizes past states to predict future observations.  Furthermore, the uncertainty of the prediction is characterized nonparametrically by a joint density over the learned statistic and present observation. We discuss the application of the technique to both noise driven  dynamical systems and random processes sampled from a density which  is conditioned on the past. In the first case we show results in which both  the dynamics of random walk and the statistics of the driving noise are  captured. In the second case we present results in which a summarizing  statistic is learned on noisy random telegraph waves with differing dependencies on past states. In both cases the algorithm yields a principled  approach for discriminating processes with differing dynamics and/or dependencies. The method is grounded in ideas from information theory  and nonparametric statistics.
Three contributions to developing an algorithm for assisting engineers in designing analog circuits are provided in this paper. First,  a method for representing highly nonlinear and non-continuous  analog circuits using Kirchoff current law potential functions within  the context of a Markov field is described. Second, a relatively efficient algorithm for optimizing the Markov field objective function  is briefly described and the convergence proof is briefly sketched.  And third, empirical results illustrating the strengths and limitations of the approach are provided within the context of a JFET  transistor design problem. The proposed algorithm generated a set  of circuit components for the JFET circuit model that accurately  generated the desired characteristic curves.
The project pursued in this paper is to develop from first  information-geometric principles a general method for learning  the similarity between text documents. Each individual document is modeled as a memoryless information source. Based on  a latent class decomposition of the term-document matrix, a lowdimensional (curved) multinomial subfamily is learned. From this  model a canonical similarity function known as the Fisher kernel  is derived. Our approach can be applied for unsupervised and  supervised learning problems alike. This in particular covers interesting cases where both, labeled and unlabeled data are available.  Experiments in automated indexing and text categorization verify  the advantages of the proposed method.
The committee approach has been proposed for reducing model  uncertainty and improving generalization performance. The advantage of committees depends on (1) the performance of individual members and (2) the correlational structure of errors between  members. This paper presents an input grouping technique for designing a heterogeneous committee. With this technique, all input  variables are first grouped based on their mutual information. Statistically similar variables are assigned to the same group. Each  member's input set is then formed by input variables extracted  from different groups. Our designed committees have less error correlation between its members, since each member observes different  input variable combinations. The individual member's feature sets  contain less redundant information, because highly correlated variables will not be combined together. The member feature sets contain almost complete information, since each set contains a feature  from each information group. An empirical study for a noisy and  nonstationary economic forecasting problem shows that committees constructed by our proposed technique outperform committees  formed using several existing techniques.
We provide preliminary evidence that existing algorithms for  inferring small-scale gene regulation networks from gene  expression data can be adapted to large-scale gene expression data  coming from hybridization microarrays. The essential steps are (1)  clustering many genes by their expression time-course data into a  minimal set of clusters of co-expressed genes, (2) theoretically  modeling the various conditions under which the time-courses are  measured using a continious-time analog recurrent neural network  for the cluster mean time-courses, (3) fitting such a regulatory  model to the cluster mean time courses by simulated annealing  with weight decay, and (4) analysing several such fits for  commonalities in the circuit parameter sets including the  connection matrices. This procedure can be used to assess the  adequacy of existing and future gene expression time-course data  sets for determining transcriptional regulatory relationships such as  coregulation.
Competition in the wireless telecommunications industry is rampant. To maintain profitability, wireless carriers must control churn, the loss of subscribers  who switch from one carder to another. We explore statistical techniques for  chum prediction and, based on these predictions, an optimal policy for identifying customers to whom incentives should be offered to increase retention. Our  experiments are based on a data base of nearly 47,000 U.S. domestic subscribers, and includes information about their usage, billing, credit, application, and  complaint history. We show that under a wide variety of assumptions concerning  the cost of intervention and the retention rate resulting from intervention, chum  prediction and remediation can yield significant savings to a carrier. We also  show the importance of a data representation crafted by domain experts.  Competition in the wireless telecommunications industry is rampant. As many as seven  competing carders operate in each market. The industry is extremely dynamic, with new  services, technologies, and carriers constantly altering the landscape. Carriers announce  new rates and incentives weekly, hoping to entice new subscribers and to lure subscribers  away from the competition. The extent of rivalry is reflected in the deluge of advertisements for wireless service in the daily newspaper and other mass media.  The United States had 69 million wireless subscribers in 1998, roughly 25% of the  population. Some markets are further developed; for example, the subscription rate in Finland is 53%. Industry forecasts are for a U.S. penetration rate of 48% by 2003. Although  there is significant room for growth in most markets, the industry growth rate is declining  and competition is rising. Consequently, it has become crucial for wireless carriers to control churn--the loss of customers who switch from one carrier to another. At present,  domestic monthly chum rates are 2-3% of the customer base. At an average cost of $400  to acquire a subscriber, churn cost the industry nearly $6.3 billion in 1998; the total annual  loss rose to nearly $9.6 billion when lost monthly revenue from subscriber cancellations is  considered (Luna, 1998). It costs roughly five times as much to sign on a new subscriber  as to retain an existing one. Consequently, for a carrier with 1.5 million subscribers, reducing the monthly churn' rate from 2% to 1% would yield an increase in annual earnings of at  least $54 million, and an increase in shareholder value of approximately $150 million.  (Estimates are even higher when lost monthly revenue is considered; see Fowlkes, Madan,  Andrew, & Jensen, 1999; Luna, 1998.)  The goal of our research is to evaluate the benefits of predicting churn using techniques from statistical machine learning. We designed models that predict the probability  936 M. C. Mozer, R. Wolniewicz, D. B. Grimes, E. Johnson and H. Kaushansky  of a subscriber churning within a short time window, and we evaluated how well these predictions could be used for decision making by estimating potential cost savings to the  wireless carrier under a variety of assumptions concerning subscriber behavior.
In hyperspectral imagery one pixel typically consists of a mixture  of the reflectance spectra of several materials, where the mixture  coefficients correspond to the abundances of the constituting materials. We assume linear combinations of reflectance spectra with  some additive normal sensor noise and derive a probabilistic MAP  framework for analyzing hyperspectral data. As the material reflectance characteristics are not know a priori, we face the problem  of unsupervised linear unmixing. The incorporation of different  prior information (e.g. positivity and normalization of the abundances) naturally leads to a family of interesting algorithms, for  example in the noise-free case yielding an algorithm that can be  understood as constrained independent component analysis (ICA).  Simulations underline the usefulness of our theory.
In the analysis of data recorded by optical imaging from intrinsic signals  (measurement of changes of light reflectance from cortical tissue) the removal of noise and artifacts such as blood vessel patterns is a serious  problem. Often bandpass filtering is used, but the underlying assumption  that a spatial frequency exists, which separates the mapping component  from other components (especially the global signal), is questionable.  Here we propose alternative ways of processing optical imaging data, using blind source separation techniques based on the spatial decorrelation  of the data. We first perform benchmarks on artificial data in order to  select the way of processing, which is most robust with respect to sensor noise. We then apply it to recordings of optical imaging experiments  from macaque primary visual cortex. We show that our BSS technique is  able to extract ocular dominance and orientation preference maps from  single condition stacks, for data, where standard post-processing procedures fail. Artifacts, especially blood vessel patterns, can often be  completely removed from the maps. In summary, our method for blind  source separation using extended spatial decorrelation is a superior technique for the analysis of optical recording data.
Recently, a number of authors have proposed treating dialogue systems as Markov  decision processes (MDPs). However, the practical application of MDP algorithms  to dialogue systems faces a number of severe technical challenges. We have built a  general software tool (RLDS, for Reinforcement Learning for Dialogue Systems)  based on the MDP framework, and have applied it to dialogue corpora gathered  from two dialogue systems built at AT&T Labs. Our experiments demonstrate that  RLDS holds promise as a tool for "browsing" and understanding correlations in  complex, temporally dependent dialogue corpora.
We propose a new and efficient technique for incorporating contextual  information into object classification. Most of the current techniques face  the problem of exponential computation cost. In this paper, we propose a  new general framework that incorporates partial context at a linear cost.  This technique is applied to microscopic urinalysis image recognition,  resulting in a significant improvement of recognition rate over the context  free approach. This gain would have been impossible using conventional  context incorporation techniques.
We describe a Bayesian approach to model selection in unsupervised  learning that determines both the feature set and the number of  clusters. We then evaluate this scheme (based on marginal likelihood)  and one based on cross-validated likelihood. For the Bayesian  scheme we derive a closed-form solution of the marginal likelihood  by assuming appropriate forms of the likelihood function and prior.  Extensive experiments compare these approaches and all results are  verified by comparison against ground truth. In these experiments the  Bayesian scheme using our objective function gave better results than  cross-validation.
We formulate the problem of retrieving images from visual databases  as a problem of Bayesian inference. This leads to natural and effective  solutions for two of the most challenging issues in the design of a retrieval  system: providing support for region-based queries without requiring  prior image segmentation, and accounting for user-feedback during a  retrieval session. We present a new learning algorithm that relies on  belief propagation to account for both positive and negative examples of  the user's interests.
Reinforcement learning in nonstationary environments is generally  regarded as an important and yet difficult problem. This paper  partially addresses the problem by formalizing a subclass of nonstationary environments. The environment model, called hidden-mode  Markov decision process (HM-MDP), assumes that environmental  changes are always confined to a small number of hidden modes.  A mode basically indexes a Markov decision process (MDP) and  evolves with time according to a Markov chain. While HM-MDP  is a special case of partially observable Markov decision processes  (POMDP), modeling an HM-MDP environment via the more general POMDP model unnecessarily increases the problem complexity. A variant of the Baum-Welch algorithm is developed for model  learning requiring less data and time.
Many researchers have explored methods for hierarchical reinforcement learning (RL) with temporal abstractions, in which abstract  actions are defined that can perform many primitive actions before  terminating. However, little is known about learning with state abstractions, in which aspects of the state space are ignored. In previous work, we developed the MAXQ method for hierarchical RL. In  this paper, we define five conditions under which state abstraction  can be combined with the MAXQ value function decomposition.  We prove that the MAXQ-Q learning algorithm converges under  these conditions and show experimentally that state abstraction is  important for the successful application of MAXQ-Q learning.
We consider the problem of reliably choosing a near-best strategy from  a restricted class of strategies II in a partially observable Markov decision process (POMDP). We assume we are given the ability to simulate  the POMDP, and study what might be called the sample complexity -that is, the amount of data one must generate in the POMDP in order  to choose a good strategy. We prove upper bounds on the sample complexity showing that, even for infinitely large and arbitrarily complex  POMDPs, the amount of data needed can be finite, and depends only  linearly on the complexity of the restricted strategy class II, and exponentially on the horizon time. This latter dependence can be eased in a  variety of ways, including the application of gradient and local search  algorithms. Our measure of complexity generalizes the classical supervised learning notion of VC dimension to the settings of reinforcement  learning and planning.
We propose and analyze a class of actor-critic algorithms for  simulation-based optimization of a Markov decision process over  a parameterized family of randomized stationary policies. These  are two-time-scale algorithms in which the critic uses TD learning  with a linear approximation architecture and the actor is updated  in an approximate gradient direction based on information provided by the critic. We show that the features for the critic should  span a subspace prescribed by the choice of parameterization of the  actor. We conclude by discussing convergence properties and some  open problems.
We consider the problem of learning a grid-based map using a robot  with noisy sensors and actuators. We compare two approaches:  online EM, where the map is treated as a fixed parameter, and  Bayesian inference, where the map is a (matrix-valued) random  variable. We show that even on a very simple example, online EM  can get stuck in local minima, which causes the robot to get "lost"  and the resulting map to be useless. By contrast, the Bayesian  approach, by maintaining multiple hypotheses, is much more robust. We then introduce a method for approximating the Bayesian  solution, called Rao-Blackwellised particle filtering. We show that  this approximation, when coupled with an active learning strategy,  is fast but accurate.
We propose a new approach to the problem of searching a space of  stochastic controllers for a Markov decision process (MDP) or a partially  observable Markov decision process (POMDP). Following several other  authors, our approach is based on searching in parameterized families  of policies (for example, via gradient descent) to optimize solution quality. However, rather than trying to estimate the values and derivatives  of a policy directly, we do so indirectly using estimates for the probability densities that the policy induces on states at the different points  in time. This enables our algorithms to exploit the many techniques for  efficient and robust approximate density propagation in stochastic systems. We show how our techniques can be applied both to deterministic  propagation schemes (where the MDP's dynamics are given explicitly in  compact form,) and to stochastic propagation schemes (where we have  access only to a generative model, or simulator, of the MDP). We present  empirical results for both of these variants on complex problems.
Model Predictive Control (MPC), a control algorithm which uses  an optimizer to solve for the optimal control moves over a future  time horizon based upon a model of the process, has become a standard control technique in the process industries over the past two  decades. In most industrial applications, a linear dynamic model  developed using empirical data is used even though the process itself is often nonlinear. Linear models have been used because of the  difficulty in developing a generic nonlinear model from empirical  data and the computational expense often involved in using nonlinear models. In this paper, we present a generic neural network  based technique for developing nonlinear dynamic models from empirical data and show that these models can be efficiently used in  a model predictive control framework. This nonlinear MPC based  approach has been successfully implemented in a number of industrial applications in the refining, petrochemical, paper and food  industries. Performance of the controller on a nonlinear industrial  process, a polyethylene reactor, is presented.
The problem of developing good policies for partially observable Markov  decision problems (POMDPs) remains one of the most challenging areas of research in stochastic planning. One line of research in this area  involves the use of reinforcement learning with belief states, probability distributions over the underlying model states. This is a promising method for small problems, but its application is limited by the intractability of computing or representing a full belief state for large problems. Recent work shows that, in many settings, we can maintain an  approximate belief state, which is fairly close to the true belief state. In  particular, great success has been shown with approximate belief states  that marginalize out correlations between state variables. In this paper,  we investigate two methods of full belief state reinforcement learning and  one novel method for reinforcement learning using factored approximate  belief states. We compare the performance of these algorithms on several  well-known problem from the literature. Our results demonstrate the importance of approximate belief state representations for large problems.
The problem that we address in this paper is how a mobile robot can plan in order  to arrive at its goal with minimum uncertainty. Traditional motion planning algorithms often assume that a mobile robot can track its position reliably, however, in real  world situations, reliable localization may not always be feasible. Partially Observable  Markov Decision Processes (POMDPs) provide one way to maximize the certainty of  reaching the goal state, but at the cost of computational intractability for large state  spaces.  The method we propose explicitly models the uncertainty of the robot's position as  a state variable, and generates trajectories through the augmented pose-uncertainty  space. By minimizing the positional uncertainty at the goal, the robot reduces the  likelihood it becomes lost. We demonstrate experimentally that coastal navigation  reduces the uncertainty at the goal, especially with degraded localization.
The problem of reinforcement learning in a non-Markov environment is  explored using a dynamic Bayesian network, where conditional independence assumptions between random variables are compactly represented  by network parameters. The parameters are learned on-line, and approximations are used to perform inference and to compute the optimal value  function. The relative effects of inference and value function approximations on the quality of the final policy are investigated, by learning to  solve a moderately difficult driving task. The two value function approximations, linear and quadratic, were found to perform similarly, but the  quadratic model was more sensitive to initialization. Both performed below the level of human performance on the task. The dynamic Bayesian  network performed comparably to a model using a localist hidden state  representation, while requiring exponentially fewer parameters.
Function approximation is essential to reinforcement learning, but  the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable.  In this paper we explore an alternative approach in which the policy  is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient  of expected reward with respect to the policy parameters. Williams's  REINFORCE method and actor-critic methods are examples of this  approach. Our main new result is to show that the gradient can  be written in a form suitable for estimation from experience aided  by an approximate action-value or advantage function. Using this  result, we prove for the first time that a version of policy iteration  with arbitrary differentiable function approximation is convergent to  a locally optimal policy.  Large applications of reinforcement learning (RL) require the use of generalizing function approximators such neural networks, decision-trees, or instance-based methods.  The dominant approach for the last decade has been the value-function approach, in  which all function approximation effort goes into estimating a value function, with  the action-selection policy represented implicitly as the "greedy" policy with respect  to the estimated values (e.g., as the policy that selects in each state the action with  highest estimated value). The value-function approach has worked well in many applications, but has several limitations. First, it is oriented toward finding deterministic  policies, whereas the optimal policy is often stochastic, selecting different actions with  specific probabilities (e.g., see Singh, Jaakkola, and Jordan, 1994). Second, an arbitrarily small change in the estimated value of an action can cause it to be, or not be,  selected. Such discontinuous changes have been identified as a key obstacle to establishing convergence assurances for algorithms following the value-function approach  (Bertsekas and Tsitsiklis, 1996). For example, Q-learning, Sarsa, and dynamic programming methods have all been shown unable to converge to any policy for simple  MDPs and simple function approximators (Gordon, 1995, 1996; Baird, 1995; Tsitsiklis and van Roy, 1996; Bertsekas and Tsitsiklis, 1996). This can occur even if the  best approximation is found at each step before changing the policy, and whether the  notion of "best" is in the mean-squared-error sense or the slightly different senses of  residual-gradient, temporal-difference, and dynamic-programming methods.  In this paper we explore an alternative approach to function approximation in RL.  1058 R. S. Sutton, D. McAllester, S. Singh and Y. Mansour  Rather than approximating a value function and using that to compute a deterministic policy, we approximate a stochastic policy directly using an independent function  approximator with its own parameters. For example, the policy might be represented  by a neural network whose input is a representation of the state, whose output is  action selection probabilities, and whose weights are the policy parameters. Let 0  denote the vector of policy parameters and p the performance of the corresponding  policy (e.g., the average reward per step). Then, in the policy gradient approach, the  policy parameters are updated approximately proportional to the gradient:  Op  A  a, (1)  where a is a positive-definite step size. If the above can be achieved, then 0 can  usually be assured to converge to a locally optimal policy in the performance measure  p. Unlike the value-function approach, here small changes in 0 can cause only small  changes in the policy and in the state-visitation distribution.  In this paper we prove that an unbiased estimate of the gradient (1) can be obtained  from experience using an approximate value function satisfying certain properties.  Williams's (1988, 1992) REINFORCE algorithm also finds an unbiased estimate of  the gradient, but without the assistance of a learned value function. REINFORCE  learns much more slowly than RL methods using value functions and has received  relatively little attention. Learning a value function and using it to reduce'the variance  of the gradient estimate appears to be essential for rapid learning. Jaakkola, Singh  and Jordan (1995) proved a result very similar to ours for the special case of function  approximation corresponding to tabular POMDPs. Our result strengthens theirs and  generalizes it to arbitrary differentiable function approximators. Konda and Tsitsiklis  (in prep.) independently developed a very simialr result to ours. See also Baxter and  Bartlett (in prep.) and Marbach and Tsitsiklis (1998).  Our result also suggests a way of proving the convergence of a wide variety of algorithms based on "actor-critic" or policy-iteration architectures (e.g., Barto, Sutton,  and Anderson, 1983; Sutton, 1984; Kimura and Kobayashi, 1998). In this paper we  take the first step in this direction by proving for the first time that a version of  policy iteration with general differentiable function approximation is convergent to  a locally optimal policy. Baird and Moore (1999) obtained a weaker but superficially similar result for their VAPS family of methods. Like policy-gradient methods,  VAPS includes separately parameterized policy and value functions updated by gradient methods. However, VAPS methods do not climb the gradient of performance  (expected long-term reward), but of a measure combining performance and valuefunction accuracy. As a result, VAPS does not converge to a locally optimal policy,  except in the case that no weight is put upon value-function accuracy, in which case  VAPS degenerates to REINFORCE. Similarly, Gordon's (1995) fitted value iteration  is also convergent and value-based, but does not find a locally optimal policy.
We present a Monte Carlo algorithm for learning to act in partially observable  Markov decision processes (POMDPs) with real-valued state and action spaces.  Our approach uses importance sampling for representing beliefs, and Monte Carlo  approximation for belief propagation. A reinforcement learning algorithm, value  iteration, is employed to learn value functions over belief states. Finally, a samplebased version of nearest neighbor is used to generalize across states. Initial  empirical results suggest that our approach works well in practical applications.
